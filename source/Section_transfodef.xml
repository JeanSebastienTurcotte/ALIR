<?xml version="1.0" encoding="UTF-8"?>

<!-- Ce fichier constitue une section du livre                              -->
<!--                                                                        -->
<!--      Algèbre linéaire : Intuition et rigueur                           -->
<!--                                                                        -->
<!-- Copyright (C) 2019  Jean-Sébastien Turcotte, Philémon Turcotte         -->
<!-- Licence à venir                                                        -->

<!-- Les sections sont divisées en quatre parties, en plus du titre. Les parties introduction et conclusion sont facultatives. Le texte de ceux-ci apparait respectivement avant et après les sections. Les exercices sont à la fin de la section -->

<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-transfodef">   <!-- Ajouter l'identifiant de la section après le - du xml:id -->
    <title> Les transformations linéaires </title>
    <introduction xml:id= "intro-transfodef">  <!-- Ajouter le même identifiant de la section après le - du xml:id -->
        <p>Aller aux <xref ref="exo-transfodef">exercices</xref> de la section.</p>
    <p>
    Il est commun d'avoir étudié le concept de fonction, <m>y=f(x)</m>, associant à tout nombre réel <m>x</m> un autre nombre réel <m>y</m>. Ces fonctions sont
    souvent représentées graphiquement, comme à la figure suivante.</p>
    <figure xml:id="fig-unefonction">
    <caption>La fonction <m>y=x^2+1</m></caption>
    <image xml:id="sageplot-unefonction">
    <sageplot>
    plot(x^2+1,(x,-5,5))
    </sageplot>
    </image>
    </figure>
    <p> Considérons maintenant la figure suivante dans laquelle un carré a subi une rotation de <m>45^\circ</m>. La transformation qu'a subie le carré est un
    exemple simple de transformation linéaire, où en fait chaque point de <m>\R^2</m> a subi la rotation. On a donc un premier exemple géométrique d'une fonction
    de <m>\R^2</m> vers <m>\R^2</m>.</p>
    <figure xml:id="fig-rot1">
    <caption>Une première transformation</caption>
    <image source="images/rot1" width="80%">
    <description>
    Un carré est illustré à gauche et sa rotation de 45 degrés, à droite.
    </description>
    </image>
    </figure>
    <p>Dans cette section, on définit la notion de transformation linéaire et on regarde les propriétés de ces transformations. On aborde aussi le concept de matrice,
    étroitement lié aux transformations linéaires.</p>
    </introduction>
    
    <!-- Sous-sections à écrire, à même ce fichier -->
    <subsection xml:id="sssec-deftransfo">
    <title>Définition et premiers exemples de transformations linéaires</title>
    <definition xml:id="def-transfo">
    <statement><p>Une fonction vectorielle de <m>\R^n</m> vers <m>\R^m</m> est une fonction <m>T</m> qui prend un vecteur <m>\vec{x}\in \R^n</m> et lui associe un vecteur <m>\vec{y}\in \R^m</m>. On
    écrit alors <m>T(\vec{x})=\vec{y}</m>.</p></statement>
    </definition>
    <example xml:id="ex-transfquelc">
    <title>Des transformations quelconques</title>
    <p> Voici quelques exemples de transformations:</p>
    <list xml:id="liste-transfquelc">
    <title>Des transformations quelconques</title>
    <ol>
    <li><p>La norme d'un vecteur peut être considérée comme une fonction de <m>\R^n</m> vers <m>\R</m>, où <m>T_1(\vec{u})=\sqrt{u_1^2+u_2^2+\cdots +u_n^2}</m>.</p></li>
    <li><p>La fonction <m>T_2(t)=(\cos(t),\sin(t))</m> est une fonction de <m>\R</m> vers <m>\R^2</m>.</p></li>
    <li><p>La fonction <m>T_3(x,y)=(x^2,y-xy)</m> est une fonction de <m>\R^2</m> vers <m>\R^2</m>.</p></li>
    <li xml:id="li-transfolin"><p> La fonction <m>T_4(x,y)=(x-y,x+y)</m> est une fonction de <m>\R^2</m> vers <m>\R^2</m>.</p></li>
    <li><p>La fonction <m>T_5(x,y,z)=(\sin(x),\ln(y),z^2-x,4)</m> est une fonction de <m>\R^3</m> vers <m>\R^4</m>.</p></li>
    <li xml:id="li-translation"><p> La translation de <m>\vec{w}</m>, qui transforme tout vecteur <m>\vec{u}</m> par <m>T_6(\vec{u})=\vec{u}+\vec{w}</m>.</p></li>
    </ol></list>
    </example>
    <p>Une étude exhaustive de toutes les fonctions serait beaucoup trop technique et difficile. On se restreint donc à un type particulier de fonctions, dites linéaires, exception faite pour la transformation <xref ref="li-translation">translation</xref>.
    Pour l'instant, la motivation derrière ce choix sera surtout de nature géométrique. <!-- ToDo: faire un ref sur l'importance des transf lin générale, polynome derivée etc. -->
    Il est assez difficile de représenter une fonction vectorielle, principalement dû à la dimension des vecteurs. Pour illustrer une fonction comme la fonction <m>T_3(x,y)</m>
    de l'exemple <xref ref="ex-transfquelc"/>, il faut deux dimensions pour le domaine et deux pour l'image. On s'en sauve en utilisant deux copies de <m>\R^2</m> comme 
    dans la figure suivante.</p>
    <figure xml:id="fig-transfquelc">
    <caption>La fonction <m>T_3(x,y)=(x^2,y-xy)</m> </caption>
    <sidebyside widths="40% 40%" margins="auto" valign="middle">
    <image source="images/transfquelc1">
    <description>
    Le plan R deux est illustré, avec trois courbes de couleurs différentes
    </description>
    </image>
    <image source="images/transfquelc2">
    <description>
    Le plan R deux est illustré, avec l'image des trois courbes de couleurs différentes
    </description>
    </image>
    </sidebyside>
    </figure>
    <p>Dans la figure, le plan à gauche représente le domaine. Certaines courbes ont été mises en évidence en couleur dans le but d'observer leur image. En réalité, tous les 
    points de <m>\R^2</m> sont transformés. Dans le plan à droite, on retrouve l'image de chacune des courbes.
    </p>
    <p>On constate assez rapidement que la visualisation des fonctions vectorielles peut être difficile. Les exemples de la section <xref provisional="La section un peu plus loin du chapitre 1"/>
    sont des cas particuliers qui sont souvent étudiés à l'aide du calcul vectoriel. 
    </p>
    <p>Quelles sont donc ces transformations dites linéaires? Dans un premier temps, on donne la définition, pour ensuite regarder les conséquences de cette définition, particulièrement au niveau géométrique.</p>
    <definition xml:id="def-transfolin">
    <title>Transformation linéaire</title>
    <statement><p>Une fonction <m>T</m> de <m>\R^n</m> vers <m>\R^m</m> est une transformation linéaire si elle satisfait les deux propriétés suivantes:
    <ol>
    <li xml:id="li-transfosomme"><p><m>T(\vec{u}+\vec{v})=T(\vec{u})+T(\vec{v}) </m> pour tout vecteur <m>\vec{u},\vec{v}\in\R^n</m>.</p></li>
    <li xml:id="li-transfoscal"><p><m>T(c\vec{u})=cT(\vec{u})</m> pour tout vecteur <m>\vec{u}\in\R^n</m> et scalaire <m>c\in\R</m>.</p></li>
    </ol>
    
    </p></statement></definition>
    <p>Avant de regarder les propriétés et les conséquences de cette définition, on illustre un exemple simple de transformation linéaire. La fonction au point <xref ref="li-transfolin"/> de la liste de 
    l'exemple <xref ref="ex-transfquelc"/> est une transformation linéaire (voir <xref ref="ex-transfquelclin"/>) et son effet est illustré dans la figure <xref ref="fig-transfolin1"/>.</p>
    <figure xml:id="fig-transfolin1">
    <caption>La transformation linéaire <m>T(x,y)=(x-y,x+y)</m></caption>
    <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-transfolin1">
        <slate aspect="1:1" source="code/geogebra/transfolin1.ggb"
        surface="geogebra" xml:id="slate-transfolin1">
            setCoordSystem(-8, 8,-8,8,);
          </slate>
        <instructions>
          <p>Le carré bleu représente une figure modifiable en  déplaçant les points. Son image par la transformation est en rouge. </p>
        </instructions>
        </interactive>
    </figure>
    <p>Voici maintenant une série de conséquences et propriétés des transformations linéaires, découlant directement de la définition.</p>
    <proposition xml:id="prop-transfolinprop">
    <title> Propriétés d'une transformation linéaire</title>
    <statement>
    <p>Soit <m>T</m> une transformation linéaire. Alors
    <ol>
    <li><p>L'image du vecteur nul est toujours le vecteur nul, c'est-à-dire <m>T(\vec{0})=\vec{0}</m>.</p></li>
    <li><p>Si les vecteurs <m>\vec{u}</m> et <m>\vec{v}</m> sont parallèles, alors leur image est parallèle, c'est-à-dire si <m>\vec{u}\parallel\vec{v}</m>, alors <m>T(\vec{u})\parallel T(\vec{v})</m>.</p></li>
    <li><p>L'image d'une droite par une transformation linéaire est une droite<fn>Avec la particularité qu'elle pourrait être écrasée en un point. On considère ceci comme un cas limite.</fn>.</p></li>
    </ol>
     Les transformations linéaires sont donc des transformations qui ne déforment pas trop l'espace, en lien avec le dernier point de la liste précédente. D'un point de vue géométrique, on peut voir la pertinence 
     du mot <em>linéaire</em> dans transformation linéaire par le fait que les droites demeurent des droites (comparer avec l'image de la droite dans la figure <xref ref="fig-transfquelc"/>).</p></statement>
     <proof>
     <p><ol>
     <li><p>On peut utiliser soit la propriété <xref ref="li-transfosomme"/> ou la propriété <xref ref="li-transfoscal"/>. On se propose ici d'utiliser la propriété <xref ref="li-transfosomme"/>
     et on laisse l'utilisation de l'autre propriété à explorer dans l'exercice <xref provisional="exercice vecteur 0 par la mult scal"/>.</p>
     <p> Soit <m>\vec{w}=T(\vec{0})</m> l'image du vecteur nul et <m>\vec{u}</m> un vecteur quelconque. Par la propriété <xref ref="li-transfosomme"/>, on a
     <md>
     <mrow>T(\vec{u})&amp;=T(\vec{u}+\vec{0})&amp;&amp; \text{ car } \vec{u}+\vec{0}=\vec{u} </mrow>
     <mrow>&amp;=T(\vec{u})+T(\vec{0})&amp;&amp; \text{ par } <xref ref="li-transfosomme"/>  </mrow>
     <mrow>&amp;=T(\vec{u})+\vec{w}</mrow>
     </md>.
     La dernière équation nous donne <m>T(\vec{u})=T(\vec{u})+\vec{w}</m> et donc, <m>\vec{0}=T(\vec{u})-T(\vec{u})=\vec{w}</m>.
     </p></li>
     <li><p>La seconde propriété est une simple reformulation de la propriété <xref ref="li-transfosomme"/> des transformations linéaires. 
     En effet, soit <m>\vec{v}=c\vec{u}</m> un vecteur parallèle à <m>\vec{u}</m>. Alors
     <md>
     <mrow>T(\vec{v})&amp;=T(c\vec{u})</mrow>
     <mrow>&amp;=cT(\vec{u}) &amp;&amp; \text{ par } <xref ref="li-transfoscal"/> </mrow>
     </md>
     et donc, l'image du vecteur <m>\vec{v}</m> est parallèle à l'image du  vecteur <m>\vec{u}</m>.
     </p></li>
     <li><p>Soit <m>\vecl{OP}=a\vec{u}+\vecl{OA}</m> un plan. On a
     <md>
     <mrow>T(\vecl{OP})&amp;=T(a\vec{u}+\vecl{OA})</mrow>
     <mrow>&amp;=T(a\vec{u})+T(\vecl{OA}) &amp;&amp; \text{ par } <xref ref="li-transfosomme"/> </mrow>
     <mrow>&amp;=aT(\vec{u})+T(\vecl{OA}) &amp;&amp; \text{ par } <xref ref="li-transfoscal"/> </mrow>
     </md>.
     Le cas dégénéré dont il est question dans l'énoncé fait référence au fait qu'il est possible que <m>T(\vec{u})=\vec{0}</m>. Dans ce cas, l'image de la droite est un point.
     </p></li>
     </ol></p>
     </proof>
    </proposition>
    <p>  Les transformations s'appliquent sur des vecteurs, mais comme la distinction entre point et vecteur est volontairement laissée floue, il est utile de faire la remarque suivante.</p>
    <remark xml:id="rem-transfolinpoints">
    <title>Les transformations linéaires et les points</title>
    <p>
   Si <m>A,B</m> sont des points et que <m>\vec{v}=\vecl{AB}</m>, alors on note 
   <me>
   T(\vec{v})=T(\vecl{AB})=\vecl{T(A)T(B)}
   </me>,
   où <m>\vecl{T(A)T(B)}</m> doit être vu comme une forme raccourcie du vecteur <m>T(\vecl{OB})-T(\vecl{OA})</m>.
    </p>
    </remark>
    <p>On regarde maintenant les fonctions de l'exemple <xref ref="ex-transfquelc"/> afin de déterminer lesquelles sont linéaires.</p>
    <example xml:id="ex-transfquelclin">
    <title>Retour sur les transformations quelconques</title>
    <statement>
    <p> On considère les fonctions de la liste <xref ref="liste-transfquelc"/>. On cherche à déterminer lesquelles sont linéaires.</p>
    </statement>
    <solution>
    <p>La norme d'un vecteur n'est pas une transformation linéaire. En effet, l'exercice <xref ref="exo-inegaltriangle"/> montre que souvent, on a<m>\norm{\vec{u}+\vec{v}}\leq\norm{\vec{u}}+\norm{\vec{v}}</m>.
    De plus, on sait que <m>\norm{c\vec{u}}=\abs{c}\norm{\vec{u}}</m>. La transformation n'est donc pas linéaire.
    </p>
    </solution>
    <solution>
    <p>La fonction <m>T_2(t)=(\cos(t),\sin(t))</m> n'est pas linéaire. En effet, il suffit de remarquer que <m>T_2(0)=(1,0)\neq (0,0)</m> et donc, le vecteur nul n'est pas envoyé sur le vecteur nul. Si la transformation avait
    été linéaire, on aurait eu le vecteur nul pour <m>T_2(0)</m>.
    </p>
    </solution>
    <solution>
    <p>Si on essai <m>T_3(0)</m> pour la fonction <m>T_3(x,y)=(x^2,y-xy)</m>, on obtient bel et bien le vecteur <m>(0,0)</m>. Attention toutefois, cela ne signifie pas que la transformation est linéaire.
    L'image du vecteur nul est un moyen rapide de tester si la fonction n'est pas linéaire, mais cela ne donne aucune information si cette image est bel et bien le vecteur nul. On regarde la propriété <xref ref="li-transfoscal"/>
    pour la fonction <m>T_3</m>, mais la propriété <xref ref="li-transfosomme"/> n'est également pas respectée. Soit <m>c\in \R</m> et <m>\vec{v}</m> un vecteur quelconque. On a
    <md>
    <mrow>T_3(c\vec{v})&amp;=T_3(cx,cy)</mrow>
    <mrow>&amp;=((cx)^2,cy-cxcy)</mrow>
    <mrow>&amp;=(c^2x^2,cy-c^2xy)</mrow>
    <mrow>&amp;=(c(cx^2),c(y-cxy))</mrow>
    <mrow>&amp;=c(cx^2,y-cxy)</mrow>
    <mrow>&amp;\neq c T_3(x,y)</mrow>
    </md>.
    </p>
    </solution>
    <solution>
    <p>La fonction <m>T_4(x,y)=(x-y,x+y)</m> est linéaire. En effet, soit <m>\vec{u}=(u_1,u_2)</m> et <m>\vec{v}=(v_1,v_2)</m> des vecteurs de <m>\R^2</m> et soit <m>c\in\R</m> un scalaire. On a
    <md>
   <mrow> T_4(\vec{u}+\vec{v})&amp;=T_4(u_1+v_1,u_2+v_2)</mrow>
   <mrow>&amp;=(u_1+v_1-(u_2+v_2),u_1+v_1+u_2+v_2)</mrow>
   <mrow>&amp;=(u_1+v_1-u_2-v_2,u_1+v_1+u_2+v_2)</mrow>
   <mrow>&amp;=(u_1-u_2+v_1-v_2,u_1+u_2+v_1+v_2)</mrow>
   <mrow>&amp;=(u_1-u_2,u_1+u_2)+(v_1-v_2,v_1+v_2)</mrow>
   <mrow>&amp;=T_4(\vec{u})+T_4(\vec{v})</mrow>
    </md>.
    </p>
    <p>De plus, on a
    <md>
    <mrow>T_4(c\vec{u})&amp;=T_4(cu_1,cu_2)</mrow>
    <mrow>&amp;=(cu_1-cu_2,cu_1+cu_2)</mrow>
    <mrow>&amp;=(c(u_1-u_2),c(u_1+u_2))</mrow>
    <mrow>&amp;=c(u_1-u_2,u_1+u_2)</mrow>
    <mrow>&amp;=cT_4(\vec{u})</mrow>
    </md>.
    Ainsi, la transformation est linéaire.
    </p>
    </solution>
    <solution>
    <p>La transformation  <m>T_5(x,y,z)=(\sin(x),\ln(y),z^2-x,4)</m> n'est pas linéaire. Encore une fois, on voit que le vecteur <m>(0,0,0)</m> n'est pas envoyé sur le vecteur <m>(0,0,0,0)</m>. </p>
    </solution>
    <solution>
    <p>La translation n'est pas une transformation linéaire. En effet, <m>T_6(k\vec{u})=k\vec{u}+\vec{w}\neq k(\vec{u}+\vec{w})=kT_6(\vec{u})</m>.</p>
    </solution>
    </example>
    <insight xml:id="con-satisprop">
    <title>Satisfaire et ne pas satisfaire une définition</title>
    <p>Lorsqu'on doit vérifier si quelque chose satisfait une définition comme la définition <xref ref="def-transfolin"/>, où un certain nombre de propriétés doivent être satisfaites, il est important de comprendre la 
    distinction entre satisfaire la définition et ne pas la satisfaire. Montrer que la définition est satisfaite pour un, deux ou cent cas particuliers n'est jamais suffisant si la définition comprend des mots comme 
    <em>pour tout vecteur</em> ou <em>pour tout nombre.</em> C'est souvent une bonne idée de regarder quelques cas simples afin de se donner une idée, mais jamais suffisant.</p>
     
     <p>Par contre, si le but est de montrer qu'un objet ne satisfait pas une définition contenant des phrases du style <em>pour tout vecteur ou nombre</em>, alors là il est suffisant de trouver un seul cas qui ne satisfait pas à la définition.</p>
     <p>Par exemple, pour montrer que la norme d'un vecteur n'est pas une transformation linéaire, on aurait pu tout simplement prendre les vecteurs <m>\vec{u}=(1,0),\vec{v}=(0,1)</m> et constater que 
     <me>
     \norm{\vec{u}+\vec{v}}=\sqrt{2}
     </me>
     alors que
     <me>
     \norm{\vec{u}}+\norm{\vec{v}}=1+1=2
     </me>.</p>
    </insight>
    <p>Afin de se concentrer sur l'aspect intuitif et de s'appuyer sur la géométrie, on étudie dans un premier temps les transformations linéaires de <m>\R^2</m> vers <m>\R^2</m> et de <m>\R^3</m> vers <m>\R^3</m>.
    Éventuellement, on étudiera les transformations linéaires de <m>\R^n</m> vers <m>\R^m</m> (voir le chapitre <xref ref="sec-transfodimsup"/>).</p>
    <p>Dans l'exemple qui suit, on donne une liste de plusieurs transformations de <m>\R^2</m> vers <m>\R^2</m> qui sont linéaires. On y référera tout au long du chapitre.</p>
    <example xml:id="ex-transfor2">
    <title>Des transformations linéaires du plan : dynamique</title>
    <statement>
    <p>Considérer la liste des transformations suivantes, définies géométriquement et algébriquement:</p>
    <list xml:id="liste-transfor2">
    <title>Des transformations linéaires</title>
    <ol>
    <li xml:id="li-transfor2-I"><p>La transformation <m>I(x,y)=(x,y)</m>, transformation qui laisse chaque vecteur en place. On l'appelle la transformation identité.<fn>Le choix du mot identité deviendra évident une fois qu'on aura 
    introduit la composition de deux transformations linéaires, qui sera une sorte de produit, à la section <xref ref="sec-prodmat"/></fn></p></li>
    <li xml:id="li-transfor2-refx"><p>La réflexion par rapport à l'axe des abscisses, donnée par la transformation <m>S_x(x,y)=(x,-y)</m>.</p></li>
    <li xml:id="li-transfor2-rot90"><p>La rotation de <m>90^\circ</m> ou <m>\frac{\pi}{2}</m> dans le sens antihoraire, donnée par la transformation <m>R_{\frac{\pi}{2}}(x,y)=(-y,x)</m>.</p></li>
    <li xml:id="li-transfor2-Ehr"><p>Un étirement horizontal de facteur <m>r\in\R</m> est une transformation linéaire donnée par <m>Eh_r(x,y)=(rx,y)</m>.</p> <p>De même, un étirement vertical est donné par <m>Ev_r(x,y)=(x,ry)</m>.</p></li>
    <li xml:id="li-transfor2-Evr"><p>Une homothétie est une transformation qui multiplie chaque composante d'un vecteur par un facteur <m>r\in\R</m>. Elle est donnée par la transformation <m>H_r(x,y)=(rx,ry)</m>.</p></li>
    <li xml:id="li-transfor2-P"><p>Une matrice de permutation est une matrice qui change l'ordre des composantes du vecteur. Dans <m>\R^2</m>, la seule transformation qui fait ceci est <m>P(x,y)=(y,x)</m>.  </p></li>
    <li xml:id="li-transfor2-proj"><p>Soit <m>\vec{w}</m> un vecteur non nul. La projection orthogonale sur <m>\vec{w}</m> est une transformation linéaire.</p></li>
    </ol>
    </list>
    <p> Les démonstrations algébriques et géométriques de la linéarité de ces fonctions sont faites ci-dessous.</p>
    </statement>
    <solution>
    <p>Intuitivement, la transformation laisse tout en place. Les propriétés de linéarité devraient donc découler automatiquement des propriétés des opérations sur les vecteurs.</p>
    <p>Algébriquement, la transformation est linéaire, car
    <md>
    <mrow>I(x_1+x_2,y_1+y_2)&amp;=(x_1+x_2,y_1+y_2)</mrow>
    <mrow>&amp;=(x_1,y_1)+(x_2,y_2)</mrow>
    <mrow>&amp;=I(x_1,y_1)+I(x_2,y_2)</mrow>
    </md>.
    De même,
    <me>
    I(cx_1,cy_1)=(cx_1,cy_1)=c(x_1,y_1)=cI(x_1,y_1)
    </me>.
    </p>
    </solution>
    <solution>
        <p> La figure interactive ci-dessous permet de voir la linéarité de la réflexion de manière intuitive.</p>
    <figure xml:id="fig-transfor2ref">
    <caption>La réflexion par rapport à l'axe des abscisses est une transformation linéaire</caption>
    <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-transfor2ref">
        <slate aspect="1:1" source="code/geogebra/transfor2ref.ggb"
        surface="geogebra" xml:id="slate-transfor2ref">
            setCoordSystem(-18, 18,-15,15,);
          </slate>
        <instructions>
          <p>L'interaction permet de manipuler le vecteur <m>\vec{u}</m> et, en cliquant sur les boites, les vecteurs <m>\vec{v}</m> et <m>k\vec{u}</m>. Un clic sur un bouton fera animer la transformation ou reviendra à l'identité, selon le bouton cliqué.</p>
        </instructions>
        </interactive>
    </figure>
    <p>Algébriquement, on a
    <md>
    <mrow>S_x(x_1+x_2,y_1+y_2)&amp;=(x_1+x_2,-(y_1+y_2))</mrow>
    <mrow>&amp;=(x_1+x_2,-y_1-y_2)</mrow>
    <mrow>&amp;=(x_1+x_2,-y_1+(-y_2))</mrow>
    <mrow>&amp;=(x_1,-y_1)+(x_2,-y_2)</mrow>
    <mrow>&amp;=S_x(x_1,y_1)+S_x(x_2,y_2)</mrow>
    </md>
    et 
    <md>
   <mrow> S_x(cx_1,cy_1)&amp;=(cx_1,-cy_1)</mrow>
   <mrow> &amp;=c(x_1,-y_1)</mrow>
   <mrow>&amp;=cS_x(x_1,y_1)</mrow>
    </md>.</p>
    </solution>
    <solution>
    <p> La figure interactive ci-dessous permet de voir la linéarité de la rotation de manière intuititve.</p>
    <figure xml:id="fig-transfor2rot">
    <caption>La rotation de <m>90^\circ</m> dans le sens antihoraire est une transformation linéaire</caption>
    <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-transfor2rot">
        <slate aspect="1:1" source="code/geogebra/transfor2rot.ggb"
        surface="geogebra" xml:id="slate-transfor2rot">
            setCoordSystem(-18, 18,-15,15,);
          </slate>
        <instructions>
          <p>L'interaction permet de manipuler le vecteur <m>\vec{u}</m> et, en cliquant sur les boites, les vecteurs <m>\vec{v}</m> et <m>k\vec{u}</m>. Un clic sur un bouton fera animer la transformation ou reviendra à l'identité, selon le bouton cliqué.</p>
        </instructions>
        </interactive>
    </figure>
    <p>Algébriquement, on a
    <md>
    <mrow>R_{\frac{\pi}{2}}(x_1+x_2,y_1+y_2)&amp;=(-(y_1+y_2),x_1+x_2,)</mrow>
    <mrow>&amp;=(-y_1-y_2,x_1+x_2)</mrow>
    <mrow>&amp;=(-y_1+(-y_2),x_1+x_2,)</mrow>
    <mrow>&amp;=(-y_1,x_1,)+(-y_2,x_2,)</mrow>
    <mrow>&amp;=R_{\frac{\pi}{2}}(x_1,y_1)+R_{\frac{\pi}{2}}(x_2,y_2)</mrow>
    </md>
    et 
    <md>
   <mrow> R_{\frac{\pi}{2}}(cx_1,cy_1)&amp;=(-cy_1,cx_1,)</mrow>
   <mrow> &amp;=c(-y_1,x_1,)</mrow>
   <mrow>&amp;=cR_{\frac{\pi}{2}}(x_1,y_1)</mrow>
    </md>.</p>
    </solution>
    <solution>
    <p> La figure interactive ci-dessous permet de voir la linéarité de l'étirement de manière intuititve.</p>
    <figure xml:id="fig-transfor2Ehr">
    <caption>La rotation de <m>90^\circ</m> dans le sens antihoraire est une transformation linéaire</caption>
    <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-transfor2Ehr">
        <slate aspect="1:1" source="code/geogebra/transfor2Ehr.ggb"
        surface="geogebra" xml:id="slate-transfor2Ehr">
            setCoordSystem(-18, 18,-15,15,);
          </slate>
        <instructions>
          <p>L'interaction permet de manipuler le vecteur <m>\vec{u}</m> et, en cliquant sur les boites, les vecteurs <m>\vec{v}</m> et <m>k\vec{u}</m>. Un clic sur un bouton fera animer la transformation ou reviendra à l'identité, selon le bouton cliqué.</p>
        </instructions>
        </interactive>
    </figure>
    <p>Algébriquement, on a
    <md>
    <mrow>Eh_r(x_1+x_2,y_1+y_2)&amp;=(r(x_1+x_2),y_1+y_2)</mrow>
    <mrow>&amp;=((rx_1+rx_2),y_1+y_2)</mrow>
    <mrow>&amp;=(rx_1,y_1)+(rx_2,y_2)</mrow>
    <mrow>&amp;=Eh_r(x_1,y_1)+Eh_r(x_2,y_2)</mrow>
    </md>
    et 
    <md>
   <mrow> Eh_r(cx_1,cy_1)&amp;=(rcx_1,cy_1)</mrow>
   <mrow> &amp;=c(rx_1,y_1)</mrow>
   <mrow>&amp;=cEh_r(x_1,y_1)</mrow>
    </md>.
    </p>
    </solution>
     <solution>
    <p>La démonstration est faite à l'exercice <xref provisional="homotéthie est linéaire"/></p>
    </solution>
    <solution>
    <p>La figure interactive ci-dessous permet devoir la linéarité de la permutation de composantes de manière intuitive.</p>
    <figure xml:id="fig-transfor2perm">
    <caption>La permutation des composantes d'un vecteur est une transformation linéaire</caption>
    <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-transfor2perm">
        <slate aspect="1:1" source="code/geogebra/transfor2perm.ggb"
        surface="geogebra" xml:id="slate-transfor2perm">
            setCoordSystem(-18, 18,-15,15,);
          </slate>
        <instructions>
          <p>L'interaction permet de manipuler le vecteur <m>\vec{u}</m> et, en cliquant sur les boites, les vecteurs <m>\vec{v}</m> et <m>k\vec{u}</m>. Un clic sur un bouton fera animer la transformation ou reviendra à l'identité, selon le bouton cliqué.</p>
        </instructions>
        </interactive>
    </figure>
    <p>Algébriquement, on a
    <md>
    <mrow>P(x_1+x_2,y_1+y_2)&amp;=(y_1+y_2,x_1+x_2)</mrow>
    <mrow>&amp;=(y_1,x_1)+(y_2,x_2)</mrow>
    <mrow>&amp;=P(x_1,y_1)+P(x_2,y_2)</mrow>
    </md>
    et
    <md>
    <mrow>P(kx_1,ky_1) &amp;=(ky_1,kx_1)</mrow>
    <mrow>&amp;=k(y_1,x_1)</mrow>
    <mrow>&amp;=kP(x_1,y_1)</mrow>
    </md>.
    </p>
    </solution>
    <solution>
    <p>
    On note <m>\text{proj}_{\vec{w}}(\vec{u})</m> la projection orthogonale du vecteur <m>\vec{u}</m> sur le vecteur <m>\vec{w}</m>. Algébriquement, on a
    <md>
    <mrow> \text{proj}_{\vec{w}}(\vec{u}+\vec{v})&amp;=\frac{(\vec{u}+\vec{v})\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w} &amp;&amp; \text{ selon l'équation } <xref ref="eq-projortho"/></mrow>
    <mrow> &amp;=\frac{\vec{u}\cdot \vec{w}+\vec{v}\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w} &amp;&amp; \text{selon la } <xref ref="prop-propprodscal" text="custom">propriété </xref>\text{ de distributivité du produit scalaire}</mrow>
    <mrow>&amp;=\frac{\vec{u}\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w}+\frac{\vec{v}\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w}</mrow>
    <mrow>&amp;=\text{proj}_{\vec{w}}(\vec{u})+\text{proj}_{\vec{w}}(\vec{v})</mrow>
    </md>
    et 
    <md>
    <mrow>\text{proj}_{\vec{w}}(k\vec{u})&amp;=\frac{k\vec{u}\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w} &amp;&amp; \text{ selon l'équation } <xref ref="eq-projortho"/></mrow>
    <mrow>&amp;=k\frac{\vec{u}\cdot \vec{w}}{\vec{w}\cdot \vec{w}}\vec{w} &amp;&amp; \text{ selon la } <xref ref="prop-propprodscal" text="custom">propriété </xref> \text{ du produit scalaire}</mrow>
    <mrow>&amp;=k\text{proj}_{\vec{w}}(\vec{u})</mrow>
   </md>.
    </p>
    </solution>
    </example> 
    <p>Pour conclure cette sous-section, un résultat sur la composition de deux transformations linéaires.</p>
    <theorem xml:id="thm-transfocompo">
    <title>La composition de transformations linéaires</title>
    <statement><p>Soit <m>T_1</m> et <m>T_2</m> des transformations linéaires telles que l'image de <m>T_2</m> est comprise dans le domaine de <m>T_1</m>. Alors la transformation
    <me>
    T_1\circ T_2(\vec{u})=T_1(T_2(\vec{u}))
    </me>
    est une transformation linéaire.
    </p></statement>
    <proof>
    <p>Soit <m>\vec{u},\vec{v}</m> des vecteurs tels que <m>\vec{r}=T_2(\vec{u})</m> et <m>\vec{s}=T_2(\vec{v})</m> et <m>c</m> un scalaire. Alors
    <md>
    <mrow>T_1\circ T_2(\vec{u}+\vec{v})&amp;=T_1(T_2(\vec{u}+\vec{v})) </mrow>
    <mrow>&amp;=T_1(T_2(\vec{u})+T_2(\vec{v})) &amp;&amp; \text{ car } T_2 \text{ est linéaire }</mrow>
    <mrow> &amp;=T_1(\vec{r}+\vec{s})</mrow>
    <mrow>&amp;=T_1(\vec{r})+T_1(\vec{s}) &amp;&amp; \text{ car } T_1 \text{ est linéaire} </mrow>
    <mrow>&amp;=T_1(T_2(\vec{u}))+T_1(T_2(\vec{v}))</mrow>
    <mrow>&amp;=T_1\circ T_2(\vec{u})+T_1\circ T_2(\vec{v})</mrow>
    </md>.
    De même, on a 
    <md>
    <mrow>T_1\circ T_2(c\vec{u})&amp;=T_1(T_2(c\vec{u})) </mrow>
    <mrow>&amp;=T_1(cT_2(\vec{u})) &amp;&amp; \text{ car } T_2 \text{ est linéaire }</mrow>
    <mrow> &amp;=T_1(c\vec{r})</mrow>
    <mrow>&amp;=cT_1(\vec{r}) &amp;&amp; \text{ car } T_1 \text{ est linéaire} </mrow>
    <mrow>&amp;=cT_1(T_2(\vec{u}))</mrow>
    <mrow>&amp;=cT_1\circ T_2(\vec{u})</mrow>
    </md>.
    </p>
    <p>Ainsi, la composition de deux transformations linéaires est linéaire.</p>
    </proof>
    </theorem>
    <p>La composition de transformations est particulièrement intéressante, car elle signifie l'application successive des transformations. Si par exemple un concepteur de jeux vidéos doit faire subir une réflexion et une 
    rotation à un objet, il lui suffit d'appliquer la composition de ces deux transformations. Calculons explicitement la composition de deux transformations.</p>
    <example xml:id="ex-transfocomp">
    <title>
   La composition de deux transformations linéaires
    </title> 
    <statement>
    <p>On considère la transformation linéaire <m>T</m> qui, dans un premier temps effectue la rotation de <m>90^\circ</m> définie au point <xref ref="li-transfor2-rot90"/>
    de la liste <xref ref="liste-transfor2"/>, suivie de la permutation des composantes du vecteur donnée par la transformation du point <xref ref="li-transfor2-P"/>.
    On cherche la fonction <m>T(x,y)=P\circ R_{\frac{\pi}{2}} (x,y)</m>. <!-- Dans un exercice On cherche par la suite la transformation <m>S</m> qui, dans un premier temps permute les composantes du vecteur donné pour ensuite effectuer la 
    rotation de <m>90^{\circ}</m>. -->
    </p>
    </statement>
    <solution>
    <p>Soit <m>(x,y)</m> un vecteur de <m>\R^2</m>. On a
    <md>
    <mrow>T(x,y)&amp;=P\circ R_{\frac{\pi}{2}}(x,y)</mrow>
    <mrow>&amp;=P(R_{\frac{\pi}{2}}(x,y))</mrow>
    <mrow>&amp;=P(-y,x)  &amp;&amp; \text{selon la définition de } R_{\frac{\pi}{2}} \text{ au point } <xref ref="li-transfor2-rot90"/> </mrow>
    <mrow>&amp;=(x,-y)  &amp;&amp; \text{selon la définition de } P\text{ au point } <xref ref="li-transfor2-P"/></mrow>
    </md>.
    La composition des deux transformations est donc une nouvelle transformation <m>T(x,y)=(x,-y)</m>. Concrètement, la transformation  correspond à la réflexion par 
    rapport à l'axe des abcisses, définie au point <xref ref="li-transfor2-refx"/>.
    </p>
    </solution>
    </example>
    <p>On verra prochainement comment calculer plus efficacement les compositions de fonctions, en développant un outil qui sera d'une utilité beaucoup plus grande que 
    les transformations linéaires.</p>
    <p>On termine avec des commandes Sage en lien avec la sous-section.</p>
    <computation xml:id="sageex-deftransfo">
    <title>Les transformations sur Sage</title>
    <p>On verra dans les prochaines sous-sections comment facilement vérifier si une transformation est linéaire ou non et comment l'appliquer efficacement sur un ensemble de points . Pour le moment, on construit sur l'exemple calculatoire <xref ref="sageex-utvec"/> en montrant comment on peut 
    appliquer une translation sur un ensemble de points et illustrer cette translation. Pour cela, on définit un quadrilatère, un vecteur de translation et on applique ce vecteur à chaque point du quadrilatère. Pour être efficace, 
    on utilise la commande <c>list</c>.</p>
    <sage>
    <input>
       #Définition des points du quadrilatère ABCD
       A=vector([0,0])
       B=vector([3,0])
       C=vector([5,4])
       D=vector([2,2])    
       #On forme une liste contenant tous les points (vecteurs)
       L=list([A,B,C,D])
       #On définit le vecteur translation
       w=vector([3,5])
       #On applique la translation à tous les vecteurs de la liste
       Ltrans=list([v+w for v in L])
       #On illustre les quadrilatères, ainsi que le vecteur w sur l'un des points
       polygon(L,color="blue")+polygon(Ltrans,color="red")+plot(w,start=A,color="black")
    </input>
    </sage>
    </computation>
    <!-- Ne fonctionne pas bien pour la multiplication par un scalaire <p>On termine avec des commandes Sage en lien avec la sous-section.
    <computation xml:id="sageex-deftransfo">
    <title>Les transformations linéaires sur Sage</title>
    <p>Il est possible d'utiliser Sage afin de vérifier si une fonction possède les propriétés de la définition <xref ref="def-transfolin"/>. Considérons les fonctions <m>T_1(x,y)=(xy,x+4y)</m>et 
    <m>T_2(x,y)=(3y-x,x+2y)</m>. Alors avec sage, on a
    <sage xml:id="sagecell-deftransfo-1">
    <input>
    var("y,x1,x2,y1,y2,c")
    T1=vector([x*y,x+4*y])
    T2=vector([x*3+y,x+2*y])
    show(T1(x=x1+x2,y=y1+y2)==T1(x=x1,y=y1)+T1(x=x2,y=y2))
    show(T2(x=x1+x2,y=y1+y2)==T2(x=x1,y=y1)+T2(x=x2,y=y2))
    show(T1(x=c*x1,y=c*y1)==c*T1(x=x1,y=y1))
    show(T2(x=c*x1,y=c*y1)==c*T2(x=x1,y=y1))
    </input>
    </sage>
    </p>
    </computation>
    </p>  -->
    </subsection>
    <subsection xml:id="sssec-transfomatrice">
    <title>La forme matricielle d'une transformation linéaire</title>
    <p>Soit  <m>\vec{u}=(x,y)</m> un vecteur de <m>\R^2</m>. Il est toujours possible de décomposer le vecteur <m>\vec{u}</m> comme une combinaison linéaire des vecteurs
    <m>(1,0)</m> et <m>(0,1)</m>, simplement en écrivant
    <men xml:id="eq-decstd">
    (x,y)=(x,0)+(0,y)=x(1,0)+y(0,1)
    </men>.
    En fait, cette décomposition est toujours possible avec <m>(x,y,z)\in \R^3</m>  avec les vecteurs <m>(1,0,0),(0,1,0)</m> et <m>(0,0,1)</m>, car <me>(x,y,z)=x(1,0,0)+y(0,1,0)+z(0,0,1)</me>
    ou même dans <m>\R^n</m> avec <me>\begin{pmatrix}x_1\\x_2 \\ x_3 \\\vdots \\ x_n\end{pmatrix}=x_1\begin{pmatrix}1\\0\\ 0\\ \vdots \\ 0\end{pmatrix}+x_2\begin{pmatrix}0\\1\\ 0\\ \vdots \\ 0\end{pmatrix}+x_n\begin{pmatrix}0\\ \vdots \\ 0 \\ 1\end{pmatrix}</me>.
</p>
<p>Si on considère une transformation linéaire <m>T</m>, et en se concentrant sur <m>\R^2</m> pour le moment, il est possible de voir que l'image d'un vecteur <m>(x,y)</m>
est simplement une combinaison linéaire des images des vecteurs <m>(1,0)</m> et <m>(0,1)</m>, dont les coefficients sont aussi <m>x</m> et <m>y</m>:
<md>
<mrow>T\begin{pmatrix}x\\ y\end{pmatrix}&amp;=T\left(x\begin{pmatrix}1\\ 0\end{pmatrix}+y\begin{pmatrix}0\\ 1\end{pmatrix}\right) &amp;&amp;\text{ selon l'équation } <xref ref="eq-decstd"/></mrow>
<mrow>&amp;= T\left(x\begin{pmatrix}1\\ 0\end{pmatrix}\right)+T\left(y\begin{pmatrix}0\\ 1\end{pmatrix}\right) &amp;&amp;\text{ par la propriété de linéarité } <xref ref="li-transfosomme"/></mrow>
<mrow>&amp;=xT\begin{pmatrix}1\\ 0\end{pmatrix}+yT\begin{pmatrix}0\\ 1\end{pmatrix} &amp;&amp;\text{ par la propriété de linéarité } <xref ref="li-transfoscal"/></mrow>
</md>.
</p>
<p>Posons <m>(a,b)=T(1,0)</m> et <m>(c,d)=T(0,1)</m>, l'image des vecteurs <m>(1,0),(0,1)</m> par la transformation <m>T</m>. On pousse le calcul précédent un peu plus loin, en utilisant la notation verticale des vecteurs:
<md>
<mrow>T(x,y)&amp;=xT(1,0)+yT(0,1)</mrow>
<mrow >&amp;=x(a,b)+y(c,d)</mrow>
<mrow number="yes" xml:id="eq-comblincol">&amp;=x\begin{pmatrix}a\\ b\end{pmatrix}+y\begin{pmatrix}c\\d\end{pmatrix}</mrow>
<mrow>&amp;=\begin{pmatrix}ax\\bx\end{pmatrix}+\begin{pmatrix}cy\\dy\end{pmatrix}</mrow>
<mrow>&amp;=\begin{pmatrix}ax+cy\\bx+dy\end{pmatrix}</mrow>
<mrow>&amp;=\begin{pmatrix}(a,c)\cdot (x,y)\\(b,d)\cdot(x,y)\end{pmatrix}</mrow>
</md>.
En regardant la dernière ligne, on remarque un vecteur dont chaque composante est un produit scalaire, dont l'un des vecteurs est commun, <m>(x,y)</m>. On est tenté ici de
vouloir mettre en évidence ce vecteur, mais un questionnement s'impose.
</p>
<p>Puisque <m>\begin{pmatrix}(a,c)\cdot (x,y)\\(b,d)\cdot(x,y)\end{pmatrix}</m> est un vecteur, dont chaque composante est un produit scalaire de vecteurs, il ne suffit pas
de mettre en évidence le vecteur <m>(x,y)</m> pour avoir <m>\begin{pmatrix}(a,c)\cdot \\(b,d)\cdot\end{pmatrix}(x,y)</m> ou encore <m>\begin{pmatrix}(a,c) \\(b,d)\end{pmatrix}\cdot(x,y)</m>.
Ces deux expressions n'ont pas de sens mathématique. On propose la notation suivante pour la mise en évidence du vecteur <m>(x,y)</m>:
<men xml:id="eq-matvecprod">
\begin{pmatrix}(a,c)\cdot (x,y)\\(b,d)\cdot(x,y)\end{pmatrix}=\begin{pmatrix}a&amp;c \\b&amp;d\end{pmatrix}\vecd{x}{y}
</men>.
</p>
<p>Il convient de rappeler ici que <m>\vecd{a}{b}=T(1,0)</m> et <m>\vecd{c}{d}=T(0,1)</m>, soit l'image par la transformation des vecteurs <m>(1,0)</m> et <m>(0,1)</m>.
L'objet <m>\begin{pmatrix}a&amp;c \\b&amp;d\end{pmatrix}</m> est appelé la matrice de la transformation linéaire <m>T</m>. Ses colonnes sont donc les images des vecteurs <m>(1,0)</m> et <m>(0,1)</m>.
En fait, les colonnes d'une matrice seront très importantes pour la suite des choses. Dans l'équation <xref ref="eq-matvecprod"/>, on définit le vecteur <m>\begin{pmatrix}(a,c)\cdot (x,y)\\(b,d)\cdot(x,y)\end{pmatrix}</m>
comme étant le produit de la matrice <m>\begin{pmatrix}a&amp;c \\b&amp;d\end{pmatrix}</m> et du vecteur <m>\vecd{x}{y}</m>. On peut toutefois voir le produit comme
une combinaison linéaire des colonnes de la matrice, dont les coefficients sont <m>x</m> et <m>y</m>. On peut voir cela en se référant à l'équation <xref ref="eq-comblincol"/> où
les vecteurs ont été écrits en colonne.
</p>
<p>Bien que pour le moment on se concentre sur les transformations linéaires dans <m>\R^2</m>, on définit quand même de manière plus précise la notion de matrice quelconque.</p>
<definition xml:id="def-matrice">
<title>Une matrice</title>
<statement><p>Une matrice est un ensemble de <m>m*n</m> nombres agencés dans un tableau de <m>m</m> lignes et <m>n</m> colonnes. Si <m>A</m> est une matrice, on dénote par
<m>a_{i\, j}</m> l'élément situé à la ligne <m>i</m> et à la colonne <m>j</m>, de sorte que
<men xml:id="eq-matindice">
A=\begin{pmatrix}
a_{1\, 1}&amp;a_{1\, 2}&amp;\cdots &amp; a_{1\, n}\\
a_{2\, 1}&amp;a_{2\, 2}&amp;\cdots &amp; a_{2\, n}\\
\vdots  &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m\, 1}&amp;a_{m\, 2}&amp;\cdots &amp; a_{m\, n}\\
\end{pmatrix}
</men >.
</p>
<p>Soit <m>\vec{c}_1,\vec{c}_2,\ldots, \vec{c}_n</m> des vecteurs de <m>\R^m</m>. On note parfois la matrice dont les colonnes sont formées des vecteurs 
<m>\vec{c}_1,\vec{c}_2,\ldots, \vec{c}_n</m> comme étant la matrice
<men xml:id="eq-matcol">
A=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}
</men>.

De même, si <m>\vec{r}_1,\vec{r}_2,\ldots, \vec{r}_m</m> sont des vecteurs de <m>\R^n</m>, on note la matrice dont les lignes sont formées des vecteurs 
<m>\vec{r}_1,\vec{r}_2,\ldots, \vec{r}_m</m> comme étant  
<me>
\begin{pmatrix}
    \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_1 &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} \\
    \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_2 &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} \\
    \vdots &amp; \vdots &amp; \vdots \\
     \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_m &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} 
\end{pmatrix}
</me>.</p>
<p>Cette dernière façon d'écrire une matrice permet d'écrire la généralisation de l'équation <xref ref="eq-matvecprod"/> ainsi:
<men xml:id="eq-matvecprodgeneral">A\vec{u}=\begin{pmatrix}
    \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_1 &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} \\
    \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_2 &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} \\
    \vdots &amp; \vdots &amp; \vdots \\
     \rule[.5ex]{2.5ex}{0.5pt}\hspace{-0.2cm} &amp; \vec{r}_m &amp;\hspace{-0.2cm} \rule[.5ex]{2.5ex}{0.5pt} 
\end{pmatrix}\vec{u}=\begin{pmatrix}
    \vec{r}_1\cdot\vec{u} \\
    \vec{r}_2\cdot\vec{u} \\
    \vdots \\
     \vec{r}_m\cdot\vec{u} 
\end{pmatrix}</men></p>
<p>L'ensemble de toutes les matrices de <m>m</m> lignes et <m>n</m> colonnes est noté <m>\mathcal{M}_{m\times n}</m>. Si <m>m=n</m>, la matrice est dite carrée et l'ensemble des matrices carrées de dimension <m>n</m>, aussi
dites d'ordre <m>n</m>, est simplement noté <m>\mathcal{M}_n</m>.</p></statement>
</definition>
<aside>
<title>En passant</title>
<p>Tout comme pour les vecteurs, la notation avec les crochets est aussi utilisée pour représenter les matrices. On aurait alors <m>A=\begin{bmatrix}
a_{1\, 1}&amp;a_{1\, 2}&amp;\cdots &amp; a_{1\, n}\\
a_{2\, 1}&amp;a_{2\, 2}&amp;\cdots &amp; a_{2\, n}\\
\vdots  &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m\, 1}&amp;a_{m\, 2}&amp;\cdots &amp; a_{m\, n}\\
\end{bmatrix}</m>.</p>
</aside>
<p>La représentation d'une matrice par ses colonnes, comme à l'équation <xref ref="eq-matcol"/>, est particulièrement utile pour interpréter l'application d'une transformation linéaire à un vecteur, représentée dans ce cas par
le produit matrice vecteur. En généralisant l'approche qui a mené à l'équation <xref ref="eq-comblincol"/>, si <m>\vec{u}=(u_1,u_2,\ldots, u_n)</m> et <m>A=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}</m>, alors on a
<men xml:id="eq-matvecprodgen">
A\vec{u}=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\begin{pmatrix}u_1\\ u_2\\ \vdots\\ u_n \end{pmatrix}=u_1\vec{c}_1+u_2\vec{c}_2+\cdots +u_n\vec{c}_n
</men>.
L'équation <xref ref="eq-matvecprodgen"/> est par le fait même une définition du produit d'une matrice de <m>n</m> colonnes par un vecteur de <m>\R^n</m> d'un point de vue purement algébrique. L'ordre de ces facteurs est important,
on verra dans la sous-section <xref provisional="sous-sec produit de matrice ou autre sur les lignes, à voir"/> que l'équation <m>\vec{u}A</m> ne signifie pas nécessairement la même chose, et ne serait définie ici que si <m>m=n</m>.
</p>
<p>À titre d'exemple, on détermine la matrice pour chacune des transformations linéaires de la liste <xref ref="liste-transfor2"/>.</p>
<example xml:id="ex-mattransfor2">
<title>Les matrices de certaines transformations linéaires du plan </title>
<statement><p>Pour chaque transformation linéaire de la liste <xref ref="liste-transfor2"/>, on cherche à déterminer la matrice qui la représente.</p></statement>
<solution>
<p>La transformation identité laisse les vecteurs en place. Cela signifie donc que <m>I(1,0)=\vecd{1}{0}</m> et <m>I(0,1)=\vecd{0}{1}</m>. La matrice est donc
<men xml:id="eq-id2x2">
I=\begin{pmatrix}
1&amp;0\\
0&amp;1
\end{pmatrix}
</men>.</p>
</solution>
<solution>
<p>Dans une réflexion par rapport à l'axe des abscisses, la première coordonnée reste la même et la seconde change de signe. On a donc <m>S_x(1,0)=\vecd{1}{0}</m> et
<m>S_x(0,1)=\vecd{0}{-1}</m>. La matrice est donc
<men xml:id="eq-refx">
S_x=\begin{pmatrix}
1&amp;0\\
0&amp;-1
\end{pmatrix}
</men>.</p>
</solution>
<solution>
<p>La rotation de <m>\frac{\pi}{2}</m> dans le sens antihoraire est donnée par la transformation <m>R_{\frac{\pi}{2}}(x,y)=(-y,x)</m>. On a donc
<m>R_{\frac{\pi}{2}}(1,0)=\vecd{0}{1}</m> et <m>R_{\frac{\pi}{2}}(0,1)=\vecd{-1}{0}</m>. La matrice est donc
<me>
R_{\frac{\pi}{2}}=\begin{pmatrix}
0&amp;-1\\
1&amp;0
\end{pmatrix}
</me>.
</p>
</solution>
<solution>
<p>Un étirement horizontal de facteur <m>r</m> est une transformation linéaire telle que <m>Eh_r(1,0)=\vecd{r}{0}</m> et <m>Eh_r(0,1)=\vecd{0}{1}</m>. La matrice est donc
<men xml:id="eq-etirementhr2">
Eh_r=\begin{pmatrix}
r&amp;0\\
0&amp;1
\end{pmatrix}
</men>. De même, un étirement vertical de facteur <m>r</m> est représenté par la matrice
<men xml:id="eq-etirementvr2">
Ev_r=\begin{pmatrix}
1&amp;0\\
0&amp;r
\end{pmatrix}
</men>.
</p>
</solution>
<solution>
<p>L'homothétie de facteur <m>r</m> est une transformation représentant simultanément un étirement horizontal et un étirement vertical. La matrice est donc
<men xml:id="eq-homotr2">
H_r=\begin{pmatrix}
r&amp;0\\
0&amp;r
\end{pmatrix}
</men>.
</p>
</solution>
<solution>
<p>La permutation est une transformation linéaire qui change l'ordre des composantes d'un vecteur. Dans <m>\R^2</m>, ceci revient à <m>P(1,0)=\vecd{0}{1}</m> et <m>P(0,1)=\vecd{1}{0}</m>.
La matrice est donc
<me>
P=\begin{pmatrix}
0&amp;1\\
1&amp;0
\end{pmatrix}
</me>.
</p>
</solution>
<solution>
<p>La projection orthogonale sur un vecteur non nul <m>\vec{w}</m> est une transformation linéaire. Soit <m>\text{proj}_{\vec{w}}(\vec{u})</m> cette transformation.
Si <m>\vec{v}</m> est un vecteur quelconque, on peut calculer la
projection orthogonale de <m>\vec{v}</m> sur <m>\vec{w}</m> à l'aide de l'équation <xref ref="eq-projortho"/> (en remplaçant <m>\vec{u}</m> par <m>\vec{w}</m>). On trouve 
<md>
<mrow>
\text{proj}_\vec{w}(1,0)&amp;=\frac{w_1}{\norm{\vec{w}}^2}\vec{w}
</mrow>
<mrow>&amp;\frac{1}{\norm{\vec{w}}^2}\vecd{w_1^2}{w_1w_2}</mrow>
</md>
et
<md>
<mrow>
\text{proj}_\vec{w}(0,1)&amp;=\frac{w_2}{\norm{\vec{w}}^2}\vec{w}
</mrow>
<mrow>&amp;\frac{1}{\norm{\vec{w}}^2}\vecd{w_1w_2}{w_2^2}</mrow>
</md>.
La matrice est donc
<me>
\text{proj}_{\vec{w}}=\frac{1}{\norm{\vec{w}}^2}\begin{pmatrix}
w_1^2&amp; w_1w_2\\
w_1w_2&amp; w_2^2
\end{pmatrix}
</me>.
Cette matrice est plus compliquée que les précédentes, mais la section <xref ref="sec-matinverse"/> donnera une autre manière de déterminer la matrice d'une projection
orthogonale, sans avoir à se rappeler de la matrice ci-dessus.
</p>
</solution>
</example>
<remark xml:id="rem-multscalmat">
<p>Dans l'exemple précédent, pour obtenir la matrice de la projection orthogonale, on a écrit <m>\frac{1}{\norm{\vec{w}}^2}\begin{pmatrix}
w_1^2&amp; w_1w_2\\
w_1w_2&amp; w_2^2
\end{pmatrix}</m>, soit une matrice avec un scalaire devant. On comprend ici que pour toute matrice <m>A</m> et scalaire <m>r</m>, le terme <m>rA</m> est une 
matrice dont les entrées sont multipliées par <m>r</m>. Pour le cas <m>2</m> par <m>2</m>, on a 
<me>
r\begin{pmatrix}a&amp;c \\b&amp;d\end{pmatrix}=\begin{pmatrix}ra&amp;rc \\ rb&amp;rd\end{pmatrix}
</me>.</p>
</remark>
<p>
La démarche qui a mené à la forme matricielle d'une transformation linéaire de <m>\R^2</m> vers <m>\R^2</m> se généralise facilement pour montrer que toute transformation linéaire de <m>\R^n</m> vers
<m>\R^m</m> possède une forme matricielle. À titre d'exemple, regardons une transformation de <m>\R^3</m> vers <m>\R^2</m>.</p>
<example>
<title>Une transformation de l'espace vers le plan</title>
<statement><p>Soit <m>T(x,y,z)=(x+y,x-z)</m> une transformation. On montre que <m>T</m> est linéaire et on détermine la matrice représentant la transformation.</p></statement>
<solution>
<p>Dans un premier temps, la linéarité de <m>T</m>. Soit <m>\vec{u}=(x_1,y_1,z_1),\vec{v}=(x_2,y_2,z_2)</m> des vecteurs de <m>\R^3</m> et <m>c\in\R</m> un scalaire. On a
<md>
<mrow>T(\vec{u}+\vec{v})&amp;=T(x_1+x_2,y_1+y_2,z_1+z_2)</mrow>
<mrow>&amp;=(x_1+x_2+y_1+y_2,x_1+x_2-(z_1+z_2))</mrow>
<mrow>&amp;=(x_1+y_1+x_2+y_2,x_1-z_1+x_2-z_2)</mrow>
<mrow>&amp;=(x_1+y_1,x_1-z_1)+(x_2+y_2,x_2-z_2)</mrow>
<mrow>&amp;=T(\vec{u})+T(\vec{v})</mrow>
</md>
et 
<md>
<mrow>T(c\vec{u})&amp;=T(cx_1,cy_1,cz_1)</mrow>
<mrow>&amp;=(cx_1+cy_1,cx_1-cz_1)</mrow>
<mrow>&amp;=(c(x_1+y_1),c(x_1-z_1))</mrow>
<mrow>&amp;=c(x_1+y_1,x_1-z_1)</mrow>
<mrow>&amp;=cT(\vec{u})</mrow>
</md>.
La transformation est donc linéaire. </p>

<p>Pour trouver la matrice, on doit déterminer l'image des vecteurs <m>(1,0,0),(0,1,0)</m> et <m>(0,0,1)</m>. Ces images sont
<md>
<mrow>T(1,0,0)&amp;=(1,1)</mrow>
<mrow>T(0,1,0)&amp;=(1,0)</mrow>
<mrow>T(0,0,1)&amp;=(0,-1)</mrow>
</md>.
La matrice est alors
<me>
T=\begin{pmatrix}
1&amp;1&amp;0 \\
1&amp; 0&amp;-1
\end{pmatrix}
</me>.</p>
</solution>
</example>
<p>Toute transformation linéaire <m>T</m> possède une forme matricielle la représentant. Est-ce que pour toute matrice on a également une transformation linéaire? En partant de la définition du produit d'une matrice par un vecteur,
à l'équation <xref ref="eq-matvecprodgen"/>, on peut montrer que c'est le cas.</p>
<proposition xml:id="prop-matsonttransfos">
<title>Les matrices sont des transformations linéaires</title>
<statement>
<p>Soit <m>A</m> une matrice possédant <m>m</m> lignes et <m>n</m> colonnes. Si on considère la transformation <m>T(\vec{u})=A\vec{u}</m>, alors <m>T</m> est une transformation linéaire de <m>\R^n</m> vers <m>\R^m</m>. </p>
</statement>
<proof>
<p>Soit <m>\vec{u},\vec{v}\in \R^n</m> et <m>r\in\R</m>. Posons <m>\vec{c}_1,\vec{c}_2,\ldots , \vec{c}_n</m> les colonnes de <m>A</m>. Alors on a
<md>
<mrow>T(\vec{u}+\vec{v})&amp;=A(\vec{u}+\vec{v})</mrow>
<mrow>&amp;=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\left(\begin{pmatrix}u_1\\ u_2\\ \vdots\\ u_n \end{pmatrix} +\begin{pmatrix}v_1\\ v_2\\ \vdots\\ v_n \end{pmatrix}\right)</mrow>
<mrow>&amp;=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\begin{pmatrix}u_1+v_1\\ u_2+v_2\\ \vdots\\ u_n+v_n \end{pmatrix}</mrow>
<mrow>&amp;=(u_1+v_1)\vec{c}_1+(u_2+v_2)\vec{c}_2+\cdots +(u_n+v_n)\vec{c}_n &amp;\text{selon l'équation }&amp;  <xref ref="eq-matvecprodgen"/></mrow>
<mrow>&amp;=u_1\vec{c}_1+v_1\vec{c}_1+u_2\vec{c}_2+v_2\vec{c}_2+\cdots +u_n\vec{c}_n+v_n\vec{c}_n</mrow>
<mrow>&amp;=u_1\vec{c}_1+u_2\vec{c}_2+\cdots+u_n\vec{c}_n+v_1\vec{c}_1+v_2\vec{c}_2+\cdots +v_n\vec{c}_n</mrow>
<mrow>&amp;=A\vec{u}+A\vec{v} &amp;\text{selon l'équation } &amp; <xref ref="eq-matvecprodgen"/></mrow>
<mrow>&amp;=T(\vec{u})+T(\vec{v})</mrow>
</md>
et 
<md>
<mrow>T(r\vec{u})&amp;=A(r\vec{u})</mrow>
<mrow>&amp;=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\begin{pmatrix}ru_1\\ ru_2\\ \vdots\\ ru_n \end{pmatrix}</mrow>
<mrow>&amp;=ru_1\vec{c}_1+ru_2\vec{c}_2+\cdots +ru_n\vec{c}_n &amp;&amp; \text{selon l'équation } <xref ref="eq-matvecprodgen"/></mrow>
<mrow>&amp;=r(u_1\vec{c}_1+u_2\vec{c}_2+\cdots +u_n\vec{c}_n)</mrow>
<mrow>&amp;=rA\vec{u} &amp;&amp; \text{selon l'équation } <xref ref="eq-matvecprodgen"/></mrow>
<mrow>&amp;=rT(\vec{u})</mrow>
</md>.
Toute matrice correspond donc à une transformation linéaire.
</p>
</proof>
</proposition>
<p>Cette proposition donne une autre option pour vérifier si une transformation est linéaire. Étant donnée <m>T</m> une transformation quelconque, on peut calculer l'image des vecteurs <m>(1,0,\ldots ,0),(0,1,0,\ldots, 0),\ldots , (0,\ldots ,0 ,1)</m>,
 les mettre dans une matrice, et vérifier que cette matrice correspond à la transformation <m>T</m>. Si c'est le cas, <m>T</m> est linéaire, sinon elle ne l'est pas<fn>Techniquement, il faudrait s'assurer que la représentation
 par une matrice d'une transformation linéaire est unique. Pour cela, voir l'exercice <xref ref="exo-reptransfomatunique"/>.</fn>.</p>
 <example xml:id="ex-transfomatrice">
 <title>Les transformations et les matrices</title>
 <statement>
 <p>Considérons les transformations <m>T_1(x,y,z)=(x+2,y-z,x)</m> et <m>T_2(x,y)=(y-x,2x+y)</m>. On souhaite vérifier si ces transformations sont linéaires à l'aide d'une représentation matricielle.</p>
 </statement>
 <solution>
 <p>On considère les vecteurs <m>\vec{c}_1=T_1(1,0,0)=(3,0,1), \vec{c}_2=T_1(0,1,0)=(2,1,0)</m> et <m>\vec{c}_3=T_1(0,0,1)=(2,-1,0)</m>. Si <m>T_1</m> est linéaire, alors elle devrait correspondre à la transformation
 représentée par la matrice 
 <me>
 A_1=\begin{pmatrix}
\lvert &amp; \lvert  &amp; \lvert \\
\vec{c}_1 &amp; \vec{c}_2 &amp; \vec{c}_3 \\
\lvert &amp; \lvert &amp; \lvert
\end{pmatrix}=\begin{pmatrix}  
3&amp;2&amp;2\\
0&amp;1&amp;-1\\
1&amp;0&amp;0
\end{pmatrix}
 </me>.
 Cependant, on a
 <md>
 <mrow>
 A_1\vecddd{x}{y}{z}&amp;=\begin{pmatrix}  
3&amp;2&amp;2\\
0&amp;1&amp;-1\\
1&amp;0&amp;0
\end{pmatrix}\vecddd{x}{y}{z}
 </mrow>
 <mrow>
 &amp;=x\vecddd{3}{0}{1}+y\vecddd{2}{1}{0}+z\vecddd{2}{-1}{0}
 </mrow>
 <mrow>&amp;=\vecddd{3x+2y+2z}{y-z}{x}</mrow>
 <mrow>&amp;\neq \vecddd{x+2}{y-z}{x} </mrow>
 </md>.
 La transformation n'est donc pas linéaire.
 </p>
 </solution>
 <solution>
 <p>On considère les vecteurs <m>\vec{d_1}=T_2(1,0)=(-1,2)</m> et <m>\vec{d_2}=T_2(0,1)=(1,1)</m>.Si <m>T_2</m> est linéaire, alors elle devrait correspondre à la transformation
 représentée par la matrice 
 <me>
 A_2=\begin{pmatrix}
\lvert &amp; \lvert   \\
\vec{d}_1 &amp; \vec{d}_2  \\
\lvert &amp; \lvert 
\end{pmatrix}=\begin{pmatrix}  
-1&amp;1\\
2&amp;1\\
\end{pmatrix}
 </me>. En effet, on a
 <md>
 <mrow>A_2\vecd{x}{y}&amp;=\begin{pmatrix}  
-1&amp;1\\
2&amp;1\\
\end{pmatrix}\vecd{x}{y}</mrow>
<mrow>&amp;=x\vecd{-1}{2}+y\vecd{1}{1}</mrow>
<mrow>&amp;=\vecd{-x+y}{2x+y}</mrow>
<mrow>&amp;=\vecd{y-x}{2x+y}</mrow>
 </md>.
 Ainsi, la transformation est linéaire.</p>
 </solution>
 </example>
 <remark xml:id="rem-equitransfmat">
 <title>L'équivalence entre une transformation linéaire et une matrice</title>
 <p>La proposition <xref ref="prop-matsonttransfos"/> affirme qu'il y a une équivalence entre transformation linéaire et matrice. Pour cette raison, on utilisera souvent la lettre <m>T</m> pour désigner à la fois
 la transformation ou sa matrice associée.</p>
 </remark>
 <p> Dans l'exemple <xref ref="ex-transfomatrice"/>, on a entre autre déterminé la matrice d'une rotation de <m>90^{\circ}</m> autour de l'origine. On s'intéresse maintenant
 au cas plus général d'une rotation d'angle <m>\theta</m> autour de l'origine.</p>
 <example xml:id="ex-rotr2">
 <title>Rotation autour de l'origine dans le plan: dynamique</title>
 <statement>
 <p>Considérons un angle <m>\theta</m>. On souhaite déterminer la matrice <m>R_{\theta}</m> correspondant à la rotation d'un angle <m>\theta</m>, mesuré dans le sens anti horaire.
 La figure interactive suivante permet d'explorer cette rotation avec les vecteurs <m>(1,0)</m> et <m>(0,1)</m>.</p>
 <figure xml:id="fig-rotr2">
 <caption> La rotation dans le plan</caption>
 <interactive aspect="1:1" platform="geogebra" width="100%"
      xml:id="geog-rotr2">
        <slate aspect="1:1" source="code/geogebra/rotr2.ggb"
        surface="geogebra" xml:id="slate-rotr2">
            setCoordSystem(-1.5, 1.5,-1.5,1.5,);
          </slate>
        <instructions>
          <p>L'interaction permet de manipuler l'angle <m>\theta</m> et de voir la transformation des vecteurs <m>(1,0)</m> et <m>(0,1)</m>. Un clic sur la boite
          permet de faire afficher les coordonnées horizontale et verticale du vecteur <m>T(1,0)</m> en fonction de <m>\theta</m>.</p>
        </instructions>
        </interactive>
 </figure>
 </statement>
 <solution>
 <p>Puisqu'on cherche la matrice, il suffit de déterminer l'image des vecteurs <m>(1,0)</m> et <m>(0,1)</m> par la rotation. Comme ces vecteurs sont séparés par un angle
 de <m>90^{\circ}</m> et que la rotation de <m>\theta</m> ne changera pas ceci, on peut seulement trouver l'image de <m>(1,0)</m> et déterminer l'image de <m>(0,1)</m> en
 prenant le vecteur perpendiculaire à l'image de <m>(1,0)</m>. Selon la figure <xref ref="fig-rotr2"/>, l'image du vecteur <m>(1,0)</m> est
 <m>R_{\theta}(1,0)=(\cos(\theta),\sin(\theta))</m> et donc, <m>R_{\theta}(0,1)=(-\sin(\theta),\cos(\theta))</m>. On a alors
 <men xml:id="eq-rotr2">
 R_{\theta}=\begin{pmatrix}
 \cos(\theta) &amp; -\sin(\theta)\\
 \sin(\theta) &amp; \cos(\theta)
 \end{pmatrix}
 </men>.
 </p>
 </solution>
 </example>
<p>
On termine avec des commandes Sage en lien avec la sous-section.</p>
<computation xml:id="sageex-transfomat">
<title>Les matrices avec Sage</title>
<p>Il est possible de définir des matrices dans Sage avec la commande <c>matrix</c>. À noter toutefois que Sage a une préférence pour les lignes plutôt que les colonnes, et que si on veut
définir la matrice selon ses colonnes, on doit utiliser la commande <c>column_matrix</c>.</p>
<sage>
<input>
u=vector([1,3])
v=vector([2,5])
A=matrix([u,v])
B=column_matrix([u,v])
show('A=',A)
show('B=',B)
</input>
</sage>
<p>Il n'est pas nécessaire de définir au préalable les vecteurs. C'est par contre pratique dans le contexte des transformations linéaires où l'on définit les matrices en fonction des images des vecteurs
<m>(1,0,\ldots,0),(0,1,0,\ldots , 0),\ldots (0,\ldots, 0,1)</m>. Si on choisit de ne pas mettre des vecteurs, il faut procéder avec une paire de crochets contenant les lignes ou colonnes, chacune elle-même
dans une paire de crochet.</p>
<sage>
<input>
A=matrix([[1,3],[2,5]])
B=column_matrix([[1,3],[2,5]])
show('A=',A)
show('B=',B)
</input>
</sage>
<p>
On peut accéder aux différentes entrées d'une matrice à l'aide de la commande <c>A[i][j]</c>, qui retourne l'entrée sur la ligne <m>i+1</m> et la colonne <m>j+1</m>. (Il convient de rappeler ici <xref provisional="Les entrées commencent à 0"/>.)</p>
<sage>
<input>
show('A[0][0]=',A[0][0])
show('A[1][0]=',A[1][0])
show('A[0][1]=',A[0][1])
show('A[1][1]=',A[1][1])
</input>
</sage>
<p>Si on omet une paire de crochets, par exemple <m>A[i]</m> alors Sage retourne un vecteur contenant ligne <m>i+1</m>. Il est également possible d'obtenir cette ligne avec 
la commande <c>A.row(i)</c>. Pour obtenir la colonne <m>j+1</m>, on devra utiliser la commande <c>A.column(j)</c>.</p>
<sage>
<input>
show('A=',A)
show('A[0]=',A[0])
show('La deuxième ligne de A est ', A.row(1))
show('La première colonne de A est ', A.column(0))
</input>
</sage>
<p>Avec une matrice et un vecteur, il est possible de faire la multiplication matrice vecteur, telle que définie à l'équation <xref ref="eq-matvecprodgen" />, en autant que les dimensions soient compatibles.
La deuxième cellule ci-dessous produit volontairement une erreur, car le vecteur ne peut être multiplié par la matrice <m>A</m>.</p>
<sage>
<input>
#Calcul direct de la multiplication
show(A*u)
#calcul "manuel" en prenant les combinaisons linéaires des colonnes de A
show(u[0]*A.column(0)+u[1]*A.column(1))
</input>
</sage>
<sage>
<input>
#calcul en utilisant l'opération *
w=vector([1,3,-1])
show('Aw='A*w)
</input>
</sage>
<p>On peut définir une matrice dont tous les éléments sont nuls rapidement en utilisant la commande <c>matrix(m,n,0)</c>. On aura alors une matrice <m>m\times n</m> remplie de <m>0</m>.</p>
<sage>
<input>
Z=matrix(3,5,0)
show(Z)
</input>
</sage>
<p>Pour une matrice donnée, on peut déterminer la transformation linéaire associée en multipliant par le vecteur <m>(x_1,x_2,\ldots , x_n)</m> approprié.</p>
<sage>
<input>
var("x,y")
show('T(x,y)=', A*vector([x,y]))
</input>
</sage>
<p>On peut aussi tracer graphiquement un graphique et sa transformation, à l'aide des commandes <c>plot</c>.</p>
<sage>
<input>
plot(u,color="blue")+plot(A*u,color="red")
</input>
</sage>
</computation>
    </subsection>
    <subsection xml:id="sssec-opmat">
    <title> L'addition matricielle et la multiplication par un scalaire</title>
    <p>L'exercice <xref ref="exo-sommetransfo"/> montre que la somme de deux transformations linéaires est aussi une transformation linéaire. Géométriquement, on peut le voir comme si, étant donné deux transformations linéaires
     différentes <m>T_1,T_2</m>, ayant le même domaine et la même image, et un vecteur <m>\vec{u}</m>, la transformation <m>(T_1+T_2)(\vec{u})=T_1(\vec{u})+T_2(\vec{u})</m> correspond à la somme des transformations sur <m>\vec{u}</m>. En ce sens, l'addition de deux transformations
     correspond à une addition vectorielle dans l'espace image de la transformation. Si cette somme est une transformation linéaire, elle doit donc avoir une forme matricielle.</p>
     <p>
     Soit <m>A\in \mathcal{M}_{m\times n}</m> la matrice de <m>T_1</m> et <m>\vec{a}_i</m> les colonnes de <m>A</m> et <m>B\in \mathcal{M}_{m\times n}</m> la matrice de <m>T_2</m> et <m>\vec{b}_i</m> les colonnes de <m>B</m>. Alors on a
     <md>
     <mrow>T_1(\vec{u})+T_2(\vec{u})&amp;=A\vec{u}+B\vec{u}</mrow>
     <mrow>&amp;=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{a}_1 &amp; \vec{a}_2 &amp; \cdots &amp; \vec{a}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\begin{pmatrix}u_1\\ u_2\\ \vdots\\ u_n \end{pmatrix}+
\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{b}_1 &amp; \vec{b}_2 &amp; \cdots &amp; \vec{b}_n \\
\lvert &amp; \lvert &amp; \cdots &amp;r
\end{pmatrix}\begin{pmatrix}u_1\\ u_2\\ \vdots\\ u_n \end{pmatrix}</mrow>
     <mrow>&amp;=u_1\vec{a}_1  + u_2\vec{a}_2  + \cdots + u_n\vec{a}_n +u_1\vec{b}_1  + u_2\vec{b}_2  + \cdots + u_n\vec{b}_n </mrow>
     <mrow>&amp;=u_1\vec{a}_1 +u_1\vec{b}_1 + u_2\vec{a}_2  + u_2\vec{b}_2+ \cdots + u_n\vec{a}_n  +u_n\vec{b}_n </mrow>
     <mrow>&amp;=u_1(\vec{a}_1+\vec{b}_1)  + u_2(\vec{a}_2+\vec{b}_2)  + \cdots + u_n(\vec{a}_n+\vec{b}_n) </mrow>
     <mrow>&amp;=\begin{pmatrix}
\lvert &amp; \lvert &amp; \cdots &amp; \lvert \\
\vec{a}_1+\vec{b}_1 &amp; \vec{a}_2+\vec{b}_2 &amp; \cdots &amp; \vec{a}_n+\vec{b}_n \\
\lvert &amp; \lvert &amp; \cdots &amp; \lvert
\end{pmatrix}\begin{pmatrix}u_1\\ u_2\\ \vdots\\ u_n \end{pmatrix}</mrow>
     </md>.
     La matrice de la somme est donc une matrice composée de la somme des colonnes des matrices <m>A</m> et <m>B</m>. L'exercice <xref ref="exo-matsommelignes"/> montre que cela est équivalent à dire que la matrice <m>A+B</m> est
     obtenue en prenant la somme des lignes des matrices <m>A</m> et <m>B</m> et donc qu'au final, on additionne chaque entrée correspondante. On arrive ainsi à la définition suivante.
     </p>
     <definition xml:id="def-matsomme">
     <statement><p>Soit <m>A,B\in\mathcal{M}_{m\times n}</m> deux matrices. On définit la somme de <m>A</m> et <m>B</m> comme étant la matrice telle que
     <me>
     (A+B)_{i,j}=(a_{i,j}+b_{i,j})
     </me>.</p></statement>
     </definition>
     <example xml:id="ex-matsomme">
     <title>Somme de matrices</title>
     <statement><p>Soit <m>A=\begin{pmatrix}1&amp;-3&amp;2\\ -2&amp; 1 &amp;0 \end{pmatrix},B=\begin{pmatrix}5&amp;-2&amp;1\\ 0&amp; 2 &amp;7 \end{pmatrix}</m> et <m>C=\begin{pmatrix} 1&amp;1\\ -1&amp; 2 \end{pmatrix}</m>. On calcule, si possible
     , les sommes <m>A+B</m> et <m>A+C</m>.</p></statement>
     <solution>
     <p>Puisque <m>A</m> et <m>B</m> ont les mêmes dimensions, il est possible de les additionner. Selon l'explication ci-dessus, on obtient
     <md>
     <mrow>
     A+B&amp;=\begin{pmatrix}1&amp;-3&amp;2\\ -2&amp; 1 &amp;0 \end{pmatrix}+\begin{pmatrix}5&amp;-2&amp;1\\ 0&amp; 2 &amp;7 \end{pmatrix}
     </mrow>
     <mrow>&amp;=\begin{pmatrix}1+5&amp;-3-2&amp;2+1\\ -2+0&amp; 1+2 &amp;0+7 \end{pmatrix}</mrow>
     <mrow>&amp;=\begin{pmatrix}6&amp;-5&amp;3\\ -2&amp; 3 &amp;7 \end{pmatrix}</mrow>
     </md>.
     Comme la matrice <m>C</m> est de taille différente de <m>A</m>, l'addition n'est pas possible.
     </p>
     </solution>
     </example>
     <p>Si on multiplie une transformation par un scalaire, c'est encore une transformation linéaire, puisque c'est en fait une <xref ref="li-transfoscal">propriété</xref>  définissant les transformations linéaires. Une démarche similaire
     à celle en début de sous-section permet d'arriver à la définition algébrique suivante.</p>
     <definition xml:id="def-matprodscal">
     <title>
     Multiplication d'une matrice par un scalaire
     </title>
     <statement><p>Soit <m>A\in \mathcal{m\times n}</m> et <m>k\in \R</m>. La matrice <m>kA</m> est définie comme étant la matrice telle que 
     <me>
     (kA)_{i,j}=(ka_{i,j})
     </me>.
     </p></statement>
     </definition>
     <p>Cette définition a déjà été mentionnée de manière intuitive à la remarque <xref ref="rem-multscalmat"/>.</p>
     <example xml:id="ex-matprodscal">
     <title>Multiplication d'une matrice par un scalaire </title>
     <statement><p>Soit <m>A=\begin{pmatrix}1&amp;-3&amp;2\\ -2&amp; 1 &amp;0 \end{pmatrix}</m> et <m>C=\begin{pmatrix} 1&amp;1\\ -1&amp; 2 \end{pmatrix}</m>. On calcule <m>3A</m> et <m>-2C</m>.</p></statement>
     <solution>
     <p>Selon la définition, on a
     <md>
     <mrow>
     3A&amp;=\begin{pmatrix}3*1&amp;3*(-3)&amp;3*2\\ 3*(-2)&amp; 3*1 &amp;3*0 \end{pmatrix}
     </mrow>
     <mrow>&amp;=\begin{pmatrix}3&amp;-9&amp;6\\ -6&amp; 3 &amp;0 \end{pmatrix}</mrow>
     </md>.
     Pour la matrice <m>C</m>, on a <m>-2C=\begin{pmatrix} -2&amp;-2\\ 2&amp; -4 \end{pmatrix}</m>.
     </p>
     </solution>
     </example>
     <p>L'addition matricielle et la multiplication par un scalaire possèdent un ensemble de propriétés familières à l'addition et à la multiplication régulière, ainsi qu'à ces mêmes
     opérations sur les vecteurs. En fait, dans l'exercice <xref ref="exo-propvec2"/>, ces propriétés ont été démontrées pour les vecteurs. L'exercice <xref ref="exo-propopmat"/> fera
     la même chose pour les propriétés, qui sont données ci-dessous à titre de référence.</p>
     <proposition xml:id="prop-opmat">
     <title>Les propriétés de l'addition matricielle et de la multiplication par un scalaire </title>
    <statement> <p>Soit <m>A,B,C\in \mathcal{M}_{m\times n}</m> et <m>r,s\in \R</m>. Les propriétés suivantes sont toujours vraies:</p>
     <list xml:id="li-opmat">
        <title>Propriétés de l'addition matricielle et de la multiplication d'une matrice par un scalaire</title>
     <ol>
                    <li><m>A+B=B+A</m> (commutativité de l'addition matricielle)</li>
                    <li><m>A+(B+C)=(A+B)+C</m> (associativité de l'addition matricielle)</li>
                    <li><m>A+O=A</m> (neutre additif)</li>
                    <li><m>A+(-A)=O</m> (inverse additif)</li>
                    <li><m>(rs)A=r(sA)</m> (associativité de la multiplication par un scalaire)</li>
                    <li><m>r(A+B)=rA+rB</m> (distributivité sur l'addition matricielle)</li>
                    <li><m>(r+s)A=rA+sA</m> (distributivité de l'addition des scalaires)</li>
                    <li><m>1A=A</m> (neutre multiplicatif)</li>
                </ol></list>
 </statement>
     </proposition>
     <p>On termine avec des commandes Sage en lien avec la sous-section.</p>
     <computation xml:id="sageex-opmat">
     <title>Les opérations matricielles sur Sage</title>
     <p>Il est aussi facile d'additionner deux matrices et d'en multiplier une par un scalaire que de faire ces mêmes opérations pour un vecteur. </p>
     <sage>
     <input>
A=column_matrix([[1,2],[3,-1]])
B=column_matrix([[4,-1],[-1,2]])
show("A+B=",A+B)
show("3A=",3*A)
show("2A-5B=",2*A-5*B)     
     </input>
     </sage>
     </computation>
    </subsection>
    <conclusion xml:id="concl-transfodef">  <!-- Ajouter le même identifiant de la section après le - du xml:id -->
    <p>Les points importants de cette section sont:
    <ul>
    <li><p> Les <xref ref="def-transfolin">propriétés</xref> définissant une transformation linéaire.</p></li>
    <li><p> Le produit d'une matrice avec un vecteur, défini à l'équation <xref ref="eq-matvecprodgen"/>.</p></li>
    <li><p> Le fait que dans une matrice, les colonnes représentent l'image des vecteurs  <m>(1,0,\ldots ,0),(0,1,0,\ldots, 0),\ldots , (0,\ldots ,0 ,1)</m>.</p></li>
    <li><p> L'équivalence entre une matrice et une transformation linéaire.</p></li>
    <li><p> La forme matricielle d'une <xref ref="eq-rotr2"> rotation </xref> dans <m>\R^2</m>.</p></li>
    <li><p> L'addition matricielle et la multiplication d'une matrice par un scalaire.</p></li>
    </ul> 
    De plus avec Sage, on peut définir une matrice avec la commande <c>matrix</c>. Par défaut, Sage définit les matrices selon les lignes. La commande <c>column_matrix()</c> permet
    de le faire selon les colonnes. Lorsque compatible, on peut multiplier une matrice par un vecteur avec l'opération <c>*</c>. On peut accéder aux lignes et colonnes d'une matrice <m>A</m> avec les commandes
    <c>A.row(i)</c> et <c>A.column(j)</c>. L'addition de deux matrices se fait avec l'opération <c>+</c> et la multiplication par un scalaire avec l'opération <c>*</c>.
    </p>
    </conclusion>
   <xi:include href="Exercices_transfodef.xml" />
</section>
