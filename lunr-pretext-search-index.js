var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "colophon-1",
  "level": "1",
  "url": "colophon-1.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " Première édition   https:\/\/alir-jsturcotte.profweb.ca\/  https:\/\/alir-jsturcotte.profweb.ca\/alir.html   copyright   Pour citer ce document :  Turcotte, J-S. (2023). Algèbre linéaire : Intuition et rigueur. Cégep Gérald-Godin. Sous licence CC BY-SA 4.0    Page couverture :  La page couverture est une Œuvre du photographe Viktor Hanacek intitulée Railway in The Fog . Elle provient du site Picjumbo et est rendue disponible gratuitement par l'auteur.   "
},
{
  "id": "dedication-1",
  "level": "1",
  "url": "dedication-1.html",
  "type": "Dédicace",
  "number": "",
  "title": "Dédicace",
  "body": " Pour tous les élèves  "
},
{
  "id": "acknowledgement-1",
  "level": "1",
  "url": "acknowledgement-1.html",
  "type": "Remerciements",
  "number": "",
  "title": "Remerciements",
  "body": " Remerciements    L'essentiel de l'écriture de ce projet s'est réalisé en deux phases. Une première, à l'automne 2019, où les quatre premiers chapitres furent rédigés. Quelques ajouts ici et là ont été faits durant les deux années suivantes, mais c'est en 2022 2023 que la seconde vraie phase a eu lieu.  Dans un premier temps, je remercie la direction du Cégep Gérald-Godin, qui a permis de financer la première partie de ce projet par le biais du plan numérique en éducation. Un merci particulier à mes collègues du département de mathématiques, qui ont accepté que j'accapare la totalité du financement qui nous était alloué.  Ensuite, un grand merci à l'organisme la fabrique REL qui a financé la deuxième phase. En particulier, merci à Marianne Dubé, de m'avoir fait connaitre l'organisme. Notre rencontre en janvier 2022 m'aura permis de trouver le véhicule idéal pour terminer et diffuser mon projet. Merci également à Claude Potvin, pour son soutien tout au long de cette aventure. Localement, merci à ma spécialiste en moyens et techniques d'enseignement, Sandra Lenneville, qui a, un peu en même temps que moi, découvert et apprivoisé l'univers des ressources libres.  Un immense merci à Sylvain Pelletier, conseiller pédagogique et enseignant en français, langue et littérature, qui a assuré de main de maitre la révision linguistique de ce projet et qui dut, bien malgré lui, replonger dans les mathématiques de son parcours collégial! Malgré des relectures, une utilisation en classe par près de 300 élèves, il restait immanquablement de nombreuses erreurs, certaine que j'aurais dû attraper, mais certaines autres que seul l'œil d'un expert pouvait voir. Merci pour ton dévouement à la chose et pour tes précieux conseils.  Merci à Philémon, qui a, durant la première phase, rédigé une bonne partie des solutions aux exercices. Merci de me conseiller, de me pousser (et parfois de me retenir) dans mes idées, d'avoir accepté de tout chambouler et de m'avoir fait confiance.  Merci aux étudiants et étudiantes de la session d'automne 2020, qui ont eu à tester un produit imparfait, incomplet, et qui ont su s'adapter à une session entièrement en ligne, apprivoisant par le fait même une nouvelle façon de faire. Vos commentaires ont été les bienvenus.  Merci à Rob Beezer, pour PreTeXt , la machinerie qui permet de produire les différentes formes que peut prendre ce manuel. Merci pour ta patience et tes réponses aux nombreuses questions. Merci également aux autres développeurs et contributeurs, notamment David Farmer, Steven Clontz, Oscar Levin, Sean Fitzpatrick, Alex Jordan et tous les autres membres actifs du groupe d'aide Google .  Finalement, un merci à l'avance à tous ceux et celles, élèves autant qu'enseignantes et enseignants, qui utiliseront ce manuel et qui, je l'espère, contribueront à l'améliorer et à le bonifier.    Logo de l'organisme la fabriqueREL    Logo du cégep Gérald-Godin    "
},
{
  "id": "preface",
  "level": "1",
  "url": "preface.html",
  "type": "Préface",
  "number": "",
  "title": "Préface",
  "body": " Préface  Quand j'ai su que j'allais donner le cours Algèbre linéaire et géométrie vectorielle pour la première fois, j'ai tout de suite pensé au cours que j'avais moi-même suivi une dizaine d'années auparavant. Je voulais offrir quelque chose de différent à mes élèves, loin des manipulations algébriques sans intérêt ne servant qu'à couvrir un contenu prescrit. À l'université, mes cours d'algèbre ont été, la plupart du temps, très théoriques et très peu de liens étaient faits avec les applications ou la géométrie. Pour quelqu'un qui s'intéresse aux mathématiques pour la richesse que cela apporte, ça ne pose pas problème, mais pour une personne pour qui le cours n'est qu'un passage obligé, il me semblait important de l'intéresser avec davantage de concret.  Tout a commencé par l'idée de relier les deux parties du contenu du cours. Je voulais établir une continuité entre matrices, vecteurs, droites et plans. Dans la majorité des cours et des manuels disponibles, les matrices deviennent un outil servant à résoudre des problèmes portant sur les droites et les plans. On énonce une panoplie de termes et de résultats sur les matrices sans en motiver la provenance ou l'utilité. Le déterminant d'une matrice? Un nombre qui lui est associé, mais sans plus. L'inverse? C'est utile pour résoudre des problèmes (alors qu'en réalité, ce n'est pas la méthode la plus efficace). Je n'ose même pas parler des notions de transposée, matrice symétrique ou orthogonale qui sont parfois présentées comme de simples propriétés algébriques sans applications.  Comment faire en sorte que ce passage entre matrice et géométrie vectorielle se fasse naturellement? La réponse se trouve dans les transformations linéaires. Elles sont mormalement reléguées dans un court chapitre voire une seule section sur les applications. En faisant des transformations linéaires le concept central du manuel, tous ces liens entre matrices et géométrie vectorielle se font aisément, en toute fluidité. L'utilisation des matrices comme un outil dans la résolution de problèmes demeure un concept important, mais ce n'est pas au cœur de ce manuel. De même, je considère que beaucoup des manipulations algébriques qui sont normalement effectuées dans ce cours, et qui le rendent selon moi terne et inintéressant, sont inutiles et ne rendent pas justice à toute la richesse du contenu qu'est l'algèbre linéaire. Les calculs et manipulations sont réservés presque entièrement aux matrices de petite taille et le logiciel libre Sage est utilisé pour le reste. Également, ceci a pour avantage de faire en sorte qu'il est possible de considérer des exemples beaucoup plus intéressants et des situations réelles, plutôt que des versions simplifiées de ces problèmes.  C'est donc avec l'intention de ne pas reproduire ce qui se faisait déjà, de proposer une nouvelle approche, que j'ai entrepris l'écriture de ce manuel. On dit parfois qu'une image vaut mille mots. Soit, mais en mathématique, cela signifie parfois aussi qu'une image vaut mille maux, si cette image tente de représenter un concept difficile ou si elle n'est pas bien construite et que l'on n’arrive pas à y voir la plus-value. La technologie permet maintenant de créer des images et des animations qui sont dynamiques ou interactives, permettant de les manipuler pour en changer l'orientation et la perspective. C'est particulièrement utile pour des situations dans l'espace à trois dimensions et cela permet de diminuer la difficulté de visualiser de la 3D sur une page ou un écran à deux dimensions. Dans sa version web, le manuel comprend aussi des cellules Sage qui servent à effectuer des calculs fastidieux qui déconcentrent de l'objectif principal du problème. Ces cellules permettent également d'introduire de petites notions de programmation qu'il est de plus en plus utile de connaitre dans toutes les branches de la science.  L'approche intuition et rigueur tente de plaire aux deux côtés de ma personnalité. D'un sens, je suis d'avis que derrière de nombreux résultats en apparence difficiles à démontrer se cache une explication plus simple, intuitive, mais qui tourne peut-être certains coins ronds. Pour plusieurs, cette explication est plus que suffisante et le gain obtenu en creusant pour aller comprendre la subtilité des détails est plus faible que le cout cognitif associé à l'entreprise de cette démarche. Dans l'autre sens, pour ceux et celles qui, comme moi, sont d'une nature à vouloir tout comprendre, l'explication intuitive les laisse sur leur faim. J'ai donc inclus dans le corps principal du texte la très grande majorité des démonstrations aux résultats. Quelques exceptions, principalement dans le chapitre , sont dues au fait que ces résultats utilisent des notions qui ne sont pas à proprement parler de l'algèbre linéaire. J'ai aussi pris la décision de fournir la totalité des réponses et solutions aux exercices du texte. Dans cette période où une simple recherche sur internet permet, par la multitude de sites (quora, stack.exchange, chegg, etc.) destinés à fournir des réponses aux questions d'étudiants, d'obtenir des réponses à ces exercices, les cacher me semblait futile. D'autant plus que certaines des solutions proposées par ces sites sont parfois erronées, quelquefois de manière subtile. Sans prétendre que mes solutions sont dépourvues d'erreurs, je peux au moins en prendre l'entière responsabilité.  C'est en forgeant que l'on devient forgeron comme dit l'adage! C'est tout aussi vrai en mathématiques, où il est nécessaire de faire beaucoup d'exercices pour maitriser la matière. Les exercices de bas niveau, souvent plus calculatoires, sont peu nombreux dans cet ouvrage, mais demeurent importants, dans une certaine mesure. J'ai fait le choix d'en inclure moins qu'ailleurs pour laisser plus de place aux exercices portant sur les concepts, les applications et les liens entre la matière. De nombreuses plateformes, comme WeBWorK , existent pour retrouver les exercices plus simples. Le manuel comporte tout de même plus de exercices, des indices pour certains ainsi que les réponses ou les solutions pour tous.   Un mot sur l'écriture des nombres  En français, la convention pour écrire un nombre décimal est d'utiliser la virgule pour séparer la partie entière de la partie fractionnaire. Par exemple, le nombre s'écrit normalement selon la notation française. De plus, les espaces sont souvent utilisés pour faciliter la lecture des grands nombres. Ainsi, le nombre dix-huit-mille-sept-cent-vingt-trois s'écrirait . Dans le cas de la notation anglaise, c'est plutôt le point qui est utilisé pour séparer la partie entière de la partie décimale et la virgule sert à séparer les grands nombres. Dans ce texte, j'ai choisi d'utiliser le point comme séparateur décimal. La principale raison est que cela assure une cohérence avec le logiciel Sage, puisque celui-ci fonctionne selon la notation anglaise.   J'espère que tout un chacun pourra trouver son compte dans ce manuel, offert gratuitement. Que vous soyez un de mes élèves, un élève d'un ou d'une collègue ou même d'une autre école, un enseignant ou une enseignante d'un autre établissement ou simplement un passionné ou une passionnée des mathématiques, j'ai espoir qu'au moins une partie de ce texte vous sera utile. Je serais heureux de recevoir tout commentaire, suggestion, correction, idée ou collaboration potentielle pour améliorer le contenu ou le bonifier.   Jean-Sébastien Turcotte  Cégep Gérald-Godin, 2023   "
},
{
  "id": "messageeleve",
  "level": "1",
  "url": "messageeleve.html",
  "type": "Préface",
  "number": "",
  "title": "Un message pour l’élève",
  "body": " Un message pour l'élève  Malgré le fait que le parcourt actuel comprenne deux cours de calcul différentiel et intégral obligatoire et un seul d'algèbre linéaire, je suis de ceux qui crois que l'avenir appartient à ceux qui maitrisent les notions de ce dernier. Le calcul traite principale de fonctions et de phénomènes continus, mais en réalité, beaucoup d'applications mathématiques portent sur le discret. C'est davantage vrai avec l'utilisation des ordinateurs, qui simulent pratiquement tout ce qui est continu par du discret. Si vous vous dirigez vers une carrière scientifique, les chances que vous aurez à étudier ou travailler avec des systèmes comprenant un grand nombre de composantes sont grandes. Connaitre les outils disponibles pour analyser ces systèmes vous donnera une longueur d'avance et cela permettra peut-être de vous démarquer. À présent, voici quelques conseils pour vous aider à suivre ce manuel.   Comment lire le manuel  Vous êtes sans doute habitué à lire un livre de la première à la dernière page. C'est très bien pour les romans et autres œuvre du genre, mais pour un manuel de mathématiques, ce n'est pas la bonne méthode. Vous allez sans doute vouloir retourner en arrière à plusieurs reprises, relire des paragraphes, revoir des exemples et il n'y a aucun problème à cela, c'est la chose chose à faire! Tout sujet mathématique vient avec son langage et les mathématiques elles-mêmes sont en soi un langage. Il faut se familiariser avec plusieurs nouveaux termes et revoir fréquemment les définitions. Ce manuel existe en version web et en version PDF. Par contre, pour bénéficier de toutes les fonctionnalités, il est recommander de l'utiliser dans sa version web autant que possible. Lisez la partie qui suit afin de voir tous ses bénéfices et de les utiliser à bon escient.    Note sur la programmation  À plusieurs endroits, le logiciel Sage est utilisé pour effectuer des calculs et pour offrir un approfondissement qui serait impossible sans lui. Pour ce qui est de son utilisation à l'intérieur des sections, la majorité des commandes utilisées sont simples et n'importe qui devrait être en mesure de les comprendre et de les réutiliser. Par contre, certains des exercices Sage se trouvant à la fin de chaque section suppose une connaissance plus avancée de la programmation et de Sage. Pour une première lecture, une personne moins familière avec la programmation peut facilement ne pas considérer ces exercices sans avoir peur de manquer quelque chose d'important. Pour ceux et celles qui sont à l'aise de programmer et qui aiment les défis, ces exercices offrent un bon aperçu de l'utilisation de l'informatique pour résoudre des problèmes mathématiques. N'étant moi-même pas programmeur, je ne prétends pas que les solutions que je propose sont les meilleures. Toutefois, je pense qu'elles offrent un équilibre entre la compréhension et l'efficacité.    À propos des exercices  Ce texte contient beaucoup d'exercices, trop diront certains. Les réponses et solutions à tous ces exercices se trouvent dans le texte et sont disponibles immédiatement. Ne tombez pas dans le piège de lire la solution et de penser comprendre. Je suis persuadé que les sportifs et sportives parmi vous ne se contente pas de regarder leur sport favori en espérant devenir meilleur ou que les plus créatifs et créatives passent leur journée à regarder dessins, images, films ou à écouter de la musique, sans eux-mêmes prendre le crayon, l'appareil photo ou un instrument de musique quelconque. Je suis aussi certain que, la majorité de ses activités, de nombreux échecs surviennent avant de connaitre du succès. Comparez les difficultés que vous rencontrerez lors de la résolution d'un exercice, les mauvaises réponses et les autres embûches à une passe ratée au hockey, à une photographie mal cadrée ou à une fausse note. Toutes ces erreurs font partie de l'apprentissage et il n'en n'est pas différent pour vos études. Pour en revenir aux solutions, elles sont disponibles, mais elles sont cachées (pour la version web) dans un lien qui s'ouvre suite à un clic. Résister à l'envie de cliquer ce lien sans avoir au moins essayé quelque chose. Face à une impasse, relisez la question et tentez de cerner quel(s) concept(s) de la section ou des précédentes peut(vent) être utile(s). Faites ressortir une liste de faits que vous pouvez dire à propos des objets donnés dans l'énoncé du problème. Comme il est mentionné plus haut, allez revoir les exemples similaires dans la section et voyez si vous ne pouvez pas y trouver une piste. N'ayez pas peur de vous tromper. Il est d'ailleurs très probable que j'aie fait des erreurs dans le texte, je serais heureux de vous voir les corriger!   Finalement, ce manuel est encore et sera probablement toujours en construction. N'hésitez pas à me communiquer vos commentaires, positifs ou négatifs, ainsi que vos suggestions pour améliorer le contenu du texte. Le livre a été écrit, d'abord et avant tout, pour vous. J'espère qu'il sera à la hauteur de vos attentes et saura vous apprendre ce sujet passionnant qu'est l'algèbre linéaire.  "
},
{
  "id": "utilisation",
  "level": "1",
  "url": "utilisation.html",
  "type": "Préface",
  "number": "",
  "title": "Comment utiliser les fonctionnalités de ce manuel",
  "body": " Comment utiliser les fonctionnalités de ce manuel  Dans sa version web, ce manuel contient plusieurs ajouts qui facilitent l'apprentissage et bonifient la lecture. En voici quelques-uns:   Les liens knowl  L'une des principales fonctionnalités de la version web est la référence knowl . Un knowl est un lien cliquable vers une partie du texte représentant une équation, un exemple, une proposition, un exercice, etc. Ces liens, en bleu et soulignés par de subtils pointillés, ouvrent un cadre à l'intérieur de la fenêtre dévoilant le contenu. Lorsque le knowl est une référence à un contenu, plutôt que le contenu en soi, il est possible de cliquer sur contexte afin de se rendre à l'endroit dans le texte où pointe le lien. Les images ci-dessous montrent un knowl et l'effet après un clic.    Une capture d'écran d'une courte partie du texte principale, dans lequel on peut voir un knowl qui pointe vers l'équation un point un point treize.    Une capture d'écran d'une courte partie du texte principale, dans lequel on peut voir un knowl ouvert qui pointe vers l'équation un point un point treize Cette équation apparait dans un encadré sous le knowl.    Une capture d'écran d'une courte partie du texte principale, dans lequel on peut voir l'équation un point un point treize en surbrillance, suite au clic sur le knowl.    L'avantage principal d'un knowl est que, après un clic sur un lien, la page reste en place et le contenu s'ouvre à même l'endroit où le lien se trouve. Il y a quelques exceptions à cette règle, d'abord lorsque le lien pointe vers un chapitre ou une section entière. Dans ce cas, le lien mène au début du chapitre ou de la section.  Dans la version PDF, les knowls sont remplacés par des hyperliens traditionnels. Un clic renvoie à l'endroit du texte où se trouve la référence. Dans certains lecteurs PDF, on peut revenir à l'endroit précédent en appuyant simplement sur les touches alt + . Ce n'est pas un knowl , mais c'est mieux que de se perdre dans le texte.    Figures interactives  Le texte contient une multitude de figures interactives, la plupart créées à l'aide du logiciel Geogebra . Près de chaque figure interactive se trouve un knowl contenant les instructions pour manipuler la figure. Le texte entourant la figure est aussi accompagné d'explications.  Dans la version PDF, un code QR renvoie à une page web contenant la figure interactive.    Cellules Sage  Au travers du texte, on retrouve à plusieurs endroits des cellules Sage comme celle-ci:   Parfois vide, parfois avec du contenu, il est possible d'exécuter le code s'y trouvant en cliquant sur Évaluer (Sage) . Les cellules d'une même page, exception faite de celles qui sont à l'intérieur d'un knowl , gardent en mémoire le résultat des cellules exécutées avant, jusqu'au rafraichissement de la page. Si une cellule cause un message d'erreur, il est possible qu'il soit nécessaire d'exécuter une cellule précédente. Normalement, seules les cellules rapprochées ont une dépendance.  Lorsque la cellule possède du contenu, on devrait retrouver, dans la version PDF, un aperçu du résultat produit lors de l'exécution de la cellule.    Recherche intelligente  Toujours dans sa version web, une boite de recherche est disponible dans le coin supérieur droit. En entrant du texte dans le champ de recherche et en cliquant sur ou sur la loupe, cela ouvrira une fenêtre à même la page avec des liens vers toutes les parties du texte qui comprennent l'expression recherchée.    Une capture d'écran d'une page du texte, montrant la boite de recherche dans le coin supérieur droit.    Une capture d'écran du résultat de la recherche du mot parabole dans la boite. On y voit quelques liens vers des parties du texte.      Des liens vers n'importe quelle partie du texte  Envie de pointer vers un endroit spécifique au texte, comme un exemple, un exercice ou même un paragraphe, pour demander des explications ou des précisions? C'est possible sur la version web. À la gauche de la majorité des éléments se trouve, de manière presque transparente, une petite icône cliquable qui offrira un lien vers la portion souhaitée, ainsi qu'une courte description. Par exemple, un clic sur l'icône de la figure suivante produit le texte suivant: Exemple 1.2.1: L'angle entre deux vecteurs de dimensions deux: dynamique https:\/\/alir-jsturcotte.profweb.ca\/sec-prodscal.html#ex-angle2d . Dans la figure, on voit également, sous l'icône à cliquer en surbrillance (effet de la souris qui est sur l'icône), une autre icône, à peine visible, pour laquelle un clic offrira un lien vers le paragraphe sous l'exemple.   Une capture d'écran d'une partie de texte. On y voit, à gauche, l'icône à cliquer afin d'obtenir le lien.    "
},
{
  "id": "versions",
  "level": "1",
  "url": "versions.html",
  "type": "Préface",
  "number": "",
  "title": "Versions et source",
  "body": " Versions et source  Ce livre existe en deux formats principaux. La version la plus complète et la plus à jour sera toujours la version web. Elle est disponible à l'adresse . Au besoin, des mises à jour seront effectuées chaque début de session, dans les premières semaines du mois d'aout ou du mois de janvier. Si une mise à jour ne change pas la structure de la numérotation, elle pourrait être effectuée à un autre moment. Une liste des changements de l'édition en cours est disponible sur GitHub.  Une version PDF existe et est disponible en cliquant sur ce . Cette version sera mise à jour moins régulièrement que la version en ligne. Elle le sera uniquement en cas de changement majeur, dans le but de la garder arrimée avec la version en ligne.  Le code source du manuel se trouve sur GitHub, à l'adresse .  "
},
{
  "id": "sec-vec",
  "level": "1",
  "url": "sec-vec.html",
  "type": "Section",
  "number": "1.1",
  "title": "Vecteurs géométriques et algébriques",
  "body": "  Vecteurs géométriques et algébriques    Aller aux exercices de la section.  On connait tous et toutes l'ensemble des nombres réels, , souvent illustré par une droite. Le plan cartésien devrait aussi être familier, puisqu'il est régulièrement utilisé dans le tracé de graphique des cours de calcul. Même l'espace tridimensionnel s'imagine facilement avec les notions d'origine et d'axes similaires à celles du plan. Ces trois espaces sont illustrés à la figure .   Les espaces , et   La droite réelle, le plan cartésien et l'espace tridimensionnel sont illustrés.    Dans cette section, on présente les vecteurs dans le plan cartésien et dans l'espace à trois dimensions , on présente également des opérations simples sur ces vecteurs.     Vecteurs à deux et à trois dimensions  Lorsqu'on parle d'un endroit sur le plan cartésien, on utilise souvent le mot \"point\". La notion de point renvoie à un système de référence spécifique, comprenant notamment une origine et des axes. La position du point est donnée en lien avec la distance parcourue parallèle à chaque axe en partant de l'origine pour se rendre au point.  Ce déplacement suggère une autre manière de voir la notion de point, soit en traçant une flèche entre l'origine et le point. Cette flèche est ce qui est communément appelé un vecteur. En fait, la notion de vecteur est un peu plus complexe. C'est ce que nous allons découvrir au fil du texte.  On associe souvent à un point le vecteur où représente l'origine. Par contre, un vecteur n'a pas de localisation particulière. C'est plutôt son résultat qui est important. La différence entre un point et un vecteur est minime et dépend souvent seulement du contexte. Algébriquement, le point et le vecteur ne sont qu'une liste de nombres. On ne s'attardera pas davantage à cette différence.     En passant  Le mot vecteur vient du latin vector , dérivé de veho , qui signifie \"transporter\". À l'origine, le mot vecteur aurait été utilisé pour désigner le conducteur d'un véhicule ou d'un bateau. Ce serait autour des années 1840 que le mathématicien allemand Grassmann l'aurait introduit dans un contexte mathématique. Son utilisation contemporaine aurait commencé au tournant du vingtième siècle.    Intuitivement, un vecteur géométrique est une flèche possédant:  une longueur, aussi appelée la norme du vecteur;  une orientation, Certains auteurs vont plutôt définir la direction et le sens d'un vecteur. La direction correspond à la droite supportant le vecteur et le sens au sens de parcours de cette droite. qui correspond aux angles que fait le vecteur avec chacun des axes de coordonnées.    Un vecteur sera souvent représenté par une lettre minuscule surmontée d'une flèche, typiquement comme et . On accepte aussi la demi-flèche .      Tel que mentionné, un vecteur n'a pas de localisation précise. Le vecteur qui relie le point et est le même vecteur que celui qui relie le point au point puisque si on les considère comme des déplacements, ils sont équivalents.   Par défaut, on place un vecteur à l'origine, sauf s'il y a une utilité à le placer à un autre endroit.   Tous les vecteurs ont une grandeur, notée . Un vecteur dont la norme vaut est appelé un vecteur unitaire et est parfois dénoté avec un chapeau plutôt qu'une flèche, par exemple le vecteur .    Il existe un seul vecteur qui n'a pas d'orientation. C'est le vecteur nul, noté . L'importance de ce vecteur deviendra évidente sous peu.     Comme les vecteurs sont souvent utilisés pour représenter un déplacement, on notera le vecteur reliant le point au point par .  Géométriquement, deux vecteurs sont égaux s'ils ont la même longueur et la même orientation. L'image interactive de l'exemple permet de manipuler en deux dimensions trois vecteurs, dont deux sont toujours égaux. L'exemple , quant à lui, offre une introduction aux vecteurs en trois dimensions.   Des vecteurs géométriques: dynamique  Dans la figure, les vecteurs et ont été construits pour être égaux. Il est possible de changer les vecteurs en les manipulant. Il est possible de visualiser la notion de même orientation dans cet exemple.   Premiers contacts avec des vecteurs géométriques      Des vecteurs géométriques en trois dimensions: dynamique  On note que dans la figure, les vecteurs et sont toujours égaux. Cette figure sera aussi utilisée pour parler du concept d'addition de vecteurs dans la sous-section    Premiers contacts avec des vecteurs géométriques tridimensionnels    Algébriquement maintenant, il est possible de décrire un vecteur à l'aide de composantes. Ces composantes renvoient aux concepts d'origine et de base, qui seront définis dans la section . L'idée est d'associer à un vecteur les nombres correspondant au point à son extrémité lorsque le vecteur est placé à l'origine. Ainsi, un vecteur de longueur parallèle à l'axe des abscisses serait décrit comme . On verra aussi prochainement l'utilité de la notation .   En passant  Plusieurs notations sont utilisées pour les vecteurs algébriques. On peut avoir et même sans les virgules. Dans ce texte, on utilise la première notation, horizontale ou verticale, mais la seconde sera utile lors de l'utilisation du programme informatique Sage.   Si est un vecteur de , alors . C'est une conséquence immédiate du théorème de Pythagore, comme l'illustre la figure . Pour les vecteurs de , on peut montrer qu'une formule similaire s'applique (voir exercice ), c'est-à-dire que .  Algébriquement, deux vecteurs sont égaux s'ils ont les mêmes composantes.  Il est plus difficile de caractériser l'orientation d'un vecteur algébriquement. Toutefois, dans , il suffit d'un angle. Par convention, on choisit l'angle que fait le vecteur avec l'horizontale, mesuré dans le sens antihoraire. On appelle souvent cet angle l'angle polaire. Il est aussi illustré à la figure . C'est un exercice simple de trigonométrie de calculer l'angle d'un vecteur dans , mais il y a toutefois des exceptions à considérer. En général, l'équation donne une relation entre l'angle et les composantes du vecteur, pourvu que . La fonction permet d'obtenir l'angle, mais il faudra parfois ajuster selon le quadrant avec un terme .  Pour les vecteurs dans , on définit la notion de cosinus directeurs (voir l'exercice ).   Un vecteur algébrique   Un vecteur algébrique quelconque. Ses coordonnées et sont illustrées de même que l'angle polaire.     L'angle polaire de vecteurs de dimension 2     Considérons le vecteur , illustré à la figure . Comme on cherche l'angle que fait le vecteur avec l'horizontale, il suffit de faire une fonction pour y arriver: .   Un vecteur du premier quadrant   Un vecteur du premier quadrant      Considérons maintenant , illustré à la figure . Comme ce vecteur est dans le quatrième quadrant, son angle sera donné par (ou ) moins l'angle bleu . Ce dernier peut être calculé avec la fonction , en tenant compte d'ajuster les signes: .   Un vecteur du quatrième quadrant   Un vecteur du quatrième quadrant      Finalement, considérons le vecteur , illustré à la figure . L'angle cherché correspond à (ou ) moins l'angle bleu . Ce dernier peut aussi être calculé avec la fonction , en tenant compte d'ajuster les signes: .   Un vecteur du deuxième quadrant   Un vecteur du deuxième quadrant       On termine avec des commandes Sage en lien avec la sous-section.   Définition de vecteurs sur Sage  Avec Sage, il est possible de définir des vecteurs, pour ensuite les utiliser pour effectuer des calculs. On commence par nommer un vecteur en le définissant avec la commande vector . À noter que, pour faire la distinction entre les arguments de la commande et le vecteur, on utilise les crochets [ ] pour les vecteurs dans Sage. En cliquant sur \"évaluer\", on peut voir s'afficher le résultat de la cellule.   On rappelle ici, tel que mentionné à , qu'il est possible de faire un affichage plus courant avec la commande show .   Il est possible d'accéder aux composantes d'un vecteur à l'aide des indices. Il est important de se rappeler que dans Sage, la première composante a pour indice 0.   On peut illustrer graphiquement des vecteurs à l'aide d'une commande plot . Ici, on remarque l'utilisation des virgules pour une définition simultanée de deux vecteurs. On utilise aussi le fait que, pour Sage, les graphiques peuvent s'additionner afin d'afficher plusieurs graphiques en une seule sortie.   On remarque que les vecteurs sont par défaut tracés à l'origine, ce qui est cohérent avec la remarque . Si l'on veut faire commencer le vecteur à un autre endroit, disons qui commencerait à la fin de , il est possible de le faire avec l'option start . Cette option sera particulièrement pratique lors de l'addition de vecteur de la sous-section .   Il est possible de calculer la norme d'un vecteur en utilisant la commande norm et l'angle à l'aide des fonctions trigonométriques usuelles.        Opérations sur les vecteurs  Considérons un vecteur quelconque et un nombre réel . On s'intéresse à définir la multiplication de par . Intuitivement, on peut voir cette multiplication comme un étirement ou une compression du vecteur original. Il semble donc logique de vouloir que son orientation soit inchangée. Alors, quelle devrait être sa longueur? À priori, on est tenté de dire que la longueur devrait être fois la longueur de , mais cela pose un problème si .  Avant d'aller plus loin, on essaie de donner un sens à la multiplication par un nombre négatif. Pour ce faire, on considère une valeur positive de et on la laisse s'approcher de . L'exemple permet de voir ce concept.  L'intuition semble dire que la multiplication par un nombre négatif renverserait l'orientation du vecteur afin de continuer le comportement.   La multiplication par un scalaire: dynamique  Dans la figure, le vecteur est donné. Il est possible de changer le vecteur en le manipulant. En cliquant sur les différentes boites, on peut se donner l'intuition nécessaire pour la multiplication d'un vecteur par un nombre négatif.   La multiplication d'un vecteur géométrique par un scalaire     En comparant une valeur positive et son opposé (négative) dans l'exemple , on constate que la longueur du vecteur reste la même. Cela nous mène donc à la définition suivante.   Multiplication par un scalaire   Soit un vecteur et un nombre réel. On définit la multiplication par un scalaire de par , notée simplement , comme étant le vecteur tel que :    ;    l'orientation de est :  la même que celle de si ;  n'existe pas si , car il devient le vecteur nul;  d'angles différents de des angles de si .        En passant Puisque la multiplication par un scalaire engendre un changement d'échelle (étirement ou compression) du vecteur original, un nombre réel est souvent appelé un scalaire dans un contexte vectoriel, du latin scala , \"échelle\".  Dans la remarque , on a défini la notion de vecteur unitaire comme étant un vecteur dont la norme vaut . Or si est un vecteur non nul quelconque, on peut facilement, à l'aide de la multiplication par un scalaire, obtenir un vecteur unitaire noté , ayant la même orientation que . En effet, il suffit de trouver tel que . Or selon la définition , la norme de est . En fixant , on obtient un vecteur unitaire .  Unitariser des vecteurs est un concept important en algèbre linéaire. Cela simplifie souvent les problèmes où la longueur d'un vecteur n'est pas importante, mais où seule compte son orientation.  Si deux vecteurs non nuls ont la même orientation, alors il existe toujours tel que . Ceci nous permet de définir la notion de vecteurs parallèles.   Vecteurs parallèles   Deux vecteurs non nuls sont parallèles s'il existe tel que . On écrit alors ou encore .  Par convention, on considère que le vecteur nul n'est parallèle à aucun vecteur En théorie, on aurait aussi pu dire que le vecteur nul est parallèle à tous les vecteurs. .   Si l'on connait les composantes d'un vecteur, disons , on peut montrer facilement que le vecteur satisfait la définition .   Unitariser un vecteur  On considère le vecteur . On cherche le vecteur unitaire .  On commence par calculer la norme du vecteur : .  On obtient le vecteur cherché en divisant par deux: .   Le vecteur unitaire obtenu à l'exemple peut sembler familier à ceux et celles qui connaissent leur cercle trigonométrique. En effet, ce vecteur correspond au point du cercle lorsque l'angle au centre est de . Puisque dans , l'orientation de tout vecteur non nul peut être caractérisée par l'angle que fait le vecteur avec l'horizontale, on obtient l'équation suivante, appelée forme polaire d'un vecteur : .  Avant de passer à l'addition de vecteurs, on termine sur une remarque concernant la multiplication par un scalaire.      Le vecteur s'écrit plus simplement . On l'appelle le vecteur opposé à .    La multiplication par un scalaire est commutative, c'est-à-dire que .    Si , la division par un scalaire est définie simplement comme étant .     Si l'on imagine à nouveau les vecteurs comme générant le mouvement, il est logique de vouloir combiner l'effet de deux ou plusieurs vecteurs, comme une suite de déplacements successifs. Géométriquement, cela revient à placer les flèches les unes à la suite des autres. L'exemple permet de jouer avec ce concept.   L'addition de vecteurs: dynamique  Dans la figure, les vecteurs et sont donnés. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser l'addition de deux vecteurs dans .   L'addition de deux vecteurs géométriques     L'exemple montre que l'addition de deux vecteurs forme un triangle dont les côtés sont . Un triangle congru est formé lorsque l'on considère plutôt la somme . Ensemble, ces triangles forment un parallélogramme. En fait, dès que deux vecteurs sont non parallèles, ils engendrent un parallélogramme. L'addition des vecteurs et est l'une des diagonales de ce parallélogramme. Ce simple fait permet de comprendre beaucoup de résultats en géométrie vectorielle. De fait, l'addition de vecteurs est commutative, tout comme l'addition régulière de nombres réels.  Il est important de rappeler encore une fois que l'endroit où se trouve un vecteur n'a pas d'importance. C'est ce que le vecteur représente, le déplacement, qui compte. En se référant à la figure , on peut remarquer que le déplacement du vecteur suivi de celui par correspond au vecteur , bien que et ne soient pas consécutifs dans le dessin. Il est également possible de voir qu'un même déplacement peut être exprimé de plusieurs manières. Par exemple, l'addition est égale à l'addition ou encore .  Algébriquement, pour additionner deux vecteurs, il suffit d'additionner les composantes correspondantes. Pour comprendre, on s'imagine que le vecteur est lui-même une somme des vecteurs et . Si l'on a un deuxième vecteur décomposé de la même manière, il est possible de voir que la somme correspond à une suite de déplacements horizontaux et verticaux. La figure permet de visualiser le concept.   L'addition de vecteurs algébriques   Les vecteurs et sont illustrés en triangle ainsi que le vecteur somme. Chacun des vecteurs et est décomposé selon l'horizontale et la verticale. Le vecteur somme correspond à l'addition des composantes horizontales et verticales    L'addition de deux vecteurs algébriques est donc . La notation verticale est particulièrement utile pour illustrer l'addition de vecteurs algébriques: .  La commutativité de l'addition vectorielle, de même que plusieurs autres propriétés (voir l'exercice ), se déduisent immédiatement des propriétés équivalentes pour l'addition de nombres réels. L'image interactive de l'exemple permet de visualiser géométriquement l'associativité de l'addition vectorielle.   L'associativité de l'addition vectorielle: dynamique  Dans la figure, les vecteurs et sont donnés. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser l'associativité de l'addition vectorielle.   L'associativité de l'addition vectorielle     Qu'en est-il de la soustraction de vecteurs? Algébriquement, il est intuitif de définir la soustraction comme étant l'addition de . Cela revient donc à soustraire aux composantes de les composantes correspondantes de .  Géométriquement, où se situe cette soustraction de vecteurs? À l'exemple , on a observé que l'addition de vecteurs peut être représentée par la diagonale d'un parallélogramme. Dans l'exemple , on constate que la soustraction de vecteurs correspond à l'autre diagonale. Le sens de la flèche dépendra de l'ordre de la soustraction.   Soustraction de vecteurs: dynamique  Dans la figure, les vecteurs et sont donnés, ainsi que leur addition. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser les soustractions de deux vecteurs.   Soustraction de deux vecteurs géométriques     On remarque que le vecteur correspondant à est le vecteur tel que . Le parallélogramme illustre bien cette interprétation.  Lorsque deux points et sont donnés, on peut définir algébriquement le vecteur comme étant . En particulier, si et sont quatre points de , les vecteurs et sont égaux si .  Regardons maintenant un exemple algébrique d'addition et de soustraction de vecteurs.   Additions et soustractions de vecteurs  Soit et des vecteurs. On calcule et .   Il suffit de calculer directement en utilisant la multiplication par un scalaire et l'addition\/soustraction composante par composante. Pour , on a   De même, pour , on a    Il est possible de considérer les vecteurs comme étant une opération de translation agissant sur les points. Par exemple, le vecteur peut être interprété comme la translation du point jusqu'au point le long d'une droite. On écrira alors parfois , qui est en fait une forme abrégée, mais somme toute équivalente, de l'équation purement vectorielle . Cette dernière est simplement une réécriture de l'équation .  En utilisant cette équivalence entre points et vecteurs, on en arrive à poser quatre postulats, qui forment les axiomes initiaux de la géométrie:   Axiomes de la géométrie vectorielle    Étant donné deux points , il existe un seul vecteur tel que .  Si , alors nécessairement .   De même, si , alors nécessairement .  (Loi de Chasles).    À partir de ces axiomes, on peut déduire d'autres résultats élémentaires (voir l'exercice ). Deux résultats particulièrement importants sont et .  On termine avec des commandes Sage en lien avec la sous-section.   Opérations sur les vecteurs avec Sage  Il est possible de multiplier un vecteur par un scalaire et d'additionner et soustraire des vecteurs de manière intuitive avec Sage.   Visuellement, il est possible d'illustrer l'addition et la soustraction avec les commandes apprises à l'exemple .      Utilisation de méthodes vectorielles en géométrie  Les vecteurs permettent de traduire des résultats de la géométrie en concepts algébriques. Souvent, les méthodes vectorielles simplifient la démonstration de ces résultats. Dans beaucoup d'exemples et d'exercices, il sera utile de suivre le conseil .   Établir son propre cadre  Dans les problèmes géométriques, il sera souvent de considérer les points suivants:  Souvent, l'endroit précis où l'origine se trouve n'est pas important. Si une origine n'est pas fixée, cela peut être utile de déterminer un endroit approprié pour la placer.  Déterminer un certain nombre de vecteurs importants et exprimer les autres vecteurs en fonction de ceux-ci est parfois utile.  Dans un dessin, l'horizontale et la verticale n'auront peut-être pas la signification usuelle (celle d'un plan cartésien par exemple). Afin d'illustrer cet aspect, considérer la figure .     Un vecteur à trois dimensions   La figure montre les points et qui sont reliés par un vecteur. Le point milieu entre et est aussi illustré. La figure est dans une perspective à trois dimensions.     Un vecteur à trois dimensions dessiné en deux dimensions   La figure montre les points et qui sont reliés par un vecteur. Le point milieu entre et est aussi illustré. La figure est dans une perspective à deux dimensions      Les exemples qui suivent donnent quelques-unes des applications vectorielles à la géométrie. D'autres sont aussi données dans les exercices.   La distance entre deux points  Soit deux points et . Comment calculer la distance entre ces deux points?  En considérant le vecteur reliant à , on constate que sa norme donne la distance entre les points. Dans le reste du texte, on utilise la notation pour dénoter la distance entre et . Ces objets peuvent être des points, des droites, des plans, etc. Ainsi,  .  En particulier, si et , la distance entre et est   La figure ci-dessous montre l'effet du conseil . La position des points n'est pas vraiment importante pour répondre à la question. Le dessin est là pour aider à visualiser, tout simplement.   Changer le cadre de référence     Dans le prochain exemple, on utilise une stratégie particulièrement utile en algèbre linéaire. Celle-ci est détaillée avant l'exemple.   Le 3D n'est pas toujours en trois dimensions  Dans beaucoup de problèmes, on fera affaire avec des vecteurs à trois dimensions (et même plus, voir la section ). Par contre, cet aspect multidimensionnel n'est pas toujours nécessaire pour répondre à la question. Si l'on cherche la distance entre deux points, qu'ils soient en deux ou trois dimensions, on peut toujours les relier par des droites. Ceci signifie donc que, pour la question, on peut illustrer tous les éléments importants du problème sur un plan à deux dimensions.    Partage d'un segment  Soit et , deux points dans .  On souhaite partager le segment en deux parties congrues en trouvant le point milieu. Pour cela, il suffit de réaliser que le point peut être obtenu à partir de en lui ajoutant la moitié du vecteur . Ainsi .  En général, on peut toujours se rendre à un point entre et , situé à fois la longueur de à l'aide de la formule .  L'interaction ci-dessous permet de visualiser.   Proportion d'un segment       Un lieu géométrique est un ensemble de points possédant une propriété commune. Un cercle, une ellipse, une parabole, etc. sont des exemples de lieux géométriques. La plupart du temps, ces lieux sont caractérisés par une équation algébrique.   On peut aussi caractériser vectoriellement certains lieux géométriques.   Le cercle, vu vectoriellement  Il est possible de définir algébriquement un cercle de rayon centré à l'origine par l'équation . Plus généralement, un cercle centré au point , toujours de rayon aura pour équation . On peut également caractériser un tel cercle vectoriellement. Un cercle constitue l'ensemble des points qui sont à une distance d'un centre . Vectoriellement, on peut traduire cette phrase par une équation avec la norme. Ainsi, un cercle centré en est formé de l'ensemble des points pour lesquels .   On termine avec l'utilisation de Sage pour résoudre des problèmes géométriques.   Utilisation de Sage dans la résolution de problèmes de géométrie vectorielle  On considère le problème suivant. Soit , un quadrilatère quelconque et , le quadrilatère obtenu en joignant les points milieux des segments de . Montrer que est un parallélogramme.  Afin de développer l'intuition nécessaire pour résoudre le problème, il est utile de dessiner certains cas pour voir comment procéder. À travers cet exemple, on explore la commande polygon qui permet de tracer un polygone étant donnée une liste de points ou de vecteurs.  On pourrait d'abord vérifier l'énoncé pour un quadrilatère simple, comme un rectangle. On définit donc les points et on calcule à partir de ceux-ci les points . Par la suite, on trace les deux quadrilatères à l'aide de la commande polygon .   On essaie maintenant avec un quadrilatère moins régulier. Le code est le même, sauf pour la définition des points initiaux.   A-t-on été chanceuses et chanceux avec ces exemples? Pour se convaincre que non, on propose de créer un quadrilatère aléatoire qu'il sera possible de tester autant de fois que souhaité. La commande ZZ.random_element(a,b) permet de générer un entier ( ZZ dans Sage) dans l'intervalle . Lors de certaines exécutions, le quadrilatère sera dégénéré (un triangle ou même une ligne) ou encore, on se retrouvera avec un croisement de deux de ses côtés (dans ce cas, le résultat pourrait être faux). Si cela se produit, ignorer et exécuter à nouveau la cellule. L'exercice s'intéresse à peaufiner le code afin que le quadrilatère formé soit toujours valide.   On est maintenant prêt à démontrer le résultat, en s'appuyant sur l'intuition géométrique offerte par les graphiques Sage. On veut montrer que et . Puisque        et      ,  les vecteurs et sont égaux, car les membres de droite des équations et sont égaux.  De même, en se servant des équations ci-dessus, on a et . Puisque les membres de droite des équations et sont égaux, les vecteurs et sont égaux.     Les éléments importants de cette section sont:   Un vecteur est un objet composé d'une longueur et d'une orientation;   Algébriquement, la norme d'un vecteur est donnée par la racine carrée de la somme de ses composantes au carré, ou l'équivalent dans ;   Dans , l'orientation peut être caractérisée par l'angle que fait le vecteur avec l'horizontale, mesuré dans le sens antihoraire;  Les opérations de multiplication d'un vecteur par un scalaire et d'addition\/soustraction de vecteurs.  De plus, avec Sage:  Pour définir un vecteur, on utilise vector([u1,u2]) , ou une commande similaire pour . En particulier, le vecteur doit être mis entre crochets dans la commande vector() ;  Il est possible de définir le point de départ du vecteur avec l'option start de la commande plot(vector([u1,u2]),start=(x,y)) ;  Pour accéder aux composantes d'un vecteur, on utilise la notation crochet u[k] , en se rappelant que la première composante a comme indice 0;  On peut calculer la norme d'un vecteur à l'aide de la commande norm() ;  On peut illustrer graphiquement un vecteur à ou dimensions avec une commande plot() ;  Les opérations sur les vecteurs sur Sage se font de manière naturelle, en utilisant +,-,* .       Exercices    Considérer les vecteurs et . Calculer algébriquement les vecteurs suivants, représenter-les dans un plan cartésien et calculer l'orientation et la longueur.                                                                          On trace le vecteur à l'origine pour connaitre son direction approximative. On voit qu'il est dans le deuxième quadrant. On trouvera donc l'angle aigu ( ) avec la trigonométrie et on lui additionnera l'angle droit. On utilise toujours puisqu'on connait les côtés adjacent et opposé à l'angle .   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-1,6) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi:      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant. On donc l'angle avec la trigonométrie.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (5,4) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :     On trace le vecteur . On remarque qu'il s'agit du vecteur opposé à celui de la question précédente. On va utiliser cette information pour gagner du temps. Sa longueur est identique et son orientation est de de plus (ou moins!).   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-5,-4) ainsi que son angle polaire donnant son orientation.     La longueur est donc:      On trace le vecteur à l'origine pour connaitre son direction approximative. On voit qu'il est dans le troisième quadrant. On trouvera donc l'angle aigu ( ) avec la trigonométrie et on lui additionnera les manquants.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-4,-10) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi:      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (3,16) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (11,2) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant. On remarque que ce vecteur correspond au vecteur que l'on a multiplié par le scalaire sur sa norme. C'est ainsi qu'on \\emph{unitarise} un vecteur. Son orientation sera la même que le vecteur qu'on a tracé plus pâle pour les visualiser ensemble.   Le vecteur résultat et son orientation   Le vecteur unitaire partant de l'origine dans la même orientation que le vecteur (2,5) ainsi que son angle polaire. Le vecteur (2,5) est tracé derrière plus pâle.     La longueur est automatiquement de puisque c'est un vecteur unitaire. Calculons-la, pour vérifier :      On trace le vecteur et on voit qu'il se trouve dans le deuxième quadrant. Il s'agit encore une fois d'un vecteur unitaire. C'est celui du premier exercice de ce numéro. On en connait donc déjà l'orientation et la longueur.   Le vecteur résultat et son orientation   Le vecteur unitaire partant de l'origine dans l'orientation du vecteur (-1,6) ainsi que son angle polaire. Le vecteur (-1,6) est tracé derrière plus pâle.     La longueur est automatiquement de puisque c'est un vecteur unitaire :       Soit un vecteur allant de l'origine jusqu'au point . Démontrer que la longueur de ce vecteur est donnée par: .   Pour vous aider, voici une représentation graphique de ce vecteur dans l'espace cartésien.   Le vecteur dans l'espace     Le théorème de Pythagore et le concept de projection suffisent pour démontrer cette formule. On considère tout d'abord le vecteur , la projection de sur le plan . Il est évident que . Ainsi, par Pythagore, la longueur de ce vecteur est: . La longueur de est maintenant calculable en utilisant de nouveau le théorème avec le triangle à la verticale dont la première cathète est la longueur de et la seconde est la composante en de :     Soit le point et le vecteur suivants. Déplacer les points à afin qu'ils correspondent aux descriptions suivantes. Noter qu'il peut y avoir plusieurs réponses valides.          L'espace du problème     Il n'y a qu'une réponse possible, sauf pour où il y en a une infinité. L'explication vous permettra de visualiser l'ensemble des réponses possibles.   L'espace du problème avec solution     On doit partir de et effectuer un déplacement correspondant à pour arriver à .  On doit partir de et effectuer un déplacement correspondant à 2 fois pour arriver à .  On doit placer de telle sorte que sa distance à est égale à la longueur de . Il y a une infinité de réponses possibles puisqu'on peut le placer n'importe où sur le cercle de rayon autour de .   On doit placer de telle sorte que le déplacement de à soit le même que de à . En manipulant les outils, on voit que, si l'on place d'un côté de , les vecteurs et sont de sens opposés. Ils ne peuvent donc jamais être égaux. La seule façon d'avoir est de placer sur . Ainsi, .   On doit partir de et effectuer un déplacement correspondant à 3 fois dans le sens opposé pour arriver à .     Soit le point et le vecteur tels qu'illustrés. On indique que . Décrire le lieu géométrique de l'ensemble des points répondant à chaque expression.       a la même orientation que     L'espace du problème      Le cercle de centre et de rayon 1.  Le disque de centre et de rayon 2.  L'anneau de centre , de rayon extérieur 3 et de rayon intérieur 1.  La droite parallèle à et passant par .  La demi-droite issue de dans l'orientation de excluant .  L'ensemble des points sur la droite parallèle à et passant par qui sont à une distance entière de . Cela inclut le point .     Soit et , deux points distincts dans l'espace ( ). Décrire le lieu géométrique de l'ensemble des points répondant à chaque expression.         L'espace du problème      Le point doit être le point milieu du segment .  Aucun point ne satisfait à cette condition.  Tous les points se situant sur le plan perpendiculaire à , passant par le point milieu de ce même segment.     Dans le parallélogramme suivant, trouver les coordonnées du point .   Le parallélogramme   Un parallélogramme formé des points (-3,2), (3,-1), (0,-3) et du point D dont les coordonnées sont inconnues.     Il est conseillé d'identifier chaque point connu par une lettre et de calculer les composantes des différents vecteurs reliant ces points. Choisir ensuite un point de départ dont les coordonnées sont connues et se déplacer selon un vecteur en additionnant ses composantes pour aller au point dont les coordonnées sont inconnues.   Les coordonnées du point sont .   Identifions les points suivants: , et sur le dessin.  Alors, le vecteur suivant se calcule facilement.  Finalement, on part du point et on arrive à en se déplaçant selon puisque . Ainsi, on a calculé les coordonnées du point .    Calculer les coordonnées du point se situant aux du segment à partir du point . Les coordonnées des points sont et .   Les coordonnées de ce point sont .   La méthode préférée ici consiste à débuter par un point connu ( , par exemple), de trouver un vecteur dans la direction où l'on veut se déplacer ( , par exemple) et finalement de l'étirer à la longueur voulue. De cette démarche, on obtient la formule suivante: Les coordonnées du point cherché sont donc .    En utilisant les quatre axiomes initiaux de la géométrie vectorielle ( ), démontrer les trois propriétés suivantes.    Si , alors .       L'axiome 4 appliqué au vecteur permet d'écrire . De ce qu'on connait de l'addition vectorielle, on peut additionner de chaque côté de l'égalité par le vecteur . Ainsi,    On a .    Sachant que , alors,      Déplacer les vecteurs et afin que les égalités ou inégalités suivantes soient vérifiées, une à la fois. Ensuite, énoncer en mots pour chacune les conditions nécessaires à leur vérification.   (l'inégalité du triangle)        L'espace du problème      Cette inégalité se nomme l'inégalité du triangle. Elle est toujours vraie pour deux vecteurs et . Comme son nom l'indique, on la représente bien lorsque les deux vecteurs sont additionnés avec la méthode du triangle, tel que le dessin le montre. Elle signifie que la somme des longueurs des deux premiers côtés sera toujours supérieure à la longueur du dernier côté.  Les seules possibilités que cela soit faux impliquent ou (ou les deux!) ou lorsque les deux vecteurs ont la même orientation. Dans ce dernier cas, les trois vecteurs seraient donc sur une seule droite et l'addition de et donne un vecteur de même longueur que l'addition de leurs longueurs.  À l'inverse de la lettre précédente, cette égalité est vraie dans les trois cas donnés, mais elle ne l'est pas lorsque les deux vecteurs sont nuls. Bref, lorsque ou lorsque (mais pas les deux!) ou lorsque les deux vecteurs ont la même orientation.  Dans ce cas, avec les restrictions imposées, il faut absolument que les deux vecteurs soient non-nuls et aient la même orientation.  Ce dernier cas est particulier. Il faut y réfléchir ainsi: on cherche à créer un triangle avec l'addition de vecteurs et on veut que chaque côté ait la même longueur. Bref, on veut un triangle équilatéral. Il faut donc que et soient de même longueur et forment un angle de pour que l'énoncé soit vérifié.     Montrer que les diagonales de n'importe quel parallélogramme se croisent en leurs milieux.   Utiliser les axiomes de la géométrie vectorielle ( ). Le dessin suivant peut vous être utile.   Les diagonales d'un parallélogramme    On peut reformuler la preuve demandée ainsi: si est le point milieu de , alors montrer que . On sait donc, par la définition de point milieu, que .   Soit un parallélogramme et , le point milieu de , tel qu'illustré dans l'indice. Alors,   Aussi, maintenant qu'on a prouvé cette égalité, on peut écrire:     Soit le triangle et les points et se trouvant respectivement au milieu des segments et . Montrer que .   Une histoire de milieu   Le triangle ABC ainsi que les points M et N respectivement milieux des segments AB et AC.     Utiliser les axiomes de la géométrie vectorielle ( ) et le conseil suivant: passer par un détour pour exprimer le vecteur .   On va réécrire le vecteur en utilisant d'autres vecteurs et utiliser le fait que et sont des points milieux.      Les propriétés suivantes sur les vecteurs découlent naturellement de leur interprétation géométrique. Nous avons déjà vérifié certaines d'entre elles intuitivement. Dans cet exercice, démontrer algébriquement leur validité en utilisant les définitions algébriques de l'addition vectorielle et de la multiplication par un scalaire .  Soit , et et et . Alors,   (commutativité de l'addition vectorielle)  (associativité de l'addition vectorielle)  (neutre additif)  (inverse additif)  (associativité de la multiplication par un scalaire)  (distributivité sur l'addition vectorielle)  (distributivité de l'addition des scalaires)  (neutre multiplicatif)                Observer le prisme ci-dessous et donner un seul vecteur reliant deux points qui exprime les déplacements suivants.   Un prisme à base triangulaire   Un prisme ayant comme base le triangle ABC.              Puisque l'on spécifie qu'il s'agit d'un prisme, on peut considérer que . De même, les deux triangles formant les bases du prisme sont parallèles et donc les vecteurs parallèles sont égaux. Par exemple, .  Ainsi, pour exprimer le déplacement correspondant à , il faut considérer que et donc que , en utilisant la Loi de Chasles .  Finalement, remarquer qu'il y a parfois plusieurs réponses possibles.      ou ou   ou ou  ou      Observer le parallélipipède suivant et dire si les énoncés ci-dessous sont vrais ou faux.   Un parallélipipède   Un parallélipipède ayant comme base le parallélogramme ABCD.                Vrai  Faux  Vrai  Vrai  Faux  Faux  Vrai  Faux    Il y a plusieurs façons de raisonner pour déterminer si les vecteurs de ces énoncés sont égaux. Avant de débuter, on donne quelques principes importants pour structurer le raisonnement à l'écrit. D'abord, on veut souvent exprimer un vecteur de façon équivalente en utilisant d'autres points pour le décrire. Ensuite, on veut exprimer l'addition de vecteurs de façon équivalente avec un seul vecteur (Loi de Chasles) . Finalement, il peut arriver que l'on veuille effectuer les étapes précédentes dans l'ordre inverse et ainsi exprimer un vecteur comme l'addition de deux ou trois vecteurs afin d'expliciter comment il s'annule avec d'autres vecteurs. Noter qu'il est utile de réorganiser l'ordre de l'addition des vecteurs pour mieux communiquer ce qu'on simplifie.   Ces vecteurs sont clairement parallèles et de même longueur. C'est donc vrai qu'ils sont égaux.   C'est donc faux.     C'est donc vrai.     C'est donc vrai.     C'est donc faux.     C'est donc faux.     C'est donc vrai.     C'est donc faux.      Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Soit et deux vecteurs de .   Définir et tracer les vecteurs et sur un même graphique, le vecteur en rouge et le vecteur en bleu. Les deux vecteurs partent de l'origine.    Les vecteurs et   Les vecteurs u et v sont tracés tel que demandé, respectivement en rouge et en bleu.       Le code solution pour l'exercice   u=vector([-1,2]) v=vector([2,1]) plot(u,color=\"red\")+plot(v,color=\"blue\")     Calculer le vecteur et donner sa norme.    Le vecteur est et la norme est .     Tracer un parallélogramme passant par le point qui est engendré par les vecteurs . Utiliser des couleurs différentes pour chaque côté du parallélogramme. Identifier les vecteurs avec la commande text(\"texte\",(x,y)) où \"texte\" est le nom du vecteur et sa position.     Un parallélogramme engendré par les vecteurs et passant par le point .   Le parallélogramme passant par le point (1,3) est tracé à partir des vecteurs u et v.       Le code solution pour l'exercice   u1=plot(u,start=(1,3),color=\"red\")+text('$\\\\vec{u}$',(0.5,3.6),color=\"red\") v1=plot(v,start=(1,3),color=\"blue\")+text('$\\\\vec{v}$',(2,3.4),color=\"blue\") u2=plot(u,start=vector([1,3])+v,color=\"green\")+text('$\\\\vec{u}$',(2.5,5.3),color=\"green\") v2=plot(v,start=vector([1,3])+u,color=\"orange\")+text('$\\\\vec{v}$',(1,5.4),color=\"orange\") u1+u2+v1+v2    Remarquer que, pour placer certains vecteurs au bon endroit, il a fallu convertir le point en vecteur afin de pouvoir lui additionner un vecteur. Sage ne veut pas additionner un vecteur à un point. Votre texte est aussi probablement plus simple que la réponse donnée. Sage est capable d'utiliser un langage de traitement de texte appelé latex et la bonne syntaxe a été utilisée pour avoir l'effet voulu. Ce n'est pas nécessaire pour l'exercice.   Automatisation de la conversion entre degrés et radians Le but de cet exercice est de créer deux fonctions Sage. La première, étant donné un angle en degrés, va calculer la valeur de l'angle en radians. La seconde, étant donné un angle en radians, va calculer la valeur de l'angle en degrés.   Plus précisément, créer une fonction nommée radians qui va prendre comme argument un nombre réel correspondant à une valeur d'angle en degrés et la convertir en radians. Ensuite, créer une fonction nommée degres qui va prendre comme argument un nombre réel correspondant à une valeur d'angle en radians et la convertir en degrés.     On aimerait maintenant modifier les fonctions afin qu'elle retourne toujours une valeur entre et pour la fonction radians et une valeur entre et pour la fonction degres .  On pourrait procéder de plusieurs manières. On choisit de créer deux fonctions, radians2pi et degres360 qui prennent chacune respectivement une valeur en radians et en degrés et la convertisse dans l'intervalle restreint d'une période. Par la suite, on appellera les fonctions créées ci-dessus pour faire la conversion.  Tester les fonctions en vérifiant que  radians est équivalent à degrés;  radians est équivalent à degrés;  degrés est équivalent à radians;  degrés est équivalent à radians.             La conversion d'un angle de degrés à radians   def radians(theta): #Pour convertir theta degrés en radians theta=theta*2*pi\/360 return theta radians(45) radians(90) radians(340) radians(-60) radians(400)      La conversion d'un angle de radians à degrés   def degres(theta): #Pour convertir theta radians en degrés theta=theta*360\/(2*pi) return theta degres(pi\/4) degres(pi\/2) degres(7*pi\/5) degres(-6*pi\/7) degres(13*pi\/6)      La conversion d'un angle en degrés à l'intervalle   def degres360(theta): #Prend un angle en degrés et le ramène à son équivalent entre 0 et 360 if theta>=0 and theta< 360: return theta else: if theta>=360: while theta>=360: theta=theta-360 return theta else: while theta<0: theta=theta+360 return theta degres360(390) degres360(-60) degres360(1988)      La conversion d'un angle en radians à l'intervalle   def radians2pi(theta): #Prend un angle en radians et le ramène à son équivalent entre 0 et 2pi if theta >=0 and theta <2*pi: return theta else: if theta >=2*pi: while theta >=2*pi: theta=theta-2*pi return theta else: while theta <0: theta=theta+2*pi return theta radians2pi(7*pi\/2) radians2pi(19*pi\/6) radians2pi(-5*pi\/3) radians2pi(2020*pi\/4)      On peut ensuite convertir n'importe quel angle et le ramener sur un intervalle plus conventionel en combinant ces fonctions.   Vérifications demandées   show(\"$\\\\frac{-2020\\pi}{3}\\equiv$\",degres360(degres(-2020*pi\/3))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$\\\\frac{-109\\pi}{5}\\equiv$\",degres360(degres(-109*pi\/5))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$2020^\\circ\\equiv$\",radians2pi(radians(2020))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$-1988^\\circ\\equiv$\",radians2pi(radians(-1988))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360       "
},
{
  "id": "espaceseuclidiens",
  "level": "2",
  "url": "sec-vec.html#espaceseuclidiens",
  "type": "Figure",
  "number": "1.1.1",
  "title": "",
  "body": " Les espaces , et   La droite réelle, le plan cartésien et l'espace tridimensionnel sont illustrés.   "
},
{
  "id": "def-vecgeo",
  "level": "2",
  "url": "sec-vec.html#def-vecgeo",
  "type": "Définition",
  "number": "1.1.2",
  "title": "",
  "body": " Intuitivement, un vecteur géométrique est une flèche possédant:  une longueur, aussi appelée la norme du vecteur;  une orientation, Certains auteurs vont plutôt définir la direction et le sens d'un vecteur. La direction correspond à la droite supportant le vecteur et le sens au sens de parcours de cette droite. qui correspond aux angles que fait le vecteur avec chacun des axes de coordonnées.    Un vecteur sera souvent représenté par une lettre minuscule surmontée d'une flèche, typiquement comme et . On accepte aussi la demi-flèche .  "
},
{
  "id": "rem-vecloca",
  "level": "2",
  "url": "sec-vec.html#rem-vecloca",
  "type": "Remarque",
  "number": "1.1.3",
  "title": "",
  "body": "   Tel que mentionné, un vecteur n'a pas de localisation précise. Le vecteur qui relie le point et est le même vecteur que celui qui relie le point au point puisque si on les considère comme des déplacements, ils sont équivalents.   Par défaut, on place un vecteur à l'origine, sauf s'il y a une utilité à le placer à un autre endroit.   Tous les vecteurs ont une grandeur, notée . Un vecteur dont la norme vaut est appelé un vecteur unitaire et est parfois dénoté avec un chapeau plutôt qu'une flèche, par exemple le vecteur .    Il existe un seul vecteur qui n'a pas d'orientation. C'est le vecteur nul, noté . L'importance de ce vecteur deviendra évidente sous peu.    "
},
{
  "id": "ex-vecgeo",
  "level": "2",
  "url": "sec-vec.html#ex-vecgeo",
  "type": "Exemple",
  "number": "1.1.4",
  "title": "Des vecteurs géométriques: dynamique.",
  "body": " Des vecteurs géométriques: dynamique  Dans la figure, les vecteurs et ont été construits pour être égaux. Il est possible de changer les vecteurs en les manipulant. Il est possible de visualiser la notion de même orientation dans cet exemple.   Premiers contacts avec des vecteurs géométriques    "
},
{
  "id": "ex-vecgeo3d",
  "level": "2",
  "url": "sec-vec.html#ex-vecgeo3d",
  "type": "Exemple",
  "number": "1.1.6",
  "title": "Des vecteurs géométriques en trois dimensions: dynamique.",
  "body": " Des vecteurs géométriques en trois dimensions: dynamique  On note que dans la figure, les vecteurs et sont toujours égaux. Cette figure sera aussi utilisée pour parler du concept d'addition de vecteurs dans la sous-section    Premiers contacts avec des vecteurs géométriques tridimensionnels   "
},
{
  "id": "fig-unvec",
  "level": "2",
  "url": "sec-vec.html#fig-unvec",
  "type": "Figure",
  "number": "1.1.8",
  "title": "",
  "body": " Un vecteur algébrique   Un vecteur algébrique quelconque. Ses coordonnées et sont illustrées de même que l'angle polaire.   "
},
{
  "id": "ex-angler2",
  "level": "2",
  "url": "sec-vec.html#ex-angler2",
  "type": "Exemple",
  "number": "1.1.9",
  "title": "L’angle polaire de vecteurs de dimension 2.",
  "body": " L'angle polaire de vecteurs de dimension 2     Considérons le vecteur , illustré à la figure . Comme on cherche l'angle que fait le vecteur avec l'horizontale, il suffit de faire une fonction pour y arriver: .   Un vecteur du premier quadrant   Un vecteur du premier quadrant      Considérons maintenant , illustré à la figure . Comme ce vecteur est dans le quatrième quadrant, son angle sera donné par (ou ) moins l'angle bleu . Ce dernier peut être calculé avec la fonction , en tenant compte d'ajuster les signes: .   Un vecteur du quatrième quadrant   Un vecteur du quatrième quadrant      Finalement, considérons le vecteur , illustré à la figure . L'angle cherché correspond à (ou ) moins l'angle bleu . Ce dernier peut aussi être calculé avec la fonction , en tenant compte d'ajuster les signes: .   Un vecteur du deuxième quadrant   Un vecteur du deuxième quadrant      "
},
{
  "id": "sageex-defvec",
  "level": "2",
  "url": "sec-vec.html#sageex-defvec",
  "type": "Calcul",
  "number": "1.1.13",
  "title": "Définition de vecteurs sur Sage.",
  "body": " Définition de vecteurs sur Sage  Avec Sage, il est possible de définir des vecteurs, pour ensuite les utiliser pour effectuer des calculs. On commence par nommer un vecteur en le définissant avec la commande vector . À noter que, pour faire la distinction entre les arguments de la commande et le vecteur, on utilise les crochets [ ] pour les vecteurs dans Sage. En cliquant sur \"évaluer\", on peut voir s'afficher le résultat de la cellule.   On rappelle ici, tel que mentionné à , qu'il est possible de faire un affichage plus courant avec la commande show .   Il est possible d'accéder aux composantes d'un vecteur à l'aide des indices. Il est important de se rappeler que dans Sage, la première composante a pour indice 0.   On peut illustrer graphiquement des vecteurs à l'aide d'une commande plot . Ici, on remarque l'utilisation des virgules pour une définition simultanée de deux vecteurs. On utilise aussi le fait que, pour Sage, les graphiques peuvent s'additionner afin d'afficher plusieurs graphiques en une seule sortie.   On remarque que les vecteurs sont par défaut tracés à l'origine, ce qui est cohérent avec la remarque . Si l'on veut faire commencer le vecteur à un autre endroit, disons qui commencerait à la fin de , il est possible de le faire avec l'option start . Cette option sera particulièrement pratique lors de l'addition de vecteur de la sous-section .   Il est possible de calculer la norme d'un vecteur en utilisant la commande norm et l'angle à l'aide des fonctions trigonométriques usuelles.   "
},
{
  "id": "ex-geomultscal",
  "level": "2",
  "url": "sec-vec.html#ex-geomultscal",
  "type": "Exemple",
  "number": "1.1.14",
  "title": "La multiplication par un scalaire: dynamique.",
  "body": " La multiplication par un scalaire: dynamique  Dans la figure, le vecteur est donné. Il est possible de changer le vecteur en le manipulant. En cliquant sur les différentes boites, on peut se donner l'intuition nécessaire pour la multiplication d'un vecteur par un nombre négatif.   La multiplication d'un vecteur géométrique par un scalaire    "
},
{
  "id": "def-multscal",
  "level": "2",
  "url": "sec-vec.html#def-multscal",
  "type": "Définition",
  "number": "1.1.16",
  "title": "Multiplication par un scalaire.",
  "body": " Multiplication par un scalaire   Soit un vecteur et un nombre réel. On définit la multiplication par un scalaire de par , notée simplement , comme étant le vecteur tel que :    ;    l'orientation de est :  la même que celle de si ;  n'existe pas si , car il devient le vecteur nul;  d'angles différents de des angles de si .      "
},
{
  "id": "def-vecpara",
  "level": "2",
  "url": "sec-vec.html#def-vecpara",
  "type": "Définition",
  "number": "1.1.17",
  "title": "Vecteurs parallèles.",
  "body": " Vecteurs parallèles   Deux vecteurs non nuls sont parallèles s'il existe tel que . On écrit alors ou encore .  Par convention, on considère que le vecteur nul n'est parallèle à aucun vecteur En théorie, on aurait aussi pu dire que le vecteur nul est parallèle à tous les vecteurs. .  "
},
{
  "id": "ex-unitarisevec",
  "level": "2",
  "url": "sec-vec.html#ex-unitarisevec",
  "type": "Exemple",
  "number": "1.1.18",
  "title": "Unitariser un vecteur.",
  "body": " Unitariser un vecteur  On considère le vecteur . On cherche le vecteur unitaire .  On commence par calculer la norme du vecteur : .  On obtient le vecteur cherché en divisant par deux: .  "
},
{
  "id": "rem-multscal",
  "level": "2",
  "url": "sec-vec.html#rem-multscal",
  "type": "Remarque",
  "number": "1.1.19",
  "title": "",
  "body": "    Le vecteur s'écrit plus simplement . On l'appelle le vecteur opposé à .    La multiplication par un scalaire est commutative, c'est-à-dire que .    Si , la division par un scalaire est définie simplement comme étant .    "
},
{
  "id": "ex-geoaddvec",
  "level": "2",
  "url": "sec-vec.html#ex-geoaddvec",
  "type": "Exemple",
  "number": "1.1.20",
  "title": "L’addition de vecteurs: dynamique.",
  "body": " L'addition de vecteurs: dynamique  Dans la figure, les vecteurs et sont donnés. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser l'addition de deux vecteurs dans .   L'addition de deux vecteurs géométriques    "
},
{
  "id": "fig-addvecalg",
  "level": "2",
  "url": "sec-vec.html#fig-addvecalg",
  "type": "Figure",
  "number": "1.1.22",
  "title": "",
  "body": " L'addition de vecteurs algébriques   Les vecteurs et sont illustrés en triangle ainsi que le vecteur somme. Chacun des vecteurs et est décomposé selon l'horizontale et la verticale. Le vecteur somme correspond à l'addition des composantes horizontales et verticales   "
},
{
  "id": "ex-geoaddvecasso",
  "level": "2",
  "url": "sec-vec.html#ex-geoaddvecasso",
  "type": "Exemple",
  "number": "1.1.23",
  "title": "L’associativité de l’addition vectorielle: dynamique.",
  "body": " L'associativité de l'addition vectorielle: dynamique  Dans la figure, les vecteurs et sont donnés. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser l'associativité de l'addition vectorielle.   L'associativité de l'addition vectorielle    "
},
{
  "id": "ex-geosousvec",
  "level": "2",
  "url": "sec-vec.html#ex-geosousvec",
  "type": "Exemple",
  "number": "1.1.25",
  "title": "Soustraction de vecteurs: dynamique.",
  "body": " Soustraction de vecteurs: dynamique  Dans la figure, les vecteurs et sont donnés, ainsi que leur addition. Il est possible de changer les vecteurs en les manipulant. En cliquant sur les différentes boites, on peut visualiser les soustractions de deux vecteurs.   Soustraction de deux vecteurs géométriques    "
},
{
  "id": "ex-addsousvec",
  "level": "2",
  "url": "sec-vec.html#ex-addsousvec",
  "type": "Exemple",
  "number": "1.1.27",
  "title": "Additions et soustractions de vecteurs.",
  "body": " Additions et soustractions de vecteurs  Soit et des vecteurs. On calcule et .   Il suffit de calculer directement en utilisant la multiplication par un scalaire et l'addition\/soustraction composante par composante. Pour , on a   De même, pour , on a   "
},
{
  "id": "li-axiomesgeo",
  "level": "2",
  "url": "sec-vec.html#li-axiomesgeo",
  "type": "Liste",
  "number": "1.1.28",
  "title": "Axiomes de la géométrie vectorielle",
  "body": " Axiomes de la géométrie vectorielle    Étant donné deux points , il existe un seul vecteur tel que .  Si , alors nécessairement .   De même, si , alors nécessairement .  (Loi de Chasles).   "
},
{
  "id": "sageex-opvec",
  "level": "2",
  "url": "sec-vec.html#sageex-opvec",
  "type": "Calcul",
  "number": "1.1.29",
  "title": "Opérations sur les vecteurs avec Sage.",
  "body": " Opérations sur les vecteurs avec Sage  Il est possible de multiplier un vecteur par un scalaire et d'additionner et soustraire des vecteurs de manière intuitive avec Sage.   Visuellement, il est possible d'illustrer l'addition et la soustraction avec les commandes apprises à l'exemple .   "
},
{
  "id": "con-probcadre",
  "level": "2",
  "url": "sec-vec.html#con-probcadre",
  "type": "Conseil",
  "number": "1.1.30",
  "title": "Établir son propre cadre.",
  "body": " Établir son propre cadre  Dans les problèmes géométriques, il sera souvent de considérer les points suivants:  Souvent, l'endroit précis où l'origine se trouve n'est pas important. Si une origine n'est pas fixée, cela peut être utile de déterminer un endroit approprié pour la placer.  Déterminer un certain nombre de vecteurs importants et exprimer les autres vecteurs en fonction de ceux-ci est parfois utile.  Dans un dessin, l'horizontale et la verticale n'auront peut-être pas la signification usuelle (celle d'un plan cartésien par exemple). Afin d'illustrer cet aspect, considérer la figure .     Un vecteur à trois dimensions   La figure montre les points et qui sont reliés par un vecteur. Le point milieu entre et est aussi illustré. La figure est dans une perspective à trois dimensions.     Un vecteur à trois dimensions dessiné en deux dimensions   La figure montre les points et qui sont reliés par un vecteur. Le point milieu entre et est aussi illustré. La figure est dans une perspective à deux dimensions     "
},
{
  "id": "ex-dist2p",
  "level": "2",
  "url": "sec-vec.html#ex-dist2p",
  "type": "Exemple",
  "number": "1.1.33",
  "title": "La distance entre deux points.",
  "body": " La distance entre deux points  Soit deux points et . Comment calculer la distance entre ces deux points?  En considérant le vecteur reliant à , on constate que sa norme donne la distance entre les points. Dans le reste du texte, on utilise la notation pour dénoter la distance entre et . Ces objets peuvent être des points, des droites, des plans, etc. Ainsi,  .  En particulier, si et , la distance entre et est   La figure ci-dessous montre l'effet du conseil . La position des points n'est pas vraiment importante pour répondre à la question. Le dessin est là pour aider à visualiser, tout simplement.   Changer le cadre de référence    "
},
{
  "id": "con-3dplanaire",
  "level": "2",
  "url": "sec-vec.html#con-3dplanaire",
  "type": "Conseil",
  "number": "1.1.35",
  "title": "Le 3D n’est pas toujours en trois dimensions.",
  "body": " Le 3D n'est pas toujours en trois dimensions  Dans beaucoup de problèmes, on fera affaire avec des vecteurs à trois dimensions (et même plus, voir la section ). Par contre, cet aspect multidimensionnel n'est pas toujours nécessaire pour répondre à la question. Si l'on cherche la distance entre deux points, qu'ils soient en deux ou trois dimensions, on peut toujours les relier par des droites. Ceci signifie donc que, pour la question, on peut illustrer tous les éléments importants du problème sur un plan à deux dimensions.  "
},
{
  "id": "ex-segpart",
  "level": "2",
  "url": "sec-vec.html#ex-segpart",
  "type": "Exemple",
  "number": "1.1.36",
  "title": "Partage d’un segment.",
  "body": " Partage d'un segment  Soit et , deux points dans .  On souhaite partager le segment en deux parties congrues en trouvant le point milieu. Pour cela, il suffit de réaliser que le point peut être obtenu à partir de en lui ajoutant la moitié du vecteur . Ainsi .  En général, on peut toujours se rendre à un point entre et , situé à fois la longueur de à l'aide de la formule .  L'interaction ci-dessous permet de visualiser.   Proportion d'un segment    "
},
{
  "id": "def-lieu",
  "level": "2",
  "url": "sec-vec.html#def-lieu",
  "type": "Définition",
  "number": "1.1.38",
  "title": "",
  "body": "  Un lieu géométrique est un ensemble de points possédant une propriété commune. Un cercle, une ellipse, une parabole, etc. sont des exemples de lieux géométriques. La plupart du temps, ces lieux sont caractérisés par une équation algébrique.  "
},
{
  "id": "ex-veccercle",
  "level": "2",
  "url": "sec-vec.html#ex-veccercle",
  "type": "Exemple",
  "number": "1.1.39",
  "title": "Le cercle, vu vectoriellement.",
  "body": " Le cercle, vu vectoriellement  Il est possible de définir algébriquement un cercle de rayon centré à l'origine par l'équation . Plus généralement, un cercle centré au point , toujours de rayon aura pour équation . On peut également caractériser un tel cercle vectoriellement. Un cercle constitue l'ensemble des points qui sont à une distance d'un centre . Vectoriellement, on peut traduire cette phrase par une équation avec la norme. Ainsi, un cercle centré en est formé de l'ensemble des points pour lesquels .  "
},
{
  "id": "sageex-utvec",
  "level": "2",
  "url": "sec-vec.html#sageex-utvec",
  "type": "Calcul",
  "number": "1.1.40",
  "title": "Utilisation de Sage dans la résolution de problèmes de géométrie vectorielle.",
  "body": " Utilisation de Sage dans la résolution de problèmes de géométrie vectorielle  On considère le problème suivant. Soit , un quadrilatère quelconque et , le quadrilatère obtenu en joignant les points milieux des segments de . Montrer que est un parallélogramme.  Afin de développer l'intuition nécessaire pour résoudre le problème, il est utile de dessiner certains cas pour voir comment procéder. À travers cet exemple, on explore la commande polygon qui permet de tracer un polygone étant donnée une liste de points ou de vecteurs.  On pourrait d'abord vérifier l'énoncé pour un quadrilatère simple, comme un rectangle. On définit donc les points et on calcule à partir de ceux-ci les points . Par la suite, on trace les deux quadrilatères à l'aide de la commande polygon .   On essaie maintenant avec un quadrilatère moins régulier. Le code est le même, sauf pour la définition des points initiaux.   A-t-on été chanceuses et chanceux avec ces exemples? Pour se convaincre que non, on propose de créer un quadrilatère aléatoire qu'il sera possible de tester autant de fois que souhaité. La commande ZZ.random_element(a,b) permet de générer un entier ( ZZ dans Sage) dans l'intervalle . Lors de certaines exécutions, le quadrilatère sera dégénéré (un triangle ou même une ligne) ou encore, on se retrouvera avec un croisement de deux de ses côtés (dans ce cas, le résultat pourrait être faux). Si cela se produit, ignorer et exécuter à nouveau la cellule. L'exercice s'intéresse à peaufiner le code afin que le quadrilatère formé soit toujours valide.   On est maintenant prêt à démontrer le résultat, en s'appuyant sur l'intuition géométrique offerte par les graphiques Sage. On veut montrer que et . Puisque        et      ,  les vecteurs et sont égaux, car les membres de droite des équations et sont égaux.  De même, en se servant des équations ci-dessus, on a et . Puisque les membres de droite des équations et sont égaux, les vecteurs et sont égaux.  "
},
{
  "id": "exo-vecgeoab",
  "level": "2",
  "url": "sec-vec.html#exo-vecgeoab",
  "type": "Exercice",
  "number": "1.1.4.1",
  "title": "",
  "body": " Considérer les vecteurs et . Calculer algébriquement les vecteurs suivants, représenter-les dans un plan cartésien et calculer l'orientation et la longueur.                                                                          On trace le vecteur à l'origine pour connaitre son direction approximative. On voit qu'il est dans le deuxième quadrant. On trouvera donc l'angle aigu ( ) avec la trigonométrie et on lui additionnera l'angle droit. On utilise toujours puisqu'on connait les côtés adjacent et opposé à l'angle .   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-1,6) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi:      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant. On donc l'angle avec la trigonométrie.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (5,4) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :     On trace le vecteur . On remarque qu'il s'agit du vecteur opposé à celui de la question précédente. On va utiliser cette information pour gagner du temps. Sa longueur est identique et son orientation est de de plus (ou moins!).   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-5,-4) ainsi que son angle polaire donnant son orientation.     La longueur est donc:      On trace le vecteur à l'origine pour connaitre son direction approximative. On voit qu'il est dans le troisième quadrant. On trouvera donc l'angle aigu ( ) avec la trigonométrie et on lui additionnera les manquants.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (-4,-10) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi:      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (3,16) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant.   Le vecteur résultat et son orientation   Le vecteur partant de l'origine et allant au point (11,2) ainsi que son angle polaire donnant son orientation.     La longueur est calculée ainsi :      On trace le vecteur et on voit qu'il se trouve dans le premier quadrant. On remarque que ce vecteur correspond au vecteur que l'on a multiplié par le scalaire sur sa norme. C'est ainsi qu'on \\emph{unitarise} un vecteur. Son orientation sera la même que le vecteur qu'on a tracé plus pâle pour les visualiser ensemble.   Le vecteur résultat et son orientation   Le vecteur unitaire partant de l'origine dans la même orientation que le vecteur (2,5) ainsi que son angle polaire. Le vecteur (2,5) est tracé derrière plus pâle.     La longueur est automatiquement de puisque c'est un vecteur unitaire. Calculons-la, pour vérifier :      On trace le vecteur et on voit qu'il se trouve dans le deuxième quadrant. Il s'agit encore une fois d'un vecteur unitaire. C'est celui du premier exercice de ce numéro. On en connait donc déjà l'orientation et la longueur.   Le vecteur résultat et son orientation   Le vecteur unitaire partant de l'origine dans l'orientation du vecteur (-1,6) ainsi que son angle polaire. Le vecteur (-1,6) est tracé derrière plus pâle.     La longueur est automatiquement de puisque c'est un vecteur unitaire :     "
},
{
  "id": "exo-norm3",
  "level": "2",
  "url": "sec-vec.html#exo-norm3",
  "type": "Exercice",
  "number": "1.1.4.2",
  "title": "",
  "body": " Soit un vecteur allant de l'origine jusqu'au point . Démontrer que la longueur de ce vecteur est donnée par: .   Pour vous aider, voici une représentation graphique de ce vecteur dans l'espace cartésien.   Le vecteur dans l'espace     Le théorème de Pythagore et le concept de projection suffisent pour démontrer cette formule. On considère tout d'abord le vecteur , la projection de sur le plan . Il est évident que . Ainsi, par Pythagore, la longueur de ce vecteur est: . La longueur de est maintenant calculable en utilisant de nouveau le théorème avec le triangle à la verticale dont la première cathète est la longueur de et la seconde est la composante en de :   "
},
{
  "id": "exo-vecgeopoint",
  "level": "2",
  "url": "sec-vec.html#exo-vecgeopoint",
  "type": "Exercice",
  "number": "1.1.4.3",
  "title": "",
  "body": " Soit le point et le vecteur suivants. Déplacer les points à afin qu'ils correspondent aux descriptions suivantes. Noter qu'il peut y avoir plusieurs réponses valides.          L'espace du problème     Il n'y a qu'une réponse possible, sauf pour où il y en a une infinité. L'explication vous permettra de visualiser l'ensemble des réponses possibles.   L'espace du problème avec solution     On doit partir de et effectuer un déplacement correspondant à pour arriver à .  On doit partir de et effectuer un déplacement correspondant à 2 fois pour arriver à .  On doit placer de telle sorte que sa distance à est égale à la longueur de . Il y a une infinité de réponses possibles puisqu'on peut le placer n'importe où sur le cercle de rayon autour de .   On doit placer de telle sorte que le déplacement de à soit le même que de à . En manipulant les outils, on voit que, si l'on place d'un côté de , les vecteurs et sont de sens opposés. Ils ne peuvent donc jamais être égaux. La seule façon d'avoir est de placer sur . Ainsi, .   On doit partir de et effectuer un déplacement correspondant à 3 fois dans le sens opposé pour arriver à .   "
},
{
  "id": "exo-decrirelieux",
  "level": "2",
  "url": "sec-vec.html#exo-decrirelieux",
  "type": "Exercice",
  "number": "1.1.4.4",
  "title": "",
  "body": " Soit le point et le vecteur tels qu'illustrés. On indique que . Décrire le lieu géométrique de l'ensemble des points répondant à chaque expression.       a la même orientation que     L'espace du problème      Le cercle de centre et de rayon 1.  Le disque de centre et de rayon 2.  L'anneau de centre , de rayon extérieur 3 et de rayon intérieur 1.  La droite parallèle à et passant par .  La demi-droite issue de dans l'orientation de excluant .  L'ensemble des points sur la droite parallèle à et passant par qui sont à une distance entière de . Cela inclut le point .   "
},
{
  "id": "exo-trouverpoints",
  "level": "2",
  "url": "sec-vec.html#exo-trouverpoints",
  "type": "Exercice",
  "number": "1.1.4.5",
  "title": "",
  "body": " Soit et , deux points distincts dans l'espace ( ). Décrire le lieu géométrique de l'ensemble des points répondant à chaque expression.         L'espace du problème      Le point doit être le point milieu du segment .  Aucun point ne satisfait à cette condition.  Tous les points se situant sur le plan perpendiculaire à , passant par le point milieu de ce même segment.   "
},
{
  "id": "exo-trouvercoordo2D",
  "level": "2",
  "url": "sec-vec.html#exo-trouvercoordo2D",
  "type": "Exercice",
  "number": "1.1.4.6",
  "title": "",
  "body": " Dans le parallélogramme suivant, trouver les coordonnées du point .   Le parallélogramme   Un parallélogramme formé des points (-3,2), (3,-1), (0,-3) et du point D dont les coordonnées sont inconnues.     Il est conseillé d'identifier chaque point connu par une lettre et de calculer les composantes des différents vecteurs reliant ces points. Choisir ensuite un point de départ dont les coordonnées sont connues et se déplacer selon un vecteur en additionnant ses composantes pour aller au point dont les coordonnées sont inconnues.   Les coordonnées du point sont .   Identifions les points suivants: , et sur le dessin.  Alors, le vecteur suivant se calcule facilement.  Finalement, on part du point et on arrive à en se déplaçant selon puisque . Ainsi, on a calculé les coordonnées du point .  "
},
{
  "id": "exo-pointpartage",
  "level": "2",
  "url": "sec-vec.html#exo-pointpartage",
  "type": "Exercice",
  "number": "1.1.4.7",
  "title": "",
  "body": " Calculer les coordonnées du point se situant aux du segment à partir du point . Les coordonnées des points sont et .   Les coordonnées de ce point sont .   La méthode préférée ici consiste à débuter par un point connu ( , par exemple), de trouver un vecteur dans la direction où l'on veut se déplacer ( , par exemple) et finalement de l'étirer à la longueur voulue. De cette démarche, on obtient la formule suivante: Les coordonnées du point cherché sont donc .  "
},
{
  "id": "exo-axiomesgeo",
  "level": "2",
  "url": "sec-vec.html#exo-axiomesgeo",
  "type": "Exercice",
  "number": "1.1.4.8",
  "title": "",
  "body": " En utilisant les quatre axiomes initiaux de la géométrie vectorielle ( ), démontrer les trois propriétés suivantes.    Si , alors .       L'axiome 4 appliqué au vecteur permet d'écrire . De ce qu'on connait de l'addition vectorielle, on peut additionner de chaque côté de l'égalité par le vecteur . Ainsi,    On a .    Sachant que , alors,    "
},
{
  "id": "exo-inegaltriangle",
  "level": "2",
  "url": "sec-vec.html#exo-inegaltriangle",
  "type": "Exercice",
  "number": "1.1.4.9",
  "title": "",
  "body": " Déplacer les vecteurs et afin que les égalités ou inégalités suivantes soient vérifiées, une à la fois. Ensuite, énoncer en mots pour chacune les conditions nécessaires à leur vérification.   (l'inégalité du triangle)        L'espace du problème      Cette inégalité se nomme l'inégalité du triangle. Elle est toujours vraie pour deux vecteurs et . Comme son nom l'indique, on la représente bien lorsque les deux vecteurs sont additionnés avec la méthode du triangle, tel que le dessin le montre. Elle signifie que la somme des longueurs des deux premiers côtés sera toujours supérieure à la longueur du dernier côté.  Les seules possibilités que cela soit faux impliquent ou (ou les deux!) ou lorsque les deux vecteurs ont la même orientation. Dans ce dernier cas, les trois vecteurs seraient donc sur une seule droite et l'addition de et donne un vecteur de même longueur que l'addition de leurs longueurs.  À l'inverse de la lettre précédente, cette égalité est vraie dans les trois cas donnés, mais elle ne l'est pas lorsque les deux vecteurs sont nuls. Bref, lorsque ou lorsque (mais pas les deux!) ou lorsque les deux vecteurs ont la même orientation.  Dans ce cas, avec les restrictions imposées, il faut absolument que les deux vecteurs soient non-nuls et aient la même orientation.  Ce dernier cas est particulier. Il faut y réfléchir ainsi: on cherche à créer un triangle avec l'addition de vecteurs et on veut que chaque côté ait la même longueur. Bref, on veut un triangle équilatéral. Il faut donc que et soient de même longueur et forment un angle de pour que l'énoncé soit vérifié.   "
},
{
  "id": "exo-diagpara",
  "level": "2",
  "url": "sec-vec.html#exo-diagpara",
  "type": "Exercice",
  "number": "1.1.4.10",
  "title": "",
  "body": " Montrer que les diagonales de n'importe quel parallélogramme se croisent en leurs milieux.   Utiliser les axiomes de la géométrie vectorielle ( ). Le dessin suivant peut vous être utile.   Les diagonales d'un parallélogramme    On peut reformuler la preuve demandée ainsi: si est le point milieu de , alors montrer que . On sait donc, par la définition de point milieu, que .   Soit un parallélogramme et , le point milieu de , tel qu'illustré dans l'indice. Alors,   Aussi, maintenant qu'on a prouvé cette égalité, on peut écrire:   "
},
{
  "id": "exo-preuve-ptsmilieux",
  "level": "2",
  "url": "sec-vec.html#exo-preuve-ptsmilieux",
  "type": "Exercice",
  "number": "1.1.4.11",
  "title": "",
  "body": " Soit le triangle et les points et se trouvant respectivement au milieu des segments et . Montrer que .   Une histoire de milieu   Le triangle ABC ainsi que les points M et N respectivement milieux des segments AB et AC.     Utiliser les axiomes de la géométrie vectorielle ( ) et le conseil suivant: passer par un détour pour exprimer le vecteur .   On va réécrire le vecteur en utilisant d'autres vecteurs et utiliser le fait que et sont des points milieux.   "
},
{
  "id": "exo-propvec2",
  "level": "2",
  "url": "sec-vec.html#exo-propvec2",
  "type": "Exercice",
  "number": "1.1.4.12",
  "title": "",
  "body": " Les propriétés suivantes sur les vecteurs découlent naturellement de leur interprétation géométrique. Nous avons déjà vérifié certaines d'entre elles intuitivement. Dans cet exercice, démontrer algébriquement leur validité en utilisant les définitions algébriques de l'addition vectorielle et de la multiplication par un scalaire .  Soit , et et et . Alors,   (commutativité de l'addition vectorielle)  (associativité de l'addition vectorielle)  (neutre additif)  (inverse additif)  (associativité de la multiplication par un scalaire)  (distributivité sur l'addition vectorielle)  (distributivité de l'addition des scalaires)  (neutre multiplicatif)              "
},
{
  "id": "exo-vecprisme",
  "level": "2",
  "url": "sec-vec.html#exo-vecprisme",
  "type": "Exercice",
  "number": "1.1.4.13",
  "title": "",
  "body": " Observer le prisme ci-dessous et donner un seul vecteur reliant deux points qui exprime les déplacements suivants.   Un prisme à base triangulaire   Un prisme ayant comme base le triangle ABC.              Puisque l'on spécifie qu'il s'agit d'un prisme, on peut considérer que . De même, les deux triangles formant les bases du prisme sont parallèles et donc les vecteurs parallèles sont égaux. Par exemple, .  Ainsi, pour exprimer le déplacement correspondant à , il faut considérer que et donc que , en utilisant la Loi de Chasles .  Finalement, remarquer qu'il y a parfois plusieurs réponses possibles.      ou ou   ou ou  ou    "
},
{
  "id": "exo-VFvecpara",
  "level": "2",
  "url": "sec-vec.html#exo-VFvecpara",
  "type": "Exercice",
  "number": "1.1.4.14",
  "title": "",
  "body": " Observer le parallélipipède suivant et dire si les énoncés ci-dessous sont vrais ou faux.   Un parallélipipède   Un parallélipipède ayant comme base le parallélogramme ABCD.                Vrai  Faux  Vrai  Vrai  Faux  Faux  Vrai  Faux    Il y a plusieurs façons de raisonner pour déterminer si les vecteurs de ces énoncés sont égaux. Avant de débuter, on donne quelques principes importants pour structurer le raisonnement à l'écrit. D'abord, on veut souvent exprimer un vecteur de façon équivalente en utilisant d'autres points pour le décrire. Ensuite, on veut exprimer l'addition de vecteurs de façon équivalente avec un seul vecteur (Loi de Chasles) . Finalement, il peut arriver que l'on veuille effectuer les étapes précédentes dans l'ordre inverse et ainsi exprimer un vecteur comme l'addition de deux ou trois vecteurs afin d'expliciter comment il s'annule avec d'autres vecteurs. Noter qu'il est utile de réorganiser l'ordre de l'addition des vecteurs pour mieux communiquer ce qu'on simplifie.   Ces vecteurs sont clairement parallèles et de même longueur. C'est donc vrai qu'ils sont égaux.   C'est donc faux.     C'est donc vrai.     C'est donc vrai.     C'est donc faux.     C'est donc faux.     C'est donc vrai.     C'est donc faux.    "
},
{
  "id": "exosage-vec-1",
  "level": "2",
  "url": "sec-vec.html#exosage-vec-1",
  "type": "Exercice",
  "number": "1.1.4.15",
  "title": "",
  "body": " Soit et deux vecteurs de .   Définir et tracer les vecteurs et sur un même graphique, le vecteur en rouge et le vecteur en bleu. Les deux vecteurs partent de l'origine.    Les vecteurs et   Les vecteurs u et v sont tracés tel que demandé, respectivement en rouge et en bleu.       Le code solution pour l'exercice   u=vector([-1,2]) v=vector([2,1]) plot(u,color=\"red\")+plot(v,color=\"blue\")     Calculer le vecteur et donner sa norme.    Le vecteur est et la norme est .     Tracer un parallélogramme passant par le point qui est engendré par les vecteurs . Utiliser des couleurs différentes pour chaque côté du parallélogramme. Identifier les vecteurs avec la commande text(\"texte\",(x,y)) où \"texte\" est le nom du vecteur et sa position.     Un parallélogramme engendré par les vecteurs et passant par le point .   Le parallélogramme passant par le point (1,3) est tracé à partir des vecteurs u et v.       Le code solution pour l'exercice   u1=plot(u,start=(1,3),color=\"red\")+text('$\\\\vec{u}$',(0.5,3.6),color=\"red\") v1=plot(v,start=(1,3),color=\"blue\")+text('$\\\\vec{v}$',(2,3.4),color=\"blue\") u2=plot(u,start=vector([1,3])+v,color=\"green\")+text('$\\\\vec{u}$',(2.5,5.3),color=\"green\") v2=plot(v,start=vector([1,3])+u,color=\"orange\")+text('$\\\\vec{v}$',(1,5.4),color=\"orange\") u1+u2+v1+v2    Remarquer que, pour placer certains vecteurs au bon endroit, il a fallu convertir le point en vecteur afin de pouvoir lui additionner un vecteur. Sage ne veut pas additionner un vecteur à un point. Votre texte est aussi probablement plus simple que la réponse donnée. Sage est capable d'utiliser un langage de traitement de texte appelé latex et la bonne syntaxe a été utilisée pour avoir l'effet voulu. Ce n'est pas nécessaire pour l'exercice.  "
},
{
  "id": "exosage-vec-4",
  "level": "2",
  "url": "sec-vec.html#exosage-vec-4",
  "type": "Exercice",
  "number": "1.1.4.16",
  "title": "Automatisation de la conversion entre degrés et radians.",
  "body": "Automatisation de la conversion entre degrés et radians Le but de cet exercice est de créer deux fonctions Sage. La première, étant donné un angle en degrés, va calculer la valeur de l'angle en radians. La seconde, étant donné un angle en radians, va calculer la valeur de l'angle en degrés.   Plus précisément, créer une fonction nommée radians qui va prendre comme argument un nombre réel correspondant à une valeur d'angle en degrés et la convertir en radians. Ensuite, créer une fonction nommée degres qui va prendre comme argument un nombre réel correspondant à une valeur d'angle en radians et la convertir en degrés.     On aimerait maintenant modifier les fonctions afin qu'elle retourne toujours une valeur entre et pour la fonction radians et une valeur entre et pour la fonction degres .  On pourrait procéder de plusieurs manières. On choisit de créer deux fonctions, radians2pi et degres360 qui prennent chacune respectivement une valeur en radians et en degrés et la convertisse dans l'intervalle restreint d'une période. Par la suite, on appellera les fonctions créées ci-dessus pour faire la conversion.  Tester les fonctions en vérifiant que  radians est équivalent à degrés;  radians est équivalent à degrés;  degrés est équivalent à radians;  degrés est équivalent à radians.             La conversion d'un angle de degrés à radians   def radians(theta): #Pour convertir theta degrés en radians theta=theta*2*pi\/360 return theta radians(45) radians(90) radians(340) radians(-60) radians(400)      La conversion d'un angle de radians à degrés   def degres(theta): #Pour convertir theta radians en degrés theta=theta*360\/(2*pi) return theta degres(pi\/4) degres(pi\/2) degres(7*pi\/5) degres(-6*pi\/7) degres(13*pi\/6)      La conversion d'un angle en degrés à l'intervalle   def degres360(theta): #Prend un angle en degrés et le ramène à son équivalent entre 0 et 360 if theta>=0 and theta< 360: return theta else: if theta>=360: while theta>=360: theta=theta-360 return theta else: while theta<0: theta=theta+360 return theta degres360(390) degres360(-60) degres360(1988)      La conversion d'un angle en radians à l'intervalle   def radians2pi(theta): #Prend un angle en radians et le ramène à son équivalent entre 0 et 2pi if theta >=0 and theta <2*pi: return theta else: if theta >=2*pi: while theta >=2*pi: theta=theta-2*pi return theta else: while theta <0: theta=theta+2*pi return theta radians2pi(7*pi\/2) radians2pi(19*pi\/6) radians2pi(-5*pi\/3) radians2pi(2020*pi\/4)      On peut ensuite convertir n'importe quel angle et le ramener sur un intervalle plus conventionel en combinant ces fonctions.   Vérifications demandées   show(\"$\\\\frac{-2020\\pi}{3}\\equiv$\",degres360(degres(-2020*pi\/3))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$\\\\frac{-109\\pi}{5}\\equiv$\",degres360(degres(-109*pi\/5))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$2020^\\circ\\equiv$\",radians2pi(radians(2020))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360 show(\"$-1988^\\circ\\equiv$\",radians2pi(radians(-1988))) #On convertit en degres et ensuite on ramène dans l'intervalle 0-360    "
},
{
  "id": "sec-prodscal",
  "level": "1",
  "url": "sec-prodscal.html",
  "type": "Section",
  "number": "1.2",
  "title": "Produit scalaire et calcul d’angles",
  "body": "  Produit scalaire et calcul d'angles    Aller aux exercices de la section.  Dans la section , on a défini le concept d'angle polaire pour un vecteur de , et, plus généralement, le concept de cosinus directeurs. Pour l'angle polaire, on peut imaginer que c'est l'angle que fait le vecteur avec tout vecteur de la forme où .  Dans cette section, on vise à définir le concept d'angle entre deux vecteurs quelconques dans et . Ceci nous mènera à la définition du produit scalaire, une opération vectorielle qui a de nombreuses applications.     L'angle entre deux vecteurs de dimensions deux  Considérons deux vecteurs non nuls et de et dénotons par le plus petit angle entre ces vecteurs S'il n'y a pas d'ambigüité et que le contexte est clair, on laissera tomber l'indice au profit de seulement . . On cherche à trouver un moyen de déterminer cet angle à partir des vecteurs et . L'image interactive permet de manipuler des vecteurs et de découvrir l'intuition derrière la formule qui suivra.   L'angle entre deux vecteurs de dimensions deux: dynamique  L'angle entre deux vecteurs peut être obtenu à l'aide d'un résultat bien connu à propos des triangles.   L'angle entre deux vecteurs    Algébriquement, on peut développer le numérateur de la formule obtenue pour simplifier. Il est bon de rappeler que le vecteur , voir la figure . On a donc .  De cette équation, on peut tirer quelques remarques. On peut, dans un premier temps, vérifier que si et sont parallèles, alors l'angle sera ou ( ou ). En effet, si , on a .  Comme le cosinus donne ou , on conclut que l'angle doit être de ou .  Une autre valeur particulière pour l'angle est ( ). Ceci correspond à des vecteurs qui sont perpendiculaires. Puisque , on conclut que lorsque deux vecteurs sont perpendiculaires.   Un calcul d'angle  On considère les vecteurs et . Le cosinus de l'angle entre ces vecteurs est .  L'angle entre les vecteurs est donc radians ou encore degrés.   La situation dans est similaire. Puisque deux vecteurs non nuls peuvent toujours être vus comme étant sur un plan ou sur une droite (s'ils sont parallèles), un argument similaire permet d'obtenir l'équation suivante pour l'angle entre des vecteurs : , voir l'exercice .  À voir ces deux équations, on peut remarquer que l'addition du produit des composantes correspondantes de deux vecteurs semble être une quantité importante. Elle sera définie dans la sous-section .    Le produit scalaire  Motivé par les calculs de la sous-section , on définit algébriquement le produit scalaire pour ensuite regarder ses propriétés autant algébriques que géométriques.   Le produit scalaire  Soit deux vecteurs de ou . On définit le produit scalaire de ces vecteurs, noté , comme étant la somme du produit des composantes correspondantes, c'est-à-dire .   Le produit scalaire, comme son nom l'indique, donne un nombre réel (un scalaire), et non un vecteur. En reprenant l'équation pour l'angle entre deux vecteurs, on peut écrire . Comme les normes sont toujours positives et que le cosinus varie entre et , le produit scalaire peut être positif ou négatif, selon l'angle, et de n'importe quelle grandeur, selon les normes.  On a déjà observé que, si l'angle entre deux vecteurs est , le produit scalaire vaut . Le signe du produit scalaire correspond alors au type d'angle (aigu ou obtus) qu'il y a entre les deux vecteurs.  Voici maintenant quelques propriétés du produit scalaire.   Le produit scalaire entre deux vecteurs quelconques possède les propriétés suivantes:   Les propriétés du produit scalaire    (commutativité du produit scalaire)  pour tout .  (distributivité du produit scalaire)       La plupart de ces propriétés découlent directement des propriétés de l'addition et de la multiplication de nombres réels. Par exemple, pour deux vecteurs de , on a . À remarquer que la propriété donne l'analogue à droite de la propriété .  Géométriquement, l'équation permet aussi de voir que la propriété est toujours valide étant donné que .  La seconde propriété est aussi algébriquement simple à démontrer. Il est toutefois intéressant de constater l'effet géométrique de la multiplication par un scalaire d'un vecteur sur le produit scalaire. Dans un premier temps, si , on a .  Et si , alors .   L'angle entre les vecteurs et .    Finalement, le cas découle simplement du fait que .  La troisième propriété n'est qu'une simple manipulation algébrique. Dans le cas de vecteurs dans , on a . Une démonstration géométrique sera donnée à l'exercice   Finalement, tant géométriquement qu'algébriquement, la démonstration de la dernière propriété est simple. Par exemple, avec l'équation , on a .    Les vecteurs perpendiculaires seront d'une grande importance. Deux vecteurs perpendiculaires sont aussi dits orthogonaux.   Lorsqu'on généralise les concepts d'algèbre linéaire à des structures plus abstraites, la notion de perpendiculaire est difficile à imaginer. Toutefois, le concept de produit scalaire nul reste important. C'est pourquoi en mathématiques, on utilise le terme orthogonal, du grec orthos , droit, et du grec gōnia , angle.    Les diagonales d'un losange  On sait que deux vecteurs non parallèles engendrent un parallélogramme. Dans l'exercice , on peut montrer que les diagonales se coupent en leur milieu. Lorsque les deux vecteurs ont la même longueur, on obtient en fait un losange. On montre algébriquement que les diagonales d'un losange se coupent à angle droit. La figure interactive permet de manipuler un losange et servira de support pour la preuve qui suit.   Les diagonales d'un losange    Pour commencer, il est utile de se fixer un repère. En cliquant sur la case \"repère\", on choisit de fixer l'origine à l'un des quatre sommets du losange et de nommer les autres sommets et . On veut montrer que est perpendiculaire à ou, de manière équivalente, que . On a comme hypothèse que et donc que les quatre côtés sont égaux. En réécrivant les diagonales comme étant respectivement la somme et la différence des vecteurs , on a . Ainsi, les diagonales sont perpendiculaires, car le produit scalaire donne .   Dans l'exercice , on montre que, similairement à la somme de nombres réels, le carré de la norme d'une somme introduit un facteur croisé dans la réponse: . On peut aussi borner les valeurs possibles du produit scalaire. On appelle l'inégalité de Cauchy-Schwarz la proposition qui suit. On donne plusieurs démonstrations de cette proposition, afin de montrer qu'il peut souvent y avoir plusieurs manières d'arriver à une solution à un problème.    L'inégalité de Cauchy-Schwarz   Soit des vecteurs. Alors .    On peut procéder à partir de la définition par le calcul d'angle. Puisque , l'inégalité découlant du fait que .    Une autre manière est de procéder avec une combinaison d'arguments géométriques et algébriques. On remarque que si l'un des vecteurs est , alors l'inégalité est vraie, car et .  On suppose donc que les vecteurs sont non nuls. En ayant en tête l'image du parallélogramme engendré par les vecteurs et ses diagonales, reproduite à la figure , on constate que   Le parallélogramme engendré par les vecteurs, et ses diagonales   Les vecteurs u et v sont illustrés, ainsi que le parallélogramme qu'ils engendrent. De plus, on voit les diagonales formées par u plus v et u moins v.    On regarde ce qui se passe dans un premier temps avec les vecteurs unitaires et . On s'intéresse aux longueurs des diagonales du parallélogramme engendré par ces vecteurs unitaires. On a .  Parce que les vecteurs sont unitaires, les deux équations se réduisent à , et comme ce sont des longueurs, elles sont plus grandes ou égales à d'où l'on obtient que , ce qui revient à dire que .  En reprenant la définition des vecteurs unitaires, on obtient .   Voir l'exercice pour une preuve utilisant les zéros d'une parabole.   Le produit scalaire est utilisé dans beaucoup de domaines et contextes différents. En physique, il permet de calculer le travail effectué par une force. Dans un contexte administratif, par exemple une école, le produit scalaire peut être utilisé pour calculer la note d'un étudiant dans un cours. Si ses résultats aux évaluations sont par exemple de et que la pondération des évaluations est , alors la note de l'étudiant sera , qui n'est rien d'autre que le produit scalaire entre et .  Une fois que l'on comprend que le produit scalaire n'est qu'une somme de produits, les possibilités sont illimitées.  On termine avec des commandes Sage en lien avec la sous-section.   Le produit scalaire avec Sage  Il est possible de calculer le produit scalaire entre et avec la commande u.dot_product(v) . Il est également possible d'utiliser plus simplement u*v .   Pour calculer l'angle entre deux vecteurs, on utilise la formule .      La projection orthogonale  Considérons deux vecteurs non nuls et considérons la droite de même direction que . On aimerait trouver le point sur cette droite qui est le plus près de l'extrémité de . L'intuition nous dit qu'il faut aller vers en partant de , dans une direction perpendiculaire à . On crée de cette façon un vecteur parallèle à . On cherche à déterminer mathématiquement ce vecteur, noté .   La projection orthogonale    Par définition, le vecteur allant de à l'extrémité de est perpendiculaire à . Ce vecteur n'est rien d'autre que . De plus, le vecteur étant parallèle à ( ), il est possible de déterminer le bon scalaire : .  En réarrangeant la dernière égalité, on obtient le scalaire menant à la définition mathématique du vecteur :   La projection orthogonale  Soit deux vecteurs non nuls . La projection de sur , notée , est l'unique vecteur pour lequel   est parallèle à ;  est perpendiculaire à .  Si l'un des vecteurs est nul, on définit .  La projection orthogonale est donnée par la formule suivante : .   Algébriquement, on voit que si les vecteurs et sont perpendiculaires, la projection sera nulle. La figure interactive permet aussi de voir géométriquement cet aspect.   Le pied de la hauteur   Un triangle est formé des points et . On cherche les coordonnées du point correspondant au pied de la hauteur issue de .  On trace le triangle dans un repère quelconque.   Le pied de la hauteur   Le triangle ABC est illustré, ainsi que la hauteur issue de C menant au point H.    Le point cherché peut être obtenu en additionnant au point le vecteur correspondant à la projection de sur , ou de manière équivalente en ajoutant à le vecteur correspondant à la projection de sur . On choisit la première option: .    On termine avec des commandes Sage en lien avec la sous-section.   La projection orthogonale sur Sage  Avec les commandes apprises jusqu'à maintenant, on peut calculer la projection orthogonale d'un vecteur sur un autre grâce à la formule .   On illustre les vecteurs afin de visualiser le résultat.       Les éléments importants de cette section sont:  L'angle entre deux vecteurs, donné par les formules et ;  Le produit scalaire de deux vecteurs, dont le signe donne une idée de l'orientation relative des vecteurs;  L'inégalité de Cauchy-Schwarz ;  La notion de projection orthogonale, donnée par la formule .    De plus, avec Sage, on peut utiliser l'opération * sur deux vecteurs pour avoir le produit scalaire. Les opérations algébriques usuelles permettent de calculer l'angle entre deux vecteurs ou la projection orthogonale.      Exercices    Pour chacune des paires de vecteurs suivantes, calculer le produit scalaire ainsi que l'angle entre les vecteurs.     et        et        et        et        et        et        et        et       Pour quelle(s) valeur(s) de les vecteurs suivants sont-ils orthogonaux (perpendiculaires)?             . Comme n'importe quelle valeur de permet de satisfaire cette équation, il s'ensuit que ces vecteurs sont toujours perpendiculaires.           Deux vecteurs sont orthogonaux lorsque leur produit scalaire est nul.        Soit deux vecteurs et et . Simplifier les expressions suivantes en vous servant des propriétés de la proposition . Dire si la réponse est un scalaire ou un vecteur.      C'est un scalaire.   C'est un scalaire.      C'est un vecteur.   C'est un vecteur. En effet, on a une constante multipliée par une norme additionnée d'un produit scalaire. Tout cela ensemble est un scalaire. On le multiplie ensuite par le vecteur (multiplication par un scalaire) et le résultat est donc un vecteur.    Soit et . Utiliser la loi des cosinus afin de démontrer l'équation . Il faudra exprimer la loi en termes des normes des vecteurs , et du vecteur avec représentant l'angle entre les deux vecteurs.      Démontrer la propriété (distributivité du produit scalaire) en utilisant la définition géométrique du produit scalaire . Utiliser les symboles fournis par le dessin pour les angles entre les différents vecteurs.           Soit deux vecteurs ou . En utilisant les propriétés de la proposition , démontrer l'égalité suivante:   Comme pour beaucoup de preuves d'énoncés sous forme d'égalités, il faut commencer par réécrire le membre de l'égalité qui nous semble le plus compliqué. On suggère de commencer par celui de droite, bien que celui de gauche serait tout aussi simple dans ce cas.   Tel que mentionné dans l'indication, on choisit de partir du membre de droite pour se rendre au membre de gauche de l'égalité.    Soit deux vecteurs et . Démontrer algébriquement les deux énoncés suivants en vous servant des propriétés de la proposition .            À l'aide de vecteurs, calculer l'angle entre la plus longue diagonale d'un cube et la diagonale adjacente d'une de ses faces, tel que représenté dans la figure.        Considérer l'origine des deux diagonales comme l'origine d'un espace cartésien. Créer des vecteurs en considérant que la longueur du côté du cube est de .   L'angle entre les diagonales est radians ou encore degrés.   Considérant l'origine des deux diagonales comme l'origine d'un espace cartésien et la longueur du côté du cube égale à , les vecteurs créés ont pour composantes respectivement et . L'angle désiré devient tout simplement l'angle entre ces deux vecteurs. On le calcule comme à l'exemple  .  L'angle entre les vecteurs et donc entre les diagonales est alors radians ou encore degrés. De plus, on constate que cet angle ne dépend pas de la longueur du côté du cube.    Une molécule de méthane a quatre atomes d'hydrogène aux points indiqués sur la figure ci-dessous et un atome de carbone à l'origine. Trouver l'angle du lien H-C-H.   Une molécule de méthane     L'angle du lien H-C-H est radians ou encore degrés.   On calcule l'angle illustré en vert dans la figure. Il s'agit de l'angle entre les vecteurs et . Les composantes de ces vecteurs sont données directement par les coordonnées des points et puisque le point est l'origine. Ainsi, et .   L'angle entre les vecteurs et donc l'angle du lien H-C-H est radians ou encore degrés.    L'orientation d'un vecteur de est complètement déterminée par l'angle que fait le vecteur avec l'horizontale. Dans , un angle ne suffit plus. Il est toutefois possible de caractériser l'orientation à l'aide de trois angles.  Soit un vecteur non nul. On note l'angle que fait le vecteur avec l'axe des abscisses , l'angle que fait le vecteur avec l'axe des ordonnées et l'angle que fait le vecteur avec l'axe des cotes .       Démontrer les affirmations suivantes:   Le vecteur s'écrit comme . On appelle le triplet les cosinus directeurs du vecteur .   En regardant la figure interactive, on voit qu'il y a un triangle rectangle formé par chaque axe dont l'hypoténuse est le vecteur et une cathète correspond à la coordonnée dans cet axe. Par exemple, on voit que le vecteur forme un angle de avec l'axe des . On peut donc déterminer avec la trigonométrie du triangle rectangle que le côté adjacent à l'angle est donné par l'hypoténuse multiplié par le cosinus de l'angle. Ainsi, On a donc:  Une autre approche serait d'utiliser la définition géométrique du produit scalaire donnée par l'équation . En effet, en prenant le produit scalaire du vecteur avec chaque vecteur unitaire dans la direction des axes, on obtient:  Les deux autres composantes se retrouvent de façon similaire.      En isolant chaque cosinus des équations précédentes, on a: .   Dans , la notion de cosinus directeurs existe aussi et un vecteur s'écrit aussi .   La solution sera virtuellement la même qu'en , mais avec les angles et , respectivement l'angle formé par le vecteur et les axes des abscisses et l'angle formé par le vecteur et l'axe des ordonnées.  On pourrait également avoir une solution alternative en utilisant le produit scalaire dans sa définition géométrique.  Remarquer également que cet exercice rappelle l'équation qu'on peut obtenir en considérant que , car ce sont des angles complémentaires. Une identité trigonométrique complètera la preuve.   Montrer qu'un vecteur non nul de peut aussi être entièrement déterminé à l'aide de deux angles, et et sa longueur. (Remarquer le parallèle avec où seul était nécessaire dans la forme polaire.)   Il s'agit des coordonnées sphériques illustrées dans la figure interactive. Suivant le raisonnement de la dernière remarque du , il est clair qu'on peut écrire un vecteur de ainsi: . On voit également, en comparant les figures des cosinus directeurs et des coordonnées sphériques, que la coordonnée en ne changera pas et dépendra uniquement de l'angle entre le vecteur et l'axe des .  La démonstration se fera en considérant la projection du vecteur sur le plan . Ce côté correspond à l'autre cathète du triangle formé par l'angle dans la figure. Par la trigonométrie du triangle rectangle, sa longueur est donc donnée par . En regardant maintenant le triangle orange, cette longueur est l'hypoténuse. Il s'ensuit donc que les deux cathètes sont données en multipliant par le cosinus ou le sinus de l'angle . Ainsi, Et donc, On a donc écrit le vecteur seulement en termes de sa longueur et de deux angles, en coordonnées sphériques.    Dans la figure , on peut comprendre, en déplaçant les vecteurs, que la projection orthogonale d'un vecteur sur un autre vecteur perpendiculaire donne le vecteur nul. Montrer cela algébriquement pour deux vecteurs orthogonaux et .   Puisque ces deux vecteurs sont orthogonaux, on sait déjà que leur produit scalaire est nul. La preuve sera immédiate en utilisant la formule .   Soit et , deux vecteurs orthogonaux. Alors, la projection de sur est donnée par:    Dans l'exemple , nous avons démontré que les diagonales d'un losange se coupent à angle droit. Utiliser la figure pour vous aider à bien visualiser l'énoncé suivant, puis le montrer algébriquement à l'aide des propriétés de la proposition :  « Les diagonales d'un losange sont de même longueur si et seulement si ce losange est un carré. »   Pour structurer une preuve de ce type (équivalence), il est possible de montrer l'énoncé en deux étapes. Dans ce cas-ci, il est conseillé de procéder en développant l'expression de la norme au carré des deux diagonales exprimées comme l'addition et la soustraction des vecteurs formant le losange. On verra alors que ces deux expressions seront égales si et seulement si le produit scalaire des deux vecteurs est nul.   Comme suggéré dans l'indication, on développe l'expression de la norme au carré des deux diagonales exprimées comme l'addition et la soustraction des vecteurs formant le losange. Rappelons que, par la définition d'un losange, on sait que et . On va donc utiliser seulement les vecteurs partant de l'origine à partir de la quatrième ligne. Le produit scalaire des deux vecteurs formant le losange étant nul, ils doivent être à angle droit. C'est donc un carré.    Pour décrire tout mouvement circulaire ou même toute trajectoire courbe, on dessine le vecteur vitesse (instantanée) et le vecteur accélération qui agit sur un mobile pour occasionner son changement de direction. Dans un mouvement circulaire, ce vecteur accélération est constant. Dans la figure ci-dessous, on observe qu'il est possible de décomposer le vecteur en sa composante radiale ( ) et sa composante tangentielle ( ). Cette dernière est calculable en faisant la projection de sur . Les deux composantes sont alors perpendiculaires.  En utilisant cela et la définition de la projection orthogonale , déterminer l'accélération tangentielle et l'accélération radiale d'une particule en mouvement, au moment où sa vitesse est donnée par le vecteur et son accélération est .        et   On sait que . On peut ensuite calculer l'accélération radiale en utilisant le fait que .    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Considérer les vecteurs et . Calculer    L'angle entre et   L'angle entre et   La projection orthogonale du vecteur sur le vecteur .                 Le code solution pour l'exercice   u=vector([-1,2,4]) v=vector([2,4,-1]) w=vector([5,-3,2]) show(u*v) show(u*w) show(arccos(u*v\/(norm(u)*norm(v)))) show(arccos(w*v\/(norm(w)*norm(v)))) show(v*u\/(u*u)*u)     Automatisation du calcul de l'angle entre deux vecteurs Le but de cet exercice est de créer une fonction Sage qui, étant donné deux vecteurs , va calculer l'angle entre les vecteurs sur . Plus précisément, créer une fonction nommée angle_entre_vec qui aura comme arguments deux vecteurs et qui va retourner la valeur de l'angle entre ces vecteurs.  Vérifier la fonction créée avec les données de l'exercice .     L'angle entre deux vecteurs   def angle_entre_vec(u,v): return arccos(u*v\/(norm(u)*norm(v))) u=vector([-1,2,4]) v=vector([2,4,-1]) w=vector([5,-3,2]) show(angle_entre_vec(u,v)) show(angle_entre_vec(v,w))     Automatisation de la projection orthogonale Le but de cet exercice est de créer une fonction Sage qui, étant donné deux vecteurs , va calculer la projection orthogonale de sur . Plus précisément, créer une fonction nommée proj_v_sur_u qui aura comme arguments deux vecteurs et qui va retourner la projection orthogonale du premier vecteur sur le second.     La fonction projection orthogonale   def proj_v_sur_u(u,v): return u*v\/(u*u)*u u=vector([-1,2,4]) v=vector([2,4,-1]) show(proj_v_sur_u(u,v))        "
},
{
  "id": "ex-angle2d",
  "level": "2",
  "url": "sec-prodscal.html#ex-angle2d",
  "type": "Exemple",
  "number": "1.2.1",
  "title": "L’angle entre deux vecteurs de dimensions deux: dynamique.",
  "body": " L'angle entre deux vecteurs de dimensions deux: dynamique  L'angle entre deux vecteurs peut être obtenu à l'aide d'un résultat bien connu à propos des triangles.   L'angle entre deux vecteurs   "
},
{
  "id": "ex-calculangle2d",
  "level": "2",
  "url": "sec-prodscal.html#ex-calculangle2d",
  "type": "Exemple",
  "number": "1.2.3",
  "title": "Un calcul d’angle.",
  "body": " Un calcul d'angle  On considère les vecteurs et . Le cosinus de l'angle entre ces vecteurs est .  L'angle entre les vecteurs est donc radians ou encore degrés.  "
},
{
  "id": "def-prodscal",
  "level": "2",
  "url": "sec-prodscal.html#def-prodscal",
  "type": "Définition",
  "number": "1.2.4",
  "title": "Le produit scalaire.",
  "body": " Le produit scalaire  Soit deux vecteurs de ou . On définit le produit scalaire de ces vecteurs, noté , comme étant la somme du produit des composantes correspondantes, c'est-à-dire .  "
},
{
  "id": "prop-propprodscal",
  "level": "2",
  "url": "sec-prodscal.html#prop-propprodscal",
  "type": "Proposition",
  "number": "1.2.5",
  "title": "",
  "body": " Le produit scalaire entre deux vecteurs quelconques possède les propriétés suivantes:   Les propriétés du produit scalaire    (commutativité du produit scalaire)  pour tout .  (distributivité du produit scalaire)       La plupart de ces propriétés découlent directement des propriétés de l'addition et de la multiplication de nombres réels. Par exemple, pour deux vecteurs de , on a . À remarquer que la propriété donne l'analogue à droite de la propriété .  Géométriquement, l'équation permet aussi de voir que la propriété est toujours valide étant donné que .  La seconde propriété est aussi algébriquement simple à démontrer. Il est toutefois intéressant de constater l'effet géométrique de la multiplication par un scalaire d'un vecteur sur le produit scalaire. Dans un premier temps, si , on a .  Et si , alors .   L'angle entre les vecteurs et .    Finalement, le cas découle simplement du fait que .  La troisième propriété n'est qu'une simple manipulation algébrique. Dans le cas de vecteurs dans , on a . Une démonstration géométrique sera donnée à l'exercice   Finalement, tant géométriquement qu'algébriquement, la démonstration de la dernière propriété est simple. Par exemple, avec l'équation , on a .   "
},
{
  "id": "ex-diaglos",
  "level": "2",
  "url": "sec-prodscal.html#ex-diaglos",
  "type": "Exemple",
  "number": "1.2.8",
  "title": "Les diagonales d’un losange.",
  "body": " Les diagonales d'un losange  On sait que deux vecteurs non parallèles engendrent un parallélogramme. Dans l'exercice , on peut montrer que les diagonales se coupent en leur milieu. Lorsque les deux vecteurs ont la même longueur, on obtient en fait un losange. On montre algébriquement que les diagonales d'un losange se coupent à angle droit. La figure interactive permet de manipuler un losange et servira de support pour la preuve qui suit.   Les diagonales d'un losange    Pour commencer, il est utile de se fixer un repère. En cliquant sur la case \"repère\", on choisit de fixer l'origine à l'un des quatre sommets du losange et de nommer les autres sommets et . On veut montrer que est perpendiculaire à ou, de manière équivalente, que . On a comme hypothèse que et donc que les quatre côtés sont égaux. En réécrivant les diagonales comme étant respectivement la somme et la différence des vecteurs , on a . Ainsi, les diagonales sont perpendiculaires, car le produit scalaire donne .  "
},
{
  "id": "prop-ineqCS",
  "level": "2",
  "url": "sec-prodscal.html#prop-ineqCS",
  "type": "Proposition",
  "number": "1.2.10",
  "title": "L’inégalité de Cauchy-Schwarz.",
  "body": " L'inégalité de Cauchy-Schwarz   Soit des vecteurs. Alors .    On peut procéder à partir de la définition par le calcul d'angle. Puisque , l'inégalité découlant du fait que .    Une autre manière est de procéder avec une combinaison d'arguments géométriques et algébriques. On remarque que si l'un des vecteurs est , alors l'inégalité est vraie, car et .  On suppose donc que les vecteurs sont non nuls. En ayant en tête l'image du parallélogramme engendré par les vecteurs et ses diagonales, reproduite à la figure , on constate que   Le parallélogramme engendré par les vecteurs, et ses diagonales   Les vecteurs u et v sont illustrés, ainsi que le parallélogramme qu'ils engendrent. De plus, on voit les diagonales formées par u plus v et u moins v.    On regarde ce qui se passe dans un premier temps avec les vecteurs unitaires et . On s'intéresse aux longueurs des diagonales du parallélogramme engendré par ces vecteurs unitaires. On a .  Parce que les vecteurs sont unitaires, les deux équations se réduisent à , et comme ce sont des longueurs, elles sont plus grandes ou égales à d'où l'on obtient que , ce qui revient à dire que .  En reprenant la définition des vecteurs unitaires, on obtient .   Voir l'exercice pour une preuve utilisant les zéros d'une parabole.  "
},
{
  "id": "sageex-prodscal",
  "level": "2",
  "url": "sec-prodscal.html#sageex-prodscal",
  "type": "Calcul",
  "number": "1.2.12",
  "title": "Le produit scalaire avec Sage.",
  "body": " Le produit scalaire avec Sage  Il est possible de calculer le produit scalaire entre et avec la commande u.dot_product(v) . Il est également possible d'utiliser plus simplement u*v .   Pour calculer l'angle entre deux vecteurs, on utilise la formule .   "
},
{
  "id": "fig-projortho",
  "level": "2",
  "url": "sec-prodscal.html#fig-projortho",
  "type": "Figure",
  "number": "1.2.13",
  "title": "",
  "body": " La projection orthogonale   "
},
{
  "id": "def-projortho",
  "level": "2",
  "url": "sec-prodscal.html#def-projortho",
  "type": "Définition",
  "number": "1.2.14",
  "title": "La projection orthogonale.",
  "body": " La projection orthogonale  Soit deux vecteurs non nuls . La projection de sur , notée , est l'unique vecteur pour lequel   est parallèle à ;  est perpendiculaire à .  Si l'un des vecteurs est nul, on définit .  La projection orthogonale est donnée par la formule suivante : .  "
},
{
  "id": "ex-piedhauteur",
  "level": "2",
  "url": "sec-prodscal.html#ex-piedhauteur",
  "type": "Exemple",
  "number": "1.2.15",
  "title": "Le pied de la hauteur.",
  "body": " Le pied de la hauteur   Un triangle est formé des points et . On cherche les coordonnées du point correspondant au pied de la hauteur issue de .  On trace le triangle dans un repère quelconque.   Le pied de la hauteur   Le triangle ABC est illustré, ainsi que la hauteur issue de C menant au point H.    Le point cherché peut être obtenu en additionnant au point le vecteur correspondant à la projection de sur , ou de manière équivalente en ajoutant à le vecteur correspondant à la projection de sur . On choisit la première option: .   "
},
{
  "id": "sageex-projortho",
  "level": "2",
  "url": "sec-prodscal.html#sageex-projortho",
  "type": "Calcul",
  "number": "1.2.17",
  "title": "La projection orthogonale sur Sage.",
  "body": " La projection orthogonale sur Sage  Avec les commandes apprises jusqu'à maintenant, on peut calculer la projection orthogonale d'un vecteur sur un autre grâce à la formule .   On illustre les vecteurs afin de visualiser le résultat.   "
},
{
  "id": "exo-prodscal-drill",
  "level": "2",
  "url": "sec-prodscal.html#exo-prodscal-drill",
  "type": "Exercice",
  "number": "1.2.4.1",
  "title": "",
  "body": " Pour chacune des paires de vecteurs suivantes, calculer le produit scalaire ainsi que l'angle entre les vecteurs.     et        et        et        et        et        et        et        et     "
},
{
  "id": "exo-trouvervaleursperp",
  "level": "2",
  "url": "sec-prodscal.html#exo-trouvervaleursperp",
  "type": "Exercice",
  "number": "1.2.4.2",
  "title": "",
  "body": " Pour quelle(s) valeur(s) de les vecteurs suivants sont-ils orthogonaux (perpendiculaires)?             . Comme n'importe quelle valeur de permet de satisfaire cette équation, il s'ensuit que ces vecteurs sont toujours perpendiculaires.           Deux vecteurs sont orthogonaux lorsque leur produit scalaire est nul.      "
},
{
  "id": "exo-reduireprodscal",
  "level": "2",
  "url": "sec-prodscal.html#exo-reduireprodscal",
  "type": "Exercice",
  "number": "1.2.4.3",
  "title": "",
  "body": " Soit deux vecteurs et et . Simplifier les expressions suivantes en vous servant des propriétés de la proposition . Dire si la réponse est un scalaire ou un vecteur.      C'est un scalaire.   C'est un scalaire.      C'est un vecteur.   C'est un vecteur. En effet, on a une constante multipliée par une norme additionnée d'un produit scalaire. Tout cela ensemble est un scalaire. On le multiplie ensuite par le vecteur (multiplication par un scalaire) et le résultat est donc un vecteur.  "
},
{
  "id": "exo-loicospourR3",
  "level": "2",
  "url": "sec-prodscal.html#exo-loicospourR3",
  "type": "Exercice",
  "number": "1.2.4.4",
  "title": "",
  "body": " Soit et . Utiliser la loi des cosinus afin de démontrer l'équation . Il faudra exprimer la loi en termes des normes des vecteurs , et du vecteur avec représentant l'angle entre les deux vecteurs.    "
},
{
  "id": "exo-preuvegeodistriprodscal",
  "level": "2",
  "url": "sec-prodscal.html#exo-preuvegeodistriprodscal",
  "type": "Exercice",
  "number": "1.2.4.5",
  "title": "",
  "body": " Démontrer la propriété (distributivité du produit scalaire) en utilisant la définition géométrique du produit scalaire . Utiliser les symboles fournis par le dessin pour les angles entre les différents vecteurs.         "
},
{
  "id": "exo-normsommecarree",
  "level": "2",
  "url": "sec-prodscal.html#exo-normsommecarree",
  "type": "Exercice",
  "number": "1.2.4.6",
  "title": "",
  "body": " Soit deux vecteurs ou . En utilisant les propriétés de la proposition , démontrer l'égalité suivante:   Comme pour beaucoup de preuves d'énoncés sous forme d'égalités, il faut commencer par réécrire le membre de l'égalité qui nous semble le plus compliqué. On suggère de commencer par celui de droite, bien que celui de gauche serait tout aussi simple dans ce cas.   Tel que mentionné dans l'indication, on choisit de partir du membre de droite pour se rendre au membre de gauche de l'égalité.  "
},
{
  "id": "exo-normeaddvec",
  "level": "2",
  "url": "sec-prodscal.html#exo-normeaddvec",
  "type": "Exercice",
  "number": "1.2.4.7",
  "title": "",
  "body": " Soit deux vecteurs et . Démontrer algébriquement les deux énoncés suivants en vous servant des propriétés de la proposition .          "
},
{
  "id": "exo-anglecube",
  "level": "2",
  "url": "sec-prodscal.html#exo-anglecube",
  "type": "Exercice",
  "number": "1.2.4.8",
  "title": "",
  "body": " À l'aide de vecteurs, calculer l'angle entre la plus longue diagonale d'un cube et la diagonale adjacente d'une de ses faces, tel que représenté dans la figure.        Considérer l'origine des deux diagonales comme l'origine d'un espace cartésien. Créer des vecteurs en considérant que la longueur du côté du cube est de .   L'angle entre les diagonales est radians ou encore degrés.   Considérant l'origine des deux diagonales comme l'origine d'un espace cartésien et la longueur du côté du cube égale à , les vecteurs créés ont pour composantes respectivement et . L'angle désiré devient tout simplement l'angle entre ces deux vecteurs. On le calcule comme à l'exemple  .  L'angle entre les vecteurs et donc entre les diagonales est alors radians ou encore degrés. De plus, on constate que cet angle ne dépend pas de la longueur du côté du cube.  "
},
{
  "id": "exo-tetrachimie",
  "level": "2",
  "url": "sec-prodscal.html#exo-tetrachimie",
  "type": "Exercice",
  "number": "1.2.4.9",
  "title": "",
  "body": " Une molécule de méthane a quatre atomes d'hydrogène aux points indiqués sur la figure ci-dessous et un atome de carbone à l'origine. Trouver l'angle du lien H-C-H.   Une molécule de méthane     L'angle du lien H-C-H est radians ou encore degrés.   On calcule l'angle illustré en vert dans la figure. Il s'agit de l'angle entre les vecteurs et . Les composantes de ces vecteurs sont données directement par les coordonnées des points et puisque le point est l'origine. Ainsi, et .   L'angle entre les vecteurs et donc l'angle du lien H-C-H est radians ou encore degrés.  "
},
{
  "id": "exo-cosdir",
  "level": "2",
  "url": "sec-prodscal.html#exo-cosdir",
  "type": "Exercice",
  "number": "1.2.4.10",
  "title": "",
  "body": " L'orientation d'un vecteur de est complètement déterminée par l'angle que fait le vecteur avec l'horizontale. Dans , un angle ne suffit plus. Il est toutefois possible de caractériser l'orientation à l'aide de trois angles.  Soit un vecteur non nul. On note l'angle que fait le vecteur avec l'axe des abscisses , l'angle que fait le vecteur avec l'axe des ordonnées et l'angle que fait le vecteur avec l'axe des cotes .       Démontrer les affirmations suivantes:   Le vecteur s'écrit comme . On appelle le triplet les cosinus directeurs du vecteur .   En regardant la figure interactive, on voit qu'il y a un triangle rectangle formé par chaque axe dont l'hypoténuse est le vecteur et une cathète correspond à la coordonnée dans cet axe. Par exemple, on voit que le vecteur forme un angle de avec l'axe des . On peut donc déterminer avec la trigonométrie du triangle rectangle que le côté adjacent à l'angle est donné par l'hypoténuse multiplié par le cosinus de l'angle. Ainsi, On a donc:  Une autre approche serait d'utiliser la définition géométrique du produit scalaire donnée par l'équation . En effet, en prenant le produit scalaire du vecteur avec chaque vecteur unitaire dans la direction des axes, on obtient:  Les deux autres composantes se retrouvent de façon similaire.      En isolant chaque cosinus des équations précédentes, on a: .   Dans , la notion de cosinus directeurs existe aussi et un vecteur s'écrit aussi .   La solution sera virtuellement la même qu'en , mais avec les angles et , respectivement l'angle formé par le vecteur et les axes des abscisses et l'angle formé par le vecteur et l'axe des ordonnées.  On pourrait également avoir une solution alternative en utilisant le produit scalaire dans sa définition géométrique.  Remarquer également que cet exercice rappelle l'équation qu'on peut obtenir en considérant que , car ce sont des angles complémentaires. Une identité trigonométrique complètera la preuve.   Montrer qu'un vecteur non nul de peut aussi être entièrement déterminé à l'aide de deux angles, et et sa longueur. (Remarquer le parallèle avec où seul était nécessaire dans la forme polaire.)   Il s'agit des coordonnées sphériques illustrées dans la figure interactive. Suivant le raisonnement de la dernière remarque du , il est clair qu'on peut écrire un vecteur de ainsi: . On voit également, en comparant les figures des cosinus directeurs et des coordonnées sphériques, que la coordonnée en ne changera pas et dépendra uniquement de l'angle entre le vecteur et l'axe des .  La démonstration se fera en considérant la projection du vecteur sur le plan . Ce côté correspond à l'autre cathète du triangle formé par l'angle dans la figure. Par la trigonométrie du triangle rectangle, sa longueur est donc donnée par . En regardant maintenant le triangle orange, cette longueur est l'hypoténuse. Il s'ensuit donc que les deux cathètes sont données en multipliant par le cosinus ou le sinus de l'angle . Ainsi, Et donc, On a donc écrit le vecteur seulement en termes de sa longueur et de deux angles, en coordonnées sphériques.  "
},
{
  "id": "exo-vecperpproj",
  "level": "2",
  "url": "sec-prodscal.html#exo-vecperpproj",
  "type": "Exercice",
  "number": "1.2.4.11",
  "title": "",
  "body": " Dans la figure , on peut comprendre, en déplaçant les vecteurs, que la projection orthogonale d'un vecteur sur un autre vecteur perpendiculaire donne le vecteur nul. Montrer cela algébriquement pour deux vecteurs orthogonaux et .   Puisque ces deux vecteurs sont orthogonaux, on sait déjà que leur produit scalaire est nul. La preuve sera immédiate en utilisant la formule .   Soit et , deux vecteurs orthogonaux. Alors, la projection de sur est donnée par:  "
},
{
  "id": "exo-diaglosange",
  "level": "2",
  "url": "sec-prodscal.html#exo-diaglosange",
  "type": "Exercice",
  "number": "1.2.4.12",
  "title": "",
  "body": " Dans l'exemple , nous avons démontré que les diagonales d'un losange se coupent à angle droit. Utiliser la figure pour vous aider à bien visualiser l'énoncé suivant, puis le montrer algébriquement à l'aide des propriétés de la proposition :  « Les diagonales d'un losange sont de même longueur si et seulement si ce losange est un carré. »   Pour structurer une preuve de ce type (équivalence), il est possible de montrer l'énoncé en deux étapes. Dans ce cas-ci, il est conseillé de procéder en développant l'expression de la norme au carré des deux diagonales exprimées comme l'addition et la soustraction des vecteurs formant le losange. On verra alors que ces deux expressions seront égales si et seulement si le produit scalaire des deux vecteurs est nul.   Comme suggéré dans l'indication, on développe l'expression de la norme au carré des deux diagonales exprimées comme l'addition et la soustraction des vecteurs formant le losange. Rappelons que, par la définition d'un losange, on sait que et . On va donc utiliser seulement les vecteurs partant de l'origine à partir de la quatrième ligne. Le produit scalaire des deux vecteurs formant le losange étant nul, ils doivent être à angle droit. C'est donc un carré.  "
},
{
  "id": "exo-accelradtan",
  "level": "2",
  "url": "sec-prodscal.html#exo-accelradtan",
  "type": "Exercice",
  "number": "1.2.4.13",
  "title": "",
  "body": " Pour décrire tout mouvement circulaire ou même toute trajectoire courbe, on dessine le vecteur vitesse (instantanée) et le vecteur accélération qui agit sur un mobile pour occasionner son changement de direction. Dans un mouvement circulaire, ce vecteur accélération est constant. Dans la figure ci-dessous, on observe qu'il est possible de décomposer le vecteur en sa composante radiale ( ) et sa composante tangentielle ( ). Cette dernière est calculable en faisant la projection de sur . Les deux composantes sont alors perpendiculaires.  En utilisant cela et la définition de la projection orthogonale , déterminer l'accélération tangentielle et l'accélération radiale d'une particule en mouvement, au moment où sa vitesse est donnée par le vecteur et son accélération est .        et   On sait que . On peut ensuite calculer l'accélération radiale en utilisant le fait que .  "
},
{
  "id": "exo-sage-prodscal-1",
  "level": "2",
  "url": "sec-prodscal.html#exo-sage-prodscal-1",
  "type": "Exercice",
  "number": "1.2.4.14",
  "title": "",
  "body": " Considérer les vecteurs et . Calculer    L'angle entre et   L'angle entre et   La projection orthogonale du vecteur sur le vecteur .                 Le code solution pour l'exercice   u=vector([-1,2,4]) v=vector([2,4,-1]) w=vector([5,-3,2]) show(u*v) show(u*w) show(arccos(u*v\/(norm(u)*norm(v)))) show(arccos(w*v\/(norm(w)*norm(v)))) show(v*u\/(u*u)*u)    "
},
{
  "id": "exo-sage-prodscal-2",
  "level": "2",
  "url": "sec-prodscal.html#exo-sage-prodscal-2",
  "type": "Exercice",
  "number": "1.2.4.15",
  "title": "Automatisation du calcul de l’angle entre deux vecteurs.",
  "body": "Automatisation du calcul de l'angle entre deux vecteurs Le but de cet exercice est de créer une fonction Sage qui, étant donné deux vecteurs , va calculer l'angle entre les vecteurs sur . Plus précisément, créer une fonction nommée angle_entre_vec qui aura comme arguments deux vecteurs et qui va retourner la valeur de l'angle entre ces vecteurs.  Vérifier la fonction créée avec les données de l'exercice .     L'angle entre deux vecteurs   def angle_entre_vec(u,v): return arccos(u*v\/(norm(u)*norm(v))) u=vector([-1,2,4]) v=vector([2,4,-1]) w=vector([5,-3,2]) show(angle_entre_vec(u,v)) show(angle_entre_vec(v,w))    "
},
{
  "id": "exo-sage-prodscal-3",
  "level": "2",
  "url": "sec-prodscal.html#exo-sage-prodscal-3",
  "type": "Exercice",
  "number": "1.2.4.16",
  "title": "Automatisation de la projection orthogonale.",
  "body": "Automatisation de la projection orthogonale Le but de cet exercice est de créer une fonction Sage qui, étant donné deux vecteurs , va calculer la projection orthogonale de sur . Plus précisément, créer une fonction nommée proj_v_sur_u qui aura comme arguments deux vecteurs et qui va retourner la projection orthogonale du premier vecteur sur le second.     La fonction projection orthogonale   def proj_v_sur_u(u,v): return u*v\/(u*u)*u u=vector([-1,2,4]) v=vector([2,4,-1]) show(proj_v_sur_u(u,v))    "
},
{
  "id": "sec-droitesplans",
  "level": "1",
  "url": "sec-droitesplans.html",
  "type": "Section",
  "number": "1.3",
  "title": "Droites et plans",
  "body": " Droites et plans   Aller aux exercices de la section.  Lorsqu'on multiplie un vecteur par un scalaire, le vecteur garde la même direction. En observant l'extrémité du vecteur lorsque parcourt l'ensemble des nombres réels, on remarque qu'elle trace une droite. De même, si l'on a deux vecteurs non nuls et non parallèles et que l'on considère les vecteurs lorsque , on remarque que ces vecteurs se retrouvent toujours sur un plan.  Dans cette section, on introduit la notion de combinaison linéaire de vecteurs et on définit vectoriellement la notion de droite et de plan. On effectue aussi certains calculs, par exemple de distance, à l'aide des outils développés jusqu'à maintenant.     Les droites  Lorsque deux ou plusieurs vecteurs qui sont multipliés par un scalaire sont additionnés, on parle alors de combinaison linéaire .   Si l'on a vecteurs , une combinaison linéaire de ces vecteurs est s'écrit .   Le symbole signifie « pour tout. » Par exemple, l'expression mathématique se lit est plus grand que zéro pour tout réel.  Les coefficients sont parfois appelés les poids de la combinaison linéaire.  La multiplication par un scalaire, un cas limite de combinaison linéaire, sera aussi considérée comme une combinaison linéaire d'un seul vecteur. À l'aide d'un certain nombre de vecteurs et des combinaisons linéaires, il est possible de générer (ou engendrer) d'autres vecteurs. Par exemple, un vecteur seul peut générer tout autre vecteur parallèle par la bonne combinaison linéaire, alors que deux vecteurs non parallèles de pourront engendrer n'importe quel vecteur de . La figure de l'exemple interactif permet de comprendre ces exemples de manière intuitive, alors que les détails techniques seront abordés avec le concept de base d'un espace au chapitre .   Combinaison linéaire de deux vecteurs: dynamique  Dans cet exemple, on considère, pour des vecteurs de , les combinaisons de la forme et . En se référant à la figure , sans toucher aux vecteurs de départ, on s'intéresse aux questions suivantes:   Au départ, les poids de la combinaison linéaire valent . En laissant l'un des paramètres nul et en faisant varier l'autre, on observe que la combinaison linéaire n'est qu'une multiplication par un scalaire. Celle-ci se déplace sur une droite. Ceci est cohérent avec les observations faites lors de l'exemple .    En cliquant sur \"grille\" et en prenant des valeurs entières de et , on observe que les multiplications de et , respectivement par les scalaires et , se retrouvent aux intersections de la grille. Si, en plus, on fait afficher la combinaison linéaire, on peut voir géométriquement l'addition des vecteurs et .    On fixe une valeur de quelconque, entière ou non et on laisse varier . Qu'observe-t-on?    Est-il possible de décrire n'importe quel vecteur de comme une combinaison linéaire de et ? Cette question revient à dire, étant donné un vecteur , que l'on peut trouver des coefficients tels que . Puisque deux vecteurs sont égaux si leurs composantes respectives le sont, on obtient les deux équations suivantes: . Ce type de paires d'équations à résoudre est appelé un système d'équations linéaires et sera l'objet d'étude du chapitre .  Il est assez simple de voir intuitivement que, dès que deux vecteurs sont non parallèles dans , on peut écrire n'importe quel autre vecteur en fonction de ceux-ci. Un clic sur \"Cible\" fera apparaitre un point (plutôt qu'un vecteur, pour ne pas encombrer davantage la figure). À l'aide des curseurs, il devrait être possible de trouver une combinaison linéaire dont l'extrémité sera le point \"Cible\".   On observe ce qui se passe lorsque les vecteurs initiaux sont changés, en particulier si et sont parallèles.    Combinaison linéaire dans      Les observations de l'exemple permettent de voir que les vecteurs et les droites sont des notions étroitement liées. On est tous et toutes capables de déterminer l'équation d'une droite, souvent de la forme , à l'aide d'informations comme deux points appartenant à la droite ou encore d'un point et de la pente. Pourquoi, alors, développer une théorie vectorielle pour un objet aussi bien connu?  La réponse à cette question se trouve en particulier dans . En effet, l'équation vue dans décrit non pas une droite, mais un plan (plus d'information sur les plans dans la sous-section ). Pour comprendre cela, on rappelle qu'un point dans est composé d'une valeur et . Comme l'équation lie les variables et , mais laisse libre, pour chaque couple satisfaisant l'équation , il existe une infinité de valeurs la satisfaisant aussi, d'où le plan plutôt que la droite. Une approche vectorielle permettra de décrire une droite dans et ainsi de surmonter cette difficulté.  Une droite passant par l'origine , dans ou , peut toujours être décrite comme l'ensemble des points ou atteints par la multiplication d'un certain vecteur par un scalaire réel. Le vecteur est appelé le vecteur directeur de la droite . On donne alors l'équation vectorielle de la droite comme étant l'ensemble des points tels que .  Évidemment, toute droite ne passe pas par l'origine. Si une droite ne passant pas par l'origine passe par un point quelconque, mais est parallèle à une droite , qui passe par l'origine, on peut obtenir une équation vectorielle pour en translatant les points de la droite le long du vecteur . On obtient alors l'équation , où est le vecteur directeur de la droite . Le vecteur directeur est l'équivalent de la pente et le point est l'équivalent de l'ordonnée à l'origine dans l'équation .  Connaitre le vecteur directeur est un peu l'équivalent de connaitre la pente de la droite. Parfois, on connait deux points et on veut trouver l'équation de la droite passant par ces points. On peut créer un vecteur directeur en déterminant le vecteur reliant et .   L'équation de droites  Considérons le point de et les points et . On cherche l'équation de la droite dans qui passe par le point et qui a la même direction que la droite et l'équation de la droite dans qui passe par et .  La première partie est assez simple, puisque toute l'information nous est donnée. On connait un point de la droite et la direction. L'équation est donc .  Pour la seconde partie, on doit d'abord trouver un vecteur directeur pour la droite. Le vecteur fera l'affaire. Pour un point, on a le choix entre ou , n'importe lequel fera l'affaire. On obtient finalement .   Pour une droite dans , il n'y a qu'une seule paire de nombres décrivant la droite sous la forme . Par contre, cette équation peut être multipliée par n'importe quelle constante et la nouvelle équation décrit toujours la même droite, sous une forme moins conventionnelle. L'équation vectorielle d'une droite n'est pas unique. En effet, n'importe quel point sur la droite peut être utilisé comme point de départ et n'importe quel multiple non nul du vecteur directeur peut être utilisé. En fait, on devrait parler d'une équation vectorielle de la droite plutôt que de l'équation vectorielle, mais on accepte cet abus de langage.   L'équation vectorielle n'est pas unique  On reprend l'équation de la droite dans de l'exemple  . En utilisant le point plutôt que le point et un vecteur parallèle à , disons en le multipliant par , on obtient une nouvelle représentation pour la droite : . On remarque l'utilisation du scalaire plutôt que afin d'évoquer la différence entre les deux équations. On aurait pu utiliser également, en gardant en tête qu'une valeur de dans la première représentation de la droite ne donnera pas nécessairement le même point que cette même valeur de dans la nouvelle représentation.  Comment s'assurer que ces deux équations décrivent la même droite? Une manière simple est de partir de l'une des équations et de montrer que l'on peut arriver à l'autre par une suite de manipulations algébriques. Dans notre cas, on a , où . Comme on peut faire les opérations dans l'ordre inverse, les deux représentations sont équivalentes.   On va maintenant s'intéresser à réconcilier la forme vectorielle d'une droite à la forme standard , pour les droites de .   De la forme standard à la forme vectorielle  Considérons une droite dans , par exemple . Sous forme vectorielle, on cherche à exprimer l'ensemble de points sur la droite. Ces points sont de la forme . On peut décomposer cette forme afin d'obtenir la forme vectorielle. . On trouve donc une droite de vecteur directeur passant par le point . On Remarque qu'en suivant cette démarche, la première composante du vecteur directeur sera toujours , et la seconde correspondra à la pente de la droite.  Évidemment, ce n'est pas la seule forme valide pour décrire la droite vectoriellement.    De la forme vectorielle à la forme standard  Considérons une droite dans , par exemple . On cherche la forme de cette droite. Plusieurs démarches sont possibles. On peut facilement trouver deux points en utilisant deux scalaires différents dans la forme vectorielle. Par la suite, la démarche usuelle mènera à l'équation de la droite.  On peut aussi y aller avec l'interprétation géométrique du vecteur directeur. Le vecteur correspond à un déplacement horizontal de unités et un déplacement vertical de unités. Ceci nous donne la pente . Pour trouver l'ordonnée à l'origine, il suffit de mettre la première composante de la forme vectorielle à , en prenant ici . On trouve alors l'ordonnée à l'origine . La droite est donc aussi décrite par l'équation .   En regardant de manière plus détaillée l'équation vectorielle d'une droite , plus particulièrement avec la notation verticale pour les vecteurs, on découvre une autre manière de décrire la droite, composante par composante.    . Cette dernière manière de décrire la droite est appelée la forme paramétrique d'une droite, ou encore les équations paramétriques d'une droite. On y voit d'ailleurs que chaque composante et est en quelque sorte elle-même l'équation d'une droite, et . La variable indépendante ici est et chaque composante du vecteur est associée à la \"pente\", alors que les composantes du vecteur sont associées aux \"ordonnées à l'origine\".  Les équations paramétriques se généralisent à des courbes quelconques dans le plan ou l'espace. Ce sujet est exploré dans la section .  On regarde une autre manipulation de l'équation d'une droite. Celle-ci ne sera valide que pour une droite dans , mais reste toutefois importante. On considère à nouveau les équations paramétriques d'une droite dans : . On va tenter d'éliminer le paramètre , un peu comme on l'a fait à l'exemple . On utilsera cependant une autre méthode, qui sera en quelque sorte un avant-gout de la section . On multiplie les équations paramétriques par pour la première et pour la seconde afin d'obtenir . On soustrait maintenant la première équation de la seconde pour obtenir . On simplifie un peu l'écriture en posant et . On obtient alors , une forme semblable à la forme standard, mais plus générale. En effet, avec la forme , il est impossible de décrire une droite verticale, mais avec la forme , il suffit que pour obtenir une droite verticale. On peut aller plus loin dans l'analyse. En posant , il est possible de réécrire l'équation normale à l'aide du produit scalaire: . De cette dernière équation, on déduit que le vecteur est perpendiculaire au vecteur . Puisque et sont sur la droite, le vecteur est parallèle au vecteur directeur de la droite et donc, le vecteur est perpendiculaire à la droite elle-même. Pour cette raison, la forme est appelée l'équation normale de la droite et le vecteur est un vecteur normal.  Avant de voir pourquoi l'équation normale d'une droite n'est pas possible dans , on énonce une proposition intéressante découlant des calculs que l'on vient de faire.   Le vecteur perpendiculaire   Soit un vecteur de non nul. Alors le vecteur est perpendiculaire à .    Il suffit de vérifier que l'on a bien . Algébriquement, et donc, c'est vérifié.    On remarque que la direction du vecteur normal est la seule qui soit perpendiculaire à la droite dans . Considérons maintenant une droite quelconque et un point sur cette droite. Combien de droites perpendiculaires à et passant par existe-t-il? Si la droite est dans , une seule droite satisfait ces conditions, mais si est dans , il y en a une infinité. La figure permet de voir une droite bleue, ainsi que trois autres droites en rouge qui sont de directions différentes, mais perpendiculaires à la droite bleue.   Des droites perpendiculaires    On termine avec des commandes Sage en lien avec la sous-section.   Les droites avec Sage  Pour tracer une droite dans ou dans , deux options sont possibles. La première option est simple et nécessite deux points sur la droite. Il suffit alors d'utiliser la commande line .   Une autre option, plus flexible, utilise les équations paramétriques. Elle est plus flexible puisqu qu'elle permet de décrire des courbes quelconques comme celles explorées dans la section . La commande est parametric_plot ou parametric_plot3d , selon le cas.  On illustre les deux droites solutions de l'exemple .    Les options habituelles de couleur, épaisseur, etc. sont aussi disponibles.  Si l'équation de la droite est donnée vectoriellement, il est aussi possible de la tracer avec la commande parametric_plot ou son équivalent .      Les plans  Après avoir considéré la géométrie derrière les combinaisons linéaires d'un vecteur, on s'intéresse maintenant à la géométrie des combinaisons de deux vecteurs. Plus spécifiquement, deux vecteurs non nuls et non parallèles et engendrent un plan. Lorsque ces vecteurs se trouvent dans , on obtient l'ensemble du plan cartésien, tel qu'observé à l'exemple .  Dans , les combinaisons linéaires génèrent un plan passant par l'origine lorsque parcourent toutes les valeurs réelles possibles. Ceci est illustré à l'exemple .   Combinaison linéaire en trois dimensions: dynamique  Cet exemple est semblable à l'exemple , mais avec des vecteurs de . Les combinaisons de la forme et sont étudiées en se référant à la figure et aux questions suivantes:   Comme précédemment, les multiples d'un seul vecteur donnent une droite.    En cliquant sur \"grille\" et en prenant des valeurs entières de et , on observe que les multiplications par un scalaire respectives de et se retrouvent à une intersection de la grille. Si en plus on fait afficher la combinaison linéaire, on peut voir géométriquement l'addition des vecteurs et .    Est-il possible de décrire n'importe quel vecteur de comme une combinaison linéaire de et ? Cette question revient à dire, étant donné un vecteur , peut-on trouver des coefficients tels que . Puisque deux vecteurs sont égaux si leurs composantes respectives le sont, on obtient les deux équations suivantes: . Cette fois-ci, on a trois équations, mais seulement deux inconnues. Si l'on ne se soucie pas de l'équation , on peut, probablement, trouver des valeurs de qui vont satisfaire les équations et . Ces valeurs ne vont pas forcément satisfaire l'autre équation. Les détails et cas possibles pouvant survenir seront traités au chapitre .  Un clic sur \"Cibles\" fera apparaitre deux points dans l'espace. L'un de ces points sera toujours atteignable par une combinaison linéaire appropriée de et , mais l'autre ne le sera probablement pas. Pourquoi?    Un clic sur \"Plan\" fera apparaitre l'ensemble des points qui sont atteignables par combinaison linéaire de et . Le point \"Cible1\" est sans doute à l'extérieur de ce plan et ne peut donc pas être atteint. Par contre, \"Cible2\" a été construit de façon à toujours être dans l'ensemble des combinaisons linéaires possibles.     Combinaison linéaire dans      Un plan passant par l'origine dans peut être décrit comme le lieu géométrique des points pouvant être obtenus comme une combinaison linéaire de deux vecteurs non nuls et non parallèles . Ces deux vecteurs sont appelés des vecteurs directeurs du plan . On peut aussi décrire le plan par une équation vectorielle, soit . En principe, un plan dans est équivalent à tout , on se concentre donc davantage sur les plans dans .  Pour décrire un plan passant par un point quelconque et de vecteurs directeurs , il est possible d'utiliser une approche semblable à celle utilisée pour les droites et de translater un plan passant par l'origine , lui aussi de vecteurs directeurs , le long du vecteur . La figure illustre cette approche.   Un plan dans passant par un point .    On obtient alors l'équation vectorielle du plan .  Comme c'était le cas pour les droites, un plan peut avoir plusieurs équations vectorielles le décrivant, toutes équivalentes. On dira toutefois « l'équation » du plan plutôt qu' « une équation », sachant que l'équation n'est pas unique.  Également, on peut aussi considérer l'équation vectorielle comme un ensemble d'équations paramétriques, comme pour les droites. À noter que deux paramètres sont nécessaires, représentant l'aspect bidimensionnel d'un plan. . Plus généralement, ce type d'équation est pratique pour décrire des surfaces dans l'espace, aussi explorées à la section .  Lorsque trois points qui ne sont pas alignés sont donnés, on peut toujours trouver l'équation d'un plan passant par ces trois points.   L'équation d'un plan passant par trois points   Soit et trois points de l'espace. On cherche une équation du plan passant par et .    Pour décrire un plan vectoriellement, on a besoin d'un point et de deux vecteurs directeurs. L'ensemble des points sur la droite passant par et doit forcément faire partie du plan, tout comme l'ensemble des points sur la droite passant par et . En particulier, les vecteurs et peuvent être considérés comme des vecteurs directeurs du plan cherché. En prenant comme point particulier le point , on obtient .     Déterminer si un point est sur un plan   Considérons le plan d'équation vectorielle . On cherche à savoir si les points et font partie du plan.    Pour savoir si le point est dans le plan, il faut trouver tels que . De cette équation vectorielle, on tire les équations suivantes: . L'équation donne immédiatement , et en remplaçant cette valeur dans les équations et , on trouve . Une vérification rapide montre qu'on a bel et bien    Pour savoir si le point est dans le plan, il faut trouver tels que . De cette équation vectorielle, on tire les équations suivantes: . L'équation donne immédiatement . En remplaçant cette valeur dans les équations et , on trouve une incohérence, puisque d'une part, l'équation demande à ce que alors l'équation que demanque que . Comme ne peut être simultanément et , on conclut que le point ne peut pas appartenir au plan .  On verra prochainement une autre manière de déterminer si un point appartient à un plan de et le chapitre donnera une méthode structurée pour résoudre les systèmes d'équations comme ceux dans cet exemple.    Dans , il y a une seule direction perpendiculaire à une droite donnée alors que dans , il en existe une infinité. Pour un plan dans , il n'y a aussi qu'une seule direction perpendiculaire au plan. Comment peut-on la trouver? Avant de procéder, on démontre le résultat suivant.   Orthogonalité et combinaison linéaire   Soit et tels que est perpendiculaire à la fois à et . Alors est perpendiculaire à toute combinaison linéaire de et .    Soit une combinaison linéaire quelconque des vecteurs et . On doit montrer que . On a .  Ainsi, est perpendiculaire à toute combinaison linéaire des vecteurs et .   On illustre maintenant la méthode pour trouver la direction perpendiculaire au plan avec un exemple numérique. L'exemple donnera la manière générale de déterminer cette direction.   L'équation d'une droite perpendiculaire à un plan   On considère le plan d'équation . On cherche l'équation de la droite qui passe par le point et qui est perpendiculaire au plan .    Soit , un vecteur directeur de cette droite. Si l'on réussit à trouver perpendiculaire à et , alors, selon la proposition , sera orthogonal à tous les vecteurs du plan. On doit avoir et . On a par conséquent trois inconnues à déterminer et deux équations qui les relient. En réarrangeant les équations, on arrive à et . Le vecteur peut donc être exprimé comme . On met le facteur commun en évidence pour obtenir , avec un nombre réel quelconque. Peu importe la valeur de , on obtient un multiple du vecteur . On choisit donc ce vecteur (en posant ) comme étant la direction cherchée.  Puisque l'on cherchait l'équation de la droite passant par le point , la réponse est .    Une équation de la forme est appelée une équation normale d'un plan dans . On peut aussi la réécrire sous la forme , où est perpendiculaire à tous les vecteurs du plan. L'exemple montre comment passer de l'équation vectorielle à l'équation normale. En effet, le vecteur directeur de la droite perpendiculaire au plan servira de vecteur normal . On a donc . On peut calculer la valeur de la constante manquante en remplaçant dans l'équation n'importe quel point sur le plan. On utilise le point puisqu'on sait qu'il s'y trouve. On y arrive ainsi: On regarde maintenant la situation inverse.   De l'équation normale à l'équation vectorielle   Soit l'équation une équation normale d'un plan dans . On cherche une équation vectorielle décrivant ce plan.    Une première solution est d'isoler l'une des variables dans l'équation normale. Ici, on a par exemple . Un point dans le plan doit satisfaire , où l'on a réécrit le point en regroupant les termes semblables.  On réécrit avec la notation habituelle pour obtenir .   Une autre option est de sélectionner trois points non alignés sur le plan et de créer des vecteurs directeurs à partir de ces points. On retrouve alors facilement l'équation vectorielle. Par exemple, si , le point sur le plan doit avoir . De même, si , on a et si , on a . Des points et , on tire les vecteurs directeurs et . Le plan peut donc être décrit par l'équation .  Est-ce que les deux équations obtenues sont vraiment équivalentes?   Dans le dernier exemple, on a déterminé deux vecteurs directeurs à partir de trois points du plan. Dans la définition d'un plan, il faut que les vecteurs directeurs soient non parallèles. Peut-on alors penser que deux vecteurs formés à partir de trois points sont toujours non parallèles ?  Avec les équations normales, le contexte est très important afin d'interpréter correctement un objet donné. L'équation représente une droite dans et un plan dans . Il est donc primordial de spécifier l'espace dans lequel on se trouve si l'on travaille avec les équations normales.  On termine avec des commandes Sage en lien avec la sous-section.   Les plans avec Sage  Pour tracer un plan dans , deux possibilités sont possibles. Pour la première, on peut utiliser l'équation normale et la commande implicit_plot3d . À remarquer l'utilisation de la double égalité == , puisque le symbole = est réservé à l'assignation des variables.   On peut aussi utiliser les équations paramétriques. La commande est parametric_plot3d .  On illustre les deux plans des exemples et .    Les options habituelles de couleur, transparence, etc. sont aussi disponibles.  Si l'équation du plan est donnée vectoriellement, il est aussi possible de le tracer avec la commande parametric_plot3d .      Distances  Soit une droite quelconque, quelle est la distance entre la droite et un point quelconque? Si le point est sur la droite, cette distance vaut , mais sinon, comment la calculer? Géométriquement, la distance est donnée par la longueur du segment de droite perpendiculaire à reliant le point et un point sur la droite, au pied du segment perpendiculaire. Celui-ci est illustré à la figure . La longueur de ce segment correspond à la norme du vecteur , qui lui, est obtenu à partir des vecteurs et de sa projection sur le vecteur directeur de la droite .   Distance entre un point et une droite    La distance entre un point et une droite est donc donnée par la formule où est un point connu sur et est le vecteur directeur de la droite. À remarquer que la formule fonctionne que la droite soit dans ou , et que, si le point est sur la droite, la formule donne , car le vecteur .  Il est parfois utile de connaitre la position du point , soit le point sur la droite qui est le plus près du point externe . Celui-ci peut être obtenu en ajoutant au vecteur le vecteur .  On s'intéresse maintenant à la distance entre un point et un plan dans . Encore une fois, si le point est sur le plan, la distance sera de et si le point est à l'extérieur, la distance sera calculée en déterminant la longueur du segment de droite reliant et un point de telle sorte que le vecteur soit perpendiculaire au plan. Si est un point connu d'un plan , le vecteur correspond à la projection du vecteur sur le vecteur normal du plan. La figure l'illustre bien.   Distance entre un point et un plan    La distance entre un point et un plan est donc donnée par la formule où est un point connu sur le plan et est le vecteur normal du plan. À remarquer que la formule fonctionne si le point est sur le plan, car le vecteur .  Il est parfois utile de connaitre la position du point , soit le point sur le plan qui est le plus près du point externe . Celui-ci peut être obtenu en soustrayant au vecteur le vecteur .  Dans , il est également possible de calculer la distance entre une droite et un plan ou deux plans. Autant pour le calcul de la distance entre une droite et un plan que pour la distance entre deux plans, deux cas peuvent survenir: ils peuvent se croiser, auquel cas la distance sera nulle, ou ils peuvent être parallèles. Si deux plans sont parallèles, il suffit de prendre un point sur l'un d'entre eux et de calculer la distance point plan. Si, par contre, une droite est parallèle au plan, il est important de prendre un point de la droite et de calculer la distance point-plan. L'exercice explique pourquoi prendre un point sur le plan et faire la distance point-droite ne fonctionne généralement pas.  La question de la distance entre deux droites demande un peu plus de réflexion. Dans , deux droites sont soit parallèles, soit sécantes, mais dans , il existe une troisième option. Deux droites peuvent ne pas se croiser sans être parallèles. On dit alors qu'elles sont gauches. Pour déterminer la distance entre les deux droites, on doit trouver la distance entre deux plans parallèles contenant chacun l'une des droites. Ceci nécessite de déterminer un vecteur qui est perpendiculaire au vecteur directeur respectif de chaque droite. Les détails pour trouver ce vecteur sont donnés dans l'exemple . En attendant, la figure illustre l'intuition derrière la méthode décrite ci-dessus.  Il n'y a pas de nouvelles commandes Sage, mais on illustre l'utilisation de Sage pour résoudre un exemple concret de calcul de distance.   La distance entre un point et une droite  On considère l'équation et le point . On cherche la distance entre et .  On commence par illustrer la droite et le point pour avoir une image de la situation   Pour calculer la distance, on doit connaitre un point de la droite et faire la projection du vecteur sur le vecteur directeur de la droite. On peut bonifier l'image précédente avec les vecteurs.   On calcule maintenant la projection et le vecteur et on ajoute ce dernier à la figure.   Enfin, on obtient la distance en calculant la longueur du vecteur .      Les éléments importants de cette section sont:  Le concept de combinaison linéaire de vecteurs.  Les droites dans et leur équation vectorielle , paramétrique et normale ;  Les droites dans et leur équation vectorielle (sous sa forme verticale) et paramétrique ;  Les plans dans et leur équation vectorielle , paramétrique et normale ;  La distance entre un point et une droite ;  La distance entre un point et un plan .        Exercices    Soit et . Exprimer comme une combinaison linéaire de et .     On veut résoudre l'équation vectorielle: . On veut donc trouver les valeurs de et . Bref, la combinaison linéaire suivante permet d'exprimer comme une combinaison linéaire de et :     Considérer la droite d'équation vectorielle , .   Parmi les points suivants, lesquels appartiennent à la droite? , , et   On cherche à déterminer si chaque point est sur la droite. On rappelle que l'équation vectorielle consiste à décrire l'ensemble des points de la droite par un vecteur directeur et un point. On peut voir le point comme la valeur initiale ou le point de départ et le vecteur directeur multiplié par le scalaire comme le chemin parcouru sur la droite pour arriver à n'importe quel autre point. Il est important de ne pas confondre vecteur et point, car les deux sont simplement écrits entre parenthèses dans l'équation. Ici, est le vecteur directeur et est le point de départ.   Les points , et sont sur la droite.   Pour : Il est clair que est sur la droite.  Pour : Il y a donc une contradiction et ne peut pas être sur la droite.  Pour : Le point est donc sur la droite.  Pour : Le point est donc sur la droite.   Quelle serait une équation normale de la droite .     On a appris que le vecteur normal \\vec{n}=(a,b) s'obtient du vecteur directeur, car il lui est perpendiculaire. Ainsi, On a maintenant presque toute l'information nécessaire pour compléter l'équation normale. On trouve la valeur de en remplaçant et par les coordonnées d'un point. On utilise le point .   Trouver une équation standard de la droite passant par le point qui est parallèle à la droite .     L'équation normale est la plus proche de l'équation standard. Comme on cherche une droite parallèle à , elle aura le même vecteur normal. Ainsi, il ne reste qu'à remplacer et dans l'équation par les coordonnées du point . On isole simplement pour obtenir l'équation standard.    Trouver les équations paramétriques de la droite perpendiculaire à la droite passant par le point .     Pour obtenir une équation paramétrique (ou vectorielle), il faut d'abord un vecteur directeur. Puisqu'on cherche une droite perpendiculaire à , son vecteur directeur est donc donné par le vecteur normal . On sait que la droite passe par le point . On a: .  On convertit en équations paramétriques pour avoir .    Dans la proposition , on a introduit le vecteur perpendiculaire . Pour chacune des propositions suivantes, expliquer d'abord son sens géométrique et ensuite la démontrer algébriquement.        On obtient le vecteur à partir de en lui faisant faire une rotation de degrés dans le sens antihoraire.   Il y a seulement deux vecteurs perpendiculaires à un vecteur donné dans . Il faut alors simplement déterminer que la proposition définit bien le vecteur obtenu à partir de en lui faisant faire une rotation de degrés dans le sens antihoraire. On observe sur le dessin que c'est le cas. On pourra le démontrer algébriquement en considérant que si et sont positifs, alors sera dans le premier quadrant. Ainsi, aura une valeur négative en et positive en , ce qui le place dans le deuxième quadrant. On voit que la rotation de s'est effectuée dans le sens horaire.     Dès qu'on accepte le résultat précédent, cette proposition est évidente géométriquement. Les deux vecteurs sont de même longueur. On le démontre algébriquement.      On observe géométriquement que ces vecteurs sont perpendiculaires. Cela revient à dire que leur produit scalaire est nul. On le démontre algébriquement.    quel que soit le scalaire   La figure interactive permet de visualiser efficacement cette proposition. Voici la démonstration algébrique.      Cette dernière proposition est plus difficile à visualiser géométriquement, mais sa démonstration algébrique est assez facile.     L'angle entre deux droites est défini comme étant l'angle obtenu en calculant l'angle entre les vecteurs directeurs des droites, ou son supplémentaire si celui-ci excède . Cet angle est défini même si les droites ne se croisent pas (parallèles ou gauches).  Calculer l'angle entre les droites et     On doit simplement calculer l'angle entre les vecteurs directeurs des droites, soit l'angle entre et . On utilise l'équation pour faire ce calcul. Puisque cet angle se trouve dans l'intervalle , on n'a pas à calculer l'angle supplémentaire. C'est donc l'angle entre les deux droites.    Soit une droite dans le plan dont le vecteur normal est . La droite sépare le plan en deux régions distinctes. On appelle le haut de la droite la région située dans le sens positif du vecteur normal et le bas la région dans le sens négatif du vecteur normal. La figure illustre ce concept.   La droite de partage du plan     Soit un point sur la droite et un point quelconque du plan. Décrire une manière vectorielle qui détermine si le point est en haut ou en bas de la droite.   Qu'ont de particulier les points sur la droite avec le vecteur normal?    Il faut construire le vecteur et calculer l'angle entre ce dernier et le vecteur normal . Si cet angle est plus grand que (angle obtu), alors le point se situe en bas de la droite. Si l'angle est plus petit que (angle aigu), alors le point se situe en haut de la droite. Finalement, si l'angle est d'exactement , alors le point se situe sur la droite.  Une version simplifiée de cette démarche se dessine en remarquant que les angles aigus s'obtiennent à partir de vecteurs dont le produit scalaire est positif, les angles obtus, à partir d'un produit scalaire négatif, et finalement, comme on le sait déjà, les vecteurs perpendiculaires ont un produit scalaire nul.   Soit une droite et un point. Est-ce que le point est en haut ou en bas de la droite?   Le point est en bas de la droite.   On passera par la version simplifiée de la démarche, en utilisant seulement le signe du produit scalaire. On a besoin de trouver un point quelconque sur la droite ainsi que le vecteur normal. Puisqu'on a déjà l'équation normale, le vecteur normal est: . On trouve un point en posant et en isolant . Le point est donc . Ensuite, calculons le vecteur . Le produit scalaire est donc: Puisqu'il est négatif, le point est en bas de la droite.   Expliquer pourquoi, géométriquement, ce concept n'est pas possible avec une droite dans .   La réponse courte est qu'il n'y a pas de vecteur normal pour une droite dans . La raison géométrique est qu'il existe une infinité de directions perpendiculaires à une droite dans l'espace en trois dimensions. On ne peut donc pas parler de \"en haut\" ou \"en bas\" de la droite. On pourrait cependant le faire avec un plan. Le point pourrait être sur la droite, mais il ne serait pas possible de déterminer que c'est le cas avec la méthode décrite plus haut, puisqu'il y a une infinité de directions perpendiculaires.    Dans la démarche ayant mené à l'équation normale d'une droite, , on pose . Il semble donc que l'équation dépende du point connu. Montrer que ce n'est pas le cas et que, peu importe le point sur la droite, la quantité est toujours égale à .   On remarque que la quantité . La figure ci-dessous peut être utile.   L'équation d'une droite ne dépend pas du point     Posons . On cherche à montrer que peu importe le point sur la droite. Selon la figure , le vecteur et le vecteur étant sur la droite, il est perpendiculaire à . On a donc . Ainsi, l'équation de la droite ne dépend pas du point connu.    Soit et .   Exprimer comme une combinaison linéaire de et .     On cherche les valeurs de et telles que: . On vérifie que cette combinaison fonctionne dans l'équation du milieu que l'on n'a pas utilisée: . Bref, .   Est-ce que le vecteur peut s'écrire comme une combinaison linéaire de et ?   Non, c'est impossible.   On cherche les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans l'équation du milieu que l'on n'a pas utilisée: . Bref, cette contradiction implique que , et il n'existe donc aucune combinaison linéaire permettant d'écrire comme une combinaison linéaire de et .   Géométriquement, quelle est la signification des résultats précédents?   L'existence d'une combinaison linéaire permettant d'écrire un vecteur de à l'aide de deux autres vecteurs non parallèles signifie que le vecteur se situe dans le plan engendré par les vecteurs et .  L'absence d'une combinaison linéaire permettant d'écrire un vecteur de à l'aide de deux autres vecteurs non parallèles signifie que le vecteur se situe à l'extérieur du plan engendré par les vecteurs et .    Le plan est donné par l'équation vectorielle .   Est-ce que le point  est sur le plan?   Oui, le point est sur le plan.   Pour le déterminer, il faut tenter de trouver les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans la seconde équation que l'on n'a pas utilisée. . Bref, le point est sur le plan.   Est-ce que le vecteur  est dans le plan?   Non, le vecteur n'est pas dans le plan.   Pour le déterminer, il faut tenter de trouver les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans la seconde équation que l'on n'a pas utilisée. . Bref, le vecteur n'est pas dans le plan.   Quelle est la différence géométrique entre les questions précédentes?   Le point correspond à un endroit physique dans l'espace à trois dimensions par rapport à l'origine. S'il est possible d'atteindre le point, se déplaçant à partir du point de départ en ajoutant une combinaison linéaire des deux vecteurs du plan, alors le point se trouve sur le plan.  Pour ce qui est du vecteur, il s'agit uniquement d'une orientation et d'une longueur. Si cette orientation est parallèle au plan, alors on dit que ce vecteur est dans le plan. Bref, il faut simplement que le vecteur puisse s'exprimer comme une combinaison linéaire des deux vecteurs directeurs du plan pour qu'il soit parallèle au plan et donc dans le plan.    Considérer un plan quelconque d'équation vectorielle . Considérer une droite d'équation vectorielle .   Quelles sont les conditions sur et pour que la droite soit dans le plan?   Il faut à la fois que le vecteur soit dans le plan et que le point de départ soit sur le plan. On a considéré ces deux problèmes à l'exercice .   Quelles sont les conditions sur et pour que la droite soit parallèle au plan, mais à l'extérieur de celui-ci?   Il faut que le vecteur soit dans le plan, mais que le point de départ ne soit pas sur le plan.   Si l'équation du plan est donnée sous sa forme normale, , quelles sont les conditions sur et pour que la droite soit parallèle au plan?   Il suffit d'utiliser le produit scalaire. En effet, si le produit scalaire du vecteur directeur de la droite ( ) et du vecteur normal du plan est nul, les deux vecteurs seront perpendiculaires. Ainsi, la droite sera parallèle au plan.   Comment déterminer si une droite intersecte un plan?   Il y a plusieurs façons de faire.  D'abord, on pourrait utiliser la méthode longue , mais simple, qui consiste à tenter de trouver ce point d'intersection et de bien interpréter la solution. Pour ce faire, on doit résoudre l'équation : . Il faut donc trouver les valeurs de , et qui la solutionnent. Avec cette résolution, on pourra arriver aux trois options classiques d'un système à trois équations et trois inconnues: aucune solution (pas d'intersection), solution unique (un point d'intersection) ou infinité de solutions (droite dans le plan).  Si le but est uniquement de déterminer si il y a une intersection, on peut se servir de ce qu'on a vu précédemment. En effet, une droite quelconque aura presque toujours une ou une infinité d'intersections avec un plan quelconque, sauf si ce plan est parallèle à la droite, sans toutefois la contenir. On peut donc savoir qu'il existe une intersection sauf si le vecteur est dans le plan et que le point de départ n'est pas sur le plan.    Dans le texte, il est dit que, pour calculer la distance entre une droite et un plan qui sont parallèles, il suffit de faire la distance entre un point quelconque de la droite et le plan.   Expliquer géométriquement pourquoi cette manière de procéder fonctionne.   La réponse à cette question est la suivante: puisque la droite est parallèle au plan, tous les points de la droite sont à la même distance du plan. On déduit que la distance point plan donnera la même valeur que la distance droite plan, peu importe le choix du point sur la droite.   Expliquer, à l'aide de la figure , pourquoi procéder en calculant la distance entre un point du plan et la droite ne fonctionne généralement pas.   La distance entre un plan et une droite parallèles     Puisqu'en général, le point choisi sur le plan ne sera pas le plus près possible de la droite, on le voit assez bien sur la figure, on obtiendra alors une valeur de distance plus élevée que la vraie distance entre la droite et le plan.   Quels sont les cas où, par un pur hasard, la distance point droite fonctionnerait?   Considérer la figure interactive suivante:   La projection d'une droite sur un plan parallèle     Il faudrait que le point choisi sur le plan soit le plus proche possible de la droite. Cela correspond à tous les points qui sont sur la projection de la droite sur le plan tel qu'illustré dans la figure.   Vérifier que la droite d'équation est parallèle au plan . Quelle est la distance entre la droite et le plan?   La distance est de .   Pour faire cette vérification, on peut simplement calculer le produit scalaire entre le vecteur directeur de la droite et le vecteur normal du plan. Si ce produit donne zéro, alors on saura que ces vecteurs sont perpendiculaires et que la droite est parallèle au plan. On a le vecteur directeur et le vecteur normal est donné par les coefficients de l'équation normale de la droite: . Les vecteurs sont donc perpendiculaires et la droite et le plan sont parallèles.  On obtient cette distance en calculant la distance point-plan entre le point sur la droite et le plan. On a besoin du vecteur normal du plan et d'un point quelconque du plan. On en choisit un qui est simple et qui fonctionne dans l'équation, par exemple le point .     Soit un plan de vecteurs directeurs et soit un vecteur normal du plan.   On suppose que les vecteurs et sont perpendiculaires. Montrer que, pour tout vecteur dans le plan, on a .   Pour qu'un vecteur soit dans le plan, il doit être exprimable comme une combinaison linéaire des vecteurs directeurs et . On sait donc qu'il existe des valeurs telles que . Aussi, lorsqu'on écrit le vecteur en termes de ses projections sur les vecteurs et perpendiculaires, on obtient cette combinaison linéaire directement. La preuve réside dans le fait qu'ils sont perpendiculaires. La projection orthogonale fournit déjà de quoi décomposer un vecteur en termes de et . On peut donc écrire:   Donner un exemple où si et ne sont pas perpendiculaires, alors l'équation ne fonctionne pas.   et avec le vecteur   On propose et avec le vecteur . En effet, Bref, la décomposition en termes des vecteurs et ne s'obtient pas par la projection orthogonale.   Soit un vecteur normal du plan et supposer à nouveau que les vecteurs et sont perpendiculaires. Montrer que pour tout vecteur dans , on a .   Appliquer la partie (a) au vecteur .   De façon semblable, on sait qu'on peut écrire le vecteur . On applique la partie (a) au vecteur entre parenthèses puisqu'il se trouve dans le plan. Ainsi, on aura: Par conséquent, en remplaçant dans l'équation précédente, on a:    Soit et un point et une droite dans . On cherche l'équation de l'ensemble des points qui sont à distance égale de et . Il est bien connu que l'ensemble des points à distance égale d'un point et d'une droite forme une parabole.      On doit simplement écrire dans une équation le calcul de la distance point droite et point point. En effet, tout point étant sur la parabole devra être à la même distance de la droite et du point fixe. On nommera le point de départ dans l'équation de la droite.    Soit et deux vecteurs de non parallèles et un autre vecteur de quelconque.   Montrer qu'il est toujours possible d'écrire comme une combinaison linéaire de et .   On sait que et étant non parallèles, il n'existe pas de constante telle que . On cherche à montrer qu'il existe des constantes telles que . Si l'on réussit à isoler ces constantes et à toujours avoir des valeurs, peu importe les vecteurs, on aura fait la preuve. On remarque que, puisqu'on a trouvé une expression pour et qui dépende de toutes les valeurs quelconques pour les vecteurs et , on peut toujours trouver cette combinaison linéaire. La seule condition est que le dénominateur ne soit pas égal à zéro. Cela sera toujours le cas en raison de l'hypothèse de départ que les vecteurs et ne sont pas parallèles. En effet, s'il n'existe pas de constante telle que , alors , ce qui complète la preuve.   Montrer qu'il est possible d'avoir avec pas tous égaux à .   On a obtenu qu'il existe des constantes telles que . Il suffit d'envoyer tous les vecteurs du même côté de l'égalité: En posant , et , on obtient aisément cette équation qui est tout à fait équivalente. On utilisera cette façon de faire au chapitre pour montrer qu'un ensemble de vecteurs est linéairement dépendant .    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Tracer les droites et sur un même graphique, respectivement en noir et en rouge.     Deux droites tracées à partir de leur équation vectorielle.   La droite D un et la droite D deux sont tracées dans le plan cartésien, respectivement en noire et en rouge       Le code solution pour l'exercice   var(\"a\") D1=parametric_plot([-a-3,2*a+2],(a,-5,5),color=\"black\") D2=parametric_plot([3*a+4,-a],(a,-5,5),color=\"red\") D1+D2       Considérer le plan d'équation et le point .    Trouver une équation normale pour le plan .  Calculer la distance entre le plan et le point .  Quelles sont les coordonnées du point le plus près du point ?  Illustrer sur un graphique le plan, le point et le vecteur dont la norme est égale à la distance plan-point, issue du point        Le vecteur normal est , ou n'importe quel multiple de ce dernier. L'équation normale est donc de la forme  La distance est .          Pour trouver le vecteur normal , il faut résoudre simultanément les équations et . Le code suivant permet d'obtenir une solution.   Le code pour le vecteur normal, partie 1   u=vector([-1,2,1]) #le premier vecteur directeur v=vector([-5,4,-3]) #le second vecteur directeur var(\"a\",\"b\",\"c\") n=vector([a,b,c]) #le vecteur normal eq1=u*n==0 #le vecteur normal doit être perpendiculaire à u eq2=v*n==0 #le vecteur normal doit être perpendiculaire à v sol=solve([eq1,eq2],a,b,c,solution_dict=True) #on résout les équations en fonction des composantes du vecteur normal. L'option solution_dict permet de coder différement les entrées de sol sol    À remarquer qu'il y a une infinité de solutions, données sous forme paramétrique ici. Ceci est attendu étant donné que n'importe quel multiple d'un vecteur normal est aussi un vecteur normal. Dans ce cas-ci, si l'on prend la variable libre comme étant égale à (pour éliminer les fractions), on obtient   Le code pour le vecteur normal, partie 2   n=vector([sol[0][a],sol[0][b],sol[0][c]]) #on extrait de la liste de solutions sol les expressions voulues libre=sol[0][a].variables()[0] #On va chercher le nom de la variable libre. Ceci est nécessaire au cas où des exécutions multiples sont effectuées n=n.subs({libre:3}) #on pose la variable libre à 3 n    Finalement, on obtient l'équation normale ce qui donne   Le code pour l'équation normale   var(\"x\",\"y\",\"z\") show(n*vector([x-6,y-3,z-2])==0)     La distance est obtenue à l'aide de la formule :   Le code pour la distance point plan   OA=vector([6,3,2]) #un point connu sur le plan OP=vector([3,-4,2]) #le point extérieur au plan AP=OP-OA APsurn=AP*n\/(n*n)*n #calcul de la projection show(norm(APsurn))     Le point est donné par la formule . On obtient alors:   Les coordonnées du points   OQ=OP-APsurn show(OQ)     Pour illustrer le plan, le point et le vecteur , on utilise:   Le code de la représentation graphique   plan=implicit_plot3d(n*vector([x-6,y-3,z-2])==0,(x,-10,10),(y,-10,10),(z,-10,10),color=\"blue\") P=point(OP,size=15,color=\"black\") vecproj=plot(APsurn,color=\"red\",start=OQ) plan+P+vecproj        Automatisation de l'équation d'une parabole  Dans l'exercice , on a déterminé une équation implicite d'une parabole à distance égale d'un point et d'une droite . Le but de cet exercice est de créer un programme qui, étant donné les coordonnées d'un point , d'un point et d'un vecteur , déterminera l'équation de la parabole de foyer et de droite directrice . À Finir (Tracer graphique, tester avec celle de l'exercice)     L'équation d'une parabole   def eqpara(v,A,F): var(\"x\",\"y\",domain=\"real\") P=vector([x,y]) AP=P-A PF=F-P return (expand(norm(PF)^2-norm(AP-AP*v\/(v*v)*v)^2)==0)       "
},
{
  "id": "def-comblin",
  "level": "2",
  "url": "sec-droitesplans.html#def-comblin",
  "type": "Définition",
  "number": "1.3.1",
  "title": "",
  "body": " Si l'on a vecteurs , une combinaison linéaire de ces vecteurs est s'écrit .  "
},
{
  "id": "ex-comblin",
  "level": "2",
  "url": "sec-droitesplans.html#ex-comblin",
  "type": "Exemple",
  "number": "1.3.2",
  "title": "Combinaison linéaire de deux vecteurs: dynamique.",
  "body": " Combinaison linéaire de deux vecteurs: dynamique  Dans cet exemple, on considère, pour des vecteurs de , les combinaisons de la forme et . En se référant à la figure , sans toucher aux vecteurs de départ, on s'intéresse aux questions suivantes:   Au départ, les poids de la combinaison linéaire valent . En laissant l'un des paramètres nul et en faisant varier l'autre, on observe que la combinaison linéaire n'est qu'une multiplication par un scalaire. Celle-ci se déplace sur une droite. Ceci est cohérent avec les observations faites lors de l'exemple .    En cliquant sur \"grille\" et en prenant des valeurs entières de et , on observe que les multiplications de et , respectivement par les scalaires et , se retrouvent aux intersections de la grille. Si, en plus, on fait afficher la combinaison linéaire, on peut voir géométriquement l'addition des vecteurs et .    On fixe une valeur de quelconque, entière ou non et on laisse varier . Qu'observe-t-on?    Est-il possible de décrire n'importe quel vecteur de comme une combinaison linéaire de et ? Cette question revient à dire, étant donné un vecteur , que l'on peut trouver des coefficients tels que . Puisque deux vecteurs sont égaux si leurs composantes respectives le sont, on obtient les deux équations suivantes: . Ce type de paires d'équations à résoudre est appelé un système d'équations linéaires et sera l'objet d'étude du chapitre .  Il est assez simple de voir intuitivement que, dès que deux vecteurs sont non parallèles dans , on peut écrire n'importe quel autre vecteur en fonction de ceux-ci. Un clic sur \"Cible\" fera apparaitre un point (plutôt qu'un vecteur, pour ne pas encombrer davantage la figure). À l'aide des curseurs, il devrait être possible de trouver une combinaison linéaire dont l'extrémité sera le point \"Cible\".   On observe ce qui se passe lorsque les vecteurs initiaux sont changés, en particulier si et sont parallèles.    Combinaison linéaire dans     "
},
{
  "id": "ex-eqdroite-1",
  "level": "2",
  "url": "sec-droitesplans.html#ex-eqdroite-1",
  "type": "Exemple",
  "number": "1.3.4",
  "title": "L’équation de droites.",
  "body": " L'équation de droites  Considérons le point de et les points et . On cherche l'équation de la droite dans qui passe par le point et qui a la même direction que la droite et l'équation de la droite dans qui passe par et .  La première partie est assez simple, puisque toute l'information nous est donnée. On connait un point de la droite et la direction. L'équation est donc .  Pour la seconde partie, on doit d'abord trouver un vecteur directeur pour la droite. Le vecteur fera l'affaire. Pour un point, on a le choix entre ou , n'importe lequel fera l'affaire. On obtient finalement .  "
},
{
  "id": "ex-eqdroite-2",
  "level": "2",
  "url": "sec-droitesplans.html#ex-eqdroite-2",
  "type": "Exemple",
  "number": "1.3.5",
  "title": "L’équation vectorielle n’est pas unique.",
  "body": " L'équation vectorielle n'est pas unique  On reprend l'équation de la droite dans de l'exemple  . En utilisant le point plutôt que le point et un vecteur parallèle à , disons en le multipliant par , on obtient une nouvelle représentation pour la droite : . On remarque l'utilisation du scalaire plutôt que afin d'évoquer la différence entre les deux équations. On aurait pu utiliser également, en gardant en tête qu'une valeur de dans la première représentation de la droite ne donnera pas nécessairement le même point que cette même valeur de dans la nouvelle représentation.  Comment s'assurer que ces deux équations décrivent la même droite? Une manière simple est de partir de l'une des équations et de montrer que l'on peut arriver à l'autre par une suite de manipulations algébriques. Dans notre cas, on a , où . Comme on peut faire les opérations dans l'ordre inverse, les deux représentations sont équivalentes.  "
},
{
  "id": "ex-stdavec",
  "level": "2",
  "url": "sec-droitesplans.html#ex-stdavec",
  "type": "Exemple",
  "number": "1.3.6",
  "title": "De la forme standard à la forme vectorielle.",
  "body": " De la forme standard à la forme vectorielle  Considérons une droite dans , par exemple . Sous forme vectorielle, on cherche à exprimer l'ensemble de points sur la droite. Ces points sont de la forme . On peut décomposer cette forme afin d'obtenir la forme vectorielle. . On trouve donc une droite de vecteur directeur passant par le point . On Remarque qu'en suivant cette démarche, la première composante du vecteur directeur sera toujours , et la seconde correspondra à la pente de la droite.  Évidemment, ce n'est pas la seule forme valide pour décrire la droite vectoriellement.  "
},
{
  "id": "ex-vecastd",
  "level": "2",
  "url": "sec-droitesplans.html#ex-vecastd",
  "type": "Exemple",
  "number": "1.3.7",
  "title": "De la forme vectorielle à la forme standard.",
  "body": " De la forme vectorielle à la forme standard  Considérons une droite dans , par exemple . On cherche la forme de cette droite. Plusieurs démarches sont possibles. On peut facilement trouver deux points en utilisant deux scalaires différents dans la forme vectorielle. Par la suite, la démarche usuelle mènera à l'équation de la droite.  On peut aussi y aller avec l'interprétation géométrique du vecteur directeur. Le vecteur correspond à un déplacement horizontal de unités et un déplacement vertical de unités. Ceci nous donne la pente . Pour trouver l'ordonnée à l'origine, il suffit de mettre la première composante de la forme vectorielle à , en prenant ici . On trouve alors l'ordonnée à l'origine . La droite est donc aussi décrite par l'équation .  "
},
{
  "id": "pro-vecperp",
  "level": "2",
  "url": "sec-droitesplans.html#pro-vecperp",
  "type": "Proposition",
  "number": "1.3.8",
  "title": "Le vecteur perpendiculaire.",
  "body": " Le vecteur perpendiculaire   Soit un vecteur de non nul. Alors le vecteur est perpendiculaire à .    Il suffit de vérifier que l'on a bien . Algébriquement, et donc, c'est vérifié.   "
},
{
  "id": "fig-droitesperp",
  "level": "2",
  "url": "sec-droitesplans.html#fig-droitesperp",
  "type": "Figure",
  "number": "1.3.9",
  "title": "",
  "body": " Des droites perpendiculaires   "
},
{
  "id": "sageex-droites",
  "level": "2",
  "url": "sec-droitesplans.html#sageex-droites",
  "type": "Calcul",
  "number": "1.3.10",
  "title": "Les droites avec Sage.",
  "body": " Les droites avec Sage  Pour tracer une droite dans ou dans , deux options sont possibles. La première option est simple et nécessite deux points sur la droite. Il suffit alors d'utiliser la commande line .   Une autre option, plus flexible, utilise les équations paramétriques. Elle est plus flexible puisqu qu'elle permet de décrire des courbes quelconques comme celles explorées dans la section . La commande est parametric_plot ou parametric_plot3d , selon le cas.  On illustre les deux droites solutions de l'exemple .    Les options habituelles de couleur, épaisseur, etc. sont aussi disponibles.  Si l'équation de la droite est donnée vectoriellement, il est aussi possible de la tracer avec la commande parametric_plot ou son équivalent .   "
},
{
  "id": "ex-comblinplan",
  "level": "2",
  "url": "sec-droitesplans.html#ex-comblinplan",
  "type": "Exemple",
  "number": "1.3.11",
  "title": "Combinaison linéaire en trois dimensions: dynamique.",
  "body": " Combinaison linéaire en trois dimensions: dynamique  Cet exemple est semblable à l'exemple , mais avec des vecteurs de . Les combinaisons de la forme et sont étudiées en se référant à la figure et aux questions suivantes:   Comme précédemment, les multiples d'un seul vecteur donnent une droite.    En cliquant sur \"grille\" et en prenant des valeurs entières de et , on observe que les multiplications par un scalaire respectives de et se retrouvent à une intersection de la grille. Si en plus on fait afficher la combinaison linéaire, on peut voir géométriquement l'addition des vecteurs et .    Est-il possible de décrire n'importe quel vecteur de comme une combinaison linéaire de et ? Cette question revient à dire, étant donné un vecteur , peut-on trouver des coefficients tels que . Puisque deux vecteurs sont égaux si leurs composantes respectives le sont, on obtient les deux équations suivantes: . Cette fois-ci, on a trois équations, mais seulement deux inconnues. Si l'on ne se soucie pas de l'équation , on peut, probablement, trouver des valeurs de qui vont satisfaire les équations et . Ces valeurs ne vont pas forcément satisfaire l'autre équation. Les détails et cas possibles pouvant survenir seront traités au chapitre .  Un clic sur \"Cibles\" fera apparaitre deux points dans l'espace. L'un de ces points sera toujours atteignable par une combinaison linéaire appropriée de et , mais l'autre ne le sera probablement pas. Pourquoi?    Un clic sur \"Plan\" fera apparaitre l'ensemble des points qui sont atteignables par combinaison linéaire de et . Le point \"Cible1\" est sans doute à l'extérieur de ce plan et ne peut donc pas être atteint. Par contre, \"Cible2\" a été construit de façon à toujours être dans l'ensemble des combinaisons linéaires possibles.     Combinaison linéaire dans     "
},
{
  "id": "fig-planquelconque",
  "level": "2",
  "url": "sec-droitesplans.html#fig-planquelconque",
  "type": "Figure",
  "number": "1.3.13",
  "title": "",
  "body": " Un plan dans passant par un point .   "
},
{
  "id": "ex-eqplan3p",
  "level": "2",
  "url": "sec-droitesplans.html#ex-eqplan3p",
  "type": "Exemple",
  "number": "1.3.14",
  "title": "L’équation d’un plan passant par trois points.",
  "body": " L'équation d'un plan passant par trois points   Soit et trois points de l'espace. On cherche une équation du plan passant par et .    Pour décrire un plan vectoriellement, on a besoin d'un point et de deux vecteurs directeurs. L'ensemble des points sur la droite passant par et doit forcément faire partie du plan, tout comme l'ensemble des points sur la droite passant par et . En particulier, les vecteurs et peuvent être considérés comme des vecteurs directeurs du plan cherché. En prenant comme point particulier le point , on obtient .   "
},
{
  "id": "ex-pointsurplan",
  "level": "2",
  "url": "sec-droitesplans.html#ex-pointsurplan",
  "type": "Exemple",
  "number": "1.3.15",
  "title": "Déterminer si un point est sur un plan.",
  "body": " Déterminer si un point est sur un plan   Considérons le plan d'équation vectorielle . On cherche à savoir si les points et font partie du plan.    Pour savoir si le point est dans le plan, il faut trouver tels que . De cette équation vectorielle, on tire les équations suivantes: . L'équation donne immédiatement , et en remplaçant cette valeur dans les équations et , on trouve . Une vérification rapide montre qu'on a bel et bien    Pour savoir si le point est dans le plan, il faut trouver tels que . De cette équation vectorielle, on tire les équations suivantes: . L'équation donne immédiatement . En remplaçant cette valeur dans les équations et , on trouve une incohérence, puisque d'une part, l'équation demande à ce que alors l'équation que demanque que . Comme ne peut être simultanément et , on conclut que le point ne peut pas appartenir au plan .  On verra prochainement une autre manière de déterminer si un point appartient à un plan de et le chapitre donnera une méthode structurée pour résoudre les systèmes d'équations comme ceux dans cet exemple.   "
},
{
  "id": "prop-perpclin",
  "level": "2",
  "url": "sec-droitesplans.html#prop-perpclin",
  "type": "Proposition",
  "number": "1.3.16",
  "title": "Orthogonalité et combinaison linéaire.",
  "body": " Orthogonalité et combinaison linéaire   Soit et tels que est perpendiculaire à la fois à et . Alors est perpendiculaire à toute combinaison linéaire de et .    Soit une combinaison linéaire quelconque des vecteurs et . On doit montrer que . On a .  Ainsi, est perpendiculaire à toute combinaison linéaire des vecteurs et .  "
},
{
  "id": "ex-eqnormplan",
  "level": "2",
  "url": "sec-droitesplans.html#ex-eqnormplan",
  "type": "Exemple",
  "number": "1.3.17",
  "title": "L’équation d’une droite perpendiculaire à un plan.",
  "body": " L'équation d'une droite perpendiculaire à un plan   On considère le plan d'équation . On cherche l'équation de la droite qui passe par le point et qui est perpendiculaire au plan .    Soit , un vecteur directeur de cette droite. Si l'on réussit à trouver perpendiculaire à et , alors, selon la proposition , sera orthogonal à tous les vecteurs du plan. On doit avoir et . On a par conséquent trois inconnues à déterminer et deux équations qui les relient. En réarrangeant les équations, on arrive à et . Le vecteur peut donc être exprimé comme . On met le facteur commun en évidence pour obtenir , avec un nombre réel quelconque. Peu importe la valeur de , on obtient un multiple du vecteur . On choisit donc ce vecteur (en posant ) comme étant la direction cherchée.  Puisque l'on cherchait l'équation de la droite passant par le point , la réponse est .   "
},
{
  "id": "ex-normavec",
  "level": "2",
  "url": "sec-droitesplans.html#ex-normavec",
  "type": "Exemple",
  "number": "1.3.18",
  "title": "De l’équation normale à l’équation vectorielle.",
  "body": " De l'équation normale à l'équation vectorielle   Soit l'équation une équation normale d'un plan dans . On cherche une équation vectorielle décrivant ce plan.    Une première solution est d'isoler l'une des variables dans l'équation normale. Ici, on a par exemple . Un point dans le plan doit satisfaire , où l'on a réécrit le point en regroupant les termes semblables.  On réécrit avec la notation habituelle pour obtenir .   Une autre option est de sélectionner trois points non alignés sur le plan et de créer des vecteurs directeurs à partir de ces points. On retrouve alors facilement l'équation vectorielle. Par exemple, si , le point sur le plan doit avoir . De même, si , on a et si , on a . Des points et , on tire les vecteurs directeurs et . Le plan peut donc être décrit par l'équation .  Est-ce que les deux équations obtenues sont vraiment équivalentes?  "
},
{
  "id": "sageex-plans",
  "level": "2",
  "url": "sec-droitesplans.html#sageex-plans",
  "type": "Calcul",
  "number": "1.3.19",
  "title": "Les plans avec Sage.",
  "body": " Les plans avec Sage  Pour tracer un plan dans , deux possibilités sont possibles. Pour la première, on peut utiliser l'équation normale et la commande implicit_plot3d . À remarquer l'utilisation de la double égalité == , puisque le symbole = est réservé à l'assignation des variables.   On peut aussi utiliser les équations paramétriques. La commande est parametric_plot3d .  On illustre les deux plans des exemples et .    Les options habituelles de couleur, transparence, etc. sont aussi disponibles.  Si l'équation du plan est donnée vectoriellement, il est aussi possible de le tracer avec la commande parametric_plot3d .   "
},
{
  "id": "fig-distpd",
  "level": "2",
  "url": "sec-droitesplans.html#fig-distpd",
  "type": "Figure",
  "number": "1.3.20",
  "title": "",
  "body": " Distance entre un point et une droite   "
},
{
  "id": "fig-distpp",
  "level": "2",
  "url": "sec-droitesplans.html#fig-distpp",
  "type": "Figure",
  "number": "1.3.21",
  "title": "",
  "body": " Distance entre un point et un plan   "
},
{
  "id": "sageex-distpd",
  "level": "2",
  "url": "sec-droitesplans.html#sageex-distpd",
  "type": "Calcul",
  "number": "1.3.22",
  "title": "La distance entre un point et une droite.",
  "body": " La distance entre un point et une droite  On considère l'équation et le point . On cherche la distance entre et .  On commence par illustrer la droite et le point pour avoir une image de la situation   Pour calculer la distance, on doit connaitre un point de la droite et faire la projection du vecteur sur le vecteur directeur de la droite. On peut bonifier l'image précédente avec les vecteurs.   On calcule maintenant la projection et le vecteur et on ajoute ce dernier à la figure.   Enfin, on obtient la distance en calculant la longueur du vecteur .   "
},
{
  "id": "exo-comblin-1",
  "level": "2",
  "url": "sec-droitesplans.html#exo-comblin-1",
  "type": "Exercice",
  "number": "1.3.4.1",
  "title": "",
  "body": " Soit et . Exprimer comme une combinaison linéaire de et .     On veut résoudre l'équation vectorielle: . On veut donc trouver les valeurs de et . Bref, la combinaison linéaire suivante permet d'exprimer comme une combinaison linéaire de et :   "
},
{
  "id": "exo-droites-1",
  "level": "2",
  "url": "sec-droitesplans.html#exo-droites-1",
  "type": "Exercice",
  "number": "1.3.4.2",
  "title": "",
  "body": " Considérer la droite d'équation vectorielle , .   Parmi les points suivants, lesquels appartiennent à la droite? , , et   On cherche à déterminer si chaque point est sur la droite. On rappelle que l'équation vectorielle consiste à décrire l'ensemble des points de la droite par un vecteur directeur et un point. On peut voir le point comme la valeur initiale ou le point de départ et le vecteur directeur multiplié par le scalaire comme le chemin parcouru sur la droite pour arriver à n'importe quel autre point. Il est important de ne pas confondre vecteur et point, car les deux sont simplement écrits entre parenthèses dans l'équation. Ici, est le vecteur directeur et est le point de départ.   Les points , et sont sur la droite.   Pour : Il est clair que est sur la droite.  Pour : Il y a donc une contradiction et ne peut pas être sur la droite.  Pour : Le point est donc sur la droite.  Pour : Le point est donc sur la droite.   Quelle serait une équation normale de la droite .     On a appris que le vecteur normal \\vec{n}=(a,b) s'obtient du vecteur directeur, car il lui est perpendiculaire. Ainsi, On a maintenant presque toute l'information nécessaire pour compléter l'équation normale. On trouve la valeur de en remplaçant et par les coordonnées d'un point. On utilise le point .   Trouver une équation standard de la droite passant par le point qui est parallèle à la droite .     L'équation normale est la plus proche de l'équation standard. Comme on cherche une droite parallèle à , elle aura le même vecteur normal. Ainsi, il ne reste qu'à remplacer et dans l'équation par les coordonnées du point . On isole simplement pour obtenir l'équation standard.    Trouver les équations paramétriques de la droite perpendiculaire à la droite passant par le point .     Pour obtenir une équation paramétrique (ou vectorielle), il faut d'abord un vecteur directeur. Puisqu'on cherche une droite perpendiculaire à , son vecteur directeur est donc donné par le vecteur normal . On sait que la droite passe par le point . On a: .  On convertit en équations paramétriques pour avoir .  "
},
{
  "id": "exo-vecperp",
  "level": "2",
  "url": "sec-droitesplans.html#exo-vecperp",
  "type": "Exercice",
  "number": "1.3.4.3",
  "title": "",
  "body": " Dans la proposition , on a introduit le vecteur perpendiculaire . Pour chacune des propositions suivantes, expliquer d'abord son sens géométrique et ensuite la démontrer algébriquement.        On obtient le vecteur à partir de en lui faisant faire une rotation de degrés dans le sens antihoraire.   Il y a seulement deux vecteurs perpendiculaires à un vecteur donné dans . Il faut alors simplement déterminer que la proposition définit bien le vecteur obtenu à partir de en lui faisant faire une rotation de degrés dans le sens antihoraire. On observe sur le dessin que c'est le cas. On pourra le démontrer algébriquement en considérant que si et sont positifs, alors sera dans le premier quadrant. Ainsi, aura une valeur négative en et positive en , ce qui le place dans le deuxième quadrant. On voit que la rotation de s'est effectuée dans le sens horaire.     Dès qu'on accepte le résultat précédent, cette proposition est évidente géométriquement. Les deux vecteurs sont de même longueur. On le démontre algébriquement.      On observe géométriquement que ces vecteurs sont perpendiculaires. Cela revient à dire que leur produit scalaire est nul. On le démontre algébriquement.    quel que soit le scalaire   La figure interactive permet de visualiser efficacement cette proposition. Voici la démonstration algébrique.      Cette dernière proposition est plus difficile à visualiser géométriquement, mais sa démonstration algébrique est assez facile.   "
},
{
  "id": "exo-angledroites",
  "level": "2",
  "url": "sec-droitesplans.html#exo-angledroites",
  "type": "Exercice",
  "number": "1.3.4.4",
  "title": "",
  "body": " L'angle entre deux droites est défini comme étant l'angle obtenu en calculant l'angle entre les vecteurs directeurs des droites, ou son supplémentaire si celui-ci excède . Cet angle est défini même si les droites ne se croisent pas (parallèles ou gauches).  Calculer l'angle entre les droites et     On doit simplement calculer l'angle entre les vecteurs directeurs des droites, soit l'angle entre et . On utilise l'équation pour faire ce calcul. Puisque cet angle se trouve dans l'intervalle , on n'a pas à calculer l'angle supplémentaire. C'est donc l'angle entre les deux droites.  "
},
{
  "id": "exercise-37",
  "level": "2",
  "url": "sec-droitesplans.html#exercise-37",
  "type": "Exercice",
  "number": "1.3.4.5",
  "title": "",
  "body": " Soit une droite dans le plan dont le vecteur normal est . La droite sépare le plan en deux régions distinctes. On appelle le haut de la droite la région située dans le sens positif du vecteur normal et le bas la région dans le sens négatif du vecteur normal. La figure illustre ce concept.   La droite de partage du plan     Soit un point sur la droite et un point quelconque du plan. Décrire une manière vectorielle qui détermine si le point est en haut ou en bas de la droite.   Qu'ont de particulier les points sur la droite avec le vecteur normal?    Il faut construire le vecteur et calculer l'angle entre ce dernier et le vecteur normal . Si cet angle est plus grand que (angle obtu), alors le point se situe en bas de la droite. Si l'angle est plus petit que (angle aigu), alors le point se situe en haut de la droite. Finalement, si l'angle est d'exactement , alors le point se situe sur la droite.  Une version simplifiée de cette démarche se dessine en remarquant que les angles aigus s'obtiennent à partir de vecteurs dont le produit scalaire est positif, les angles obtus, à partir d'un produit scalaire négatif, et finalement, comme on le sait déjà, les vecteurs perpendiculaires ont un produit scalaire nul.   Soit une droite et un point. Est-ce que le point est en haut ou en bas de la droite?   Le point est en bas de la droite.   On passera par la version simplifiée de la démarche, en utilisant seulement le signe du produit scalaire. On a besoin de trouver un point quelconque sur la droite ainsi que le vecteur normal. Puisqu'on a déjà l'équation normale, le vecteur normal est: . On trouve un point en posant et en isolant . Le point est donc . Ensuite, calculons le vecteur . Le produit scalaire est donc: Puisqu'il est négatif, le point est en bas de la droite.   Expliquer pourquoi, géométriquement, ce concept n'est pas possible avec une droite dans .   La réponse courte est qu'il n'y a pas de vecteur normal pour une droite dans . La raison géométrique est qu'il existe une infinité de directions perpendiculaires à une droite dans l'espace en trois dimensions. On ne peut donc pas parler de \"en haut\" ou \"en bas\" de la droite. On pourrait cependant le faire avec un plan. Le point pourrait être sur la droite, mais il ne serait pas possible de déterminer que c'est le cas avec la méthode décrite plus haut, puisqu'il y a une infinité de directions perpendiculaires.  "
},
{
  "id": "exo-droitenormalc",
  "level": "2",
  "url": "sec-droitesplans.html#exo-droitenormalc",
  "type": "Exercice",
  "number": "1.3.4.6",
  "title": "",
  "body": " Dans la démarche ayant mené à l'équation normale d'une droite, , on pose . Il semble donc que l'équation dépende du point connu. Montrer que ce n'est pas le cas et que, peu importe le point sur la droite, la quantité est toujours égale à .   On remarque que la quantité . La figure ci-dessous peut être utile.   L'équation d'une droite ne dépend pas du point     Posons . On cherche à montrer que peu importe le point sur la droite. Selon la figure , le vecteur et le vecteur étant sur la droite, il est perpendiculaire à . On a donc . Ainsi, l'équation de la droite ne dépend pas du point connu.  "
},
{
  "id": "exo-comblin-2",
  "level": "2",
  "url": "sec-droitesplans.html#exo-comblin-2",
  "type": "Exercice",
  "number": "1.3.4.7",
  "title": "",
  "body": " Soit et .   Exprimer comme une combinaison linéaire de et .     On cherche les valeurs de et telles que: . On vérifie que cette combinaison fonctionne dans l'équation du milieu que l'on n'a pas utilisée: . Bref, .   Est-ce que le vecteur peut s'écrire comme une combinaison linéaire de et ?   Non, c'est impossible.   On cherche les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans l'équation du milieu que l'on n'a pas utilisée: . Bref, cette contradiction implique que , et il n'existe donc aucune combinaison linéaire permettant d'écrire comme une combinaison linéaire de et .   Géométriquement, quelle est la signification des résultats précédents?   L'existence d'une combinaison linéaire permettant d'écrire un vecteur de à l'aide de deux autres vecteurs non parallèles signifie que le vecteur se situe dans le plan engendré par les vecteurs et .  L'absence d'une combinaison linéaire permettant d'écrire un vecteur de à l'aide de deux autres vecteurs non parallèles signifie que le vecteur se situe à l'extérieur du plan engendré par les vecteurs et .  "
},
{
  "id": "exo-pointsurplan",
  "level": "2",
  "url": "sec-droitesplans.html#exo-pointsurplan",
  "type": "Exercice",
  "number": "1.3.4.8",
  "title": "",
  "body": " Le plan est donné par l'équation vectorielle .   Est-ce que le point  est sur le plan?   Oui, le point est sur le plan.   Pour le déterminer, il faut tenter de trouver les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans la seconde équation que l'on n'a pas utilisée. . Bref, le point est sur le plan.   Est-ce que le vecteur  est dans le plan?   Non, le vecteur n'est pas dans le plan.   Pour le déterminer, il faut tenter de trouver les valeurs de et telles que: . On vérifie si cette combinaison fonctionne dans la seconde équation que l'on n'a pas utilisée. . Bref, le vecteur n'est pas dans le plan.   Quelle est la différence géométrique entre les questions précédentes?   Le point correspond à un endroit physique dans l'espace à trois dimensions par rapport à l'origine. S'il est possible d'atteindre le point, se déplaçant à partir du point de départ en ajoutant une combinaison linéaire des deux vecteurs du plan, alors le point se trouve sur le plan.  Pour ce qui est du vecteur, il s'agit uniquement d'une orientation et d'une longueur. Si cette orientation est parallèle au plan, alors on dit que ce vecteur est dans le plan. Bref, il faut simplement que le vecteur puisse s'exprimer comme une combinaison linéaire des deux vecteurs directeurs du plan pour qu'il soit parallèle au plan et donc dans le plan.  "
},
{
  "id": "exo-droiteplanpara",
  "level": "2",
  "url": "sec-droitesplans.html#exo-droiteplanpara",
  "type": "Exercice",
  "number": "1.3.4.9",
  "title": "",
  "body": " Considérer un plan quelconque d'équation vectorielle . Considérer une droite d'équation vectorielle .   Quelles sont les conditions sur et pour que la droite soit dans le plan?   Il faut à la fois que le vecteur soit dans le plan et que le point de départ soit sur le plan. On a considéré ces deux problèmes à l'exercice .   Quelles sont les conditions sur et pour que la droite soit parallèle au plan, mais à l'extérieur de celui-ci?   Il faut que le vecteur soit dans le plan, mais que le point de départ ne soit pas sur le plan.   Si l'équation du plan est donnée sous sa forme normale, , quelles sont les conditions sur et pour que la droite soit parallèle au plan?   Il suffit d'utiliser le produit scalaire. En effet, si le produit scalaire du vecteur directeur de la droite ( ) et du vecteur normal du plan est nul, les deux vecteurs seront perpendiculaires. Ainsi, la droite sera parallèle au plan.   Comment déterminer si une droite intersecte un plan?   Il y a plusieurs façons de faire.  D'abord, on pourrait utiliser la méthode longue , mais simple, qui consiste à tenter de trouver ce point d'intersection et de bien interpréter la solution. Pour ce faire, on doit résoudre l'équation : . Il faut donc trouver les valeurs de , et qui la solutionnent. Avec cette résolution, on pourra arriver aux trois options classiques d'un système à trois équations et trois inconnues: aucune solution (pas d'intersection), solution unique (un point d'intersection) ou infinité de solutions (droite dans le plan).  Si le but est uniquement de déterminer si il y a une intersection, on peut se servir de ce qu'on a vu précédemment. En effet, une droite quelconque aura presque toujours une ou une infinité d'intersections avec un plan quelconque, sauf si ce plan est parallèle à la droite, sans toutefois la contenir. On peut donc savoir qu'il existe une intersection sauf si le vecteur est dans le plan et que le point de départ n'est pas sur le plan.  "
},
{
  "id": "exo-distancedroiteplanpara",
  "level": "2",
  "url": "sec-droitesplans.html#exo-distancedroiteplanpara",
  "type": "Exercice",
  "number": "1.3.4.10",
  "title": "",
  "body": " Dans le texte, il est dit que, pour calculer la distance entre une droite et un plan qui sont parallèles, il suffit de faire la distance entre un point quelconque de la droite et le plan.   Expliquer géométriquement pourquoi cette manière de procéder fonctionne.   La réponse à cette question est la suivante: puisque la droite est parallèle au plan, tous les points de la droite sont à la même distance du plan. On déduit que la distance point plan donnera la même valeur que la distance droite plan, peu importe le choix du point sur la droite.   Expliquer, à l'aide de la figure , pourquoi procéder en calculant la distance entre un point du plan et la droite ne fonctionne généralement pas.   La distance entre un plan et une droite parallèles     Puisqu'en général, le point choisi sur le plan ne sera pas le plus près possible de la droite, on le voit assez bien sur la figure, on obtiendra alors une valeur de distance plus élevée que la vraie distance entre la droite et le plan.   Quels sont les cas où, par un pur hasard, la distance point droite fonctionnerait?   Considérer la figure interactive suivante:   La projection d'une droite sur un plan parallèle     Il faudrait que le point choisi sur le plan soit le plus proche possible de la droite. Cela correspond à tous les points qui sont sur la projection de la droite sur le plan tel qu'illustré dans la figure.   Vérifier que la droite d'équation est parallèle au plan . Quelle est la distance entre la droite et le plan?   La distance est de .   Pour faire cette vérification, on peut simplement calculer le produit scalaire entre le vecteur directeur de la droite et le vecteur normal du plan. Si ce produit donne zéro, alors on saura que ces vecteurs sont perpendiculaires et que la droite est parallèle au plan. On a le vecteur directeur et le vecteur normal est donné par les coefficients de l'équation normale de la droite: . Les vecteurs sont donc perpendiculaires et la droite et le plan sont parallèles.  On obtient cette distance en calculant la distance point-plan entre le point sur la droite et le plan. On a besoin du vecteur normal du plan et d'un point quelconque du plan. On en choisit un qui est simple et qui fonctionne dans l'équation, par exemple le point .   "
},
{
  "id": "exo-projetplan",
  "level": "2",
  "url": "sec-droitesplans.html#exo-projetplan",
  "type": "Exercice",
  "number": "1.3.4.11",
  "title": "",
  "body": " Soit un plan de vecteurs directeurs et soit un vecteur normal du plan.   On suppose que les vecteurs et sont perpendiculaires. Montrer que, pour tout vecteur dans le plan, on a .   Pour qu'un vecteur soit dans le plan, il doit être exprimable comme une combinaison linéaire des vecteurs directeurs et . On sait donc qu'il existe des valeurs telles que . Aussi, lorsqu'on écrit le vecteur en termes de ses projections sur les vecteurs et perpendiculaires, on obtient cette combinaison linéaire directement. La preuve réside dans le fait qu'ils sont perpendiculaires. La projection orthogonale fournit déjà de quoi décomposer un vecteur en termes de et . On peut donc écrire:   Donner un exemple où si et ne sont pas perpendiculaires, alors l'équation ne fonctionne pas.   et avec le vecteur   On propose et avec le vecteur . En effet, Bref, la décomposition en termes des vecteurs et ne s'obtient pas par la projection orthogonale.   Soit un vecteur normal du plan et supposer à nouveau que les vecteurs et sont perpendiculaires. Montrer que pour tout vecteur dans , on a .   Appliquer la partie (a) au vecteur .   De façon semblable, on sait qu'on peut écrire le vecteur . On applique la partie (a) au vecteur entre parenthèses puisqu'il se trouve dans le plan. Ainsi, on aura: Par conséquent, en remplaçant dans l'équation précédente, on a:  "
},
{
  "id": "exo-parabole",
  "level": "2",
  "url": "sec-droitesplans.html#exo-parabole",
  "type": "Exercice",
  "number": "1.3.4.12",
  "title": "",
  "body": " Soit et un point et une droite dans . On cherche l'équation de l'ensemble des points qui sont à distance égale de et . Il est bien connu que l'ensemble des points à distance égale d'un point et d'une droite forme une parabole.      On doit simplement écrire dans une équation le calcul de la distance point droite et point point. En effet, tout point étant sur la parabole devra être à la même distance de la droite et du point fixe. On nommera le point de départ dans l'équation de la droite.  "
},
{
  "id": "exo-3vecr2dep",
  "level": "2",
  "url": "sec-droitesplans.html#exo-3vecr2dep",
  "type": "Exercice",
  "number": "1.3.4.13",
  "title": "",
  "body": " Soit et deux vecteurs de non parallèles et un autre vecteur de quelconque.   Montrer qu'il est toujours possible d'écrire comme une combinaison linéaire de et .   On sait que et étant non parallèles, il n'existe pas de constante telle que . On cherche à montrer qu'il existe des constantes telles que . Si l'on réussit à isoler ces constantes et à toujours avoir des valeurs, peu importe les vecteurs, on aura fait la preuve. On remarque que, puisqu'on a trouvé une expression pour et qui dépende de toutes les valeurs quelconques pour les vecteurs et , on peut toujours trouver cette combinaison linéaire. La seule condition est que le dénominateur ne soit pas égal à zéro. Cela sera toujours le cas en raison de l'hypothèse de départ que les vecteurs et ne sont pas parallèles. En effet, s'il n'existe pas de constante telle que , alors , ce qui complète la preuve.   Montrer qu'il est possible d'avoir avec pas tous égaux à .   On a obtenu qu'il existe des constantes telles que . Il suffit d'envoyer tous les vecteurs du même côté de l'égalité: En posant , et , on obtient aisément cette équation qui est tout à fait équivalente. On utilisera cette façon de faire au chapitre pour montrer qu'un ensemble de vecteurs est linéairement dépendant .  "
},
{
  "id": "exosage-droitesplans-1",
  "level": "2",
  "url": "sec-droitesplans.html#exosage-droitesplans-1",
  "type": "Exercice",
  "number": "1.3.4.14",
  "title": "",
  "body": " Tracer les droites et sur un même graphique, respectivement en noir et en rouge.     Deux droites tracées à partir de leur équation vectorielle.   La droite D un et la droite D deux sont tracées dans le plan cartésien, respectivement en noire et en rouge       Le code solution pour l'exercice   var(\"a\") D1=parametric_plot([-a-3,2*a+2],(a,-5,5),color=\"black\") D2=parametric_plot([3*a+4,-a],(a,-5,5),color=\"red\") D1+D2    "
},
{
  "id": "exosage-droitesplans-2",
  "level": "2",
  "url": "sec-droitesplans.html#exosage-droitesplans-2",
  "type": "Exercice",
  "number": "1.3.4.15",
  "title": "",
  "body": " Considérer le plan d'équation et le point .    Trouver une équation normale pour le plan .  Calculer la distance entre le plan et le point .  Quelles sont les coordonnées du point le plus près du point ?  Illustrer sur un graphique le plan, le point et le vecteur dont la norme est égale à la distance plan-point, issue du point        Le vecteur normal est , ou n'importe quel multiple de ce dernier. L'équation normale est donc de la forme  La distance est .          Pour trouver le vecteur normal , il faut résoudre simultanément les équations et . Le code suivant permet d'obtenir une solution.   Le code pour le vecteur normal, partie 1   u=vector([-1,2,1]) #le premier vecteur directeur v=vector([-5,4,-3]) #le second vecteur directeur var(\"a\",\"b\",\"c\") n=vector([a,b,c]) #le vecteur normal eq1=u*n==0 #le vecteur normal doit être perpendiculaire à u eq2=v*n==0 #le vecteur normal doit être perpendiculaire à v sol=solve([eq1,eq2],a,b,c,solution_dict=True) #on résout les équations en fonction des composantes du vecteur normal. L'option solution_dict permet de coder différement les entrées de sol sol    À remarquer qu'il y a une infinité de solutions, données sous forme paramétrique ici. Ceci est attendu étant donné que n'importe quel multiple d'un vecteur normal est aussi un vecteur normal. Dans ce cas-ci, si l'on prend la variable libre comme étant égale à (pour éliminer les fractions), on obtient   Le code pour le vecteur normal, partie 2   n=vector([sol[0][a],sol[0][b],sol[0][c]]) #on extrait de la liste de solutions sol les expressions voulues libre=sol[0][a].variables()[0] #On va chercher le nom de la variable libre. Ceci est nécessaire au cas où des exécutions multiples sont effectuées n=n.subs({libre:3}) #on pose la variable libre à 3 n    Finalement, on obtient l'équation normale ce qui donne   Le code pour l'équation normale   var(\"x\",\"y\",\"z\") show(n*vector([x-6,y-3,z-2])==0)     La distance est obtenue à l'aide de la formule :   Le code pour la distance point plan   OA=vector([6,3,2]) #un point connu sur le plan OP=vector([3,-4,2]) #le point extérieur au plan AP=OP-OA APsurn=AP*n\/(n*n)*n #calcul de la projection show(norm(APsurn))     Le point est donné par la formule . On obtient alors:   Les coordonnées du points   OQ=OP-APsurn show(OQ)     Pour illustrer le plan, le point et le vecteur , on utilise:   Le code de la représentation graphique   plan=implicit_plot3d(n*vector([x-6,y-3,z-2])==0,(x,-10,10),(y,-10,10),(z,-10,10),color=\"blue\") P=point(OP,size=15,color=\"black\") vecproj=plot(APsurn,color=\"red\",start=OQ) plan+P+vecproj      "
},
{
  "id": "exo-parabolesage",
  "level": "2",
  "url": "sec-droitesplans.html#exo-parabolesage",
  "type": "Exercice",
  "number": "1.3.4.16",
  "title": "Automatisation de l’équation d’une parabole.",
  "body": "Automatisation de l'équation d'une parabole  Dans l'exercice , on a déterminé une équation implicite d'une parabole à distance égale d'un point et d'une droite . Le but de cet exercice est de créer un programme qui, étant donné les coordonnées d'un point , d'un point et d'un vecteur , déterminera l'équation de la parabole de foyer et de droite directrice . À Finir (Tracer graphique, tester avec celle de l'exercice)     L'équation d'une parabole   def eqpara(v,A,F): var(\"x\",\"y\",domain=\"real\") P=vector([x,y]) AP=P-A PF=F-P return (expand(norm(PF)^2-norm(AP-AP*v\/(v*v)*v)^2)==0)    "
},
{
  "id": "sec-vecndim",
  "level": "1",
  "url": "sec-vecndim.html",
  "type": "Section",
  "number": "1.4",
  "title": "Vecteurs dans <span class=\"process-math\">\\(\\mathbb{R}^n\\)<\/span>",
  "body": "  Vecteurs dans    Aller aux exercices de la section.  Bien que notre conception de la géométrie se limite aux objets dans ou , il y a de l'intérêt à considérer les objets de dimension supérieure. Dans le chapitre , on s'intéresse à résoudre un ensemble d'équations de la forme , appelées équations linéaires. Ces équations comportant variables apparaissent dans plusieurs domaines. On n'a qu'à penser à la quantité sans cesse grandissante de données disponibles pour les compagnies, gouvernements, etc. Une approche vectorielle des problèmes liés à l'interprétation de ces données facilite grandement la chose, en particulier grâce à la puissance des ordinateurs d'aujourd'hui. Dans cette section, on généralise les concepts du présent chapitre afin de les étendre, lorsque possible, à des vecteurs à composantes.    Définition et opérations sur les vecteurs  Un vecteur dans possède les mêmes caractéristiques qu'un vecteur dans ou ; ces caractéristiques sont données dans la définition . Il est toujours possible de représenter le vecteur comme une flèche, mais on ne pourra pas le représenter dans l'espace au complet. Algébriquement, on décrit un vecteur à l'aide d'une suite de nombres, entre parenthèses, séparés par des virgules. Par exemple, sont deux vecteurs, respectivement de et . L'espace est donc défini comme l'ensemble des points ou vecteurs de la forme où . Le vecteur nul est toujours noté et possède les mêmes propriétés que dans ou .  Si deux points et de sont donnés, il est possible de créer le vecteur les reliant à l'aide de l'équation vectorielle .  La longueur d'un vecteur est définie comme étant . De plus, on définit la multiplication par un scalaire et l'addition vectorielle composante par composante, de sorte que . Les propriétés de la multiplication par un scalaire et de l'addition, en particulier celles données à l'exercice demeurent valides dans puisqu'une simple adaptation de la solution à l'exercice permettrait d'avoir l'équivalent dans .  Même sans la géométrie, on garde la notion de vecteurs parallèles lorsque . Par convention, on considère toujours que le vecteur nul n'est parallèle à aucun vecteur.  Sage est capable de travailler avec les vecteurs de dimension , à l'aide des mêmes commandes algébriques que celles définies tout au long du chapitre.   Les vecteurs de dimension supérieure avec Sage  On peut définir des vecteurs à l'aide de la commande vector . On peut les multiplier par un scalaire, les additionner, etc.      Le produit scalaire et le calcul d'angle en dimension supérieure  À la section , on a obtenu de manière algébrique le produit scalaire de deux vecteurs à la définition . Cette définition se généralise donc facilement aux vecteurs à composantes: .  On a également, à partir de la loi des cosinus, obtenu une formule pour l'angle entre deux vecteurs. La notion d'angle entre deux vecteurs de peut sembler inutile sans la géométrie pour l'appuyer, or le concept de vecteurs orthogonaux est primordial dans toutes les dimensions. Comme il est possible d'exprimer le cosinus de l'angle entre deux vecteurs d'une manière purement algébrique, on définit pour tout vecteur de l'unique valeur de telle que . Deux vecteurs non nuls sont dits orthogonaux si cet angle vaut ou . Notons encore une fois que le vecteur nul n'est orthogonal à aucun vecteur.  Les propriétés du produit scalaire, notamment celles de la proposition , sont aussi valides dans . Nulle part dans leur démonstration on n'a utilisé le fait que les vecteurs étaient dans ou spécifiquement. L'inégalité de Cauchy-Schwarz est aussi valide dans .  Finalement, la notion de projection orthogonale définie par l'équation est aussi un concept qui se généralise, et comme deux vecteurs peuvent toujours être représentés dans un même plan, l'image est la même (figure ).   Exemple de calculs avec les vecteurs de dimension supérieure  On considère les vecteurs et . On cherche à calculer  L'angle entre les vecteurs et .  La projection .  La projection .     On sait selon, la formule , que le cosinus de l'angle doit être égal à . En prenant la fonction cosinus inverse, on trouve .    Pour la projection, on utilise la formule (les rôles de sont inversés ici). On obtient donc .    Toujours en utilisant la formule . On obtient donc .      Espace engendré  Dans les espaces et , l'ensemble des combinaisons linéaires de vecteurs engendre toujours un point, une droite, un plan ou l'espace au complet. Comme la dimension de l'espace y est limitée à deux ou trois, il y est toujours possible de décrire le résultat géométriquement. Que représente l'ensemble des combinaisons linéaires de deux, quatre ou sept vecteurs de ? Sans la géométrie, on se contente de définir certains termes analogues à ceux déjà définis et pour le reste, on y va d'une définition plus abstraite.  Soit un vecteur non nul et un point de . Le lieu des points tels que est aussi appelé une droite, en raison de l'aspect unidimensionnel (un seul vecteur). Le vecteur est toujours appelé un vecteur directeur de la droite . De même, si est un autre vecteur non parallèle au vecteur , alors le lieu des points décrits par l'équation est appelé un plan, de vecteurs directeurs .  Dans , une droite peut être caractérisée par une équation normale, de la forme . Cette même équation avec des vecteurs de représente un plan.  Que représente-t-elle dans un espace de dimension ? En la développant, on obtient une équation de la forme , où est appelé un vecteur normal. On définit le lieu des points satisfaisant une telle équation comme un hyperplan de . On verra plus loin que cet objet est composé de dimensions et peut donc aussi être décrit à partir d'un ensemble de vecteurs possédant une propriété spécifique.  De façon plus générale, on définit l'espace engendré par un ensemble de vecteurs.   Soit un ensemble de vecteurs. On définit l'espace engendré par ces vecteurs, noté , comme étant l'ensemble des combinaisons linéaires des vecteurs : .   À noter qu'on ne donne aucune condition sur les vecteurs engendrant l'espace. Certains pourraient être nuls, parallèles à d'autres vecteurs ou une combinaison linéaire des autres vecteurs.   Un exemple d'espace engendré   On considère les vecteurs et . On cherche à caractériser le .    En principe, l'espace engendré est constitué de tous les vecteurs de la forme . Il est parfois possible, selon les vecteurs présents, de simplifier l'équation vectorielle et peut-être même de reconnaitre une droite, un plan ou un hyperplan. Dans notre cas, on a . Comme est un nombre réel quelconque, on peut réécrire les vecteurs du comme les vecteurs s'écrivant comme une combinaison linéaire des deux vecteurs et . Le est donc un plan dans .        Les éléments importants de cette section sont:  Les vecteurs à dimensions se comportent essentiellement comme ceux à ou dimensions, en particulier pour ce qui est des opérations;  Le produit scalaire de deux vecteurs quelconques;  L'angle entre deux vecteurs, défini à partir du produit scalaire;  La définition du span , l'espace engendré par les combinaisons linéaires de vecteurs.        Exercices    Soit et , des vecteurs de .   Calculer , et .             Calculer l'angle entre et . Donner l'angle entre et et entre et .         D'abord, pour l'angle entre et , on utilise la formule habituelle. Pour les angles entre et et entre et , on peut immédiatement conclure du fait que leur produit scalaire est nul que leur angle sera de ou .   L'affirmation suivante est seulement vraie dans . Expliquer pourquoi géométriquement en donnant un exemple dans .  «Deux vecteurs perpendiculaires au même vecteur sont nécessairement parallèles.»   C'est tout simplement puisqu'il existe une infinité de directions qui sont toutes perpendiculaires à un même vecteur. On a compris ceci en étudiant le plan dans . Le vecteur normal au plan était perpendiculaire à tout vecteur dans le plan. C'est pour cette raison qu'on peut donner une infinité de paires de vecteurs directeurs afin de définir le plan.  On donne un exemple très simple. Les vecteurs et sont tous les deux perpendiculaires au vecteur . Cependant, ils ne sont pas parallèles. Ils sont même perpendiculaires entre eux aussi!   Calculer la projection et expliquer pourquoi donne le vecteur nul.     La projection donne le vecteur nul puisque leur produit scalaire est nul. Ce produit étant au numérateur de la formule de la projection, on obtiendra donc le vecteur nul dans , soit    Soit un ensemble de vecteurs et . Caractériser le en termes de combinaisons linéaires de vecteurs. Est-ce que cet espace correspond à ?   Utiliser l'exemple pour vous aider.   Cet espace ne correspond pas à . Noter qu'on aurait pu caractériser le span avec d'autres paires de vecteurs.   On suit le conseil de l'indication et on cherche à caractériser l'ensemble des combinaisons linéaires possibles avec ces quatre vecteurs. On verra qu'il est difficile de trouver un moyen de combiner les vecteurs afin de trouver les redondances. Puisque les valeurs de et de n'apparaissent qu'une fois pour chaque vecteur, toutes les combinaisons linéaires imaginables avec les quatre vecteurs initiaux se construisent à l'aide des deux vecteurs restants. Autrement dit, peu importe les valeurs choisies pour et , on est incapable de créer un nouveau vecteur simplement en ajustant les valeurs de et de en conséquence. Les vecteurs et sont donc redondants.  Il est primordial de remarquer qu'on aurait pu combiner différemment et obtenir deux autres vecteurs à la fin. L'important est que le est un sous-espace de engendré par deux vecteurs. C'est donc un plan. On verra plus tard que cet espace est de dimension .  On peut donc écrire:    Soit deux vecteurs qui sont tous les deux des combinaisons linéaires des vecteurs .   Montrer que, pour tout scalaire , le vecteur est une combinaison linéaire des vecteurs .   On sait que est une combinaison linéaire des vecteurs donnés. Supposons que cette combinaison est donnée par les scalaires . Ainsi, . Alors, Les valeurs étant des scalaires, on a montré que est une combinaison linéaire des vecteurs .   Montrer que le vecteur est une combinaison linéaire des vecteurs .   On sait que et sont des combinaisons linéaires des vecteurs donnés. Supposons que ces combinaisons sont données par les scalaires et . Ainsi, et . Alors, Les valeurs étant des scalaires, on a montré que est une combinaison linéaire des vecteurs .   Expliquer pourquoi il n'est pas important de connaitre l'espace dans lequel ces vecteurs existent?   Puisqu'on n'a jamais utilisé les composantes des vecteurs en question. On se limite purement à la multiplication par un scalaire et l'addition vectorielle. Ces opérations fonctionnent de la même façon peu importe l'espace dans lequel on se trouve. Attention, tous les vecteurs doivent faire partie du même espace. On ne peut jamais additionner des vecteurs de avec des vecteurs de , par exemple.    Soit deux vecteurs et une constante . Montrer algébriquement l'égalité suivante en vous servant de la définition : .   On montrera cette égalité en partant du membre de droite. Puisque les valeurs de et de sont n'importe quelle valeur réelle, on pourrait rebaptiser et on obtient donc directement la définition du span.    Soit un vecteur . Si pour tout vecteur , montrer que .   Pour démontrer ce genre de conclusion où l'hypothèse est vraie pour tout vecteur , il faut choisir des vecteurs spécifiques qui permettent de trouver les composantes de .   On suit l'indication et on décide de choisir des vecteurs qui permettent de trouver les composantes de . On propose d'utiliser des vecteurs qui sont presque le vecteur nul, à l'exception d'une composante. Ainsi, si on pose , alors En refaisant cette démarche avec, chaque fois, un choix de vecteur pour qui soit toujours le vecteur nul sauf une composante, on montre que la composante correspondante du vecteur doit être nulle.   Soit . Si pour tout vecteur , que peut-on conclure à propos de et ?   Appliquer la démarche de la première question.   Ils sont égaux ( ).   On suit l'indication et on décide de choisir des vecteurs qui permettent de trouver les composantes de et de . Ainsi, si on pose , alors En refaisant cette démarche avec, chaque fois, un choix de vecteur pour qui soit toujours le vecteur nul sauf une composante, on montre que les composantes correspondantes des vecteurs et doivent être égales.    Dans l'exercice , nous avons vérifié géométriquement la validité de l'inégalité du triangle. Nous savons maintenant que les vecteurs de tout espace euclidien ( ) possèdent sensiblement les mêmes propriétés. Ceci est vrai pour cette inégalité.  Soit . Démontrer l'inégalité du triangle: .   Il est conseillé de démontrer cette inégalité en en démontrant sa forme élevée au carré: .  Observer que le produit scalaire est très utile pour exprimer une norme au carré. Cela évite d'avoir à expliciter les composantes des vecteurs. On démontre donc l'inégalité dans tous les espaces euclidiens en même temps.   Comme suggéré dans l'indication, on va démontrer l'inégalité élevée au carré qui lui est équivalente.    Dans l'exemple , on a montré deux techniques différentes pour trouver l'équation vectorielle d'un plan dans . Dans la présente section, on a compris que l'équation normale dans définit un objet géométrique de dimension que l'on appelle un hyperplan.  Pour chaque équation normale suivante, trouver une équation vectorielle décrivant le même hyperplan.   dans     On rappelle qu'il y a au moins deux façons de faire et une infinité de réponses différentes, en raison du fonctionnement des équations vectorielles. On choisit la première façon de faire. Ici, dans , on va créer des vecteurs à quatre composantes. On isole une des variables, par exemple , et on crée l'équation vectorielle du plan ainsi: On remplace les constantes par des lettres plus habituelles pour obtenir:   dans     Attention, il s'agit de la même équation, mais les vecteurs doivent maintenant avoir cinq composantes. On isole une des variables, par exemple et on crée l'équation vectorielle du plan ainsi: On remplace les constantes par des lettres plus habituelles pour obtenir:   dans      On remplace les constantes par des lettres plus habituelles pour obtenir:    dans      On remplace les constantes par des lettres plus habituelles pour obtenir:    "
},
{
  "id": "sageex-vecndim",
  "level": "2",
  "url": "sec-vecndim.html#sageex-vecndim",
  "type": "Calcul",
  "number": "1.4.1",
  "title": "Les vecteurs de dimension supérieure avec Sage.",
  "body": " Les vecteurs de dimension supérieure avec Sage  On peut définir des vecteurs à l'aide de la commande vector . On peut les multiplier par un scalaire, les additionner, etc.   "
},
{
  "id": "ex-vecndimproj",
  "level": "2",
  "url": "sec-vecndim.html#ex-vecndimproj",
  "type": "Exemple",
  "number": "1.4.2",
  "title": "Exemple de calculs avec les vecteurs de dimension supérieure.",
  "body": " Exemple de calculs avec les vecteurs de dimension supérieure  On considère les vecteurs et . On cherche à calculer  L'angle entre les vecteurs et .  La projection .  La projection .     On sait selon, la formule , que le cosinus de l'angle doit être égal à . En prenant la fonction cosinus inverse, on trouve .    Pour la projection, on utilise la formule (les rôles de sont inversés ici). On obtient donc .    Toujours en utilisant la formule . On obtient donc .   "
},
{
  "id": "def-span",
  "level": "2",
  "url": "sec-vecndim.html#def-span",
  "type": "Définition",
  "number": "1.4.3",
  "title": "",
  "body": " Soit un ensemble de vecteurs. On définit l'espace engendré par ces vecteurs, noté , comme étant l'ensemble des combinaisons linéaires des vecteurs : .  "
},
{
  "id": "ex-span",
  "level": "2",
  "url": "sec-vecndim.html#ex-span",
  "type": "Exemple",
  "number": "1.4.4",
  "title": "Un exemple d’espace engendré.",
  "body": " Un exemple d'espace engendré   On considère les vecteurs et . On cherche à caractériser le .    En principe, l'espace engendré est constitué de tous les vecteurs de la forme . Il est parfois possible, selon les vecteurs présents, de simplifier l'équation vectorielle et peut-être même de reconnaitre une droite, un plan ou un hyperplan. Dans notre cas, on a . Comme est un nombre réel quelconque, on peut réécrire les vecteurs du comme les vecteurs s'écrivant comme une combinaison linéaire des deux vecteurs et . Le est donc un plan dans .   "
},
{
  "id": "exo-vecRncalculs",
  "level": "2",
  "url": "sec-vecndim.html#exo-vecRncalculs",
  "type": "Exercice",
  "number": "1.4.4.1",
  "title": "",
  "body": " Soit et , des vecteurs de .   Calculer , et .             Calculer l'angle entre et . Donner l'angle entre et et entre et .         D'abord, pour l'angle entre et , on utilise la formule habituelle. Pour les angles entre et et entre et , on peut immédiatement conclure du fait que leur produit scalaire est nul que leur angle sera de ou .   L'affirmation suivante est seulement vraie dans . Expliquer pourquoi géométriquement en donnant un exemple dans .  «Deux vecteurs perpendiculaires au même vecteur sont nécessairement parallèles.»   C'est tout simplement puisqu'il existe une infinité de directions qui sont toutes perpendiculaires à un même vecteur. On a compris ceci en étudiant le plan dans . Le vecteur normal au plan était perpendiculaire à tout vecteur dans le plan. C'est pour cette raison qu'on peut donner une infinité de paires de vecteurs directeurs afin de définir le plan.  On donne un exemple très simple. Les vecteurs et sont tous les deux perpendiculaires au vecteur . Cependant, ils ne sont pas parallèles. Ils sont même perpendiculaires entre eux aussi!   Calculer la projection et expliquer pourquoi donne le vecteur nul.     La projection donne le vecteur nul puisque leur produit scalaire est nul. Ce produit étant au numérateur de la formule de la projection, on obtiendra donc le vecteur nul dans , soit  "
},
{
  "id": "exo-comblinR4",
  "level": "2",
  "url": "sec-vecndim.html#exo-comblinR4",
  "type": "Exercice",
  "number": "1.4.4.2",
  "title": "",
  "body": " Soit un ensemble de vecteurs et . Caractériser le en termes de combinaisons linéaires de vecteurs. Est-ce que cet espace correspond à ?   Utiliser l'exemple pour vous aider.   Cet espace ne correspond pas à . Noter qu'on aurait pu caractériser le span avec d'autres paires de vecteurs.   On suit le conseil de l'indication et on cherche à caractériser l'ensemble des combinaisons linéaires possibles avec ces quatre vecteurs. On verra qu'il est difficile de trouver un moyen de combiner les vecteurs afin de trouver les redondances. Puisque les valeurs de et de n'apparaissent qu'une fois pour chaque vecteur, toutes les combinaisons linéaires imaginables avec les quatre vecteurs initiaux se construisent à l'aide des deux vecteurs restants. Autrement dit, peu importe les valeurs choisies pour et , on est incapable de créer un nouveau vecteur simplement en ajustant les valeurs de et de en conséquence. Les vecteurs et sont donc redondants.  Il est primordial de remarquer qu'on aurait pu combiner différemment et obtenir deux autres vecteurs à la fin. L'important est que le est un sous-espace de engendré par deux vecteurs. C'est donc un plan. On verra plus tard que cet espace est de dimension .  On peut donc écrire:  "
},
{
  "id": "exo-comblin-kvec",
  "level": "2",
  "url": "sec-vecndim.html#exo-comblin-kvec",
  "type": "Exercice",
  "number": "1.4.4.3",
  "title": "",
  "body": " Soit deux vecteurs qui sont tous les deux des combinaisons linéaires des vecteurs .   Montrer que, pour tout scalaire , le vecteur est une combinaison linéaire des vecteurs .   On sait que est une combinaison linéaire des vecteurs donnés. Supposons que cette combinaison est donnée par les scalaires . Ainsi, . Alors, Les valeurs étant des scalaires, on a montré que est une combinaison linéaire des vecteurs .   Montrer que le vecteur est une combinaison linéaire des vecteurs .   On sait que et sont des combinaisons linéaires des vecteurs donnés. Supposons que ces combinaisons sont données par les scalaires et . Ainsi, et . Alors, Les valeurs étant des scalaires, on a montré que est une combinaison linéaire des vecteurs .   Expliquer pourquoi il n'est pas important de connaitre l'espace dans lequel ces vecteurs existent?   Puisqu'on n'a jamais utilisé les composantes des vecteurs en question. On se limite purement à la multiplication par un scalaire et l'addition vectorielle. Ces opérations fonctionnent de la même façon peu importe l'espace dans lequel on se trouve. Attention, tous les vecteurs doivent faire partie du même espace. On ne peut jamais additionner des vecteurs de avec des vecteurs de , par exemple.  "
},
{
  "id": "exo-spanvw",
  "level": "2",
  "url": "sec-vecndim.html#exo-spanvw",
  "type": "Exercice",
  "number": "1.4.4.4",
  "title": "",
  "body": " Soit deux vecteurs et une constante . Montrer algébriquement l'égalité suivante en vous servant de la définition : .   On montrera cette égalité en partant du membre de droite. Puisque les valeurs de et de sont n'importe quelle valeur réelle, on pourrait rebaptiser et on obtient donc directement la définition du span.  "
},
{
  "id": "exo-prodscalRn",
  "level": "2",
  "url": "sec-vecndim.html#exo-prodscalRn",
  "type": "Exercice",
  "number": "1.4.4.5",
  "title": "",
  "body": " Soit un vecteur . Si pour tout vecteur , montrer que .   Pour démontrer ce genre de conclusion où l'hypothèse est vraie pour tout vecteur , il faut choisir des vecteurs spécifiques qui permettent de trouver les composantes de .   On suit l'indication et on décide de choisir des vecteurs qui permettent de trouver les composantes de . On propose d'utiliser des vecteurs qui sont presque le vecteur nul, à l'exception d'une composante. Ainsi, si on pose , alors En refaisant cette démarche avec, chaque fois, un choix de vecteur pour qui soit toujours le vecteur nul sauf une composante, on montre que la composante correspondante du vecteur doit être nulle.   Soit . Si pour tout vecteur , que peut-on conclure à propos de et ?   Appliquer la démarche de la première question.   Ils sont égaux ( ).   On suit l'indication et on décide de choisir des vecteurs qui permettent de trouver les composantes de et de . Ainsi, si on pose , alors En refaisant cette démarche avec, chaque fois, un choix de vecteur pour qui soit toujours le vecteur nul sauf une composante, on montre que les composantes correspondantes des vecteurs et doivent être égales.  "
},
{
  "id": "exo-inegaltriangle-Rn",
  "level": "2",
  "url": "sec-vecndim.html#exo-inegaltriangle-Rn",
  "type": "Exercice",
  "number": "1.4.4.6",
  "title": "",
  "body": " Dans l'exercice , nous avons vérifié géométriquement la validité de l'inégalité du triangle. Nous savons maintenant que les vecteurs de tout espace euclidien ( ) possèdent sensiblement les mêmes propriétés. Ceci est vrai pour cette inégalité.  Soit . Démontrer l'inégalité du triangle: .   Il est conseillé de démontrer cette inégalité en en démontrant sa forme élevée au carré: .  Observer que le produit scalaire est très utile pour exprimer une norme au carré. Cela évite d'avoir à expliciter les composantes des vecteurs. On démontre donc l'inégalité dans tous les espaces euclidiens en même temps.   Comme suggéré dans l'indication, on va démontrer l'inégalité élevée au carré qui lui est équivalente.  "
},
{
  "id": "exo-hyperplanRn",
  "level": "2",
  "url": "sec-vecndim.html#exo-hyperplanRn",
  "type": "Exercice",
  "number": "1.4.4.7",
  "title": "",
  "body": " Dans l'exemple , on a montré deux techniques différentes pour trouver l'équation vectorielle d'un plan dans . Dans la présente section, on a compris que l'équation normale dans définit un objet géométrique de dimension que l'on appelle un hyperplan.  Pour chaque équation normale suivante, trouver une équation vectorielle décrivant le même hyperplan.   dans     On rappelle qu'il y a au moins deux façons de faire et une infinité de réponses différentes, en raison du fonctionnement des équations vectorielles. On choisit la première façon de faire. Ici, dans , on va créer des vecteurs à quatre composantes. On isole une des variables, par exemple , et on crée l'équation vectorielle du plan ainsi: On remplace les constantes par des lettres plus habituelles pour obtenir:   dans     Attention, il s'agit de la même équation, mais les vecteurs doivent maintenant avoir cinq composantes. On isole une des variables, par exemple et on crée l'équation vectorielle du plan ainsi: On remplace les constantes par des lettres plus habituelles pour obtenir:   dans      On remplace les constantes par des lettres plus habituelles pour obtenir:    dans      On remplace les constantes par des lettres plus habituelles pour obtenir:  "
},
{
  "id": "sec-veclabos",
  "level": "1",
  "url": "sec-veclabos.html",
  "type": "Section",
  "number": "1.5",
  "title": "Activités et laboratoires",
  "body": "  Activités et laboratoires    Dans cette section, on regarde des activités et des laboratoires en lien avec des concepts présentés dans le chapitre.    De la géométrie particulièrement hasardeuse  La fonction choice([]) de Sage permet d'obtenir un des éléments dans la liste [ ] de manière aléatoire. Par exemple, on simule le lancer d'un dé dans la cellule ci-dessous.   Le résultat change entre chaque clic du bouton évaluer.  La fonction triangle(n) , définie ci-dessous, utilise la fonction choice() pour sélectionner de manière aléatoire un sommet d'un triangle équilatéral centré à l'origine. On note ce point . On effectue ensuite le jeu suivant:  On sélectionne un sommet du triangle , au hasard avec la fonction choice() .  On calcule le point , situé à mi-chemin entre et .  Le point devient le nouveau point .  On répète ce processus fois et on affiche le graphique de tous les points ainsi obtenus.     Dans la fonction triangle ci-dessous, il faut compléter la ligne ####### À COMPLÉTER ####### afin de calculer le point . Une fois cette opération effectuée, exécuter la commande triangle(10) afin de générer dix tours de ce jeu. Le résultat devrait ressembler à la figure , sans nécessairement lui être identique, puisqu'il s'agit de hasard.   Dix tours du petit jeu   Un triangle équilatéral est tracé en noir ainsi que les dix premiers tours de jeu décrit ci-haut      Utiliser la cellule suivante pour comprendre comment la boucle for i in range(n) fonctionne.    On va maintenant regarder ce qui se passe lorsque le nombre de points devient suffisamment grand. Évaluer la cellule ci-dessous plusieurs fois pour voir le résultat des premiers tours de jeu. À quoi ressemblera la figure avec davantage ( ?) de points? Tenter une prédiction avant de tester points.   Évaluer la cellule suivante. Attention, cela peut prendre un certain temps.  Dans le cas présent, on prend le point milieu entre et . Que se passe-t-il si l'on prend un point sur le segment , mais avec un rapport plus petit ou plus grand que . Par exemple, si on prend au du segment (en partant de ), qu'obtiendra-t-on après tours? Tenter de faire une prédiction et modifier le code de la simulation en le copiant dans les cellules ci-dessous.    Que se passe t-il si le point Q est en dehors du segment ?    On explore maintenant d'autres généralisations. Voici des figures représentant certaines de ces généralisations.  Trouver une variante du jeu qui produit un effet intéressant. Il est possible de s'inspirer de ou de simplement reproduire ces figures.    Un triangle coloré   Un triangle comme celui du jeu est illustré, mais cette fois-ci les régions sont colorées en rouge, vert et bleu.     Des pentagones hors de soi   Un pentagone est illustré, avec ce qui semble être une variante du jeu. Cette fois, les régions touchées sont à l'extérieur du pentagone.     Un hexagone aventureux   Un tout petit hexagone apparait au centre avec ce qui semble être une variante du jeu. Cette fois, les points semblent diverger.      "
},
{
  "id": "project-1",
  "level": "2",
  "url": "sec-veclabos.html#project-1",
  "type": "Projet",
  "number": "1.5.1",
  "title": "De la géométrie particulièrement hasardeuse.",
  "body": " De la géométrie particulièrement hasardeuse  La fonction choice([]) de Sage permet d'obtenir un des éléments dans la liste [ ] de manière aléatoire. Par exemple, on simule le lancer d'un dé dans la cellule ci-dessous.   Le résultat change entre chaque clic du bouton évaluer.  La fonction triangle(n) , définie ci-dessous, utilise la fonction choice() pour sélectionner de manière aléatoire un sommet d'un triangle équilatéral centré à l'origine. On note ce point . On effectue ensuite le jeu suivant:  On sélectionne un sommet du triangle , au hasard avec la fonction choice() .  On calcule le point , situé à mi-chemin entre et .  Le point devient le nouveau point .  On répète ce processus fois et on affiche le graphique de tous les points ainsi obtenus.     Dans la fonction triangle ci-dessous, il faut compléter la ligne ####### À COMPLÉTER ####### afin de calculer le point . Une fois cette opération effectuée, exécuter la commande triangle(10) afin de générer dix tours de ce jeu. Le résultat devrait ressembler à la figure , sans nécessairement lui être identique, puisqu'il s'agit de hasard.   Dix tours du petit jeu   Un triangle équilatéral est tracé en noir ainsi que les dix premiers tours de jeu décrit ci-haut      Utiliser la cellule suivante pour comprendre comment la boucle for i in range(n) fonctionne.    On va maintenant regarder ce qui se passe lorsque le nombre de points devient suffisamment grand. Évaluer la cellule ci-dessous plusieurs fois pour voir le résultat des premiers tours de jeu. À quoi ressemblera la figure avec davantage ( ?) de points? Tenter une prédiction avant de tester points.   Évaluer la cellule suivante. Attention, cela peut prendre un certain temps.  Dans le cas présent, on prend le point milieu entre et . Que se passe-t-il si l'on prend un point sur le segment , mais avec un rapport plus petit ou plus grand que . Par exemple, si on prend au du segment (en partant de ), qu'obtiendra-t-on après tours? Tenter de faire une prédiction et modifier le code de la simulation en le copiant dans les cellules ci-dessous.    Que se passe t-il si le point Q est en dehors du segment ?    On explore maintenant d'autres généralisations. Voici des figures représentant certaines de ces généralisations.  Trouver une variante du jeu qui produit un effet intéressant. Il est possible de s'inspirer de ou de simplement reproduire ces figures.    Un triangle coloré   Un triangle comme celui du jeu est illustré, mais cette fois-ci les régions sont colorées en rouge, vert et bleu.     Des pentagones hors de soi   Un pentagone est illustré, avec ce qui semble être une variante du jeu. Cette fois, les régions touchées sont à l'extérieur du pentagone.     Un hexagone aventureux   Un tout petit hexagone apparait au centre avec ce qui semble être une variante du jeu. Cette fois, les points semblent diverger.     "
},
{
  "id": "sec-transfodef",
  "level": "1",
  "url": "sec-transfodef.html",
  "type": "Section",
  "number": "2.1",
  "title": "Les transformations linéaires",
  "body": "  Les transformations linéaires    Aller aux exercices de la section.  Le concept de fonction associant à tout nombre réel un autre nombre réel est bien connu. Ces fonctions sont souvent représentées graphiquement, comme à la figure suivante.   La fonction      Considérons maintenant la figure suivante dans laquelle un carré a subi une rotation de . La transformation qu'a subie le carré est un exemple simple de transformation linéaire, où en fait chaque point de a subi la rotation. On a donc un premier exemple géométrique d'une fonction de vers .   Une première transformation   Un carré est illustré à gauche et sa rotation de 45 degrés, à droite.    Dans cette section, on définit la notion de transformation linéaire et l'on regarde les propriétés de ce type de transformations. On aborde aussi le concept de matrice, étroitement lié aux transformations linéaires.     Définition et premiers exemples de transformations linéaires   Une fonction vectorielle de vers est une fonction qui prend un vecteur et lui associe un vecteur . On écrit alors .    Des transformations quelconques  Voici quelques exemples de transformations:   Des transformations quelconques   La norme d'un vecteur peut être considérée comme une fonction de vers , où .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La translation de , qui transforme tout vecteur par .    Une étude exhaustive de toutes les fonctions serait beaucoup trop difficile et sortirait du cadre de ce cours. On se restreint donc à un type particulier de fonctions, dites linéaires, exception faite de la transformation représentant une translation . Pour l'instant, la raison de ce choix est surtout de nature géométrique. Il est assez difficile de représenter une fonction vectorielle, principalement dû à la dimension des vecteurs. Pour illustrer une fonction comme la fonction de l'exemple , il faut deux dimensions pour le domaine et deux pour l'image. On contourne cette difficulté en utilisant deux copies de comme dans la figure suivante.   La fonction     Le plan R deux est illustré, avec trois courbes de couleurs différentes    Le plan R deux est illustré, avec l'image des trois courbes de couleurs différentes     Dans la figure, le plan de gauche représente le domaine et dans le plan de droite, on retrouve l'image de chacune des courbes. Certaines courbes ont été colorées afin de pouvoir associer la courbe originale, à gauche, et son image par la transformation, à droite. En réalité, tous les points de sont transformés.  On constate assez rapidement que la visualisation des fonctions vectorielles peut être difficile. Les exemples de la section sont des cas particuliers qui sont souvent étudiés à l'aide du calcul vectoriel.  Quelles sont donc ces transformations dites linéaires? Dans un premier temps, on donne la définition, pour ensuite regarder les conséquences de cette définition, particulièrement du point de vue géométrique.   Transformation linéaire  Une fonction de vers est une transformation linéaire si elle satisfait les deux propriétés suivantes:  pour tout vecteur .  pour tout vecteur et scalaire .    Avant de regarder les propriétés et les conséquences de cette définition, on illustre un exemple simple de transformation linéaire. La fonction au point de la liste de l'exemple est une transformation linéaire (voir ) et son effet est illustré dans la figure .   La transformation linéaire    Voici maintenant une série de conséquences et de propriétés des transformations linéaires découlant directement de la définition.   Propriétés d'une transformation linéaire   Soit une transformation linéaire. Alors  L'image du vecteur nul est toujours le vecteur nul, c'est-à-dire .  Si les vecteurs et sont parallèles, alors leur image est parallèle, c'est-à-dire si , alors .  L'image d'une droite par une transformation linéaire est une droite Avec la particularité qu'elle pourrait être écrasée en un point. On considère ceci comme un cas limite. .  Les transformations linéaires sont donc des transformations qui ne déforment pas trop l'espace, comme cela est évoqué au point 3. D'un point de vue géométrique, on peut voir la pertinence du mot linéaire dans transformation linéaire par le fait que les droites demeurent des droites (ce n'est pas le cas pour l'image de la droite dans la figure ).    On peut utiliser la propriété ou la propriété . On se propose ici d'utiliser la propriété et on laisse l'utilisation de l'autre propriété à explorer dans l'exercice .  Soit l'image du vecteur nul et un vecteur quelconque. Par la propriété , on a . La dernière équation nous donne et donc, .  La seconde propriété est une simple reformulation de la propriété des transformations linéaires. En effet, soit un vecteur parallèle à . Alors et donc, l'image du vecteur est parallèle à l'image du vecteur .  Soit un plan. On a . Le cas dégénéré dont il est question dans l'énoncé fait référence au fait qu'il est possible que . Dans ce cas, l'image de la droite est un point.     Les transformations s'appliquent sur des vecteurs, mais, comme la distinction entre point et vecteur est volontairement laissée floue, il est utile de faire la remarque suivante.   Les transformations linéaires et les points  Si sont des points et que , alors on note , où doit être vu comme une forme raccourcie du vecteur .   On regarde maintenant les fonctions de l'exemple afin de déterminer lesquelles sont linéaires.   Retour sur les transformations quelconques   On considère les fonctions de la liste . On cherche à déterminer lesquelles sont linéaires.    La norme d'un vecteur n'est pas une transformation linéaire. En effet, l'exercice montre que souvent, on a . De plus, on sait que . La transformation n'est donc pas linéaire.    La fonction n'est pas linéaire. En effet, il suffit de remarquer que . Le vecteur nul n'est pas envoyé sur le vecteur nul. Si la transformation avait été linéaire, on aurait .    Si l'on essaie pour la fonction , on obtient bel et bien le vecteur . Attention toutefois, cela ne signifie pas que la transformation est linéaire. L'image du vecteur nul est un moyen rapide de savoir si la fonction n'est pas linéaire, mais dans le cas où , aucune conclusion ne peut être tirée. On regarde la propriété pour la fonction , mais la propriété n'est pas non plus respectée. Soit et un vecteur quelconque. On a .    La fonction est linéaire. En effet, soit et des vecteurs de et soit un scalaire. On a .  De plus, on a . Ainsi, la transformation est linéaire.    La transformation n'est pas linéaire. Encore une fois, on voit que le vecteur n'est pas envoyé sur le vecteur .    La translation n'est pas une transformation linéaire. En effet, .     Satisfaire et ne pas satisfaire une définition  Lorsqu'on doit vérifier si quelque chose satisfait une définition comme la définition , où un certain nombre de propriétés doivent être satisfaites, il est important de comprendre la distinction entre satisfaire la définition et ne pas la satisfaire. Montrer que la définition est satisfaite pour un, deux ou cent cas particuliers n'est jamais suffisant si la définition comprend des mots comme pour tout vecteur ou pour tout nombre. C'est souvent une bonne idée de regarder quelques cas simples afin de se donner une idée, mais ce n'est jamais suffisant.  Par contre, si le but est de montrer qu'un objet ne satisfait pas une définition contenant des phrases comme pour tout vecteur ou nombre , alors là, il est suffisant de trouver un seul cas qui ne satisfait pas à la définition.  Par exemple, pour montrer que la norme d'un vecteur n'est pas une transformation linéaire, on aurait pu tout simplement prendre les vecteurs et constater que alors que .   Afin de se concentrer sur l'aspect intuitif et de s'appuyer sur la géométrie, on étudie dans un premier temps les transformations linéaires de vers et de vers . Plus tard, on étudiera les transformations linéaires de vers (voir le chapitre ).  Dans l'exemple qui suit, on donne une liste de plusieurs transformations de vers qui sont linéaires. On y réfèrera tout au long du chapitre.   Des transformations linéaires du plan : dynamique   Considérer la liste des transformations suivantes, définies géométriquement et algébriquement:   Des transformations linéaires   La transformation , transformation qui laisse chaque vecteur en place. On l'appelle la transformation identité. Le choix du mot identité deviendra évident une fois qu'on aura introduit la composition de deux transformations linéaires, qui sera une sorte de produit, à la section  La réflexion par rapport à l'axe des abscisses, donnée par la transformation .  La rotation de ou dans le sens antihoraire, donnée par la transformation .  Un étirement horizontal de facteur est une transformation linéaire donnée par .  De même, un étirement vertical est donné par .  Une homothétie est une transformation qui multiplie chaque composante d'un vecteur par un facteur . Elle est donnée par la transformation .  Une matrice de permutation est une matrice qui change l'ordre des composantes du vecteur. Dans , la seule transformation qui accomplit une telle permutation est , bien que l'identité est aussi vue comme une matrice de permutation.  Soit un vecteur non nul. La projection orthogonale sur est une transformation linéaire.    Les démonstrations algébriques et géométriques de la linéarité de ces fonctions sont présentées ci-dessous.    Intuitivement, la transformation laisse tout en place. Les propriétés de linéarité devraient donc découler automatiquement des propriétés des opérations sur les vecteurs.  Algébriquement, la transformation est linéaire, car . De même, .    La figure interactive ci-dessous permet de voir la linéarité de la réflexion de manière intuitive.   La réflexion par rapport à l'axe des abscisses est une transformation linéaire    Algébriquement, on a et .    La figure interactive ci-dessous permet de voir la linéarité de la rotation de manière intuititve.   La rotation de dans le sens antihoraire est une transformation linéaire    Algébriquement, on a et .    La figure interactive ci-dessous permet de voir la linéarité de l'étirement de manière intuititve.   La rotation de dans le sens antihoraire est une transformation linéaire    Algébriquement, on a et .    La démonstration est faite à l'exercice    La figure interactive ci-dessous permet devoir la linéarité de la permutation de composantes de manière intuitive.   La permutation des composantes d'un vecteur est une transformation linéaire    Algébriquement, on a et .    On note , la projection orthogonale du vecteur sur le vecteur . Algébriquement, on a et .    Pour conclure cette sous-section, voici un résultat sur la composition de deux transformations linéaires.   La composition de transformations linéaires  Soit et , des transformations linéaires telles que l'image de est comprise dans le domaine de . Alors la transformation est une transformation linéaire.   Soit , des vecteurs tels que et et un scalaire. Alors . De même, on a .  Ainsi, la composition de deux transformations linéaires est linéaire.    La composition de transformations est particulièrement intéressante, car elle représente l'application successive des transformations. Si, par exemple, un concepteur de jeux vidéos doit faire subir une réflexion et une rotation à un objet, il lui suffit d'appliquer la composition de ces deux transformations. On calcule explicitement la composition de deux transformations dans l'exemple ci-dessous.   La composition de deux transformations linéaires   On considère la transformation linéaire qui, dans un premier temps effectue la rotation de définie au point de la liste , suivie de la permutation des composantes du vecteur donnée par la transformation du point . On cherche la fonction .     Soit un vecteur de . On a . La composition des deux transformations est donc une nouvelle transformation . Concrètement, la transformation correspond à la réflexion par rapport à l'axe des abcisses, définie au point .    On verra prochainement comment calculer plus efficacement les compositions de fonctions, en développant un outil qui sera d'une utilité beaucoup plus grande que les transformations linéaires.  On termine avec des commandes Sage en lien avec la sous-section.   Les transformations sur Sage  On verra dans les prochaines sous-sections comment facilement vérifier si une transformation est linéaire ou non et comment l'appliquer efficacement sur un ensemble de points. Pour le moment, on construit à partir l'exemple calculatoire en montrant comment on peut appliquer une translation sur un ensemble de points et illustrer cette translation. Pour cela, on définit un quadrilatère, un vecteur de translation et l'on applique ce vecteur à chaque point du quadrilatère. Pour être efficace, on utilise la commande list .       La forme matricielle d'une transformation linéaire  Soit un vecteur de . Il est toujours possible de décomposer le vecteur comme une combinaison linéaire des vecteurs et , simplement en écrivant . En fait, cette décomposition est toujours possible avec avec les vecteurs et , car ou même dans avec .  Si l'on considère une transformation linéaire , en se concentrant sur pour le moment, il est possible de voir que l'image d'un vecteur est simplement une combinaison linéaire des images des vecteurs et , dont les coefficients sont aussi et : .  On pose et , l'image des vecteurs par la transformation . On pousse le calcul précédent un peu plus loin, en utilisant la notation verticale des vecteurs: . En regardant la dernière ligne, on remarque un vecteur dont chaque composante est un produit scalaire, dont l'un des vecteurs est commun, . On est tenté ici de mettre en évidence ce vecteur, mais une question s'impose.  Puisque est un vecteur dont chaque composante est un produit scalaire de vecteurs, il ne suffit pas de mettre en évidence le vecteur pour avoir ou encore . Ces deux expressions n'ont pas de sens mathématique. On propose la notation suivante pour la mise en évidence du vecteur : .  Il convient de rappeler ici que et , soit l'image par la transformation des vecteurs et . L'objet est appelé la matrice de la transformation linéaire . Ses colonnes sont donc les images des vecteurs et . En fait, les colonnes d'une matrice seront très importantes pour la suite des choses. Dans l'équation , on définit le vecteur comme étant le produit de la matrice et du vecteur . On peut toutefois voir le produit comme une combinaison linéaire des colonnes de la matrice, dont les coefficients sont et . On peut voir cela en se référant à l'équation où les vecteurs ont été écrits en colonne.  Bien que, pour le moment, on se concentre sur les transformations linéaires dans , on définit quand même de manière plus précise la notion de matrice quelconque.   Une matrice  Une matrice est un ensemble de nombres agencés dans un tableau de lignes et colonnes. Si est une matrice, on dénote par l'élément situé à la ligne et à la colonne , de sorte que .  Soit des vecteurs de . On note parfois la matrice dont les colonnes sont formées des vecteurs comme étant la matrice . De même, si sont des vecteurs de , on note la matrice dont les lignes sont formées des vecteurs comme étant .  Cette dernière façon d'écrire une matrice permet d'écrire la généralisation de l'équation ainsi:  L'ensemble de toutes les matrices de lignes et colonnes est noté . Si , la matrice est dite carrée et l'ensemble des matrices carrées de dimension , aussi dites d'ordre , est simplement noté .    En passant  Tout comme pour les vecteurs, la notation avec les crochets est aussi utilisée pour représenter les matrices. On aurait alors .   La représentation d'une matrice par ses colonnes, comme à l'équation , est particulièrement utile pour interpréter l'application d'une transformation linéaire à un vecteur, représentée dans ce cas par le produit matrice vecteur. En généralisant l'approche qui a mené à l'équation , si et , alors on a . L'équation est par le fait même une définition du produit d'une matrice de colonnes par un vecteur de d'un point de vue purement algébrique. L'ordre de ces facteurs est important, on verra dans la sous-section que l'équation ne signifie pas nécessairement la même chose, et ne serait définie ici que si .  À titre d'exemple, on détermine la matrice pour chacune des transformations linéaires de la liste .   Les matrices de certaines transformations linéaires du plan  Pour chaque transformation linéaire de la liste , on cherche à déterminer la matrice qui la représente.   La transformation identité laisse les vecteurs en place. Cela signifie donc que et . La matrice est donc .    Dans une réflexion par rapport à l'axe des abscisses, la première coordonnée reste la même et la seconde change de signe. On a donc et . La matrice est donc .    La rotation de dans le sens antihoraire est donnée par la transformation . On a donc et . La matrice est donc .    Un étirement horizontal de facteur est une transformation linéaire telle que et . La matrice est donc . De même, un étirement vertical de facteur est représenté par la matrice .    L'homothétie de facteur est une transformation représentant simultanément un étirement horizontal et un étirement vertical. La matrice est donc .    La permutation est une transformation linéaire qui change l'ordre des composantes d'un vecteur. Dans , ceci revient à et . La matrice est donc .    La projection orthogonale sur un vecteur non nul est une transformation linéaire. Soit , cette transformation. Si est un vecteur quelconque, on peut calculer la projection orthogonale de sur à l'aide de l'équation (en remplaçant par ). On trouve et . La matrice est donc . Cette matrice est plus compliquée que les précédentes, mais la section donnera une autre manière de déterminer la matrice d'une projection orthogonale, sans avoir à se rappeler la matrice ci-dessus.     Dans l'exemple précédent, pour obtenir la matrice de la projection orthogonale, on a écrit , soit une matrice précédé d'un scalaire devant. On comprend ici que, pour toute matrice et scalaire , le terme est une matrice dont les entrées sont multipliées par . Pour le cas par , on a .   La démarche qui a mené à la forme matricielle d'une transformation linéaire de vers se généralise facilement pour montrer que toute transformation linéaire de vers possède une forme matricielle. À titre d'exemple, regardons une transformation de vers .   Une transformation de l'espace vers le plan  Soit , une transformation. On montre que est linéaire et l'on détermine la matrice représentant la transformation.   Dans un premier temps, on vérifie la linéarité de . Soit des vecteurs de et un scalaire. On a et . La transformation est donc linéaire.  Pour trouver la matrice, on doit déterminer l'image des vecteurs et . Ces images sont . La matrice est alors .    Toute transformation linéaire possède une forme matricielle la représentant. Peut-on affirmer que, pour toute matrice, on a également une transformation linéaire? En partant de la définition du produit d'une matrice par un vecteur, à l'équation , on peut montrer que c'est le cas.   Les matrices sont des transformations linéaires   Soit une matrice possédant lignes et colonnes. Si l'on considère la transformation , alors est une transformation linéaire de vers .    Soit et . Posons les colonnes de . Alors on a et . Toute matrice correspond donc à une transformation linéaire.    Cette proposition donne une autre option pour vérifier si une transformation est linéaire. Étant donnée , une transformation quelconque, on peut calculer l'image des vecteurs , les mettre dans une matrice et vérifier que cette matrice correspond à la transformation . Si c'est le cas, est linéaire, sinon, elle ne l'est pas Techniquement, il faudrait s'assurer que la représentation par une matrice d'une transformation linéaire est unique. Pour cela, voir l'exercice . .   Les transformations et les matrices   Considérons les transformations et . On souhaite vérifier si ces transformations sont linéaires à l'aide d'une représentation matricielle.    On considère les vecteurs et . Si est linéaire, alors elle devrait correspondre à la transformation représentée par la matrice . Cependant, on a . La transformation n'est donc pas linéaire.    On considère les vecteurs et .Si est linéaire, alors elle devrait correspondre à la transformation représentée par la matrice . En effet, on a . Ainsi, la transformation est linéaire.     L'équivalence entre une transformation linéaire et une matrice  La proposition affirme qu'il y a une équivalence entre transformation linéaire et matrice. Pour cette raison, on utilisera souvent la lettre pour désigner à la fois la transformation ou sa matrice associée.   Dans l'exemple , on a, entre autre, déterminé la matrice d'une rotation de autour de l'origine. On s'intéresse maintenant au cas plus général d'une rotation d'angle autour de l'origine.   Rotation autour de l'origine dans le plan: dynamique   Considérons un angle . On souhaite déterminer la matrice correspondant à la rotation d'un angle , mesuré dans le sens antihoraire. La figure interactive suivante permet d'explorer cette rotation avec les vecteurs et .   La rotation dans le plan      Puisqu'on cherche la matrice, il suffit de déterminer l'image des vecteurs et par la rotation. Comme ces vecteurs sont séparés par un angle de et que la rotation de ne changera pas ceci, on peut seulement trouver l'image de et déterminer l'image de en prenant le vecteur perpendiculaire à l'image de . Selon la figure , l'image du vecteur est et donc . On a alors .    On termine avec des commandes Sage en lien avec la sous-section.   Les matrices avec Sage  Il est possible de définir des matrices dans Sage avec la commande matrix . À noter toutefois que Sage a une préférence pour les lignes plutôt que les colonnes et que si l'on veut définir la matrice selon ses colonnes, on doit utiliser la commande column_matrix .   Il n'est pas nécessaire de définir au préalable les vecteurs. Cela peut cependant être pratique dans le contexte des transformations linéaires où l'on définit les matrices en fonction des images des vecteurs . Si l'on choisit de ne pas donner des vecteurs comme argument, il faut procéder avec une paire de crochets contenant les lignes ou colonnes, chacune de celles-ci insérées dans une paire de crochets.   On peut accéder aux différentes entrées d'une matrice à l'aide de la commande A[i][j] , qui retourne l'entrée sur la ligne et la colonne . (Il convient de rappeler ici .)   Si l'on omet une paire de crochets, par exemple , alors Sage retourne un vecteur contenant ligne . Il est également possible d'obtenir cette ligne avec la commande A.row(i) . Pour obtenir la colonne , on devra utiliser la commande A.column(j) .   Avec une matrice et un vecteur, il est possible de faire la multiplication matrice vecteur, telle que définie à l'équation , pourvu que les dimensions soient compatibles. La deuxième cellule ci-dessous produit volontairement une erreur, car le vecteur ne peut être multiplié par la matrice .    On peut définir une matrice dont tous les éléments sont nuls rapidement en utilisant la commande matrix(m,n,0) . On aura alors une matrice emplie de .   Pour une matrice donnée, on peut déterminer la transformation linéaire associée en multipliant par le vecteur approprié.   On peut aussi tracer un vecteur et sa transformation, à l'aide des commandes plot .      L'addition matricielle et la multiplication par un scalaire  L'exercice montre que la somme de deux transformations linéaires est aussi une transformation linéaire. Géométriquement, on peut le voir comme si, étant donné deux transformations linéaires différentes , ayant le même domaine et la même image, et un vecteur , la transformation correspond à la somme des transformations sur . En ce sens, l'addition de deux transformations correspond à une addition vectorielle dans l'espace image de la transformation. Si cette somme est une transformation linéaire, elle doit donc avoir une forme matricielle.  Soit la matrice de et les colonnes de et la matrice de et les colonnes de . Alors on a . La matrice de la somme est donc une matrice composée de la somme des colonnes des matrices et . L'exercice montre que cela revient à dire que la matrice est obtenue en prenant la somme des lignes des matrices et et que, en fin de compte, on additionne chaque entrée correspondante. On arrive ainsi à la définition suivante.   Somme de deux matrices  Soit deux matrices. On définit la somme de et comme étant la matrice telle que .    Somme de matrices  Soit et . On calcule, si possible , les sommes et .   Puisque et ont les mêmes dimensions, il est possible de les additionner. Selon l'explication ci-dessus, on obtient . Comme les matrices et sont de tailles différentes, l'addition n'est pas possible.    Si l'on multiplie une transformation par un scalaire, c'est encore une transformation linéaire, puisque c'est en fait une propriété définissant les transformations linéaires. Une démarche similaire à celle qui est présentée en début de sous-section permet d'arriver à la définition algébrique suivante.   Multiplication d'une matrice par un scalaire  Soit et . La matrice est définie comme étant la matrice telle que .   Cette définition a déjà été mentionnée de manière intuitive à la remarque .   Multiplication d'une matrice par un scalaire  Soit et . On calcule et .   Selon la définition, on a . Pour la matrice , on a .    L'addition matricielle et la multiplication par un scalaire possèdent un ensemble de propriétés familières à l'addition et à la multiplication régulière, ainsi qu'à ces mêmes opérations sur les vecteurs. En fait, dans l'exercice , ces propriétés ont été démontrées pour les vecteurs. L'exercice fera la même chose pour les propriétés des matrices qui sont données ci-dessous à titre de référence.   Les propriétés de l'addition matricielle et de la multiplication par un scalaire   Soit et . Les propriétés suivantes sont toujours vraies:   Propriétés de l'addition matricielle et de la multiplication d'une matrice par un scalaire   (commutativité de l'addition matricielle)  (associativité de l'addition matricielle)  (neutre additif)  (inverse additif)  (associativité de la multiplication par un scalaire)  (distributivité sur l'addition matricielle)  (distributivité de l'addition des scalaires)  (neutre multiplicatif)     On termine avec des commandes Sage en lien avec la sous-section.   Les opérations matricielles sur Sage  Il est aussi facile d'additionner deux matrices et d'en multiplier une par un scalaire que de faire ces mêmes opérations pour un vecteur.       Les points importants de cette section sont:  Les propriétés définissant une transformation linéaire;  Le produit d'une matrice avec un vecteur, défini à l'équation ;  Le fait que, dans une matrice, les colonnes représentent l'image des vecteurs ;  L'équivalence entre une matrice et une transformation linéaire;  La forme matricielle d'une rotation dans ;  L'addition matricielle et la multiplication d'une matrice par un scalaire.  De plus avec Sage, on peut définir une matrice avec la commande matrix . Par défaut, Sage définit les matrices selon les lignes. La commande column_matrix() permet de le faire selon les colonnes. Lorsqu'ils sont compatibles, on peut multiplier une matrice par un vecteur avec l'opération * . On peut accéder aux lignes et colonnes d'une matrice avec les commandes A.row(i) et A.column(j) . L'addition de deux matrices se fait avec l'opération + et la multiplication par un scalaire avec l'opération * .     Exercices      Soit les trois matrices suivantes: et . Soit aussi les vecteurs et . Calculer, si possible, les expressions suivantes. Dans le cas où le calcul est impossible, expliquer pourquoi.     Considérer les règles établies dans les notes. À partir de celles-ci, on sait, que pour additionner deux matrices, elles doivent être de mêmes formats (voir la définition ).  De plus, pour multiplier une matrice avec un vecteur colonne, il faut avoir une matrice de colonnes avec un vecteur à composantes (voir l'équation ).  Finalement, on multiplie par un scalaire autant les vecteurs que les matrices de façon intuitive, c'est-à-dire en multipliant chaque élément par ce scalaire (voir la définition ).         Impossible.   Impossible, puisque les matrices sont de dimensions différentes.     Impossible.   Impossible, puisque la matrice a quatre colonnes et le vecteur ne possède que deux composantes. On ne peut donc pas faire le produit scalaire de chaque ligne avec le vecteur, tel qu'on a défini la multiplication matrice vecteur.                 Impossible.   Impossible, car les vecteurs et n'ont pas le même nombre de composantes. Il est donc impossible de les additionner.     La réponse suivra.      Pour chaque transformation linéaire de vers , dire si elle est linéaire, c'est-à-dire si elle respecte les propriétés des transformations linéaires. Si c'est le cas, le démontrer et sinon, donner un exemple prouvant le contraire.     La transformation n'est pas linéaire.   On peut utiliser la propriété de la proposition stipulant que l'image du vecteur nul est toujours le vecteur nul. Ici, .     La transformation n'est pas linéaire.   Cette fois, on ne peut utiliser l'image du vecteur nul puisque . Cela ne veut toutefois pas dire que la transformation est linéaire. En fait, la présence du terme permet de croire que la transformation n'est pas linéaire. Pour le prouver, il suffit d'exhiber deux vecteurs pour lesquels ou encore un vecteur et une constante tels que . On prend la première option. Si la transformation n'est pas linéaire, il y a de bonnes chances que n'importe quel vecteur fera l'affaire. On essaie avec et . On a , mais .     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et     La transformation n'est pas linéaire.   Comme la première composante de l'image du vecteur est donnée par , on comprend qu'on ne peut avoir . Cela entraine donc que l'image du vecteur nul n'existe pas, alors qu'on devrait avoir selon la proposition . La transformation ne peut donc pas être linéaire.     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et    Soit , une transformation linéaire de vers et , un vecteur quelconque du plan. Déterminer la matrice de transformation linéaire si:   est obtenu en faisant la réflexion de selon l'axe des ordonnées ( ).   Certaines matrices sont connues, comme la matrice de rotation et les transformations de l'exemple . Sinon, il est toujours possible de réfléchir et de déterminer où les vecteurs et seront amenés, comme on l'a fait dans l'exemple.     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . La réflexion selon l'axe des ne modifiera pas , mais amènera le vecteur vers le vecteur . Bref, et Cela donne donc:    est obtenu en faisant la rotation de de dans le sens horaire .     On connait déjà la matrice de rotation . Elle est définie pour une rotation de dans le sens antihoraire. On pose donc ici et l'on calcule les éléments de la matrice.   est obtenu en faisant la réflexion de selon l'axe .     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . La réflexion selon l'axe amènera le vecteur vers le vecteur et le vecteur vers le vecteur Bref, et Cela donne donc:   est obtenu en le projetant sur la droite .     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . Puisque c'est une projection, on peut utiliser la formule de la projection . Il faut simplement créer un vecteur qui soit sur la droite pour projeter dessus. On prend . et Cela donne donc:   est obtenu en faisant d'abord une homothétie de facteur , puis une rotation de dans le sens antihoraire.     On connait déjà les matrices d' homothétie et de rotation . Cependant, pour faire ces deux transformations successivement, il nous faut utiliser la multiplication matrice vecteur pour connaitre leur effet sur les vecteurs et . On remarque que la matrice qui agira en premier se trouve à droite, soit le plus près du vecteur à transformer. On utilisera donc et  et Cela donne donc:    est obtenue en l'étirant horizontalement d'un facteur , puis en le projetant sur la droite .     On pourrait procéder de façon semblable à la question précédente en trouvant en premier lieu les matrices d' étirement horizontal et de projection, mais on choisit une avenue plus intuitive. En se faisant un dessin, on peut comprendre où se déplaceront les vecteurs et . D'abord, le vecteur est étiré horizontalement de facteur pour devenir le vecteur . Ensuite, la projection sur la droite l'amènera au vecteur . Le vecteur ne sera pas touché par l'étirement horizontal, mais se déplacera de façon similaire par la projection pour devenir . Bref, et Cela donne donc:    Soit , une transformation linéaire de vers . Déterminer la matrice de transformation linéaire si:   et     On donne directement l'effet de sur les vecteurs et . On a donc les colonnes de la matrice. Ainsi,   et   Comme dans l'exemple , il faut déterminer et . Les résultats deviendront les colonnes de la matrice cherchée. Dans certains cas, il faudra écrire ou comme combinaison linéaire des vecteurs dont on connait l'effet de et utiliser la linéarité pour trouver ce qu'on veut.     On a les éléments de la première colonne de , mais pas ceux de la seconde. On a besoin de déterminer . On suit l'indication pour y arriver. On pourrait créer un système d'équations linéaires pour et , mais il est évident que par la composante en . Il suit que . On trouve ce qu'on cherche ainsi: Cela nous a donné la deuxième colonne de . Ainsi,   et     De façon semblable, on doit maintenant trouver à l'aide de ce qui nous est fourni. Il suit que et . Ainsi, Cela nous a donné la première colonne de . Ainsi,    et     Cette fois, il faut trouver des combinaisons linéaires pour et . On résoud les équations cachées derrière: et l'on obtient . De même, . Ce qui donne et . Ainsi, et Ainsi, .    Les graphiques suivants représentent des transformations linéaires simples. Malgré ce qu'il peut sembler à première vue, leur définition est ambigüe. Déterminer les deux matrices de transformation pouvant décrire chaque transformation illustrée.       Une première transformation linéaire illustrée par son effet sur une figure.     Comme d'habitude, il faut trouver l'effet de chaque transformation sur et .   et   La première option, qui semble la plus intuitive, est de voir cette transformation comme une réflexion par rapport à l'axe des . Ainsi, seul le vecteur se transformera pour devenir . On place les résultats en colonnes dans la matrice. Pour créer l'autre transformation, il suffit d'imaginer la transformation où les rôles des branches du L sont inversés. Il s'agit donc de combinaison d'une rotation, d'un étirement horizontal et d'une compression verticale. On peut voir que le vecteur se retrouve à . Cependant, le vecteur ne formant pas l'une des branches, on doit s'imaginer où il se retrouvera. Puisque le vecteur a pour image le vecteur , on peut conclure que l'image du vecteur sera le double de ce vecteur, soit . Ces résultats formeront les colonnes de la matrice.       Une deuxième transformation linéaire illustrée par son effet sur une figure.     et   La transformation la plus simple à visualiser est une rotation de . On connait déjà sa matrice, mais on peut aussi la construire en regardant où les vecteurs et se retrouvent. Le résultat, en colonnes, donne: La deuxième option est une réflexion selon l'axe des , ainsi qu'un étirement vertical et une compression horizontale. Les vecteurs en colonnes donneront la matrice:       Une troisième transformation linéaire illustrée par son effet sur une figure.     et   La première transformation est une combinaison d'étirements horizontal et vertical suivis d'une rotation de . Ainsi, le vecteur se retrouve à . Le vecteur n'étant pas une des branches, il faut plus d'imagination pour voir où il se retrouve. En doublant la longueur de la branche et donc ses coordonnées, on arrive à . La matrice est donc: . La deuxième transformation implique également des étirements ainsi qu'une rotation, en plus d'une réflexion. C'est donc assez complexe géométriquement, mais en utilisant la même méthode, on peut retrouver la matrice. Ainsi, le vecteur se retrouve à et le vecteur se retrouve à . On obtient donc: .    Dans l'exercice , on a démontré les propriétés des vecteurs algébriques. Ces propriétés s'appliquent également aux matrices et ont été énoncées dans la liste . Soit et . Démontrer algébriquement chacune de ces propriétés.   Il existe deux formes de notation que l'on pourrait utiliser pour cette démonstration. La version lourde est exprime chaque matrice sous la forme suivante. On exprime . On pourrait alors démontrer chaque propriété algébriquement de façon semblable à l'exercice pour les vecteurs de . Cependant, il existe une notation beaucoup moins lourde. Considérant que toutes les matrices en présence sont de mêmes dimensions, que l' addition matricielle est définie élément par élément et que la multiplication par un scalaire multiplie tous les éléments de chaque matrice, on va adopter la notation beaucoup plus simple: soit et .             Soit deux transformations linéaires et ayant le même domaine et la même image. Soit la transformation , définie comme la somme de ces transformations: . Montrer que est linéaire.   Considérer ce qu'on connait par rapport à et . Puisque ce sont des transformations linéaires, elles respectent déjà les propriétés . On doit se servir de cette information afin de montrer que respecte également ces propriétés.   Soit et dans le domaine de ces transformations et . et    Soit , une matrice. On sait que donne la colonne de la matrice. Comment obtenir l'entrée en position ? Considérer le produit scalaire de avec un vecteur bien choisi. On doit extraire de la colonne l'entrée en position . Si l'on effectue le produit scalaire avec un vecteur de bonne dimension, on aura le résultat souhaité.  On remarque aussi que la matrice n'a pas besoin d'être carrée. La cellule Sage ci-dessous permet de tester avec une matrice rectangulaire.     Dans l'exemple , on a composé deux transformations linéaires en exécutant les opérations successivement. Effectuer ces transformations dans l'ordre inverse, c'est-à-dire effectuer la permutation ( ) et ensuite la rotation de ( ).     Soit , un vecteur de . On a . La composition des deux transformations est donc une nouvelle transformation . Concrètement, la transformation correspond à la réflexion par rapport à l'axe des ordonnées, voir l'exercice .    Dans l'exercice , on a composé la permutation ( ) et la rotation de ( ). L'exemple a permis de trouver leurs matrices de transformation: Utiliser ces matrices pour trouver la matrice de la transformation .   On n'a pas encore appris à multiplier les matrices, ce qui serait de loin plus rapide. Il faut donc trouver et et les placer en colonnes dans la matrice de .     On suit l'indication. et Ce qui donne, en colonnes dans :     Montrer que la représentation matricielle d'une transformation linéaire est unique.   Supposer qu'il existe deux matrices et qui expriment la même transformation linéaire. Considérer ensuite que chaque vecteur de la base canonique devient chaque colonne de la matrice de transformation linéaire. Cela mène très rapidement à une contradiction.   Soit et , deux matrices différentes qui représentent la même transformation linéaire. On obtient la première colonne d'une matrice de transformation linéaire en regardant l'effet de cette transformation sur le premier vecteur de la base canonique . Mais l'effet résulte justement de la multiplication de la matrice de transformation par ce vecteur. Ainsi, par l'équation , et Alors, et, de même, on peut montrer que chaque colonne des matrices et sont identiques. Donc, la représentation matricielle d'une transformation linéaire est unique.    Soit deux matrices et , de mêmes dimensions qui sont telles que , pour tout vecteur compatible . Démontrer que .   On peut procéder de façon semblable au numéro , en choisissant les vecteurs de la base canonique. En effet, l'équation nous indique que si l'on choisit le vecteur comme , on obtiendra la première colonne de la matrice. Cela mènera rapidement à une contradiction.   Soit et , deux matrices différentes de mêmes dimensions. On procède de façon semblable à l'exercice précédent pour expliciter d'abord la première colonne de . On choisit . Ainsi, par l'équation , et Alors, et, de même, on peut montrer que toutes les colonnes des matrices et sont identiques. Donc, les matrices et doivent être égales puisque toutes leurs colonnes sont égales.   On considère une matrice et l'équation . On suppose d'abord que est une matrice . Si pour tous les vecteurs de , est-ce que ? Démontrer ou donner un contrexemple. Une rotation particulière Non, ce n'est pas suffisant pour que soit la matrice nulle. Si , alors est toujours perpendiculaire à et donc . Pourtant dans ce cas, . Si maintenant on a une matrice de dimension et que pour tous les vecteurs et tous les vecteurs , est-ce que ? Démontrer ou donner un contre exemple.  Utiliser l'exercice .  Cette fois, c'est suffisant. On regarde colonne par colonne la matrice . On sait que où sont les vecteurs standards et sont respectivement les colonnes un et deux de la matrice. De plus, on sait, par l'exercice , que l'entrée en position est donnée par . Or par hypothèse, l'équation pour tous les vecteurs de . La matrice est donc la matrice nulle.   On considère deux matrices de même dimensions et des vecteurs tels que l'équation est bien définie. Trouver deux matrices différentes non nulles et deux vecteurs différents (aussi non nuls) qui satisfont cette équation. Prendre dans et considérer deux rotations spécifiques. On prend , et , où ne sont pas tous les deux nuls.  On prend , et , où ne sont pas tous les deux nuls.  Puisque les vecteurs et sont parallèles, une rotation de sur fera en sorte que et seront perpendiculaires. De même, une rotation de sur fera en sorte que et seront perpendiculaires.  Dans les deux cas,  Montrer que si pour tous les vecteurs compatibles, alors . On réécrit l'équation en utilisant les propriétés du produit scalaire pour obtenir .  La matrice est donc telle que pour tout vecteur , l'équation . En utilisant l'exercice , on conclut que et donc que .   Soit deux transformations linéaires et ainsi que leurs matrices respectives et . On veut démontrer que la matrice de est égale à où l'on effectue l'addition de chaque élément correspondant dans les deux matrices.   Utiliser l'équation et commencer avec le fait que , tel que démontré à l'exercice . Définir des vecteurs lignes pour chaque matrice.   Soit la matrice de et les lignes de et la matrice de et les lignes de . Alors on a    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Considérer les matrices .    Définir les matrices et .    Additioner la deuxième ligne de la matrice avec la première colonne de la matrice .    Additionner toutes les lignes de et toutes les colonnes de .   Calculer le produit scalaire de la première colonne de avec la première colonne de , ou expliquer pourquoi ce n'est pas possible d'effectuer l'opération.   Calculer le produit scalaire de la première colonne de avec la première ligne de , ou expliquer pourquoi ce n'est pas possible d'effectuer l'opération.       et .      Impossible        Le code solution pour l'exercice   A=column_matrix([[-1,0],[2,3],[4,-2]]) B=column_matrix([[-3,2,0],[3,1,-5]]) show(\"A=\",A) show(\"B=\",B)       Le code solution pour l'exercice   show(A.row(1)+B.column(0))       Le code solution pour l'exercice   show(sum(A.column(k) for k in range(A.ncols()))+sum(B.row(k) for k in range(B.nrows())))     L'opération est impossible, car les vecteurs n'ont pas la même dimension.   Le code solution pour l'exercice   show(A.column(0)*B.row(0))       Considérer le carré de sommets et la transformation qui effectue une rotation de degrés. Tracer dans un même graphique le carré original en bleu et sa transformation par la rotation en rouge.     L'image d'un carré par une rotation de 50 degrés autour de l'origine.   Un carré bleu est affiché ainsi que son image en rouge par une rotation de 50 degrés.       Le code solution pour l'exercice   #Définition des points du quadrilatère ABCD A=vector([1,0]) B=vector([1,1]) C=vector([2,1]) D=vector([2,0]) #On forme une liste contenant tous les points (vecteurs) L=list([A,B,C,D]) #On définit la matrice de rotation theta=50\/360*2*pi R=column_matrix([[cos(theta),sin(theta)],[-sin(theta),cos(theta)]]) #On applique la translation à tous les vecteurs de la liste Ltrans=list([R*v for v in L]) #On illustre les quadrilatères, ainsi que le vecteur w sur l'un des points polygon(L,color=\"blue\")+polygon(Ltrans,color=\"red\")      La matrice permet de faire une rotation dans autour de l'origine. Il peut cependant arriver que l'on veuille tourner un objet autour d'un autre point que l'origine, tel qu'illustré à la figure .   Une rotation autour d'un point autre que l'origine    Soit un point de . On veut faire une rotation de degrés autour de ce point.   Expliquer pourquoi cette transformation n'est pas une transformation linéaire.  Pour effectuer cette transformation à l'aide des matrices, il est possible de translater à l'origine, d'appliquer la rotation autour de l'origine et de translater à nouveau au point de départ, comme illustré à la figure . Appliquer cette méthode pour trouver l'image du vecteur selon la transformation décrite ci-dessus.     Une rotation autour d'un point autre que l'origine: la méthode      La transformation n'est pas linéaire, car l'origine est déplacée, ce qui contredit la proposition .  L'image est le point .     Le code solution pour l'exercice   rot90=column_matrix([[0,1],[-1,0]]) #la matrice de rotation de 90 degrés trans=vector([2,3]) #Le centre de la rotation, aussi le vecteur de translation point=vector([-1,1]) pointtrans=point-trans # L'image du point après la translation pointtransrot=rot90*pointtrans #L'image du point translaté après la translation pointfinal=pointtransrot+trans show(pointfinal)     Une fonction pour la rotation autour d'un point quelconque En se basant sur l'exercice , on veut créer une fonction rotaffine qui prendra comme argument un centre de rotation , un angle et un point . La fonction retournera l'image du point par une rotation de autour du centre . Tester la fonction avec l'exercice afin de valider son fonctionnement.  On doit ici se poser la question de l'usage des degrés ou des radians. Selon que l'on choisit l'une ou l'autre mesure, y aura-t-il des ajustements à apporter? Créer la fonction définie dans le préambule de l'exercice et tester avec les paramètres de l'exercice .     Le code solution pour l'exercice   def rotaffine(c,theta,P): rot=column_matrix([[cos(theta),sin(theta)],[-sin(theta),cos(theta)]]) #la matrice de rotation de theta radians Ptrans=P-c # L'image du point après la translation Ptransrot=rot*Ptrans #L'image du point translaté après la translation Pfinal=Ptransrot+c return Pfinal    Il suffit ensuite d'appeler la fonction avec les arguments nécessaires. Par exemple, le code rotaffine(vector([2,3]),pi\/2,vector([-1,1])) devrait donner la réponse obtenue à l'exercice .  Calculer l'image des points suivants selon les rotations données, à l'aide de la fonction rotaffine .        "
},
{
  "id": "fig-unefonction",
  "level": "2",
  "url": "sec-transfodef.html#fig-unefonction",
  "type": "Figure",
  "number": "2.1.1",
  "title": "",
  "body": " La fonction     "
},
{
  "id": "fig-rot1",
  "level": "2",
  "url": "sec-transfodef.html#fig-rot1",
  "type": "Figure",
  "number": "2.1.2",
  "title": "",
  "body": " Une première transformation   Un carré est illustré à gauche et sa rotation de 45 degrés, à droite.   "
},
{
  "id": "def-transfo",
  "level": "2",
  "url": "sec-transfodef.html#def-transfo",
  "type": "Définition",
  "number": "2.1.3",
  "title": "",
  "body": " Une fonction vectorielle de vers est une fonction qui prend un vecteur et lui associe un vecteur . On écrit alors .  "
},
{
  "id": "ex-transfquelc",
  "level": "2",
  "url": "sec-transfodef.html#ex-transfquelc",
  "type": "Exemple",
  "number": "2.1.4",
  "title": "Des transformations quelconques.",
  "body": " Des transformations quelconques  Voici quelques exemples de transformations:   Des transformations quelconques   La norme d'un vecteur peut être considérée comme une fonction de vers , où .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La fonction est une fonction de vers .  La translation de , qui transforme tout vecteur par .   "
},
{
  "id": "fig-transfquelc",
  "level": "2",
  "url": "sec-transfodef.html#fig-transfquelc",
  "type": "Figure",
  "number": "2.1.6",
  "title": "",
  "body": " La fonction     Le plan R deux est illustré, avec trois courbes de couleurs différentes    Le plan R deux est illustré, avec l'image des trois courbes de couleurs différentes    "
},
{
  "id": "def-transfolin",
  "level": "2",
  "url": "sec-transfodef.html#def-transfolin",
  "type": "Définition",
  "number": "2.1.7",
  "title": "Transformation linéaire.",
  "body": " Transformation linéaire  Une fonction de vers est une transformation linéaire si elle satisfait les deux propriétés suivantes:  pour tout vecteur .  pour tout vecteur et scalaire .   "
},
{
  "id": "fig-transfolin1",
  "level": "2",
  "url": "sec-transfodef.html#fig-transfolin1",
  "type": "Figure",
  "number": "2.1.8",
  "title": "",
  "body": " La transformation linéaire   "
},
{
  "id": "prop-transfolinprop",
  "level": "2",
  "url": "sec-transfodef.html#prop-transfolinprop",
  "type": "Proposition",
  "number": "2.1.9",
  "title": "Propriétés d’une transformation linéaire.",
  "body": " Propriétés d'une transformation linéaire   Soit une transformation linéaire. Alors  L'image du vecteur nul est toujours le vecteur nul, c'est-à-dire .  Si les vecteurs et sont parallèles, alors leur image est parallèle, c'est-à-dire si , alors .  L'image d'une droite par une transformation linéaire est une droite Avec la particularité qu'elle pourrait être écrasée en un point. On considère ceci comme un cas limite. .  Les transformations linéaires sont donc des transformations qui ne déforment pas trop l'espace, comme cela est évoqué au point 3. D'un point de vue géométrique, on peut voir la pertinence du mot linéaire dans transformation linéaire par le fait que les droites demeurent des droites (ce n'est pas le cas pour l'image de la droite dans la figure ).    On peut utiliser la propriété ou la propriété . On se propose ici d'utiliser la propriété et on laisse l'utilisation de l'autre propriété à explorer dans l'exercice .  Soit l'image du vecteur nul et un vecteur quelconque. Par la propriété , on a . La dernière équation nous donne et donc, .  La seconde propriété est une simple reformulation de la propriété des transformations linéaires. En effet, soit un vecteur parallèle à . Alors et donc, l'image du vecteur est parallèle à l'image du vecteur .  Soit un plan. On a . Le cas dégénéré dont il est question dans l'énoncé fait référence au fait qu'il est possible que . Dans ce cas, l'image de la droite est un point.    "
},
{
  "id": "rem-transfolinpoints",
  "level": "2",
  "url": "sec-transfodef.html#rem-transfolinpoints",
  "type": "Remarque",
  "number": "2.1.10",
  "title": "Les transformations linéaires et les points.",
  "body": " Les transformations linéaires et les points  Si sont des points et que , alors on note , où doit être vu comme une forme raccourcie du vecteur .  "
},
{
  "id": "ex-transfquelclin",
  "level": "2",
  "url": "sec-transfodef.html#ex-transfquelclin",
  "type": "Exemple",
  "number": "2.1.11",
  "title": "Retour sur les transformations quelconques.",
  "body": " Retour sur les transformations quelconques   On considère les fonctions de la liste . On cherche à déterminer lesquelles sont linéaires.    La norme d'un vecteur n'est pas une transformation linéaire. En effet, l'exercice montre que souvent, on a . De plus, on sait que . La transformation n'est donc pas linéaire.    La fonction n'est pas linéaire. En effet, il suffit de remarquer que . Le vecteur nul n'est pas envoyé sur le vecteur nul. Si la transformation avait été linéaire, on aurait .    Si l'on essaie pour la fonction , on obtient bel et bien le vecteur . Attention toutefois, cela ne signifie pas que la transformation est linéaire. L'image du vecteur nul est un moyen rapide de savoir si la fonction n'est pas linéaire, mais dans le cas où , aucune conclusion ne peut être tirée. On regarde la propriété pour la fonction , mais la propriété n'est pas non plus respectée. Soit et un vecteur quelconque. On a .    La fonction est linéaire. En effet, soit et des vecteurs de et soit un scalaire. On a .  De plus, on a . Ainsi, la transformation est linéaire.    La transformation n'est pas linéaire. Encore une fois, on voit que le vecteur n'est pas envoyé sur le vecteur .    La translation n'est pas une transformation linéaire. En effet, .   "
},
{
  "id": "con-satisprop",
  "level": "2",
  "url": "sec-transfodef.html#con-satisprop",
  "type": "Conseil",
  "number": "2.1.12",
  "title": "Satisfaire et ne pas satisfaire une définition.",
  "body": " Satisfaire et ne pas satisfaire une définition  Lorsqu'on doit vérifier si quelque chose satisfait une définition comme la définition , où un certain nombre de propriétés doivent être satisfaites, il est important de comprendre la distinction entre satisfaire la définition et ne pas la satisfaire. Montrer que la définition est satisfaite pour un, deux ou cent cas particuliers n'est jamais suffisant si la définition comprend des mots comme pour tout vecteur ou pour tout nombre. C'est souvent une bonne idée de regarder quelques cas simples afin de se donner une idée, mais ce n'est jamais suffisant.  Par contre, si le but est de montrer qu'un objet ne satisfait pas une définition contenant des phrases comme pour tout vecteur ou nombre , alors là, il est suffisant de trouver un seul cas qui ne satisfait pas à la définition.  Par exemple, pour montrer que la norme d'un vecteur n'est pas une transformation linéaire, on aurait pu tout simplement prendre les vecteurs et constater que alors que .  "
},
{
  "id": "ex-transfor2",
  "level": "2",
  "url": "sec-transfodef.html#ex-transfor2",
  "type": "Exemple",
  "number": "2.1.13",
  "title": "Des transformations linéaires du plan : dynamique.",
  "body": " Des transformations linéaires du plan : dynamique   Considérer la liste des transformations suivantes, définies géométriquement et algébriquement:   Des transformations linéaires   La transformation , transformation qui laisse chaque vecteur en place. On l'appelle la transformation identité. Le choix du mot identité deviendra évident une fois qu'on aura introduit la composition de deux transformations linéaires, qui sera une sorte de produit, à la section  La réflexion par rapport à l'axe des abscisses, donnée par la transformation .  La rotation de ou dans le sens antihoraire, donnée par la transformation .  Un étirement horizontal de facteur est une transformation linéaire donnée par .  De même, un étirement vertical est donné par .  Une homothétie est une transformation qui multiplie chaque composante d'un vecteur par un facteur . Elle est donnée par la transformation .  Une matrice de permutation est une matrice qui change l'ordre des composantes du vecteur. Dans , la seule transformation qui accomplit une telle permutation est , bien que l'identité est aussi vue comme une matrice de permutation.  Soit un vecteur non nul. La projection orthogonale sur est une transformation linéaire.    Les démonstrations algébriques et géométriques de la linéarité de ces fonctions sont présentées ci-dessous.    Intuitivement, la transformation laisse tout en place. Les propriétés de linéarité devraient donc découler automatiquement des propriétés des opérations sur les vecteurs.  Algébriquement, la transformation est linéaire, car . De même, .    La figure interactive ci-dessous permet de voir la linéarité de la réflexion de manière intuitive.   La réflexion par rapport à l'axe des abscisses est une transformation linéaire    Algébriquement, on a et .    La figure interactive ci-dessous permet de voir la linéarité de la rotation de manière intuititve.   La rotation de dans le sens antihoraire est une transformation linéaire    Algébriquement, on a et .    La figure interactive ci-dessous permet de voir la linéarité de l'étirement de manière intuititve.   La rotation de dans le sens antihoraire est une transformation linéaire    Algébriquement, on a et .    La démonstration est faite à l'exercice    La figure interactive ci-dessous permet devoir la linéarité de la permutation de composantes de manière intuitive.   La permutation des composantes d'un vecteur est une transformation linéaire    Algébriquement, on a et .    On note , la projection orthogonale du vecteur sur le vecteur . Algébriquement, on a et .   "
},
{
  "id": "thm-transfocompo",
  "level": "2",
  "url": "sec-transfodef.html#thm-transfocompo",
  "type": "Théorème",
  "number": "2.1.19",
  "title": "La composition de transformations linéaires.",
  "body": " La composition de transformations linéaires  Soit et , des transformations linéaires telles que l'image de est comprise dans le domaine de . Alors la transformation est une transformation linéaire.   Soit , des vecteurs tels que et et un scalaire. Alors . De même, on a .  Ainsi, la composition de deux transformations linéaires est linéaire.   "
},
{
  "id": "ex-transfocomp",
  "level": "2",
  "url": "sec-transfodef.html#ex-transfocomp",
  "type": "Exemple",
  "number": "2.1.20",
  "title": "La composition de deux transformations linéaires.",
  "body": " La composition de deux transformations linéaires   On considère la transformation linéaire qui, dans un premier temps effectue la rotation de définie au point de la liste , suivie de la permutation des composantes du vecteur donnée par la transformation du point . On cherche la fonction .     Soit un vecteur de . On a . La composition des deux transformations est donc une nouvelle transformation . Concrètement, la transformation correspond à la réflexion par rapport à l'axe des abcisses, définie au point .   "
},
{
  "id": "sageex-deftransfo",
  "level": "2",
  "url": "sec-transfodef.html#sageex-deftransfo",
  "type": "Calcul",
  "number": "2.1.21",
  "title": "Les transformations sur Sage.",
  "body": " Les transformations sur Sage  On verra dans les prochaines sous-sections comment facilement vérifier si une transformation est linéaire ou non et comment l'appliquer efficacement sur un ensemble de points. Pour le moment, on construit à partir l'exemple calculatoire en montrant comment on peut appliquer une translation sur un ensemble de points et illustrer cette translation. Pour cela, on définit un quadrilatère, un vecteur de translation et l'on applique ce vecteur à chaque point du quadrilatère. Pour être efficace, on utilise la commande list .   "
},
{
  "id": "def-matrice",
  "level": "2",
  "url": "sec-transfodef.html#def-matrice",
  "type": "Définition",
  "number": "2.1.22",
  "title": "Une matrice.",
  "body": " Une matrice  Une matrice est un ensemble de nombres agencés dans un tableau de lignes et colonnes. Si est une matrice, on dénote par l'élément situé à la ligne et à la colonne , de sorte que .  Soit des vecteurs de . On note parfois la matrice dont les colonnes sont formées des vecteurs comme étant la matrice . De même, si sont des vecteurs de , on note la matrice dont les lignes sont formées des vecteurs comme étant .  Cette dernière façon d'écrire une matrice permet d'écrire la généralisation de l'équation ainsi:  L'ensemble de toutes les matrices de lignes et colonnes est noté . Si , la matrice est dite carrée et l'ensemble des matrices carrées de dimension , aussi dites d'ordre , est simplement noté .  "
},
{
  "id": "ex-mattransfor2",
  "level": "2",
  "url": "sec-transfodef.html#ex-mattransfor2",
  "type": "Exemple",
  "number": "2.1.23",
  "title": "Les matrices de certaines transformations linéaires du plan.",
  "body": " Les matrices de certaines transformations linéaires du plan  Pour chaque transformation linéaire de la liste , on cherche à déterminer la matrice qui la représente.   La transformation identité laisse les vecteurs en place. Cela signifie donc que et . La matrice est donc .    Dans une réflexion par rapport à l'axe des abscisses, la première coordonnée reste la même et la seconde change de signe. On a donc et . La matrice est donc .    La rotation de dans le sens antihoraire est donnée par la transformation . On a donc et . La matrice est donc .    Un étirement horizontal de facteur est une transformation linéaire telle que et . La matrice est donc . De même, un étirement vertical de facteur est représenté par la matrice .    L'homothétie de facteur est une transformation représentant simultanément un étirement horizontal et un étirement vertical. La matrice est donc .    La permutation est une transformation linéaire qui change l'ordre des composantes d'un vecteur. Dans , ceci revient à et . La matrice est donc .    La projection orthogonale sur un vecteur non nul est une transformation linéaire. Soit , cette transformation. Si est un vecteur quelconque, on peut calculer la projection orthogonale de sur à l'aide de l'équation (en remplaçant par ). On trouve et . La matrice est donc . Cette matrice est plus compliquée que les précédentes, mais la section donnera une autre manière de déterminer la matrice d'une projection orthogonale, sans avoir à se rappeler la matrice ci-dessus.   "
},
{
  "id": "rem-multscalmat",
  "level": "2",
  "url": "sec-transfodef.html#rem-multscalmat",
  "type": "Remarque",
  "number": "2.1.24",
  "title": "",
  "body": " Dans l'exemple précédent, pour obtenir la matrice de la projection orthogonale, on a écrit , soit une matrice précédé d'un scalaire devant. On comprend ici que, pour toute matrice et scalaire , le terme est une matrice dont les entrées sont multipliées par . Pour le cas par , on a .  "
},
{
  "id": "example-34",
  "level": "2",
  "url": "sec-transfodef.html#example-34",
  "type": "Exemple",
  "number": "2.1.25",
  "title": "Une transformation de l’espace vers le plan.",
  "body": " Une transformation de l'espace vers le plan  Soit , une transformation. On montre que est linéaire et l'on détermine la matrice représentant la transformation.   Dans un premier temps, on vérifie la linéarité de . Soit des vecteurs de et un scalaire. On a et . La transformation est donc linéaire.  Pour trouver la matrice, on doit déterminer l'image des vecteurs et . Ces images sont . La matrice est alors .   "
},
{
  "id": "prop-matsonttransfos",
  "level": "2",
  "url": "sec-transfodef.html#prop-matsonttransfos",
  "type": "Proposition",
  "number": "2.1.26",
  "title": "Les matrices sont des transformations linéaires.",
  "body": " Les matrices sont des transformations linéaires   Soit une matrice possédant lignes et colonnes. Si l'on considère la transformation , alors est une transformation linéaire de vers .    Soit et . Posons les colonnes de . Alors on a et . Toute matrice correspond donc à une transformation linéaire.   "
},
{
  "id": "ex-transfomatrice",
  "level": "2",
  "url": "sec-transfodef.html#ex-transfomatrice",
  "type": "Exemple",
  "number": "2.1.27",
  "title": "Les transformations et les matrices.",
  "body": " Les transformations et les matrices   Considérons les transformations et . On souhaite vérifier si ces transformations sont linéaires à l'aide d'une représentation matricielle.    On considère les vecteurs et . Si est linéaire, alors elle devrait correspondre à la transformation représentée par la matrice . Cependant, on a . La transformation n'est donc pas linéaire.    On considère les vecteurs et .Si est linéaire, alors elle devrait correspondre à la transformation représentée par la matrice . En effet, on a . Ainsi, la transformation est linéaire.   "
},
{
  "id": "rem-equitransfmat",
  "level": "2",
  "url": "sec-transfodef.html#rem-equitransfmat",
  "type": "Remarque",
  "number": "2.1.28",
  "title": "L’équivalence entre une transformation linéaire et une matrice.",
  "body": " L'équivalence entre une transformation linéaire et une matrice  La proposition affirme qu'il y a une équivalence entre transformation linéaire et matrice. Pour cette raison, on utilisera souvent la lettre pour désigner à la fois la transformation ou sa matrice associée.  "
},
{
  "id": "ex-rotr2",
  "level": "2",
  "url": "sec-transfodef.html#ex-rotr2",
  "type": "Exemple",
  "number": "2.1.29",
  "title": "Rotation autour de l’origine dans le plan: dynamique.",
  "body": " Rotation autour de l'origine dans le plan: dynamique   Considérons un angle . On souhaite déterminer la matrice correspondant à la rotation d'un angle , mesuré dans le sens antihoraire. La figure interactive suivante permet d'explorer cette rotation avec les vecteurs et .   La rotation dans le plan      Puisqu'on cherche la matrice, il suffit de déterminer l'image des vecteurs et par la rotation. Comme ces vecteurs sont séparés par un angle de et que la rotation de ne changera pas ceci, on peut seulement trouver l'image de et déterminer l'image de en prenant le vecteur perpendiculaire à l'image de . Selon la figure , l'image du vecteur est et donc . On a alors .   "
},
{
  "id": "sageex-transfomat",
  "level": "2",
  "url": "sec-transfodef.html#sageex-transfomat",
  "type": "Calcul",
  "number": "2.1.31",
  "title": "Les matrices avec Sage.",
  "body": " Les matrices avec Sage  Il est possible de définir des matrices dans Sage avec la commande matrix . À noter toutefois que Sage a une préférence pour les lignes plutôt que les colonnes et que si l'on veut définir la matrice selon ses colonnes, on doit utiliser la commande column_matrix .   Il n'est pas nécessaire de définir au préalable les vecteurs. Cela peut cependant être pratique dans le contexte des transformations linéaires où l'on définit les matrices en fonction des images des vecteurs . Si l'on choisit de ne pas donner des vecteurs comme argument, il faut procéder avec une paire de crochets contenant les lignes ou colonnes, chacune de celles-ci insérées dans une paire de crochets.   On peut accéder aux différentes entrées d'une matrice à l'aide de la commande A[i][j] , qui retourne l'entrée sur la ligne et la colonne . (Il convient de rappeler ici .)   Si l'on omet une paire de crochets, par exemple , alors Sage retourne un vecteur contenant ligne . Il est également possible d'obtenir cette ligne avec la commande A.row(i) . Pour obtenir la colonne , on devra utiliser la commande A.column(j) .   Avec une matrice et un vecteur, il est possible de faire la multiplication matrice vecteur, telle que définie à l'équation , pourvu que les dimensions soient compatibles. La deuxième cellule ci-dessous produit volontairement une erreur, car le vecteur ne peut être multiplié par la matrice .    On peut définir une matrice dont tous les éléments sont nuls rapidement en utilisant la commande matrix(m,n,0) . On aura alors une matrice emplie de .   Pour une matrice donnée, on peut déterminer la transformation linéaire associée en multipliant par le vecteur approprié.   On peut aussi tracer un vecteur et sa transformation, à l'aide des commandes plot .   "
},
{
  "id": "def-matsomme",
  "level": "2",
  "url": "sec-transfodef.html#def-matsomme",
  "type": "Définition",
  "number": "2.1.32",
  "title": "Somme de deux matrices.",
  "body": " Somme de deux matrices  Soit deux matrices. On définit la somme de et comme étant la matrice telle que .  "
},
{
  "id": "ex-matsomme",
  "level": "2",
  "url": "sec-transfodef.html#ex-matsomme",
  "type": "Exemple",
  "number": "2.1.33",
  "title": "Somme de matrices.",
  "body": " Somme de matrices  Soit et . On calcule, si possible , les sommes et .   Puisque et ont les mêmes dimensions, il est possible de les additionner. Selon l'explication ci-dessus, on obtient . Comme les matrices et sont de tailles différentes, l'addition n'est pas possible.   "
},
{
  "id": "def-matprodscal",
  "level": "2",
  "url": "sec-transfodef.html#def-matprodscal",
  "type": "Définition",
  "number": "2.1.34",
  "title": "Multiplication d’une matrice par un scalaire.",
  "body": " Multiplication d'une matrice par un scalaire  Soit et . La matrice est définie comme étant la matrice telle que .  "
},
{
  "id": "ex-matprodscal",
  "level": "2",
  "url": "sec-transfodef.html#ex-matprodscal",
  "type": "Exemple",
  "number": "2.1.35",
  "title": "Multiplication d’une matrice par un scalaire.",
  "body": " Multiplication d'une matrice par un scalaire  Soit et . On calcule et .   Selon la définition, on a . Pour la matrice , on a .   "
},
{
  "id": "prop-opmat",
  "level": "2",
  "url": "sec-transfodef.html#prop-opmat",
  "type": "Proposition",
  "number": "2.1.36",
  "title": "Les propriétés de l’addition matricielle et de la multiplication par un scalaire.",
  "body": " Les propriétés de l'addition matricielle et de la multiplication par un scalaire   Soit et . Les propriétés suivantes sont toujours vraies:   Propriétés de l'addition matricielle et de la multiplication d'une matrice par un scalaire   (commutativité de l'addition matricielle)  (associativité de l'addition matricielle)  (neutre additif)  (inverse additif)  (associativité de la multiplication par un scalaire)  (distributivité sur l'addition matricielle)  (distributivité de l'addition des scalaires)  (neutre multiplicatif)    "
},
{
  "id": "sageex-opmat",
  "level": "2",
  "url": "sec-transfodef.html#sageex-opmat",
  "type": "Calcul",
  "number": "2.1.38",
  "title": "Les opérations matricielles sur Sage.",
  "body": " Les opérations matricielles sur Sage  Il est aussi facile d'additionner deux matrices et d'en multiplier une par un scalaire que de faire ces mêmes opérations pour un vecteur.   "
},
{
  "id": "exo-additionmatrices",
  "level": "2",
  "url": "sec-transfodef.html#exo-additionmatrices",
  "type": "Exercice",
  "number": "2.1.4.1",
  "title": "",
  "body": " Soit les trois matrices suivantes: et . Soit aussi les vecteurs et . Calculer, si possible, les expressions suivantes. Dans le cas où le calcul est impossible, expliquer pourquoi.     Considérer les règles établies dans les notes. À partir de celles-ci, on sait, que pour additionner deux matrices, elles doivent être de mêmes formats (voir la définition ).  De plus, pour multiplier une matrice avec un vecteur colonne, il faut avoir une matrice de colonnes avec un vecteur à composantes (voir l'équation ).  Finalement, on multiplie par un scalaire autant les vecteurs que les matrices de façon intuitive, c'est-à-dire en multipliant chaque élément par ce scalaire (voir la définition ).         Impossible.   Impossible, puisque les matrices sont de dimensions différentes.     Impossible.   Impossible, puisque la matrice a quatre colonnes et le vecteur ne possède que deux composantes. On ne peut donc pas faire le produit scalaire de chaque ligne avec le vecteur, tel qu'on a défini la multiplication matrice vecteur.                 Impossible.   Impossible, car les vecteurs et n'ont pas le même nombre de composantes. Il est donc impossible de les additionner.     La réponse suivra.    "
},
{
  "id": "exo-transfolinoupas",
  "level": "2",
  "url": "sec-transfodef.html#exo-transfolinoupas",
  "type": "Exercice",
  "number": "2.1.4.2",
  "title": "",
  "body": " Pour chaque transformation linéaire de vers , dire si elle est linéaire, c'est-à-dire si elle respecte les propriétés des transformations linéaires. Si c'est le cas, le démontrer et sinon, donner un exemple prouvant le contraire.     La transformation n'est pas linéaire.   On peut utiliser la propriété de la proposition stipulant que l'image du vecteur nul est toujours le vecteur nul. Ici, .     La transformation n'est pas linéaire.   Cette fois, on ne peut utiliser l'image du vecteur nul puisque . Cela ne veut toutefois pas dire que la transformation est linéaire. En fait, la présence du terme permet de croire que la transformation n'est pas linéaire. Pour le prouver, il suffit d'exhiber deux vecteurs pour lesquels ou encore un vecteur et une constante tels que . On prend la première option. Si la transformation n'est pas linéaire, il y a de bonnes chances que n'importe quel vecteur fera l'affaire. On essaie avec et . On a , mais .     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et     La transformation n'est pas linéaire.   Comme la première composante de l'image du vecteur est donnée par , on comprend qu'on ne peut avoir . Cela entraine donc que l'image du vecteur nul n'existe pas, alors qu'on devrait avoir selon la proposition . La transformation ne peut donc pas être linéaire.     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et     La transformation est linéaire.   Soit et . On montre que respecte les deux propriétés des transformations linéaires. et  "
},
{
  "id": "exo-trouvermattransfomots",
  "level": "2",
  "url": "sec-transfodef.html#exo-trouvermattransfomots",
  "type": "Exercice",
  "number": "2.1.4.3",
  "title": "",
  "body": " Soit , une transformation linéaire de vers et , un vecteur quelconque du plan. Déterminer la matrice de transformation linéaire si:   est obtenu en faisant la réflexion de selon l'axe des ordonnées ( ).   Certaines matrices sont connues, comme la matrice de rotation et les transformations de l'exemple . Sinon, il est toujours possible de réfléchir et de déterminer où les vecteurs et seront amenés, comme on l'a fait dans l'exemple.     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . La réflexion selon l'axe des ne modifiera pas , mais amènera le vecteur vers le vecteur . Bref, et Cela donne donc:    est obtenu en faisant la rotation de de dans le sens horaire .     On connait déjà la matrice de rotation . Elle est définie pour une rotation de dans le sens antihoraire. On pose donc ici et l'on calcule les éléments de la matrice.   est obtenu en faisant la réflexion de selon l'axe .     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . La réflexion selon l'axe amènera le vecteur vers le vecteur et le vecteur vers le vecteur Bref, et Cela donne donc:   est obtenu en le projetant sur la droite .     On détermine où les vecteurs et seront amenés par cette transformation linéaire. Les résultats formeront les colonnes de la matrice . Puisque c'est une projection, on peut utiliser la formule de la projection . Il faut simplement créer un vecteur qui soit sur la droite pour projeter dessus. On prend . et Cela donne donc:   est obtenu en faisant d'abord une homothétie de facteur , puis une rotation de dans le sens antihoraire.     On connait déjà les matrices d' homothétie et de rotation . Cependant, pour faire ces deux transformations successivement, il nous faut utiliser la multiplication matrice vecteur pour connaitre leur effet sur les vecteurs et . On remarque que la matrice qui agira en premier se trouve à droite, soit le plus près du vecteur à transformer. On utilisera donc et  et Cela donne donc:    est obtenue en l'étirant horizontalement d'un facteur , puis en le projetant sur la droite .     On pourrait procéder de façon semblable à la question précédente en trouvant en premier lieu les matrices d' étirement horizontal et de projection, mais on choisit une avenue plus intuitive. En se faisant un dessin, on peut comprendre où se déplaceront les vecteurs et . D'abord, le vecteur est étiré horizontalement de facteur pour devenir le vecteur . Ensuite, la projection sur la droite l'amènera au vecteur . Le vecteur ne sera pas touché par l'étirement horizontal, mais se déplacera de façon similaire par la projection pour devenir . Bref, et Cela donne donc:  "
},
{
  "id": "exo-trouvermattransfovecteurs",
  "level": "2",
  "url": "sec-transfodef.html#exo-trouvermattransfovecteurs",
  "type": "Exercice",
  "number": "2.1.4.4",
  "title": "",
  "body": " Soit , une transformation linéaire de vers . Déterminer la matrice de transformation linéaire si:   et     On donne directement l'effet de sur les vecteurs et . On a donc les colonnes de la matrice. Ainsi,   et   Comme dans l'exemple , il faut déterminer et . Les résultats deviendront les colonnes de la matrice cherchée. Dans certains cas, il faudra écrire ou comme combinaison linéaire des vecteurs dont on connait l'effet de et utiliser la linéarité pour trouver ce qu'on veut.     On a les éléments de la première colonne de , mais pas ceux de la seconde. On a besoin de déterminer . On suit l'indication pour y arriver. On pourrait créer un système d'équations linéaires pour et , mais il est évident que par la composante en . Il suit que . On trouve ce qu'on cherche ainsi: Cela nous a donné la deuxième colonne de . Ainsi,   et     De façon semblable, on doit maintenant trouver à l'aide de ce qui nous est fourni. Il suit que et . Ainsi, Cela nous a donné la première colonne de . Ainsi,    et     Cette fois, il faut trouver des combinaisons linéaires pour et . On résoud les équations cachées derrière: et l'on obtient . De même, . Ce qui donne et . Ainsi, et Ainsi, .  "
},
{
  "id": "exo-transfodoubledef",
  "level": "2",
  "url": "sec-transfodef.html#exo-transfodoubledef",
  "type": "Exercice",
  "number": "2.1.4.5",
  "title": "",
  "body": " Les graphiques suivants représentent des transformations linéaires simples. Malgré ce qu'il peut sembler à première vue, leur définition est ambigüe. Déterminer les deux matrices de transformation pouvant décrire chaque transformation illustrée.       Une première transformation linéaire illustrée par son effet sur une figure.     Comme d'habitude, il faut trouver l'effet de chaque transformation sur et .   et   La première option, qui semble la plus intuitive, est de voir cette transformation comme une réflexion par rapport à l'axe des . Ainsi, seul le vecteur se transformera pour devenir . On place les résultats en colonnes dans la matrice. Pour créer l'autre transformation, il suffit d'imaginer la transformation où les rôles des branches du L sont inversés. Il s'agit donc de combinaison d'une rotation, d'un étirement horizontal et d'une compression verticale. On peut voir que le vecteur se retrouve à . Cependant, le vecteur ne formant pas l'une des branches, on doit s'imaginer où il se retrouvera. Puisque le vecteur a pour image le vecteur , on peut conclure que l'image du vecteur sera le double de ce vecteur, soit . Ces résultats formeront les colonnes de la matrice.       Une deuxième transformation linéaire illustrée par son effet sur une figure.     et   La transformation la plus simple à visualiser est une rotation de . On connait déjà sa matrice, mais on peut aussi la construire en regardant où les vecteurs et se retrouvent. Le résultat, en colonnes, donne: La deuxième option est une réflexion selon l'axe des , ainsi qu'un étirement vertical et une compression horizontale. Les vecteurs en colonnes donneront la matrice:       Une troisième transformation linéaire illustrée par son effet sur une figure.     et   La première transformation est une combinaison d'étirements horizontal et vertical suivis d'une rotation de . Ainsi, le vecteur se retrouve à . Le vecteur n'étant pas une des branches, il faut plus d'imagination pour voir où il se retrouve. En doublant la longueur de la branche et donc ses coordonnées, on arrive à . La matrice est donc: . La deuxième transformation implique également des étirements ainsi qu'une rotation, en plus d'une réflexion. C'est donc assez complexe géométriquement, mais en utilisant la même méthode, on peut retrouver la matrice. Ainsi, le vecteur se retrouve à et le vecteur se retrouve à . On obtient donc: .  "
},
{
  "id": "exo-propopmat",
  "level": "2",
  "url": "sec-transfodef.html#exo-propopmat",
  "type": "Exercice",
  "number": "2.1.4.6",
  "title": "",
  "body": " Dans l'exercice , on a démontré les propriétés des vecteurs algébriques. Ces propriétés s'appliquent également aux matrices et ont été énoncées dans la liste . Soit et . Démontrer algébriquement chacune de ces propriétés.   Il existe deux formes de notation que l'on pourrait utiliser pour cette démonstration. La version lourde est exprime chaque matrice sous la forme suivante. On exprime . On pourrait alors démontrer chaque propriété algébriquement de façon semblable à l'exercice pour les vecteurs de . Cependant, il existe une notation beaucoup moins lourde. Considérant que toutes les matrices en présence sont de mêmes dimensions, que l' addition matricielle est définie élément par élément et que la multiplication par un scalaire multiplie tous les éléments de chaque matrice, on va adopter la notation beaucoup plus simple: soit et .           "
},
{
  "id": "exo-sommetransfo",
  "level": "2",
  "url": "sec-transfodef.html#exo-sommetransfo",
  "type": "Exercice",
  "number": "2.1.4.7",
  "title": "",
  "body": " Soit deux transformations linéaires et ayant le même domaine et la même image. Soit la transformation , définie comme la somme de ces transformations: . Montrer que est linéaire.   Considérer ce qu'on connait par rapport à et . Puisque ce sont des transformations linéaires, elles respectent déjà les propriétés . On doit se servir de cette information afin de montrer que respecte également ces propriétés.   Soit et dans le domaine de ces transformations et . et   "
},
{
  "id": "exo-matentreeij",
  "level": "2",
  "url": "sec-transfodef.html#exo-matentreeij",
  "type": "Exercice",
  "number": "2.1.4.8",
  "title": "",
  "body": "Soit , une matrice. On sait que donne la colonne de la matrice. Comment obtenir l'entrée en position ? Considérer le produit scalaire de avec un vecteur bien choisi. On doit extraire de la colonne l'entrée en position . Si l'on effectue le produit scalaire avec un vecteur de bonne dimension, on aura le résultat souhaité.  On remarque aussi que la matrice n'a pas besoin d'être carrée. La cellule Sage ci-dessous permet de tester avec une matrice rectangulaire.   "
},
{
  "id": "exo-transfocomp",
  "level": "2",
  "url": "sec-transfodef.html#exo-transfocomp",
  "type": "Exercice",
  "number": "2.1.4.9",
  "title": "",
  "body": " Dans l'exemple , on a composé deux transformations linéaires en exécutant les opérations successivement. Effectuer ces transformations dans l'ordre inverse, c'est-à-dire effectuer la permutation ( ) et ensuite la rotation de ( ).     Soit , un vecteur de . On a . La composition des deux transformations est donc une nouvelle transformation . Concrètement, la transformation correspond à la réflexion par rapport à l'axe des ordonnées, voir l'exercice .  "
},
{
  "id": "exo-transfocomp-RP",
  "level": "2",
  "url": "sec-transfodef.html#exo-transfocomp-RP",
  "type": "Exercice",
  "number": "2.1.4.10",
  "title": "",
  "body": " Dans l'exercice , on a composé la permutation ( ) et la rotation de ( ). L'exemple a permis de trouver leurs matrices de transformation: Utiliser ces matrices pour trouver la matrice de la transformation .   On n'a pas encore appris à multiplier les matrices, ce qui serait de loin plus rapide. Il faut donc trouver et et les placer en colonnes dans la matrice de .     On suit l'indication. et Ce qui donne, en colonnes dans :   "
},
{
  "id": "exo-reptransfomatunique",
  "level": "2",
  "url": "sec-transfodef.html#exo-reptransfomatunique",
  "type": "Exercice",
  "number": "2.1.4.11",
  "title": "",
  "body": " Montrer que la représentation matricielle d'une transformation linéaire est unique.   Supposer qu'il existe deux matrices et qui expriment la même transformation linéaire. Considérer ensuite que chaque vecteur de la base canonique devient chaque colonne de la matrice de transformation linéaire. Cela mène très rapidement à une contradiction.   Soit et , deux matrices différentes qui représentent la même transformation linéaire. On obtient la première colonne d'une matrice de transformation linéaire en regardant l'effet de cette transformation sur le premier vecteur de la base canonique . Mais l'effet résulte justement de la multiplication de la matrice de transformation par ce vecteur. Ainsi, par l'équation , et Alors, et, de même, on peut montrer que chaque colonne des matrices et sont identiques. Donc, la représentation matricielle d'une transformation linéaire est unique.  "
},
{
  "id": "exo-AuegalBu",
  "level": "2",
  "url": "sec-transfodef.html#exo-AuegalBu",
  "type": "Exercice",
  "number": "2.1.4.12",
  "title": "",
  "body": " Soit deux matrices et , de mêmes dimensions qui sont telles que , pour tout vecteur compatible . Démontrer que .   On peut procéder de façon semblable au numéro , en choisissant les vecteurs de la base canonique. En effet, l'équation nous indique que si l'on choisit le vecteur comme , on obtiendra la première colonne de la matrice. Cela mènera rapidement à une contradiction.   Soit et , deux matrices différentes de mêmes dimensions. On procède de façon semblable à l'exercice précédent pour expliciter d'abord la première colonne de . On choisit . Ainsi, par l'équation , et Alors, et, de même, on peut montrer que toutes les colonnes des matrices et sont identiques. Donc, les matrices et doivent être égales puisque toutes leurs colonnes sont égales.  "
},
{
  "id": "exo-matprodscalzero",
  "level": "2",
  "url": "sec-transfodef.html#exo-matprodscalzero",
  "type": "Exercice",
  "number": "2.1.4.13",
  "title": "",
  "body": "On considère une matrice et l'équation . On suppose d'abord que est une matrice . Si pour tous les vecteurs de , est-ce que ? Démontrer ou donner un contrexemple. Une rotation particulière Non, ce n'est pas suffisant pour que soit la matrice nulle. Si , alors est toujours perpendiculaire à et donc . Pourtant dans ce cas, . Si maintenant on a une matrice de dimension et que pour tous les vecteurs et tous les vecteurs , est-ce que ? Démontrer ou donner un contre exemple.  Utiliser l'exercice .  Cette fois, c'est suffisant. On regarde colonne par colonne la matrice . On sait que où sont les vecteurs standards et sont respectivement les colonnes un et deux de la matrice. De plus, on sait, par l'exercice , que l'entrée en position est donnée par . Or par hypothèse, l'équation pour tous les vecteurs de . La matrice est donc la matrice nulle.  "
},
{
  "id": "exo-matprodscalegal",
  "level": "2",
  "url": "sec-transfodef.html#exo-matprodscalegal",
  "type": "Exercice",
  "number": "2.1.4.14",
  "title": "",
  "body": "On considère deux matrices de même dimensions et des vecteurs tels que l'équation est bien définie. Trouver deux matrices différentes non nulles et deux vecteurs différents (aussi non nuls) qui satisfont cette équation. Prendre dans et considérer deux rotations spécifiques. On prend , et , où ne sont pas tous les deux nuls.  On prend , et , où ne sont pas tous les deux nuls.  Puisque les vecteurs et sont parallèles, une rotation de sur fera en sorte que et seront perpendiculaires. De même, une rotation de sur fera en sorte que et seront perpendiculaires.  Dans les deux cas,  Montrer que si pour tous les vecteurs compatibles, alors . On réécrit l'équation en utilisant les propriétés du produit scalaire pour obtenir .  La matrice est donc telle que pour tout vecteur , l'équation . En utilisant l'exercice , on conclut que et donc que . "
},
{
  "id": "exo-matsommelignes",
  "level": "2",
  "url": "sec-transfodef.html#exo-matsommelignes",
  "type": "Exercice",
  "number": "2.1.4.15",
  "title": "",
  "body": " Soit deux transformations linéaires et ainsi que leurs matrices respectives et . On veut démontrer que la matrice de est égale à où l'on effectue l'addition de chaque élément correspondant dans les deux matrices.   Utiliser l'équation et commencer avec le fait que , tel que démontré à l'exercice . Définir des vecteurs lignes pour chaque matrice.   Soit la matrice de et les lignes de et la matrice de et les lignes de . Alors on a  "
},
{
  "id": "exosage-transfodef-1",
  "level": "2",
  "url": "sec-transfodef.html#exosage-transfodef-1",
  "type": "Exercice",
  "number": "2.1.4.16",
  "title": "",
  "body": " Considérer les matrices .    Définir les matrices et .    Additioner la deuxième ligne de la matrice avec la première colonne de la matrice .    Additionner toutes les lignes de et toutes les colonnes de .   Calculer le produit scalaire de la première colonne de avec la première colonne de , ou expliquer pourquoi ce n'est pas possible d'effectuer l'opération.   Calculer le produit scalaire de la première colonne de avec la première ligne de , ou expliquer pourquoi ce n'est pas possible d'effectuer l'opération.       et .      Impossible        Le code solution pour l'exercice   A=column_matrix([[-1,0],[2,3],[4,-2]]) B=column_matrix([[-3,2,0],[3,1,-5]]) show(\"A=\",A) show(\"B=\",B)       Le code solution pour l'exercice   show(A.row(1)+B.column(0))       Le code solution pour l'exercice   show(sum(A.column(k) for k in range(A.ncols()))+sum(B.row(k) for k in range(B.nrows())))     L'opération est impossible, car les vecteurs n'ont pas la même dimension.   Le code solution pour l'exercice   show(A.column(0)*B.row(0))     "
},
{
  "id": "exercise-72",
  "level": "2",
  "url": "sec-transfodef.html#exercise-72",
  "type": "Exercice",
  "number": "2.1.4.17",
  "title": "",
  "body": " Considérer le carré de sommets et la transformation qui effectue une rotation de degrés. Tracer dans un même graphique le carré original en bleu et sa transformation par la rotation en rouge.     L'image d'un carré par une rotation de 50 degrés autour de l'origine.   Un carré bleu est affiché ainsi que son image en rouge par une rotation de 50 degrés.       Le code solution pour l'exercice   #Définition des points du quadrilatère ABCD A=vector([1,0]) B=vector([1,1]) C=vector([2,1]) D=vector([2,0]) #On forme une liste contenant tous les points (vecteurs) L=list([A,B,C,D]) #On définit la matrice de rotation theta=50\/360*2*pi R=column_matrix([[cos(theta),sin(theta)],[-sin(theta),cos(theta)]]) #On applique la translation à tous les vecteurs de la liste Ltrans=list([R*v for v in L]) #On illustre les quadrilatères, ainsi que le vecteur w sur l'un des points polygon(L,color=\"blue\")+polygon(Ltrans,color=\"red\")    "
},
{
  "id": "exosage-transfodef-2",
  "level": "2",
  "url": "sec-transfodef.html#exosage-transfodef-2",
  "type": "Exercice",
  "number": "2.1.4.18",
  "title": "",
  "body": " La matrice permet de faire une rotation dans autour de l'origine. Il peut cependant arriver que l'on veuille tourner un objet autour d'un autre point que l'origine, tel qu'illustré à la figure .   Une rotation autour d'un point autre que l'origine    Soit un point de . On veut faire une rotation de degrés autour de ce point.   Expliquer pourquoi cette transformation n'est pas une transformation linéaire.  Pour effectuer cette transformation à l'aide des matrices, il est possible de translater à l'origine, d'appliquer la rotation autour de l'origine et de translater à nouveau au point de départ, comme illustré à la figure . Appliquer cette méthode pour trouver l'image du vecteur selon la transformation décrite ci-dessus.     Une rotation autour d'un point autre que l'origine: la méthode      La transformation n'est pas linéaire, car l'origine est déplacée, ce qui contredit la proposition .  L'image est le point .     Le code solution pour l'exercice   rot90=column_matrix([[0,1],[-1,0]]) #la matrice de rotation de 90 degrés trans=vector([2,3]) #Le centre de la rotation, aussi le vecteur de translation point=vector([-1,1]) pointtrans=point-trans # L'image du point après la translation pointtransrot=rot90*pointtrans #L'image du point translaté après la translation pointfinal=pointtransrot+trans show(pointfinal)    "
},
{
  "id": "exercise-74",
  "level": "2",
  "url": "sec-transfodef.html#exercise-74",
  "type": "Exercice",
  "number": "2.1.4.19",
  "title": "Une fonction pour la rotation autour d’un point quelconque.",
  "body": "Une fonction pour la rotation autour d'un point quelconque En se basant sur l'exercice , on veut créer une fonction rotaffine qui prendra comme argument un centre de rotation , un angle et un point . La fonction retournera l'image du point par une rotation de autour du centre . Tester la fonction avec l'exercice afin de valider son fonctionnement.  On doit ici se poser la question de l'usage des degrés ou des radians. Selon que l'on choisit l'une ou l'autre mesure, y aura-t-il des ajustements à apporter? Créer la fonction définie dans le préambule de l'exercice et tester avec les paramètres de l'exercice .     Le code solution pour l'exercice   def rotaffine(c,theta,P): rot=column_matrix([[cos(theta),sin(theta)],[-sin(theta),cos(theta)]]) #la matrice de rotation de theta radians Ptrans=P-c # L'image du point après la translation Ptransrot=rot*Ptrans #L'image du point translaté après la translation Pfinal=Ptransrot+c return Pfinal    Il suffit ensuite d'appeler la fonction avec les arguments nécessaires. Par exemple, le code rotaffine(vector([2,3]),pi\/2,vector([-1,1])) devrait donner la réponse obtenue à l'exercice .  Calculer l'image des points suivants selon les rotations données, à l'aide de la fonction rotaffine .     "
},
{
  "id": "sec-prodmat",
  "level": "1",
  "url": "sec-prodmat.html",
  "type": "Section",
  "number": "2.2",
  "title": "La composition et le produit matriciel",
  "body": "  La composition et le produit matriciel    Aller aux exercices de la section.  La composition de transformations linéaires est un procédé important et le produit matriciel qu'elle implique l'est encore plus. Dans cette section, on étudie la composition et le produit matriciel, les propriétés de ces opérations et quelques applications.    Le produit matriciel  Soit , deux matrices dont le format n'est pas spécifié pour le moment. Si sont les transformations linéaires associées aux matrices, on s'intéresse à la transformation , et aux conditions qui font que cette transformation est bien définie.  Selon le théorème , la composition est elle-même une transformation linéaire, pourvu que l'image de soit dans le domaine de . Selon la sous-section , cette transformation devrait elle aussi avoir une matrice la représentant.  On suppose que la matrice contient lignes et colonnes. Puisque , on doit, dans un premier temps, avoir que , et le résultat de sera un vecteur de . Pour que la multiplication soit compatible, il faut que la matrice possède colonnes. Le nombre de lignes de ne semble pas jouer un rôle autre que de donner la dimension du vecteur , on suppose ainsi que .  La composition de deux transformations linéaires n'est donc définie que si le nombre de lignes de correspond au nombre de colonnes de . Si possède lignes et possède colonnes, la transformation est une transformation linéaire de vers et il devrait donc exister une matrice dans la représentant.  Comment déterminer la matrice de la composition? Il suffit de regarder où vont les vecteurs ! On pose les colonnes de . Alors on a et ainsi de suite jusqu'à .  On obtient alors la définition suivante.   Le produit matriciel  Soit et , deux matrices. La matrice de la composition , notée , est la matrice dont la colonne correspond au vecteur , pour . On peut donc écrire .    Un produit de deux matrices  On poursuit l'exemple et l'exercice pour calculer les matrices des transformations et .   Puisque et (voir l'exemple ), on a .    Puisque et , (voir l'exemple ) on a .    Cet exemple montre en particulier que la multiplication de matrices, contrairement à la multiplication de nombres réels, n'est pas commutative. On pouvait s'y attendre, étant donnée la définition de la multiplication, il y a souvent même des cas où est bien défini, mais pas . On étudie les propriétés de la multiplication et de la composition dans la sous-section .  On regarde maintenant un exemple dynamique, de nature géométrique.   Le produit matriciel: dynamique  On considère deux transformations linéaires et la composition . Dans la figure ci-dessous, on illustre un vecteur , sa transformation par et par la composition . Sans faire de calculs algébriques, quelle est la matrice , sachant que toutes les entrées des matrices sont des entiers?   La transformation extérieure d'une composition, du point de vue géométrique      Le produit de deux matrices a été défini comme la composition de deux transformations linéaires, mais une autre approche offre une perspective intéressante. Soit des vecteurs de et soit une transformation linéaire de vers (combien de lignes et combien de colonnes possède-t-elle?). Pour calculer l'image des vecteurs par , on peut construire une matrice dont les colonnes sont les vecteurs . Puisque le produit , chaque colonne du produit représente l'image d'un vecteur par la matrice . On obtient donc une manière rapide de calculer l'effet d'une transformation linéaire sur plusieurs points.  Si la matrice est le produit des matrices et , que vaut , l'entrée de la ligne et de la colonne de la matrice ? La proposition suivante donne la réponse, offrant par le fait même une autre manière de calculer le produit de deux matrices.   Le produit matriciel, entrée par entrée  Soit et le produit des deux matrices. Alors l'entrée de la ligne et de la colonne de la matrice est donnée par où est la ligne  de la matrice et est la colonne  de la matrice . En plus visuel, on a   Le produit matriciel, entrée par entrée   Le produit de deux matrices, avec la ligne i de la première matrice mise en évidence, tout comme la colonne j. Ensemble, le produit scalaire de ces vecteurs donne l'entrée i,j de la matrice produit.      Soit , une entrée de la matrice . Alors on a     Dans l'exemple , on a défini la transformation identité dont la matrice (pour le cas ) est donnée par l'équation . Le nom identité est choisi puisque toute matrice multipliée par donne , que la multiplication soit faite à gauche ou à droite. Par exemple, pour la multiplication à droite, on a Évidemment, si l'on réfléchit géométriquement, ceci devient évident. On applique d'abord pour ensuite faire l'identité, qui ne change rien. On définit maintenant la matrice identité pour les transformations .   La matrice identité  Soit la matrice dont les entrées valent si le numéro de la ligne correspond à celui de la colonne et dans les autres cas. Ceci correspond à une transformation qui envoie les vecteurs sur eux-mêmes et donc, cela correspond à la transformation qui ne fait rien. On appelle cette matrice l'identité et on la note , ou tout simplement lorsque la dimension est évidente par le contexte ou sans importance.   Lorsqu'on multiplie une matrice par elle-même, on obtient alors le carré de cette matrice, noté . En matière de transformations linéaires, cela revient à composer la fonction avec elle-même ou à l'appliquer deux fois. En généralisant, on obtient les puissances d'une matrice.   Les puissances d'une matrice  Soit , une matrice carrée. On définit la ième puissance de comme étant le produit de avec elle-même, fois: .   Les puissances de matrices sont utiles dans divers contextes, comme le montre l'exemple suivant. Le chapitre contient d'autres exemples concrets d'applications.   Une application du produit matriciel  On considère trois villes reliées par des routes à sens unique. Les différents chemins possibles sont illustrés dans la figure ci-dessous. On peut créer une matrice qui contient l'information de ce graphe où l'entrée de la matrice représente le nombre de chemins possibles pour se rendre de la ville à la ville .   Trois villes et leurs chemins         Les puissances de la matrice représente le nombre de chemins de \"longueur\" pour se rendre de la ville à la ville en empruntant chemins. Par exemple, on peut calculer avec Sage les puissances de la matrice .    On termine avec des commandes Sage en lien avec la sous-section.   Le produit matriciel sur Sage  Si l'on a deux matrices sur Sage, on peut facilement les multiplier en utilisant l'opération * . Il faut bien entendu que les dimensions soient compatibles. La deuxième cellule produit volontairement une erreur.    On applique maintenant une transformation à un ensemble de points, en construisant à partir des exemples et . Pour cela, un peu de conversion est nécessaire, il faudra convertir une liste en matrice, puis une matrice en liste. La première conversion se fait bien avec la commande column_matrix . Celle-ci prend la liste L et la transforme en matrice colonne. Après la multiplication de cette nouvelle matrice par la transformation linéaire, il faut convertir la matrice AL en liste de points. Pour cela, on utilise la commande list sur les colonnes de AL . Le nombre de colonnes d'une matrice M est donné par la commande M.ncols() .   La matrice identité est connue de sage, on peut l'obtenir à l'aide de la commande identity_matrix(n) où est la taille de la matrice carrée.      Les propriétés du produit matriciel  Contrairement à l'addition de matrices, le produit ne possède pas exactement les mêmes propriétés que la multiplication de nombres réels. On a déjà observé, à l'exemple , que la multiplication n'est pas commutative. Les propriétés suivantes sont toujours satisfaites pour le produit matriciel.   Les propriétés du produit matriciel   Soit , et , des matrices de format approprié et . On a   Propriétés du produit matriciel    et   .   La dernière propriété signifie que la multiplication est associative. Comme elle n'est pas commutative, il est primordial de porter attention à l'ordre des multiplications dans la propriété .    On pose , les colonnes de la matrice identité et les colonnes de . Comme la ième colonne du produit est donnée par et que ce produit matrice vecteur correspond à , on a .  De plus, la ième colonne de est donnée par et ce produit matrice vecteur vaut . On a donc .    On pose , la ième colonne de la matrice . Selon l'addition matricielle, on a pour la ième colonne de  et donc, .  De même, si représente la ième colonne de , on peut déterminer la ième colonne de en utilisant le fait que la ième colonne de est pour avoir . Ainsi, .    Pour la multiplication par un scalaire, on a d'une part et d'un autre part .    Pour l'associativité, on suppose que et . On a alors .    La multiplication matricielle permet d'obtenir la matrice de certaines transformations linéaires en se ramenant à un cas connu.   Se ramener à un cas connu  En mathématiques, il est fréquent de prendre un problème et de le transformer en plusieurs problèmes plus simples et déjà connus. Par exemple, on peut calculer l'aire d'un polygone en le décomposant en triangles, formes plus simples et d'aire connue.     La réflexion par rapport à une droite passant par l'origine   On considère une droite de passant par l'origine, qui fait un angle de avec l'axe des abscisses (mesuré dans le sens antihoraire). On cherche à faire une réflexion par rapport à cette droite. On peut déterminer la matrice de cette réflexion de la manière suivante:  On commence par faire une rotation de dans le sens horaire afin de ramener la droite sur l'axe des abscisses.  On effectue ensuite la réflexion par rapport à l'axe des abscisses, que l'on sait faire (voir l'exemple ).  Par la suite, on ramène le tout à la position initiale en effectuant une rotation de dans le sens antihoraire.      Selon l'énoncé du problème, cette réflexion est en fait une composition de deux rotations et de la réflexion . Si l'on pose la réflexion cherchée, on a alors .  L'une ou l'autre des formes matricielles peut être utilisée.    On termine avec un exemple de compositions de transformations linéaires, en utilisant Sage pour faire les calculs.   La composition de certaines transformations  On considère une rotation d'angle et une rotation d'angle . Intuitivement, la composition de ces deux rotations devrait être une rotation d'angle . On peut le vérifier algébriquement à l'aide de Sage.   La dernière ligne du code permet d'obtenir la simplification voulue. La méthode apply_map permet d'appliquer trig_reduce() à chaque entrée de la matrice par le biais d'une fonction intermédiaire lambda . Ceci n'est pas très intuitif, mais, pour l'instant, ça suffira. L'exercice permettra de créer une fonction plus simple qui pourra simplifier une matrice.  On voit toutefois qu'après simplification, la transformation est bel et bien une rotation d'angle .  On s'intéresse maintenant à la composition de deux réflexions d'angle respectif . Est-ce que le résultat de ce type de composition sera aussi une réflexion? Si oui, pourquoi, si non, donner un exemple avant d'exécuter le code ci-dessous.   Le résultat, peut-être surprenant, est une rotation. La simplification effectuée par Sage ne montre pas directement la forme d'une matrice de rotation, mais on peut montrer qu'elle est équivalente à une rotation d'angle . Ceci suggère également que les réflexions ne sont pas commutatives, à savoir qu'en général, .  Maintenant, on s'intéresse à la composition d'une rotation et d'une réflexion. Comme on sait que la multiplication n'est pas commutative, on regarde s'il y a une différence entre faire la réflexion en premier suivie de la rotation et la rotation suivie de la réflexion (peut-on faire une prédiction?).  D'abord, :   Le résultat semble donc être une réflexion d'angle .  On compare maintenant avec :   Le résultat est encore une fois une réflexion, mais cette fois-ci d'angle .  Finalement, on s'intéresse à la composition de trois transformations, en utilisant les calculs précédents et l'associativité pour déterminer le résultat final.  La composition de trois rotations devrait être, elle aussi, une rotation dont l'angle correspond à la somme des angles de chacune des rotations. En utilisant l'associativité, on montre facilement que . L'associativité est ainsi vérifiée et cohérente avec la composition de rotations.  La composition de trois réflexions semble plus difficile à analyser. Deux réflexions composées ensemble donnent une rotation. Une rotation composée avec une réflexion donne une réflexion, mais on sait que l'ordre de la composition est important. Est-ce alors évident que l'associativité sera respectée? On a d'une part . D'autre part, on a . On a donc bel et bien égalité.  D'autres cas seront explorés à l'exercice .      Les points importants de cette section sont  La multiplication matricielle, selon la définition par les colonnes ou selon un calcul entrée par entrée ;  La définition de la matrice identité ;  Le fait que la multiplication n'est pas commutative;  Le concept de puissances d'une matrice;  Les propriétés de la multiplication matricielle;  La forme matricielle d'une réflexion, donnée par l'équation .  De plus, avec Sage, on peut multiplier des matrices en utilisant l'opération * . On peut aussi appliquer une transformation linéaire à un ensemble de points en transformant ces points en matrice pour ensuite effectuer la multiplication. Le nombre de colonnes d'une matrice est obtenu à l'aide de la commande A.ncols() et le nombre de lignes serait obtenu avec A.nrows() . La commande trig_reduce permet de simplifier des équations trigonométriques. On peut obtenir la matrice identité à l'aide de la commande identity_matrix(n) .     Exercices    Démontrer que, peu importe la matrice , on a .   Il faut simplement créer une matrice quelconque et faire le calcul.   Soit . Alors,    Soit deux matrices carrées et . Considérer l'équation suivante: . Démontrer cette équation si elle est valide. Sinon, donner un contrexemple.   Considérer la commutativité du produit matriciel.   L'équation n'est pas valide. Un contrexemple possible est et .   Avec le contrexemple et , on calcule et et l'on constate que ce n'est pas égal. En effet, et Algébriquement, c'est faux puisque le produit matriciel n'est pas commutatif. On a donc que . Ainsi, .    Est-ce que l'équation est valide pour les matrices carrées? Si oui, il faut le démontrer et si non, trouver un contrexemple.   L'équation n'est pas valide. L'exercice précédent fournit un contrexemple, soit et .   Avec le contrexemple et , on calcule et et l'on constate que ce n'est pas égal. En effet, et Algébriquement, c'est faux puisque le produit matriciel n'est pas commutatif. On a donc que . Ainsi, .    Avec les nombres réels, si , alors ou (possiblement les deux). Est-ce aussi vrai pour les matrices? C'est-à-dire, si pour deux matrices compatibles pour la multiplication, est-ce que ou ? Si oui, il faut le démontrer et si non, trouver un contrexemple. On rappelle que dénote la matrice nulle de taille appropriée.   Penser à deux projections orthogonales successives dans telles que leur composition annihilera tout vecteur.   Les matrices et fonctionnent. Il existe d'autres réponses possibles.   Comme le dit l'indice du problème, on peut réfléchir à une composition de transformations qui ramènerait tout vecteur au vecteur nul. La transformation dont la matrice est peut donc être obtenue en composant, par exemple, une projection orthogonale sur l'axe des ( ) et une projection orthogonale sur l'axe des ( ) . Les matrices permettant cela ont déjà été introduites, mais on peut les retrouver en réfléchissant à l'image des vecteurs de la base canonique. On aura et . En les multipliant, on obtient:     Une matrice de permutation est une matrice telle que chaque colonne et chaque ligne ne contient qu'une entrée non nulle égale à . Par exemple, la matrice est une matrice de permutation.   Faire la liste de toutes les matrices de permutations . Quel est l'effet d'une matrice de permutation sur un vecteur?   Voici la liste: et . La première matrice est l'identité, qui ne modifie donc pas les vecteurs, et la seconde est une matrice de réflexion selon l'axe . Algébriquement, cette seconde matrice fait simplement permuter ses composantes en et .   Faire la liste de toutes les matrices de permutations . Quel est l'effet d'une matrice de permutation sur un vecteur?   Voici la liste: , , , , et . La première matrice est l'identité, qui ne modifie pas les vecteurs. Les trois suivantes sont des matrices de réflexion selon différents plans, puisqu'un des trois vecteurs colonnes demeure inchangé. Par exemple, la deuxième est une réflexion selon le plan et reste inchangé. Finalement, les deux dernières sont des matrices de rotation, soit dans le sens horaire soit antihoraire autour de l'axe parallèle au vecteur . Algébriquement, toutes les matrices de permutation font permuter les composantes d'un vecteur soit deux à deux (réflexions), ou toutes les trois (rotations).   Si et sont deux matrices de permutation, est-ce que leur produit est une matrice de permutation?   Oui.   Oui, il s'agit encore d'une matrice de permutation. Logiquement, si l'on fait des permutations de composantes, et qu'on fait ensuite d'autres permutations, la composition de ces deux opérations se fera en une seule opération de permutation.   Si et sont deux matrices de permutation, est-ce que ?   Non.   En général, les matrices sont rarement commutatives et les permutations ne font pas exceptions à cette règle. Ici, il est possible de trouver un contrexemple où . On choisit et . Alors,    Soit une matrice à coefficients réels. En réfléchissant de façon géométrique, puis en démontrant algébriquement que c'est bien le cas, trouver le plus grand nombre de matrices différentes telles que   .   Autrement écrit,    Géométriquement, on cherche à trouver une transformation linéaire qui, si l'on effectue cette transformation deux fois, a comme résultat de ne rien changer au vecteur initial. Bref, le déplacement initial doit être en quelque sorte annulé en refaisant la même transformation. On pense assez rapidement aux réflexions. En effet, une réflexion par rapport à n'importe quel axe répété deux fois ramènera tout vecteur à son emplacement initial. Par l'équation , on sait que toutes les matrices de réflexion sont de la même forme. On démontre que . Une autre transformation est une rotation de . En effet, lorsque l'on répète cette rotation, on revient au point de départ. Par l'équation , on obtient rapidement la matrice de rotation et l'on vérifie que . Finalement, il ne faut pas oublier que la matrice identité est une transformation linéaire. Répéter cette transformation qui ne change rien ne transformera pas les vecteurs et donc . La vérification algébrique est simple.   .     Puisque la transformation composée doit globalement amener le vecteur à et à , on a une solution assez simple avec la rotation. Si l'on fait une rotation de et qu'on la répète, on arrivera à cette position. On le vérifie algébriquement. Par l'équation , En réalité, une infinité de matrices de rotation peuvent faire l'affaire. En effet, il suffit d'avoir une rotation qui permet, lorsque répétée deux fois, d'aboutir à un angle qui soit un multiple de , partant de . Autrement dit, si , la matrice fonctionne. On le montre. On réalise cependant que toutes les matrices où est de même parité sont identiques. En effet, une rotation de est identique à une rotation de . Bref, les deux matrices de rotation possibles sont de et de avec les matrices respectives:     .     Pour obtenir la matrice nulle en transformant deux fois de suite, il existe quelques options. La plus facile est de définir , la transformation qui ramène tous les vecteurs à l'origine. Il est évident que , on n'a pas à le démontrer algébriquement.  De la même manière, les matrices satisfont l'équation en raison des nombreux zéros. Elles représentent des transformations que l'on ne connait pas encore. On peut avoir une intuition géométrique en voyant où les vecteurs de base se retrouvent. La première matrice envoie sur et sur .   .     Intuitivement, il faut trouver une matrice de transformation qui donne le même résultat qu'elle soit composée avec elle-même ou prise seule. Toutes les transformations du type projections orthogonales ou pas sont telles qu'on ne change rien en répétant la transformation. On peut penser rapidement aux transformations orthogonales sur et sur données respectivement par les matrices . Cela dit, de nombreuses autres matrices de projection fonctionneront. En effet, dès que soit une ligne, soit une colonne est nulle, on aura une projection oblique qui fonctionne. Par exemple, si , alors Il en sera de même pour les matrices , et   Finalement, la matrice identité et la matrice nulle fonctionnent également. Il est facile de le vérifier.    En utilisant une méthode analogue à celle de l'exemple , déterminer la matrice de transformation linéaire permettant de faire un étirement de facteur dans la direction d'un vecteur . Utiliser les matrices et de l'exercice ainsi que la matrice d'étirement horizontal de facteur .   La démarche consiste en réalité à effectuer d'abord une rotation d'angle , ensuite à étirer horizontalement, puis à effectuer la rotation d'angle . On le fait en multipliant les trois matrices ensemble. On peut trouver les matrices nécessaires dans l'exemple .     Selon l'énoncé du problème, cet étirement est en fait une composition de deux rotations et de l'étirement horizontal de facteur  . Si l'on pose l'étirement cherché, on a alors .    À partir de la matrice développée à l'exercice considérer un étirement dans la direction d'angle et de facteur . Vérifier que pour le vecteur , on a et que .  On appelle ces deux directions les directions invariantes d'une transformation linéaire. On les appelle également des vecteurs propres et le facteur d'étirement une valeur propre . On étudiera ces notions à la section .   On calcule la matrice d'étirement de facteur dans la direction simplement en remplaçant cet angle et cette valeur dans la matrice trouvée précédemment. On obtient: On vérifie ensuite le résultat de la transformation des deux vecteurs donnés. et     Soit et , des matrices de rotation d'angle et et de réflexion d'angle et . En utilisant les résultats de l'exemple , décrire les compositions suivantes en utilisant à la fois et afin de vérifier l'associativité.     On procède de façon semblable à l'exemple, en utilisant les résultats pour la composition des rotations et des réflexions. Entre autres, on a et .  On remarque également que les démonstrations d'associativité se construisent souvent du début et de la fin, vers le milieu. Autrement dit, on peut développer et et simplifier pour constater qu'on arrive à la même transformation (au milieu des démarches). On a choisi de les écrire du début à la fin puisque c'est plus soignée, mais on a bel et bien construit la démonstration du début jusqu'au milieu et de la fin jusqu'au milieu.    Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une rotation d'angle .     Il s'agit donc globalement d'une rotation d'angle .     Il s'agit donc globalement d'une rotation d'angle .    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Lors d'une certaine journée au Canada, voici les offres pour des vols directs entre les principaux aéroports canadiens:   Vols intérieurs au Canada     De \/ Vers   YUL  YYZ  YVR  YYC  YEG    YUL  0  20  5  3  2    YYZ  15  0  10  7  6    YVR  3  8  0  12  8    YYC  3  6  12  0  8    YEG  2  6  8  6  0     Quelle serait une matrice qui permettrait de décrire le nombre de vols directs entre les différentes villes canadiennes?  Donner une interprétation du produit ?  Utiliser Sage pour déterminer combien de vols différents entre Montréal et Vancouver impliquent une escale.       Soit . Utiliser Sage pour calculer le produit .    Construction des matrices de permutation d'ordre Dans cet exercice, on veut donner une manière de faire la liste des matrices de permutation , définies à l'exercice .Pour cela, on va utiliser la commande Permutations(n).list() , qui renvoie la liste des permutations à éléments. Par exemple   renvoie une liste de éléments correspondant à toutes les manières d'ordonner les nombres . Une matrice de permutation est une matrice obtenue en permutant les colonnes de la matrice identité. Dans cet exercice, on crée une fonction perm_matrix(n) qui donnera une liste des matrices de permutation d'ordre . Pour cela, il faudra  Créer la liste des permutations d'ordre à l'aide de la commande Permutations(n).list() .  Créer la liste des vecteurs à partir de la matrice identité. (Utiliser la commande A.columns() .  Créer chaque matrice de permutation à partir de la liste des permutations. La liste des permutations permet de savoir à quelle colonne de la matrice identité correspond chacune des colonnes de la matrice .   Commencer par créer une fonction qui fournira les matrices de permutation et une autre fonction qui va donner les matrices de permutation . Des réponses possibles se trouvent dans l'indice suivant.   Un indice pour l'exercice   def perm_matrix2x2(): Id=identity_matrix(2) col=Id.columns() p=Permutations(2).list() #La liste des permutations L=list() #une liste vide for perm in p: #Pour chaque permutation dans la liste p, on va ajouter la matrice de permutation correspondante à la liste L P=column_matrix([col[perm[0]-1],col[perm[1]-1]]) #On construit une matrice de permutation selon une permutation spécifique L.append(P) #On l'ajoute à la liste existante return L def perm_matrix3x3(): Id=identity_matrix(3) col=Id.columns() p=Permutations(3).list() #La liste des permutations L=list() #une liste vide for perm in p: #Pour chaque permutation dans la liste p, on va ajouter la matrice de permutation correspondante à la liste L P=column_matrix([col[perm[0]-1],col[perm[1]-1],col[perm[2]-1]]) #On construit une matrice de permutation selon une permutation spécifique L.append(P) #On l'ajoute à la liste existante return L    Pour le cas , il faudra faire quelques modifications. D'abord, on change les dans les premières lignes par des , afin d'avoir une idée du comportement plus général de l'exercice. Ensuite parce, qu'on ne connait pas d'avance la dimension des matrices cherchées, il faut trouver un moyen de changer la ligne P=column_matrix(...) .    La solution pour l'exercice   def perm_matrix(n): Id=identity_matrix(n) col=Id.columns() p=Permutations(n).list() L=list() for perm in p: colperm=list() for j in range(len(perm)): colperm.append(col[perm[j]-1]) P=column_matrix(colperm) L.append(P) return L      Utiliser le produit de matrices de rotation et Sage pour démontrer les identités trigonométriques .    Si l'on compose les rotations et , on sait que l'image du vecteur correspondra à , puisque la composition de rotations donne une rotation dont l'angle est la somme des arguments respectifs des rotations initiales.     Le code solution pour l'exercice   var(\"alpha,beta\") Rotalpha=column_matrix([[cos(alpha),sin(alpha)],[-sin(alpha),cos(alpha)]]) Rotbeta=column_matrix([[cos(beta),sin(beta)],[-sin(beta),cos(beta)]]) show(LatexExpr(r\"\\cos(\\alpha+\\beta)=\"),(Rotalpha*Rotbeta)[0][0]) #La commande LatexExpr et les \"\\\" permettent un rendu plus joli, mais ne sont pas obligatoire show(LatexExpr(r\"\\sin(\\alpha+\\beta)=\"),(Rotalpha*Rotbeta)[1][0])     Les matrices nilpotentes: une fonction  Une matrice carrée est dite nilpotente d'ordre si et si , c'est-à-dire si la matrice multipliée par elle-même fois donne la matrice nulle et si est le premier entier pour lequel ceci se produit. On dit que est l'indice de nilpotence de la matrice .  Le but de cet exercice est de créer une fonction qui prend une matrice carrée comme argument et qui dit si la matrice est nilpotente ou non. Si c'est le cas, on voudra aussi avoir l'indice de nilpotence. On appellera la fonction estnilpotente .  Il y a quelques points à considérer. Les matrices ne sont pas toutes nilpotentes. Le seul critère (pour l'instant) est d'essayer de multiplier la matrice par elle-même jusqu'à l'obtention de la matrice nulle. Il faut cependant un critère d'arrêt pour ne pas essayer sans fin. Il est possible de montrer que l'indice de nilpotence d'une matrice satisfait toujours l'inégalité . Comme les commandes .ncols() ou .nrows() permettent de donner la dimension d'une matrice quelconque facilement, on se sert de ce critère pour arrêter notre fonction.  Écrire la fonction qui permet de vérifier la nilpotence d'une matrice.  À l'aide de la fonction créée, vérifier la nilpotence des matrices suivantes:            Le code solution pour l'exercice   A=column_matrix([[0,0,0,0],[2,0,0,0],[5,4,0,0],[-2,0,4,0]]) B=column_matrix([[1,0],[2,4]]) C=column_matrix([[1,1,-2],[1,1,-2],[1,1,-2]]) def estnilpotente(A): n=A.ncols() #La dimension de la matrice k=1 #L'indice de nilpotence, si while k <= n: #Le critère d'arrêt if A^k==0: #Sage comprend que 0 sera la matrice nulle. On aurait aussi pu la définir afin de comparer return print(\"La matrice est nilpotente d'ordre \",k) else: k+=1 #On augmente le potentiel indice de 1 return print(\"La matrice n'est pas nilpotente\") estnilpotente(A) estnilpotente(B) estnilpotente(C)       "
},
{
  "id": "def-matmatprod",
  "level": "2",
  "url": "sec-prodmat.html#def-matmatprod",
  "type": "Définition",
  "number": "2.2.1",
  "title": "Le produit matriciel.",
  "body": " Le produit matriciel  Soit et , deux matrices. La matrice de la composition , notée , est la matrice dont la colonne correspond au vecteur , pour . On peut donc écrire .  "
},
{
  "id": "ex-matmatprod1",
  "level": "2",
  "url": "sec-prodmat.html#ex-matmatprod1",
  "type": "Exemple",
  "number": "2.2.2",
  "title": "Un produit de deux matrices.",
  "body": " Un produit de deux matrices  On poursuit l'exemple et l'exercice pour calculer les matrices des transformations et .   Puisque et (voir l'exemple ), on a .    Puisque et , (voir l'exemple ) on a .   "
},
{
  "id": "ex-prodmatgeo",
  "level": "2",
  "url": "sec-prodmat.html#ex-prodmatgeo",
  "type": "Exemple",
  "number": "2.2.3",
  "title": "Le produit matriciel: dynamique.",
  "body": " Le produit matriciel: dynamique  On considère deux transformations linéaires et la composition . Dans la figure ci-dessous, on illustre un vecteur , sa transformation par et par la composition . Sans faire de calculs algébriques, quelle est la matrice , sachant que toutes les entrées des matrices sont des entiers?   La transformation extérieure d'une composition, du point de vue géométrique     "
},
{
  "id": "prop-matmatprod",
  "level": "2",
  "url": "sec-prodmat.html#prop-matmatprod",
  "type": "Proposition",
  "number": "2.2.5",
  "title": "Le produit matriciel, entrée par entrée.",
  "body": " Le produit matriciel, entrée par entrée  Soit et le produit des deux matrices. Alors l'entrée de la ligne et de la colonne de la matrice est donnée par où est la ligne  de la matrice et est la colonne  de la matrice . En plus visuel, on a   Le produit matriciel, entrée par entrée   Le produit de deux matrices, avec la ligne i de la première matrice mise en évidence, tout comme la colonne j. Ensemble, le produit scalaire de ces vecteurs donne l'entrée i,j de la matrice produit.      Soit , une entrée de la matrice . Alors on a    "
},
{
  "id": "def-matid",
  "level": "2",
  "url": "sec-prodmat.html#def-matid",
  "type": "Définition",
  "number": "2.2.7",
  "title": "La matrice identité.",
  "body": " La matrice identité  Soit la matrice dont les entrées valent si le numéro de la ligne correspond à celui de la colonne et dans les autres cas. Ceci correspond à une transformation qui envoie les vecteurs sur eux-mêmes et donc, cela correspond à la transformation qui ne fait rien. On appelle cette matrice l'identité et on la note , ou tout simplement lorsque la dimension est évidente par le contexte ou sans importance.  "
},
{
  "id": "def-matpui",
  "level": "2",
  "url": "sec-prodmat.html#def-matpui",
  "type": "Définition",
  "number": "2.2.8",
  "title": "Les puissances d’une matrice.",
  "body": " Les puissances d'une matrice  Soit , une matrice carrée. On définit la ième puissance de comme étant le produit de avec elle-même, fois: .  "
},
{
  "id": "ex-prodmatchemins",
  "level": "2",
  "url": "sec-prodmat.html#ex-prodmatchemins",
  "type": "Exemple",
  "number": "2.2.9",
  "title": "Une application du produit matriciel.",
  "body": " Une application du produit matriciel  On considère trois villes reliées par des routes à sens unique. Les différents chemins possibles sont illustrés dans la figure ci-dessous. On peut créer une matrice qui contient l'information de ce graphe où l'entrée de la matrice représente le nombre de chemins possibles pour se rendre de la ville à la ville .   Trois villes et leurs chemins         Les puissances de la matrice représente le nombre de chemins de \"longueur\" pour se rendre de la ville à la ville en empruntant chemins. Par exemple, on peut calculer avec Sage les puissances de la matrice .   "
},
{
  "id": "sageex-prodmatdef",
  "level": "2",
  "url": "sec-prodmat.html#sageex-prodmatdef",
  "type": "Calcul",
  "number": "2.2.11",
  "title": "Le produit matriciel sur Sage.",
  "body": " Le produit matriciel sur Sage  Si l'on a deux matrices sur Sage, on peut facilement les multiplier en utilisant l'opération * . Il faut bien entendu que les dimensions soient compatibles. La deuxième cellule produit volontairement une erreur.    On applique maintenant une transformation à un ensemble de points, en construisant à partir des exemples et . Pour cela, un peu de conversion est nécessaire, il faudra convertir une liste en matrice, puis une matrice en liste. La première conversion se fait bien avec la commande column_matrix . Celle-ci prend la liste L et la transforme en matrice colonne. Après la multiplication de cette nouvelle matrice par la transformation linéaire, il faut convertir la matrice AL en liste de points. Pour cela, on utilise la commande list sur les colonnes de AL . Le nombre de colonnes d'une matrice M est donné par la commande M.ncols() .   La matrice identité est connue de sage, on peut l'obtenir à l'aide de la commande identity_matrix(n) où est la taille de la matrice carrée.   "
},
{
  "id": "prop-prodmatprop",
  "level": "2",
  "url": "sec-prodmat.html#prop-prodmatprop",
  "type": "Proposition",
  "number": "2.2.12",
  "title": "Les propriétés du produit matriciel.",
  "body": " Les propriétés du produit matriciel   Soit , et , des matrices de format approprié et . On a   Propriétés du produit matriciel    et   .   La dernière propriété signifie que la multiplication est associative. Comme elle n'est pas commutative, il est primordial de porter attention à l'ordre des multiplications dans la propriété .    On pose , les colonnes de la matrice identité et les colonnes de . Comme la ième colonne du produit est donnée par et que ce produit matrice vecteur correspond à , on a .  De plus, la ième colonne de est donnée par et ce produit matrice vecteur vaut . On a donc .    On pose , la ième colonne de la matrice . Selon l'addition matricielle, on a pour la ième colonne de  et donc, .  De même, si représente la ième colonne de , on peut déterminer la ième colonne de en utilisant le fait que la ième colonne de est pour avoir . Ainsi, .    Pour la multiplication par un scalaire, on a d'une part et d'un autre part .    Pour l'associativité, on suppose que et . On a alors .   "
},
{
  "id": "con-casconnu",
  "level": "2",
  "url": "sec-prodmat.html#con-casconnu",
  "type": "Conseil",
  "number": "2.2.14",
  "title": "Se ramener à un cas connu.",
  "body": " Se ramener à un cas connu  En mathématiques, il est fréquent de prendre un problème et de le transformer en plusieurs problèmes plus simples et déjà connus. Par exemple, on peut calculer l'aire d'un polygone en le décomposant en triangles, formes plus simples et d'aire connue.   "
},
{
  "id": "ex-refR2",
  "level": "2",
  "url": "sec-prodmat.html#ex-refR2",
  "type": "Exemple",
  "number": "2.2.15",
  "title": "La réflexion par rapport à une droite passant par l’origine.",
  "body": " La réflexion par rapport à une droite passant par l'origine   On considère une droite de passant par l'origine, qui fait un angle de avec l'axe des abscisses (mesuré dans le sens antihoraire). On cherche à faire une réflexion par rapport à cette droite. On peut déterminer la matrice de cette réflexion de la manière suivante:  On commence par faire une rotation de dans le sens horaire afin de ramener la droite sur l'axe des abscisses.  On effectue ensuite la réflexion par rapport à l'axe des abscisses, que l'on sait faire (voir l'exemple ).  Par la suite, on ramène le tout à la position initiale en effectuant une rotation de dans le sens antihoraire.      Selon l'énoncé du problème, cette réflexion est en fait une composition de deux rotations et de la réflexion . Si l'on pose la réflexion cherchée, on a alors .  L'une ou l'autre des formes matricielles peut être utilisée.   "
},
{
  "id": "sageex-propprodmat",
  "level": "2",
  "url": "sec-prodmat.html#sageex-propprodmat",
  "type": "Calcul",
  "number": "2.2.16",
  "title": "La composition de certaines transformations.",
  "body": " La composition de certaines transformations  On considère une rotation d'angle et une rotation d'angle . Intuitivement, la composition de ces deux rotations devrait être une rotation d'angle . On peut le vérifier algébriquement à l'aide de Sage.   La dernière ligne du code permet d'obtenir la simplification voulue. La méthode apply_map permet d'appliquer trig_reduce() à chaque entrée de la matrice par le biais d'une fonction intermédiaire lambda . Ceci n'est pas très intuitif, mais, pour l'instant, ça suffira. L'exercice permettra de créer une fonction plus simple qui pourra simplifier une matrice.  On voit toutefois qu'après simplification, la transformation est bel et bien une rotation d'angle .  On s'intéresse maintenant à la composition de deux réflexions d'angle respectif . Est-ce que le résultat de ce type de composition sera aussi une réflexion? Si oui, pourquoi, si non, donner un exemple avant d'exécuter le code ci-dessous.   Le résultat, peut-être surprenant, est une rotation. La simplification effectuée par Sage ne montre pas directement la forme d'une matrice de rotation, mais on peut montrer qu'elle est équivalente à une rotation d'angle . Ceci suggère également que les réflexions ne sont pas commutatives, à savoir qu'en général, .  Maintenant, on s'intéresse à la composition d'une rotation et d'une réflexion. Comme on sait que la multiplication n'est pas commutative, on regarde s'il y a une différence entre faire la réflexion en premier suivie de la rotation et la rotation suivie de la réflexion (peut-on faire une prédiction?).  D'abord, :   Le résultat semble donc être une réflexion d'angle .  On compare maintenant avec :   Le résultat est encore une fois une réflexion, mais cette fois-ci d'angle .  Finalement, on s'intéresse à la composition de trois transformations, en utilisant les calculs précédents et l'associativité pour déterminer le résultat final.  La composition de trois rotations devrait être, elle aussi, une rotation dont l'angle correspond à la somme des angles de chacune des rotations. En utilisant l'associativité, on montre facilement que . L'associativité est ainsi vérifiée et cohérente avec la composition de rotations.  La composition de trois réflexions semble plus difficile à analyser. Deux réflexions composées ensemble donnent une rotation. Une rotation composée avec une réflexion donne une réflexion, mais on sait que l'ordre de la composition est important. Est-ce alors évident que l'associativité sera respectée? On a d'une part . D'autre part, on a . On a donc bel et bien égalité.  D'autres cas seront explorés à l'exercice .  "
},
{
  "id": "exo-AIegaleA",
  "level": "2",
  "url": "sec-prodmat.html#exo-AIegaleA",
  "type": "Exercice",
  "number": "2.2.3.1",
  "title": "",
  "body": " Démontrer que, peu importe la matrice , on a .   Il faut simplement créer une matrice quelconque et faire le calcul.   Soit . Alors,  "
},
{
  "id": "exo-prodmatpascommutatif",
  "level": "2",
  "url": "sec-prodmat.html#exo-prodmatpascommutatif",
  "type": "Exercice",
  "number": "2.2.3.2",
  "title": "",
  "body": " Soit deux matrices carrées et . Considérer l'équation suivante: . Démontrer cette équation si elle est valide. Sinon, donner un contrexemple.   Considérer la commutativité du produit matriciel.   L'équation n'est pas valide. Un contrexemple possible est et .   Avec le contrexemple et , on calcule et et l'on constate que ce n'est pas égal. En effet, et Algébriquement, c'est faux puisque le produit matriciel n'est pas commutatif. On a donc que . Ainsi, .  "
},
{
  "id": "exercise-77",
  "level": "2",
  "url": "sec-prodmat.html#exercise-77",
  "type": "Exercice",
  "number": "2.2.3.3",
  "title": "",
  "body": " Est-ce que l'équation est valide pour les matrices carrées? Si oui, il faut le démontrer et si non, trouver un contrexemple.   L'équation n'est pas valide. L'exercice précédent fournit un contrexemple, soit et .   Avec le contrexemple et , on calcule et et l'on constate que ce n'est pas égal. En effet, et Algébriquement, c'est faux puisque le produit matriciel n'est pas commutatif. On a donc que . Ainsi, .  "
},
{
  "id": "exo-prodmatzero",
  "level": "2",
  "url": "sec-prodmat.html#exo-prodmatzero",
  "type": "Exercice",
  "number": "2.2.3.4",
  "title": "",
  "body": " Avec les nombres réels, si , alors ou (possiblement les deux). Est-ce aussi vrai pour les matrices? C'est-à-dire, si pour deux matrices compatibles pour la multiplication, est-ce que ou ? Si oui, il faut le démontrer et si non, trouver un contrexemple. On rappelle que dénote la matrice nulle de taille appropriée.   Penser à deux projections orthogonales successives dans telles que leur composition annihilera tout vecteur.   Les matrices et fonctionnent. Il existe d'autres réponses possibles.   Comme le dit l'indice du problème, on peut réfléchir à une composition de transformations qui ramènerait tout vecteur au vecteur nul. La transformation dont la matrice est peut donc être obtenue en composant, par exemple, une projection orthogonale sur l'axe des ( ) et une projection orthogonale sur l'axe des ( ) . Les matrices permettant cela ont déjà été introduites, mais on peut les retrouver en réfléchissant à l'image des vecteurs de la base canonique. On aura et . En les multipliant, on obtient:   "
},
{
  "id": "exo-matpermudef",
  "level": "2",
  "url": "sec-prodmat.html#exo-matpermudef",
  "type": "Exercice",
  "number": "2.2.3.5",
  "title": "",
  "body": " Une matrice de permutation est une matrice telle que chaque colonne et chaque ligne ne contient qu'une entrée non nulle égale à . Par exemple, la matrice est une matrice de permutation.   Faire la liste de toutes les matrices de permutations . Quel est l'effet d'une matrice de permutation sur un vecteur?   Voici la liste: et . La première matrice est l'identité, qui ne modifie donc pas les vecteurs, et la seconde est une matrice de réflexion selon l'axe . Algébriquement, cette seconde matrice fait simplement permuter ses composantes en et .   Faire la liste de toutes les matrices de permutations . Quel est l'effet d'une matrice de permutation sur un vecteur?   Voici la liste: , , , , et . La première matrice est l'identité, qui ne modifie pas les vecteurs. Les trois suivantes sont des matrices de réflexion selon différents plans, puisqu'un des trois vecteurs colonnes demeure inchangé. Par exemple, la deuxième est une réflexion selon le plan et reste inchangé. Finalement, les deux dernières sont des matrices de rotation, soit dans le sens horaire soit antihoraire autour de l'axe parallèle au vecteur . Algébriquement, toutes les matrices de permutation font permuter les composantes d'un vecteur soit deux à deux (réflexions), ou toutes les trois (rotations).   Si et sont deux matrices de permutation, est-ce que leur produit est une matrice de permutation?   Oui.   Oui, il s'agit encore d'une matrice de permutation. Logiquement, si l'on fait des permutations de composantes, et qu'on fait ensuite d'autres permutations, la composition de ces deux opérations se fera en une seule opération de permutation.   Si et sont deux matrices de permutation, est-ce que ?   Non.   En général, les matrices sont rarement commutatives et les permutations ne font pas exceptions à cette règle. Ici, il est possible de trouver un contrexemple où . On choisit et . Alors,  "
},
{
  "id": "exo-eqmatgeo",
  "level": "2",
  "url": "sec-prodmat.html#exo-eqmatgeo",
  "type": "Exercice",
  "number": "2.2.3.6",
  "title": "",
  "body": " Soit une matrice à coefficients réels. En réfléchissant de façon géométrique, puis en démontrant algébriquement que c'est bien le cas, trouver le plus grand nombre de matrices différentes telles que   .   Autrement écrit,    Géométriquement, on cherche à trouver une transformation linéaire qui, si l'on effectue cette transformation deux fois, a comme résultat de ne rien changer au vecteur initial. Bref, le déplacement initial doit être en quelque sorte annulé en refaisant la même transformation. On pense assez rapidement aux réflexions. En effet, une réflexion par rapport à n'importe quel axe répété deux fois ramènera tout vecteur à son emplacement initial. Par l'équation , on sait que toutes les matrices de réflexion sont de la même forme. On démontre que . Une autre transformation est une rotation de . En effet, lorsque l'on répète cette rotation, on revient au point de départ. Par l'équation , on obtient rapidement la matrice de rotation et l'on vérifie que . Finalement, il ne faut pas oublier que la matrice identité est une transformation linéaire. Répéter cette transformation qui ne change rien ne transformera pas les vecteurs et donc . La vérification algébrique est simple.   .     Puisque la transformation composée doit globalement amener le vecteur à et à , on a une solution assez simple avec la rotation. Si l'on fait une rotation de et qu'on la répète, on arrivera à cette position. On le vérifie algébriquement. Par l'équation , En réalité, une infinité de matrices de rotation peuvent faire l'affaire. En effet, il suffit d'avoir une rotation qui permet, lorsque répétée deux fois, d'aboutir à un angle qui soit un multiple de , partant de . Autrement dit, si , la matrice fonctionne. On le montre. On réalise cependant que toutes les matrices où est de même parité sont identiques. En effet, une rotation de est identique à une rotation de . Bref, les deux matrices de rotation possibles sont de et de avec les matrices respectives:     .     Pour obtenir la matrice nulle en transformant deux fois de suite, il existe quelques options. La plus facile est de définir , la transformation qui ramène tous les vecteurs à l'origine. Il est évident que , on n'a pas à le démontrer algébriquement.  De la même manière, les matrices satisfont l'équation en raison des nombreux zéros. Elles représentent des transformations que l'on ne connait pas encore. On peut avoir une intuition géométrique en voyant où les vecteurs de base se retrouvent. La première matrice envoie sur et sur .   .     Intuitivement, il faut trouver une matrice de transformation qui donne le même résultat qu'elle soit composée avec elle-même ou prise seule. Toutes les transformations du type projections orthogonales ou pas sont telles qu'on ne change rien en répétant la transformation. On peut penser rapidement aux transformations orthogonales sur et sur données respectivement par les matrices . Cela dit, de nombreuses autres matrices de projection fonctionneront. En effet, dès que soit une ligne, soit une colonne est nulle, on aura une projection oblique qui fonctionne. Par exemple, si , alors Il en sera de même pour les matrices , et   Finalement, la matrice identité et la matrice nulle fonctionnent également. Il est facile de le vérifier.  "
},
{
  "id": "exo-etirementR2",
  "level": "2",
  "url": "sec-prodmat.html#exo-etirementR2",
  "type": "Exercice",
  "number": "2.2.3.7",
  "title": "",
  "body": " En utilisant une méthode analogue à celle de l'exemple , déterminer la matrice de transformation linéaire permettant de faire un étirement de facteur dans la direction d'un vecteur . Utiliser les matrices et de l'exercice ainsi que la matrice d'étirement horizontal de facteur .   La démarche consiste en réalité à effectuer d'abord une rotation d'angle , ensuite à étirer horizontalement, puis à effectuer la rotation d'angle . On le fait en multipliant les trois matrices ensemble. On peut trouver les matrices nécessaires dans l'exemple .     Selon l'énoncé du problème, cet étirement est en fait une composition de deux rotations et de l'étirement horizontal de facteur  . Si l'on pose l'étirement cherché, on a alors .  "
},
{
  "id": "exo-dirinvariantesR2",
  "level": "2",
  "url": "sec-prodmat.html#exo-dirinvariantesR2",
  "type": "Exercice",
  "number": "2.2.3.8",
  "title": "",
  "body": " À partir de la matrice développée à l'exercice considérer un étirement dans la direction d'angle et de facteur . Vérifier que pour le vecteur , on a et que .  On appelle ces deux directions les directions invariantes d'une transformation linéaire. On les appelle également des vecteurs propres et le facteur d'étirement une valeur propre . On étudiera ces notions à la section .   On calcule la matrice d'étirement de facteur dans la direction simplement en remplaçant cet angle et cette valeur dans la matrice trouvée précédemment. On obtient: On vérifie ensuite le résultat de la transformation des deux vecteurs donnés. et   "
},
{
  "id": "exo-associativiterotref",
  "level": "2",
  "url": "sec-prodmat.html#exo-associativiterotref",
  "type": "Exercice",
  "number": "2.2.3.9",
  "title": "",
  "body": " Soit et , des matrices de rotation d'angle et et de réflexion d'angle et . En utilisant les résultats de l'exemple , décrire les compositions suivantes en utilisant à la fois et afin de vérifier l'associativité.     On procède de façon semblable à l'exemple, en utilisant les résultats pour la composition des rotations et des réflexions. Entre autres, on a et .  On remarque également que les démonstrations d'associativité se construisent souvent du début et de la fin, vers le milieu. Autrement dit, on peut développer et et simplifier pour constater qu'on arrive à la même transformation (au milieu des démarches). On a choisi de les écrire du début à la fin puisque c'est plus soignée, mais on a bel et bien construit la démonstration du début jusqu'au milieu et de la fin jusqu'au milieu.    Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une réflexion d'angle .     Il s'agit donc globalement d'une rotation d'angle .     Il s'agit donc globalement d'une rotation d'angle .     Il s'agit donc globalement d'une rotation d'angle .  "
},
{
  "id": "exercise-84",
  "level": "2",
  "url": "sec-prodmat.html#exercise-84",
  "type": "Exercice",
  "number": "2.2.3.10",
  "title": "",
  "body": " Lors d'une certaine journée au Canada, voici les offres pour des vols directs entre les principaux aéroports canadiens:   Vols intérieurs au Canada     De \/ Vers   YUL  YYZ  YVR  YYC  YEG    YUL  0  20  5  3  2    YYZ  15  0  10  7  6    YVR  3  8  0  12  8    YYC  3  6  12  0  8    YEG  2  6  8  6  0     Quelle serait une matrice qui permettrait de décrire le nombre de vols directs entre les différentes villes canadiennes?  Donner une interprétation du produit ?  Utiliser Sage pour déterminer combien de vols différents entre Montréal et Vancouver impliquent une escale.     "
},
{
  "id": "exercise-85",
  "level": "2",
  "url": "sec-prodmat.html#exercise-85",
  "type": "Exercice",
  "number": "2.2.3.11",
  "title": "",
  "body": " Soit . Utiliser Sage pour calculer le produit .   "
},
{
  "id": "exosage-permmatrices",
  "level": "2",
  "url": "sec-prodmat.html#exosage-permmatrices",
  "type": "Exercice",
  "number": "2.2.3.12",
  "title": "Construction des matrices de permutation d’ordre <span class=\"process-math\">\\(n\\)<\/span>.",
  "body": "Construction des matrices de permutation d'ordre Dans cet exercice, on veut donner une manière de faire la liste des matrices de permutation , définies à l'exercice .Pour cela, on va utiliser la commande Permutations(n).list() , qui renvoie la liste des permutations à éléments. Par exemple   renvoie une liste de éléments correspondant à toutes les manières d'ordonner les nombres . Une matrice de permutation est une matrice obtenue en permutant les colonnes de la matrice identité. Dans cet exercice, on crée une fonction perm_matrix(n) qui donnera une liste des matrices de permutation d'ordre . Pour cela, il faudra  Créer la liste des permutations d'ordre à l'aide de la commande Permutations(n).list() .  Créer la liste des vecteurs à partir de la matrice identité. (Utiliser la commande A.columns() .  Créer chaque matrice de permutation à partir de la liste des permutations. La liste des permutations permet de savoir à quelle colonne de la matrice identité correspond chacune des colonnes de la matrice .   Commencer par créer une fonction qui fournira les matrices de permutation et une autre fonction qui va donner les matrices de permutation . Des réponses possibles se trouvent dans l'indice suivant.   Un indice pour l'exercice   def perm_matrix2x2(): Id=identity_matrix(2) col=Id.columns() p=Permutations(2).list() #La liste des permutations L=list() #une liste vide for perm in p: #Pour chaque permutation dans la liste p, on va ajouter la matrice de permutation correspondante à la liste L P=column_matrix([col[perm[0]-1],col[perm[1]-1]]) #On construit une matrice de permutation selon une permutation spécifique L.append(P) #On l'ajoute à la liste existante return L def perm_matrix3x3(): Id=identity_matrix(3) col=Id.columns() p=Permutations(3).list() #La liste des permutations L=list() #une liste vide for perm in p: #Pour chaque permutation dans la liste p, on va ajouter la matrice de permutation correspondante à la liste L P=column_matrix([col[perm[0]-1],col[perm[1]-1],col[perm[2]-1]]) #On construit une matrice de permutation selon une permutation spécifique L.append(P) #On l'ajoute à la liste existante return L    Pour le cas , il faudra faire quelques modifications. D'abord, on change les dans les premières lignes par des , afin d'avoir une idée du comportement plus général de l'exercice. Ensuite parce, qu'on ne connait pas d'avance la dimension des matrices cherchées, il faut trouver un moyen de changer la ligne P=column_matrix(...) .    La solution pour l'exercice   def perm_matrix(n): Id=identity_matrix(n) col=Id.columns() p=Permutations(n).list() L=list() for perm in p: colperm=list() for j in range(len(perm)): colperm.append(col[perm[j]-1]) P=column_matrix(colperm) L.append(P) return L    "
},
{
  "id": "exercise-87",
  "level": "2",
  "url": "sec-prodmat.html#exercise-87",
  "type": "Exercice",
  "number": "2.2.3.13",
  "title": "",
  "body": " Utiliser le produit de matrices de rotation et Sage pour démontrer les identités trigonométriques .    Si l'on compose les rotations et , on sait que l'image du vecteur correspondra à , puisque la composition de rotations donne une rotation dont l'angle est la somme des arguments respectifs des rotations initiales.     Le code solution pour l'exercice   var(\"alpha,beta\") Rotalpha=column_matrix([[cos(alpha),sin(alpha)],[-sin(alpha),cos(alpha)]]) Rotbeta=column_matrix([[cos(beta),sin(beta)],[-sin(beta),cos(beta)]]) show(LatexExpr(r\"\\cos(\\alpha+\\beta)=\"),(Rotalpha*Rotbeta)[0][0]) #La commande LatexExpr et les \"\\\" permettent un rendu plus joli, mais ne sont pas obligatoire show(LatexExpr(r\"\\sin(\\alpha+\\beta)=\"),(Rotalpha*Rotbeta)[1][0])    "
},
{
  "id": "exercise-88",
  "level": "2",
  "url": "sec-prodmat.html#exercise-88",
  "type": "Exercice",
  "number": "2.2.3.14",
  "title": "Les matrices nilpotentes: une fonction.",
  "body": "Les matrices nilpotentes: une fonction  Une matrice carrée est dite nilpotente d'ordre si et si , c'est-à-dire si la matrice multipliée par elle-même fois donne la matrice nulle et si est le premier entier pour lequel ceci se produit. On dit que est l'indice de nilpotence de la matrice .  Le but de cet exercice est de créer une fonction qui prend une matrice carrée comme argument et qui dit si la matrice est nilpotente ou non. Si c'est le cas, on voudra aussi avoir l'indice de nilpotence. On appellera la fonction estnilpotente .  Il y a quelques points à considérer. Les matrices ne sont pas toutes nilpotentes. Le seul critère (pour l'instant) est d'essayer de multiplier la matrice par elle-même jusqu'à l'obtention de la matrice nulle. Il faut cependant un critère d'arrêt pour ne pas essayer sans fin. Il est possible de montrer que l'indice de nilpotence d'une matrice satisfait toujours l'inégalité . Comme les commandes .ncols() ou .nrows() permettent de donner la dimension d'une matrice quelconque facilement, on se sert de ce critère pour arrêter notre fonction.  Écrire la fonction qui permet de vérifier la nilpotence d'une matrice.  À l'aide de la fonction créée, vérifier la nilpotence des matrices suivantes:            Le code solution pour l'exercice   A=column_matrix([[0,0,0,0],[2,0,0,0],[5,4,0,0],[-2,0,4,0]]) B=column_matrix([[1,0],[2,4]]) C=column_matrix([[1,1,-2],[1,1,-2],[1,1,-2]]) def estnilpotente(A): n=A.ncols() #La dimension de la matrice k=1 #L'indice de nilpotence, si while k <= n: #Le critère d'arrêt if A^k==0: #Sage comprend que 0 sera la matrice nulle. On aurait aussi pu la définir afin de comparer return print(\"La matrice est nilpotente d'ordre \",k) else: k+=1 #On augmente le potentiel indice de 1 return print(\"La matrice n'est pas nilpotente\") estnilpotente(A) estnilpotente(B) estnilpotente(C)    "
},
{
  "id": "sec-matinverse",
  "level": "1",
  "url": "sec-matinverse.html",
  "type": "Section",
  "number": "2.3",
  "title": "Transformations inverses",
  "body": "  Transformations inverses    Aller aux exercices de la section.  Soit une transformation linéaire, de vers . Est-il possible de trouver une transformation telle que ? En d'autres mots, est-il possible d'annuler l'effet de sur les vecteurs de par une transformation? Comme une forme d'inverse, au même sens où, pour défaire une multiplication par , on peut diviser par . Pourrait-on, ainsi, définir la division de transformations linéaires, et par le fait même, de matrices?  Est-il toujours possible de trouver cette transformation inverse? Dans ? Qu'en est-il de la situation plus générale d'une transformation de vers ?  Dans cette section, on se concentre sur l'inverse d'une transformation de vers . On verra les conditions d'existence de l'inverse, de même que certaines propriétés. Quelques-unes de ces propriétés se généraliseront plus tard au cas général, mais celui-ci demandera une attention particulière.    L'inverse de transformations géométriques  On commence cette section par une partie intuitive, qui permettra de déterminer l'inverse des transformations de nature géométrique simple, comme celles de la liste . Mais avant, il faut une définition de ce que représente l'inverse d'une transformation.   La transformation inverse, définition préliminaire  Soit , une transformation linéaire. La transformation inverse de , notée , est une transformation telle que pour tout dans le domaine de .    Une précision sur l'inverse  Dans la définition, il n'est pas mentionné que la transformation inverse est une transformation linéaire. Comme on peut interpréter l'équation de manière matricielle, on cherche l'existence d'une matrice telle que pour tout vecteur dans le domaine de , c'est-à-dire une transformation telle que . En vertu de la proposition , si une telle matrice existe, alors est une transformation linéaire.    L'inverse de transformations géométriques  On considère les transformations de la liste et l'on cherche à les inverser, si possible.   La transformation identité n'a aucun effet sur les vecteurs de . Ainsi, si l'on la compose avec elle-même, on restera avec l'identité. L'inverse de est donc .    Afin de défaire une réflexion par rapport à l'axe des , il semble suffisant d'appliquer à nouveau la réflexion. On aurait donc . On vérifie algébriquement que c'est le cas. . L'inverse de cette réflexion est donc en effet la réflexion même.    Pour défaire une rotation de , il semble logique de faire une rotation de , correspondant en fait à une rotation dans le sens horaire. Selon l'équation , cette matrice serait . Algébriquement, on a . La transformation inverse de la rotation de est donc bel et bien une rotation dans le sens opposé. Il est intéressant de remarquer que et qu'on a aussi . On vérifiera plus tard si cela se produit toujours.    Un étirement horizontal multiplie la première composante d'un vecteur par . Pour défaire cette transformation, on devrait diviser cette composante par , ce qui donnerait un étirement de facteur . Ici se présente un premier problème dans la recherche d'inverse. En effet, si , il est impossible de diviser par et donc l'inverse, s'il existe, ne serait pas un étirement de facteur . On débute par considérer le cas avant de réfléchir à ce que représente un étirement de facteur et son inverse. Ainsi, si , on a . Ainsi, si .  On considère maintenant le cas . La matrice de l'étirement est . On affirme dès le départ qu'il ne peut exister d'inverse pour cette transformation. En effet, soit , la matrice représentant l'inverse. Selon la définition , il faut que . En particulier, il faudrait que selon la définition du produit matriciel , puisque est la première colonne de et la première colonne de la matrice identité. Selon la proposition , l'image du vecteur nul sera toujours le vecteur nul et en conséquence, il est impossible d'avoir comme résultat.  Il est cependant possible que l'inverse existe, mais ne soit pas une transformation linéaire. Quand on précisera la définition , cette possibilité sera invalidée.    La solution pour l'inverse de est donnée à l'exercice .    Il est évident que, si les composantes d'un vecteur ont été permutées, cette même permutation redonnera le vecteur initial. Ainsi, . La vérification algébrique est laissée au lecteur.    On est forcé, une fois de plus, à réfléchir à la signification de l'inverse d'une transformation avec le cas de la projection orthogonale. Si l'on pense aux fonctions réelles traditionnelles et à leur inverse, il en quelque ressort chose de commun. L'inverse de la fonction est , pour autant que . La fonction a pour inverse le logarithme naturel, . Dans chacun de ces cas, on remarque pour chacun des dans le domaine, il correspond un seul dans l'image tel que . Si l'on regarde la fonction , celle-ci ne respecte pas cette condition. Par exemple, .  Lorsqu'on veut inverser la fonction , on parle souvent de la racine carrée. Cet inverse ne fonctionne toutefois que pour des valeurs de (un choix a été fait de considérer cette branche plutôt que l'autre). De même, pour inverser la fonction , on ne considère que les valeurs de . Sur chacune de ces branches, il n'existe qu'une seule paire de nombres tels que . Ainsi, on peut inverser la fonction sans problème.  On revient à la projection. Pour un vecteur parallèle à , il existe une infinité de vecteurs tels que . Comment choisir l'inverse de dans ce cas, parmi l'infinité de possibilités? On préfère ne pas choisir dans ce cas et dire que la projection orthogonale ne possède pas d'inverse.  En approfondissant notre intuition géométrique dans les prochaines sections, on comprendra davantage la raison de l'inexistence de l'inverse de la projection. On peut s'imaginer, en quelque sorte, qu'il y a une perte d'information lorsque la projection est appliquée et qu'il n'est pas possible de revenir en arrière.  L'analogie de l'ombre, souvent utilisée pour les projections orthogonales ou autres, peut aider. En effet, il est facile de réaliser qu'on ne peut pas reconstruire l'objet initial à partir seulement de son ombre. Qui n'a jamais utilisé ses mains pour créer des ombres de monstres effrayants à l'aide d'une lampe de poche?    Le dernier exemple est riche en intuition géométrique et en questionnement. On a pu trouver des inverses sans faire de calculs, sauf pour vérifier que l'intuition était bonne. On a également constaté un cas où, lorsque est l'inverse de , est aussi l'inverse de . Ce constat, vrai en général pour les matrices carrées, n'est pas aussi évident que cela puisse le paraitre. Également, on a réalisé que l'inverse d'une matrice n'existe pas toujours. On verra bientôt les premiers critères géométriques et algébriques nécessaires pour avoir l'existence d'une transformation inverse.    L'inverse d'une transformation linéaire du plan  Dans cette sous-section, on cherche à établir une formule, mais surtout des critères pour déterminer si une transformation possède une transformation inverse. Avant, on donne un exemple qui motive la recherche de l'inverse.  On sait que les colonnes de la matrice d'une transformation linéaire correspondent aux images des vecteurs et (dans , le cas général étant semblable, voir la proposition et le texte qui la suit). Qu'en est-il si l'on connait l'effet d'une transformation , non pas sur ces vecteurs, mais sur deux vecteurs quelconques? Il y a une condition à respecter, mais on ne veut pas trop en dire pour le moment.  Concrètement, si et , alors, selon la définition de la multiplication, on peut écrire . Pour simplifier, on écrit . Si l'on était capable d'inverser la matrice , on pourrait isoler la matrice de la transformation linéaire : .  En principe, l'équation suppose que l'inverse à droite sera le même que l'inverse à gauche (la définition parle seulement d'inverse à gauche). La définition qui suivra permettra de lever l'ambigüité. On accepte l'incohérence temporaire puisque le but n'est que de donner un exemple de l'utilisation de la matrice inverse.  On commence l'exploration de l'inverse d'une matrice quelconque par le calcul d'un tel inverse pour une matrice qui n'a pas d'interprétation géométrique claire.   Un premier calcul de matrice inverse   On considère la matrice . On cherche l'inverse de cette transformation, dans l'hypothèse que l'inverse existe.    On cherche une matrice telle que . En appliquant la définition de la multiplication, on trouve deux équations vectorielles et . Si l'on pose , on obtient une paire de systèmes à deux équations deux inconnues. D'une part, et d'autre part .  En prenant la première composante des équations et , qui ne contiennent que les variables et , on obtient . La seconde de ces équations permet d'obtenir , puis en substituant dans la première, on détermine . On a alors .  En prenant la deuxième composante des équations et , qui ne contiennent que les variables et , on obtient . La première de ces équations permet d'obtenir , puis en substituant dans la seconde, on détermine . On a alors .  Ainsi, la matrice inverse doit être . Une vérification ne fait jamais de tort: .    On considère maintenant une matrice quelconque et l'on cherche l'inverse. En se basant sur les calculs faits à l'exemple , on peut retrouver deux systèmes d'équations analogues. D'abord, et ensuite .  Rappelons ici que sont les coefficients de la matrice et qu'ils sont en général connus. On cherche donc à résoudre ces systèmes en fonction des inconnues . En couplant les premières composantes ensemble et les secondes composantes ensemble, on obtient deux systèmes à deux équations et deux inconnues. Le premier de ces systèmes est et le second .  Comme on veut éviter de restreindre le plus possible les valeurs de , on ne peut pas isoler ou dans la seconde équation du premier système. Cela supposerait que ou . Pour contourner ce problème, on multiplie la première équation par et la seconde par . On obtient . En soustrayant l'équation de l'équation , on obtient . On ne peut plus éviter la division et donc, en faisant la supposition que , on obtient .  En multipliant maintenant la première équation du premier système par et la seconde par , on obtient . En soustrayant cette fois l'équation de l'équation , on obtient . La supposition que ayant déjà été faite, on trouve .  Dans l'exercice , il est montré que et .  En sortant le facteur commun à chacun des termes, on obtient finalement la matrice inverse .   Calcul de l'inverse avec la formule  On reprend la matrice de l'exemple et l'on détermine son inverse avec la formule . On obtient , qui correspond à ce qui a été obtenu plus tôt.   Il semble qu'un critère pour déterminer si une matrice (ou une transformation) est inversible soit que . On réfléchit maintenant à ce que cela signifie si et pourquoi une transformation ayant cette propriété ne peut être inversible.  Dans un premier temps, si , alors . On a aussi . Les vecteurs et semblent donc parallèles. En fait, il faut distinguer certains cas problématiques, ce que l'on fera un peu plus tard. D'abord, on montre que des vecteurs parallèles sont suffisants pour faire en sorte qu'une matrice ne soit pas inversible.  En effet, si , alors . Le seul problème avec cet argument est que si ou , les vecteurs ne sont pas considérés comme parallèles (voir la définition et la note de bas de page l'accompagnant). Or, de manière évidente, si ou (ou les deux), alors . Dans tous les cas, la situation géométrique est analogue à une projection. La transformation associée à une matrice telle que envoie le plan sur une droite (ou un point si ). Comme mentionné à l'exemple , il y a perte d'information qui fait qu'on ne peut défaire la transformation.  On termine avec des commandes Sage en lien avec la sous-section.   Les matrices inverses sur Sage  Sur Sage, on peut calculer facilement l'inverse d'une matrice  en utilisant la commande A.inverse() . On pourra bien entendu vérifer avec la multiplication matricielle que le calcul est bon.   Si l'inverse n'existe pas, Sage retourne une erreur, comme le montre le code suivant     On fait maintenant un exemple en référence à l'équation , qui stipule que si l'on connait l'effet d'une transformation sur deux vecteurs, alors on peut déterminer la matrice associée à la transformation sans calculer directement l'image des vecteurs et (pour le cas ).  On considère donc une transformation linéaire telle que et . On cherche la matrice représentant . Avec Sage et l'équation , on a   Afin de vérifier, on peut calculer les images des vecteurs et .   Évidemment, on aurait pu calculer et vérifier que l'on obtient , mais on s'est permis ici de rappeler la commande U.column() qui permet d'accéder aux colonnes d'une matrice. Il est pratique de travailler de cette manière plutôt que, par exemple, définir manuellement u1=vector([2,4]) . L'idée est que si, pour une raison quelconque, on décidait de changer la matrice , il suffirait de changer seulement la ligne où est définie. Ceci est résumé dans le conseil ci-dessous.    Utilisation efficace de l'informatique  L'un des buts de utilisation de l'informatique est de lui déléguer certains calculs, afin de se concentrer davantage sur les concepts. Il faut toutefois être efficace dans son utilisation afin de bénéficier de sa flexibilité et de toute sa puissance. On illustre avec un exemple.  Soit . On cherche à calculer la quantité pour cette matrice. Si ce nombre n'est pas zéro, on veut calculer . Voici une première option.   Présentée ainsi, la séquence d'instructions ressemble à ce qui serait fait sur une feuille, les commandes étant effectuées dans l'ordre où l'on se pose les questions pertinentes lors de la résolution. Maintenant si l'on pose les mêmes questions pour la matrice , on s'imagine recopier le code et corriger les lignes 2-5 et la ligne 8 .  Voici une deuxième option pour répondre aux questions initiales.   Maintenant, pour répondre aux questions avec la matrice , seule la ligne 2 doit être éditée.     Définition formelle de l'inverse d'une matrice carrée  Dans cette sous-section, on étudie les propriétés de la matrice inverse. On précise également la définition de l'inverse. Bien que, pour le moment, on ne connaisse que l'inverse d'une transformation de vers , les propriétés étudiées ici sont valides pour toute matrice carrée possédant un inverse. On verra dans le chapitre comment obtenir l'inverse d'une matrice carrée de taille plus grande que .  La première étape de notre démarche est de valider l'hypothèse que si , alors également. Cela parait sans doute plus simple que ce ne l'est vraiment. En effet, rien ne garantit à priori que si possède un inverse, alors cet inverse possède lui-même un inverse.  Il est par contre assez intuitif que l'inverse de l'inverse de doit être . Les prochains résultats visent à mettre un peu d'ordre et de rigueur derrière l'intuition.   Le domaine et l'image d'une transformation linéaire  Les prochains résultats concernent le domaine et l'image d'une transformation linéaire. On rappelle que selon la proposition , une matrice est une transformation linéaire de vers . Le chapitre explore en profondeur domaine, image et zéros d'une transformation linéaire.  Pour ce qui suit, on s'intéresse seulement aux matrices carrées .   On cherche d'abord à démontrer que si est une matrice pour laquelle il existe telle que , alors il existe également une matrice telle que . En d'autres mots, si possède un inverse selon la définition et la remarque , alors est aussi l'inverse d'une matrice.  Par la suite, on montre que .   Les transformations inversibles atteignent tous les vecteurs de leur image   Si est une matrice possédant un inverse au sens de la définition et de la remarque , alors pour tout , il existe tel que . Cela signifie que chaque vecteur de (l'image) est atteint par la transformation d'un vecteur de (domaine). De plus, le vecteur est unique.    Soit , un vecteur de l'image de . On cherche tel que . Puisque possède un inverse , on a .  Ainsi, il existe tel que et l'on peut explicitement le calculer à l'aide de l'inverse.  L'unicité est une conséquence du fait que la matrice inverse est unique, ce qui sera démontré à la proposition . Ainsi, si était tel que , on aurait aussi . L'unicité de l'inverse assure que .     Les transformations atteignant chaque vecteur de leur image sont l'inverse d'une transformation  Soit , une matrice telle que pour tout , il existe telle que , alors est l'inverse d'une matrice , au sens de la définition et de la remarque . Cela signifie qu'il existe une matrice telle que .   Soit , les vecteurs colonnes de la matrice identité. Par hypothèse sur , il existe des vecteurs tels que pour chacun des .  On pose . On a alors puisque la colonne de est donnée par .     En passant  Une fonction d'un ensemble vers un ensemble est dite surjective (en anglais on dit parfois \"onto\") si pour chaque il existe au moins un élément tel que . Cela signifie que chaque valeur de l'image est atteinte par au moins une valeur du domaine.  La proposition montre donc qu'une transformation linéaire inversible est surjective alors que la proposition montre qu'une transformation surjective est inversible.  Lorsqu'une fonction est telle que si , alors , on dit qu'elle est injective (en anglais on dit parfois \"one-to-one\"). Cela signifie que chaque valeur atteinte dans ne l'est que par un et un seul .  Une fonction qui est à la fois injective et surjective est dite bijective.   On peut finalement montrer, en utilisant les deux propositions précédentes, que l'inverse d'une matrice fonctionne des deux côtés. Cela va permettre de préciser la définition .   L'inverse d'une matrice carrée est bilatéral   Soit , une matrice carrée pour laquelle il existe telle que . Alors .    Puisque possède un inverse au sens de la définition , la proposition dit que chaque valeur de son image est atteinte par une valeur de son domaine.  De plus, la proposition affirme qu'il existe une matrice telle que , c'est-à-dire que est l'inverse d'une matrice au sens de la définition . On a alors . Ainsi l'inverse de l'inverse de est . On dira aussi que l'inverse à gauche de est le même que son inverse à droite.    Ce résultat, qui n'est peut-être pas surprenant, est néanmoins primordial dans l'étude de l'algèbre linéaire. D'autant plus qu'on sait qu'en général, le produit matriciel ne commute pas. Toutefois, c'est le cas lorsqu'il est question de l'inverse. La définition suivante raffine la définition . Elle servira de référence à partir de maintenant pour l'inverse d'une transformation linéaire de vers ou de façon équivalente, d'une matrice carrée.   L'inverse d'une matrice carrée  Soit , une matrice carrée. On dit que est inversible s'il existe une matrice telle que .  En ce qui concerne les transformations linéaires, on dit que la transformation de vers est inversible s'il existe une transformation linéaire de vers telle que pour tout vecteur .    Obtenir l'inverse d'une matrice  Ensemble, les propositions et , combinées à la définition donnent un critère pour déterminer si une matrice carrée possède un inverse. Il faut que l'équation possède une solution pour tout . L'exercice montre qu'en fait, il est suffisant d'avoir une solution pour les vecteurs .  De plus, la proposition donne une démarche explicite pour obtenir l'inverse. Pour chaque vecteur , on cherche un vecteur tel que . La matrice inverse est alors .   On utilise cette méthode pour calculer à nouveau l'inverse de la matrice de l'exemple .   Calcul d'une matrice inverse  On considère la matrice de l'exemple . On calcule son inverse à l'aide de la méthode de la proposition , en tenant compte de la précision faite à la remarque .  Il est intéressant de s'attarder à la différence entre la méthode explicitée à l'exemple , et dans le paragraphe qui suit cet exemple, et la méthode effectuée ci-dessous basée sur la remarque .  Bien entendu, pour une matrice , la formule permet d'obtenir l'inverse sans faire beaucoup de calculs, mais on verra qu'avec une matrice de taille plus grande, il est plus difficile de trouver une formule générale et il est plus simple de rechercher les vecteurs colonnes de l'inverse.    On cherche un vecteur tel que et un vecteur tel que . On a et . Pour le premier système, on trouve en comparant les deuxièmes composantes des vecteurs de l'équation que . En remplaçant dans l'équation , on trouve , ce qui donne . On déduit alors   Pour le second système, en suivant une méthode similaire, on trouve et . Cela correspond évidemment à ce qui avait été trouvé aux exemples et .    On obtient ici la première version du théorème . Ce théorème sera construit au fur et à mesure que des résultats sur la matrice inverse vont apparaitre et donnera une panoplie d'affirmations équivalentes visant à déterminer si une matrice carrée est inversible ou non.   Théorème de la matrice inverse, première version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .     Le fait que la matrice inverse implique l'existence d'une solution unique à l'équation est le résultat de la proposition .  Le fait qu'une solution unique à l'équation implique que la matrice soit inversible est le résultat de la proposition .   Dans le chapitre , on aura une méthode efficace pour trouver les vecteurs colonnes de l'inverse d'une matrice carrée de taille . Pour le moment, on utilisera Sage ou l'on donnera simplement l'inverse en cas de besoin.  On termine avec un exemple Sage en lien avec la sous-section.   Retour sur les matrices inverses sur Sage  Avec l'aide de la définition , on regarde à nouveau des calculs de matrices inverses sur Sage. Plus précisément, on compare la multiplication à gauche et à droite par l'inverse afin de vérifier l'égalité avec la matrice identité.   Il peut être utile aussi de savoir que, pour calculer l'inverse, on peut utiliser A^(-1) , qui se rapproche davantage de la notation mathématique usuelle.      Propriétés de la matrice inverse  Dans cette sous-section, on est intéressé par les propriétés de la matrice inverse. En particulier, on énonce une première version du théorème de la matrice inverse , qui donne plusieurs critères équivalents pour déterminer si une matrice carrée possède un inverse.  Depuis le début de cette section, on parle de l'inverse d'une matrice. On ne s'est toutefois jamais posé la question à savoir si cet inverse est unique. On a déjà fait une remarque similaire dans la section au sujet des vecteurs directeurs des droites et des plans. Ceux-ci ne sont pas uniques. Dans le cas d'une matrice inverse par contre, l'unicité se vérifie.   L'inverse d'une matrice carrée est unique  Soit , une matrice carrée et , deux matrices telles que et . Alors .   L'égalité suit des propriétés de la multiplication matricielle et du fait que si , alors (théorème ). .    En plus d'être unique, l'inverse possède la propriété importante suivante.   L'inverse d'un produit  Soit et , deux matrices carrées d'ordre . Alors le produit est inversible si et seulement si les matrices sont inversibles. De plus, on a .   On commence en supposant que les matrices sont inversibles. Avant de s'embarquer dans des manipulations algébriques abstraites, on réfléchit un instant sur la signification de la proposition. Si deux transformations sont inversibles et qu'on les compose, c'est-à-dire qu'on les fait l'une après l'autre, il n'y a alors pas de raison apparente qui ferait en sorte que cette composition ne soit pas inversible. De plus, il semble que pour revenir sur le vecteur original, il suffit de faire les transformations inverses dans l'ordre inverse. Il paraît donc assez intuitif que D'un point de vue algébrique, on vérifie facilement que . Il ne reste donc qu'à vérifier l'existence de l'inverse.  Soit un vecteur de l'image de . On cherche telle que . En vertu de la proposition , si existe, la matrice est inversible. On construit en inversant successivement les matrices et . Tel qu'attendu . Comme les matrices et existent, le vecteur existe. Ainsi, la matrice possède toujours un inverse.  On suppose maintenant que et sont deux matrices telles que leur produit est inversible. Il existe alors une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire ce qui donne, toujours selon la définition , que la matrice est inversible.  La preuve que possède un inverse est laissée à l'exercice .     En passant  Parfois, la proposition est appelée le théorème du bas et du soulier. L'analogie va comme suit:  Lorsqu'on se lève le matin pour quitter la maison, on commence par mettre des bas à ses pieds, pour mettre ensuite des souliers. Le soir venu, on enlève d'abord les souliers, puis les bas. L'inverse de mettre ses bas puis ses souliers est donc d'enlever ses souliers puis ses bas : .   Avec les nombres réels, on dit souvent par exemple que est l'inverse multiplicatif de , car . De même, on peut aussi dire que est l'inverse multiplicatif de . Est-ce que ce résultat est aussi vrai pour les matrices? C'est ce que la proposition permet d'affirmer.   L'inverse de l'inverse   Soit , une matrice inversible qui possède un inverse . Alors .    Cela découle directement du théorème .     Parfois, une discussion sur les propriétés en est aussi une sur les \"non propriétés\". Par exemple, l'inverse de la somme de deux matrices n'est pas la somme des inverses de ces matrices. En fait, il est même possible que la somme de deux matrices inversibles ne soit pas inversible (contrairement au produit). Pour un exemple simple, on prend une matrice inversible et l'on considère la matrice . On obtient la matrice nulle, qui n'est pas inversible. En effet, si est un vecteur de l'image de , aucun vecteur n'est envoyé sur , car . En vertu de la proposition , la matrice nulle ne peut être inversible.   L'inverse pour la multiplication par un scalaire  Soit , une matrice inversible qui possède un inverse et , un scalaire non-nul. Alors, .   La preuve est laissée au lecteur à l'exercice .     Algèbre matricielle  Dans cette section, on illustre l'utilisation de l'algèbre matricielle, qui diffère de l'algèbre usuelle principalement par le fait que la multiplication n'est pas commutative.   Algèbre matricielle  Soit et , des matrices. On cherche à isoler dans l'équation .  Quelles sont les conditions sur les matrices pour qu'il soit possible d'isoler .   On isole , sans se soucier des conditions sur les matrices. On les déterminera après avoir effectué les opérations algébriques. On a donc .  Il faut donc que et soient de même format, puisqu'on les soustrait. De plus, on utilise l'inverse de . Il faut donc que soit une matrice carrée. Techniquement, ce n'est pas vrai, pourrait posséder un inverse à droite si elle est rectangulaire. Voir la section . Si est une matrice , il faut que ait lignes. Sans obligation sur le nombre de colonnes, on peut supposer qu'il y en a . Les matrices sont donc de format .  Le produit sera une matrice et donc, le format de sera . C'est également compatible avec l'équation initiale puisque est de format et qu'on additionne à ce produit la matrice ( ) pour avoir la matrice (aussi ).    Dans tous les exemples qui suivent, on suppose que les matrices ont un format approprié pour que les opérations soient définies et que les matrices qui ont à être inversées sont carrées. L'exercice servira à déterminer dans chaque cas les conditions sur les matrices.   Algèbre matricielle, deuxième partie   Pour chaque équation ci-dessous, isoler la matrice , en supposant que les formats sont appropriés et que les matrices devant être inversées sont inversibles.           Similairement à l'exemple , on a .    On commence par regrouper les termes ayant la matrice d'un côté. On obtient alors .    On a .    On commence par poser . L'expression devient , équivalente à celle de l'exemple . On a donc . Puisque , on a .     On termine avec un exemple Sage en lien avec la sous-section.   L'algèbre matricielle avec Sage  Parfois, il est pratique de travailler avec des matrices génériques, de manière purement algébrique, sans se soucier des entrées spécifiques des matrices. Malheureusement, Sage ne permet pas (encore) l'utilisation de variables pour des matrices comme on l'a fait dans les exemples et . On fait un compromis en se créant une matrice arbitraire de taille fixe. Les calculs faits ainsi ne pourront donc pas être considérés comme des preuves des identités, mais au moins une vérification qui est plus générale qu'un exemple précis.  On doit, dans un premier temps, créer une matrice dont les entrées seront arbitraires, par exemple .  Pour cela, on se sert du constructeur de matrices à partir d'une liste. Par exemple, pour créer une matrice dont les entrées seraient les nombres de à , enumérées ligne par ligne, on peut utiliser la suite d'instructions suivante.   On veut donc créer une fonction Sage qui, étant donné des dimensions et un paramètre alphabétique, retournera une matrice de taille dont les entrées seront dénotées par la lettre choisie indicée de la position, comme à l'équation . Voici une manière d'y arriver, avec commentaire dans le code.   On appelle maintenant le code pour créer deux matrices avec des indices respectifs et .   On remarque que les fonctions sage utilisées ne permettent pas d'écrire . Les entrées pourraient porter à confusion si la taille était supérieure à .   On peut ensuite \"vérifier\" l'équation de l'exemple de la manière suivante.   On a choisi pour la taille des matrices, mais on aurait pu choisir d'autres valeurs, respectant les conditions énumérées dans l'exemple . Un rappel s'impose aussi sur sage. Si l'expression avec le == renvoie true , alors on a l'assurance que c'est vrai. Par contre, un false ne signifie pas que l'expression est fausse, mais que sage est incapable de la vérifier.      Les points importants de cette section sont:  L'inverse d'une matrice ou d'une transformation n'existe pas toujours;  Lorsqu'il existe, l'inverse d'une matrice est donné par l'équation ;  La définition de l'inverse d'une matrice carrée et le fait qu'un inverse à gauche est un inverse à droite;  L'inverse d'un produit est le produit des inverses, mais l'ordre est renversé;  L'algèbre matricielle se comporte essentiellement comme l'algèbre usuelle, avec la restriction que la multiplication n'est pas commutative et que la division est remplacée par la multiplication par l'inverse d'une matrice.  De plus avec Sage, on peut calculer l'inverse d'une matrice avec la commande A.inverse() ou A^(-1) .      Exercices    Dans la section, on a déterminé une formule pour l'inverse d'une matrice quelconque qui n'est valide que si . On a toutefois laissé à compléter les détails de la résolution du système d'équations .  Montrer que la solution à ce système est et .   S'inspirer de la résolution du système dans le texte.   On multiplie la première équation par et la seconde par . On obtient . En soustrayant l'équation de l'équation , on obtient . Toujours dans l'hypothèse que , on obtient .  En multipliant maintenant la première équation du premier système par et la seconde par , on obtient . En soustrayant cette fois l'équation de l'équation , on obtient . On trouve .    Dans la remarque , il est mentionné qu'une matrice possède un inverse si pour tous les dans , il existe un vecteur tel que . Montrer qu'en fait, il suffit que les équations possèdent des solutions.   Essayer de montrer que si des solutions existent pour ces équations, alors une solution existe pour n'importe quel .   En suivant l'indication, on cherche à démontrer que si une solution existe pour chacune de ces équations, il découle qu'une solution existe pour , peu importe le vecteur .  Soit , un vecteur quelconque de dimension . Alors, si les équations données dans la question possèdent des solutions, on peut écrire: où les sont ces solutions. Alors, Cela implique donc qu'il existe un vecteur solution à l'équation pour la matrice et un vecteur quelconque . possède donc un inverse.   Soit , deux matrices carrées telles que est inversible. Compléter la preuve de la proposition en montrant que est inversible. Puisque est inversible, il existe une matrice telle que , selon la définition . On peut alors écrire à l'aide de l'associativité de la multiplication matricielle . Toujours selon la définition , la matrice est inversible.   Généraliser la proposition à trois matrices. Est-il possible de généraliser davantage?   On énonce la proposition à trois matrices:  Soit , et , trois matrices carrées d'ordre . Le produit est inversible si et seulement si les matrices sont inversibles. De plus, on a .  On commence en supposant que les matrices sont inversibles. Il est assez intuitif que On le vérifie algébriquement: . Il ne reste donc qu'à vérifier l'existence de l'inverse.  Soit un vecteur de l'image de . On cherche tel que . En vertu de la proposition , si existe, la matrice est inversible. On construit en inversant successivement les matrices , et . Tel qu'attendu, . Comme les matrices , et existent, le vecteur existe. Ainsi, la matrice possède toujours un inverse.  On suppose maintenant que , et sont trois matrices telles que leur produit est inversible. On a alors existence d'une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire et donc, toujours selon la définition , la matrice est inversible.  De façon semblable, si , et sont trois matrices telles que leur produit est inversible, on a alors existence d'une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire et donc, toujours selon la définition , la matrice est inversible.  Finalement, en regroupant les matrices , on a que qu'on suppose inversible. Par la proposition à deux matrices, cela implique que et sont inversibles. Si est inversible, cela implique, encore par le même proposition, que et sont inversibles.  On voit clairement que, bien que cela prenne de plus en plus de temps, on pourrait continuer de généraliser la proposition à l'infini en multipliant simplement plus de fois.    Expliquer pourquoi une projection orthogonale sur un vecteur est une transformation linéaire non inversible.   La proposition dit qu'une transformation inversible doit atteindre tous les vecteurs de son image. Comme la projection envoie les vecteurs sur une droite, elle ne peut atteindre tous les vecteurs. Elle est donc non inversible.    Soit , une matrice qui n'est pas nécessairement carrée et , la matrice nulle de dimension appropriée. Montrer que     Si la matrice est de format , alors la première matrice doit être de format et la seconde de format . La matrice nulle est la matrice de transformation linéaire qui amène tous les vecteurs au vecteur nul, toujours de formats appropriés. On démontre que la transformation amène tous les vecteurs à l'origine. On précise les dimensions des matrices et des vecteurs. Soit un vecteur . Alors, Donc, puisque la matrice amène tous les vecteurs à l'origine, c'est donc la matrice nulle. Ainsi, .     On procède de façon semblable. Soit un vecteur . Alors, Donc, puisque la matrice amène tous les vecteurs à l'origine, c'est donc la matrice nulle. Ainsi, .    Considérer la matrice inversible et le nombre réel non nul . Démontrer que . Noter que cet exercice est la démonstration de la propriété .   Pour démontrer qu'une matrice est l'inverse d'une matrice , il faut démontrer que .   Tel que suggéré dans l'indication, on montre que est bel et bien l'inverse de en les multipliant. Si le résultat donne la matrice identité, on aura démontré que .     Pour chacun des énoncés suivants, les matrices sont censées être carrées, de format approprié et inversibles lorsque nécessaire. Donner une preuve si l'énoncé est vrai, ou donner un contrexemple si l'énoncé est faux.     Cet énoncé est faux, en général. On en donne un contrexemple. Pour se simplifier la tâche, on utilise des matrices . Soit et , alors   Si est inversible et que , alors .   Cet énoncé est vrai. En effet,   Si n'est pas inversible et que , alors .   Cet énoncé est faux. On donne un contrexemple avec des matrices . Soit , et , alors Mais, .   Si est inversible et qu'on interchange deux colonnes (ou deux lignes) pour obtenir la matrice , alors est inversible.   Trouver une matrice telle que ou et utiliser la proposition .   Cet énoncé est vrai. On considère que si une matrice est carrée, alors elle est inversible. Soit , une matrice carrée inversible d'ordre . On définit , une matrice qui permet de permuter ou d'interchanger deux colonnes. La démarche serait très semblable pour les lignes en multipliant au lieu de . Pour les matrices , cette matrice est toujours : , puisque l'on n'a qu'une seule option. En effet, pour , on voit que: . Cette matrice est toujours inversible et est même sa propre inverse, puisqu'en réfléchissant en termes de transformations linéaires, comment fait-on pour ramener les colonnes permutées à leur emplacement initial? On les permute à nouveau et de la même manière. C'est toujours une matrice de symétrie que l'on construit. Lorsqu'on trouve une telle matrice pour effectuer les permutations, on montre immédiatement que est inversible. En effet, . Bref, afin de généraliser cette situation, il ne nous reste qu'à fournir une matrice de permutation qui permet d'échanger la colonne avec la colonne . Cette matrice est simplement la matrice identité où l'on a interchangé les colonnes et . Bref, . Par exemple, dans , la matrice de permutation des colonnes et est: . On remarque finalement que, puisque permuter deux colonnes de la matrice identité ou deux lignes de la matrice identité donne exactement la même matrice, les matrices de permutation de lignes et de colonnes sont les mêmes. La permutation des lignes ou des colonnes d'une matrice se produira selon si l'on multiplie à droite ou à gauche. On pourrait en dire beaucoup plus long, mais on s'arrête ici!   Si possède une ligne de zéros, alors n'est pas inversible.   Utiliser la propriété .   Cet énoncé est vrai. Comme suggéré dans l'indication, on utilise la propriété . Il faut trouver un vecteur pour lequel il est impossible de trouver un vecteur tel que . Un exemple simple est un vecteur qui ne possède que des zéros, sauf à la position correspondant à la ligne de zéros de la matrice. Ce vecteur est en fait où la i-ème ligne de la matrice est nulle. Sans perdre trop de généralité, si la première ligne de est nulle, on écrit Quand on multiplie cette matrice par , par l'équation , on peut faire , peu importe le vecteur choisi. La preuve serait semblable si l'on choisissait une autre ligne nulle dans la matrice .   Si , alors .   Cet énoncé est vrai. On le démontre en multipliant avec pour obtenir la matrice identité et ainsi démontrer que est bien l'inverse de .    En utilisant, lorsque c'est possible, le fait que peut s'écrire sous la forme , répondre aux questions suivantes:   Trouver un vecteur tel que .     On calcule simplement la matrice à l'aide de la formule et on la multiplie à gauche par le vecteur . Puis, on fait la multiplication.   Trouver un vecteur tel que .     On calcule simplement la matrice à l'aide de la formule et on la multiplie à gauche par le vecteur . Puis, on fait la multiplication.   Trouver un vecteur tel que son image par une rotation de est le vecteur .     C'est essentiellement la même question, mais la matrice est une matrice de rotation de . On pourrait simplement utiliser la formule pour obtenir l'inverse. Cependant, en réfléchissant, on réalise que l'inverse d'une rotation de est une rotation de . Ainsi, Et donc, on calcule le vecteur :    Trouver deux vecteurs tels que et .   et   On effectue d'abord l'inversion de matrice suivie de la multiplication de cet inverse par les vecteurs voulus pour calculer et . Ainsi, et    Trouver un vecteur tel que , sans calculer la matrice inverse.     Cette transformation linéaire est un étirement vertical de facteur , selon l'équation . Ainsi, la question est de savoir quel vecteur, si on l'étire verticalement de facteur , donnera le vecteur . Puisque l'étirement n'affecte pas la coordonnée en , on sait que la première composante du vecteur cherchée est . Pour la seconde, il faut simplement diviser par , ce qui donne aussi . Bref, le vecteur est . Vérifions que c'est la bonne réponse.    Du point de vue géométrique, une matrice de la forme ou est une matrice de cisaillement, dont l'effet est illustré à l'activité interactive . Donner l'effet algébrique d'un cisaillement et son inverse, en justifiant géométriquement et algébriquement.   Les transformations \"cisaillement\"     Pour la partie algébrique, multiplier les matrices par un vecteur quelconque et analyser l'effet.   Géométriquement, on peut observer qu'un cisaillement horizontal, par exemple, prend le carré original et déplace son côté supérieur vers la droite créant ainsi un parallélogramme de côtés supérieurs et inférieurs égaux aux côtés du carré original. Cependant, les côtés verticaux deviennent beaucoup plus longs. Essentiellement, si l'on regarde l'effet sur les vecteurs de base, on voit, dans les colonnes de la matrice, que et n'est donc pas déplacé. Pour l'autre colonne, on apprend que . Géométriquement, c'est un déplacement du vecteur vers la droite. Il conserve sa coordonnée en , mais on lui ajoute une coordonnée en de valeur . En résumé, Ainsi, pour un vecteur quelconque , on a: Dans cette dernière équation, on voit ce que le mot horizontal signifie dans l'expression cisaillement horizontal . C'est la coordonnée qui changera ( ), de façon proportionnelle à la coordonnée . Une analogie pour ce genre de cisaillement est celle du vent. On s'imagine un vent se dirigeant vers la droite sur la figure. Si le carré est fait d'un matériau assez souple, mais qu'il est bien ancré dans le sol (axe des ), alors il se déplacera selon le cisaillement horizontal illustré en bleu. Plus la valeur est grande, plus le vent est fort!  Pour ce qui est de l'inverse, on peut intuitivement penser que, pour défaire un cisaillement, on doit avoir le déplacement en sens inverse. Ainsi, on a:   Le cisaillement vertical est défini de façon semblable. On le résume ainsi: ou bien ainsi: Son inverse sera:     La figure montre un vecteur , de même que son effet par une transformation et la composition des transformations . On cherche à déterminer la matrice de la transformation .   La transformation intérieure d'une composition, géométriquement    Répondre aux questions suivantes:   Expliquer comment trouver la transformation à partir des informations données.   On peut procéder de diverses façons, mais généralement, on veut trouver l'effet de sur les vecteurs et . Cependant, pour y arriver, il faudra d'abord trouver la matrice . En plaçant en premier lieu le vecteur sur , on obtient , qui sera la première colonne de . Ensuite, en déplaçant le vecteur sur , on obtient , qui sera la deuxième colonne de . Maintenant que nous avons la matrice , si l'on observe attentivement l'autre information fournie, on réalise qu'en multipliant à gauche par , il est possible d'obtenir et donc ainsi que , en repositionnant aux endroits voulus.   Comparer cet exercice à l'exemple . Pourquoi à ce moment n'a-t-on pas demandé de trouver sachant l'effet de et de la composition .   La réponse est simple: nous ne connaissions pas l'inversion matricielle. C'était donc impossible à ce moment-là!    Déterminer les dimensions possibles de chaque matrice de l'exemple .    Pour l'équation , on avait obtenu . La matrice doit être carrée (disons ) puisqu'on calcule son inverse. Les matrices et doivent être de même format et, puisqu'on les multiplie à gauche par , leur format sera . Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et sont de même format et elles sont carrées, disons . La matrice doit donc être de format pour être compatible. Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et sont inversées, elles doivent donc être carrées, par exemple et respectivement. Pour être compatible, la matrice doit donc être de format . Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et étant soustraites puis inversées, elles se doivent d'être de même format et carrées, par exemple . La matrice doit donc être de format pour être compatible. Finalement, doit être carrée puisqu'on l'inverse dans l'équation de départ. Son format devrait être de , mais puisqu'elle doit être carrée, elle devra être de . La conséquence est que doit être de format pour être compatible. Bref, toutes les matrices doivent être carrées et de même format ( ).     Un étirement quelconque dans Dans , un étirement de direction et de facteur est une transformation linéaire telle que et . Autrement dit, la transformation étire la direction d'un facteur et laisse la direction perpendiculaire inchangée.  On considère un étirement dans la direction et de facteur . Déterminer la matrice de cette transformation en utilisant la formule .     On Commençe par énoncer l'effet de notre transformation sur les vecteurs et . Si est la matrice de transformation de l'étirement , alors On écrit ces résultats sous forme matricielle en incluant les deux vecteurs. Il ne reste qu'à isoler . Donc, on obtient    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Donner l'inverse des matrices suivantes. Vérifier en effectuant la multiplication pour obtenir l'identité.      Le code solution pour la matrice A de l'exercice   A=matrix([[3,-1],[0,-3]]) Ainv=A.inverse() show(\"A=\",A) show(\"A^(-1)=\",Ainv) show(\"AA^(-1)=\",A*Ainv)    On peut simplement remplacer la matrice initiale et exécuter le code à nouveau pour calculer l'inverse de B, puis de C.   Considérer les matrices et de l'exercice . Vérifier que à l'aide de Sage (équation ). Il est possible de calculer les résultats ou simplement de comparer en utilisant la double égalité == .    Le code solution pour l'exercice   B=matrix([[2,-2,1],[-1,5,1],[2,1,3]]) Binv=B.inverse() show(\"B=\",B) show(\"B^(-1)=\",Binv) C=matrix([[1\/2,-1,-2],[2,0,1\/5],[1\/3,3,4\/3]]) Cinv=C.inverse() show(\"C=\",C) show(\"C^(-1)=\",Cinv) BC=B*C BCinv=BC.inverse() show(\"C^(-1)B^(-1)=\",Cinv*Binv) show(\"(BC)^(-1)\",BCinv) show(Cinv*Binv==BCinv)    On a vérifié l'équation des deux façons proposées.   Les étirements quelconques  En se basant sur l'exercice , on souhaite trouver la formule d'un étirement dans de direction et de facteur .  Utiliser Sage pour déterminer la matrice. Essayer de le faire en créant une fonction etirR2(u,k) qui retournera la matrice.       Le code solution pour l'exercice   u1,u2,k =var('u1,u2,k') def etirR2(u,k): uperp=vector([-u[1],u[0]]) #Le vecteur u perpendiculaire U=column_matrix([u,uperp]) #La matrice U V=column_matrix([k*u,uperp]) #La matrice V T=V*(U.inverse()) #La transformation return T show(etirR2(vector([u1,u2]),k).simplify_full())    Remarquer qu'on a utilisé la commande simplify_full() afin d'avoir une forme plus compacte.    On s'intéresse à la matrice inverse des matrices de permutation.   À l'aide du code de l'exercice , déterminer combien de matrices de permutation sont leur propre inverse. Faire une liste des matrices de permutation qui sont leur propre inverse et une autre liste des matrices qui ne le sont pas.     Le code solution pour l'exercice   def perm_matrix(n): Id=identity_matrix(n) col=Id.columns() p=Permutations(n).list() L=list() for perm in p: colperm=list() for j in range(len(perm)): colperm.append(col[perm[j]-1]) P=column_matrix(colperm) L.append(P) return L P4=perm_matrix(4) P4propreinverse=list() #Nouvelle liste vide for M in P4: if M*M==identity_matrix(4): #Si la matrice de permutation au carrée donne l'identité, alors ... P4propreinverse.append(M) #... on l'ajoute à la liste. P4propreinverse P4autreinverse=P4.copy() #Voir la remarque en bas sur la création de copies for M in P4propreinverse: #Si la matrice se trouve dans la liste des matrices qui sont leur propre inverse, alors... P4autreinverse.remove(M) #... on la retire de la liste complète copiée. show(\"Le nombre de matrices de permutation 4x4 est de \", len(P4)) show(\"Voici ces matrices de permutation 4x4 :\",P4) show(\"Le nombre de matrices de permutation 4x4 qui sont leur propre inverse est de \", len(P4propreinverse)) show(\"Voici ces matrices qui sont leur propre inverse :\", P4propreinverse) show(\"Le nombre de matrices de permutation 4x4 qui ne sont pas leur propre inverse est de \", len(P4autreinverse)) show(\"Celles-ci ne sont pas leur propre inverse :\",P4autreinverse)     Une remarque concernant les copies créées simplement avec \"=\"   L1=[1,2,3,4,5] L2=L1 #On veut créer une copie de travail de la liste L1 L2.remove(4) show(L1) #Malheureusement, on a altéré L1 en voulant uniquement modifier L2. L3=L1.copy() #Cette commande permet d'éviter que les deux listes deviennent liées. L3.remove(3) show(L1) show(L2) show(L3)     Qu'est-ce qui caractérise une matrice de permutation qui est son propre inverse?    La principale caractéristique des matrices de permutation qui sont leur propre inverse est que les permutations ne se font que deux à deux. Par exemple, considérer les matrices . On regarde l'effet de ces matrices dans Sage sur un vecteur .   On voit que les matrices permutent les composantes et du vecteur entre elles, avec qui permute également avec . Par contre, envoie à la position de , à la position de et à la position de . Le lecteur intéressé d'en apprendre plus peut se renseigner sur les cycles d'une permutation. On applique une seconde fois les matrices au vecteur . Peut-on prédire ce qui va se passer?   Puisque dans et les entrées permutent en paires, une application double de la permutation revient à ne rien faire. Par contre, pour , les entrées permutent selon un cycle de longueur trois. On a donc besoin d'une troisième application pour revenir à l'identité.     On souhaite utiliser Sage pour vérifier certaines des égalités de l'exemple , en utilisant des matrices compatibles d'une taille \"arbitraire\", un peu comme on l'a fait dans l'exemple .  Pour chaque énoncé de l'exemple , utiliser Sage pour \"vérifier\" l'égalité. Les dimensions des matrices ont été trouvées à l'exercice .    On recopie la définition de la fonction de l'exemple que l'on utilisera pour chaque équation. On doit donc la recopier au début du code. On conseille de réutiliser le même code chaque fois et de modifier uniquement les matrices et l'équation à vérifier. Attention: l'exécution du code peut prendre un certain temps, surtout si l'on choisit des matrices de grands formats. Noter qu'on n'a pas à définir la matrice puisqu'elle est créée par l'équation où on l'a isolée.   Le code où l'on définit la fonction matquelc   def matquelc(m,n,lettre): a=str(lettre) #On s'assure que lettre est un caractère de la forme \"a\" liste=[] #Création d'une liste vide for i in range(m): for j in range(n): #On itère sur les lignes (i de 0 à m-1) et les colonnes (j de 0 à n-1) liste.append('%s_%d%d'%(a,i+1,j+1)) #On ajoute à la fin de la liste (append) la chaine a_i+1j+1 , les +1 paliant au fait que range(k) va de 0 à k-1 M=matrix(SR,m,n,liste) #On crée une matrice mxn à partir de liste (Le SR dit à sage que la matrice est symbolique. Il n'est pas nécessaire de comprendre son rôle) return M #La fonction retourne la matrice M      Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   #Ne pas oublier de recopier la définition de la fonction matquelc donnée plus haut. A=matquelc(3,3,'a') B=matquelc(2,3,'b') C=matquelc(2,3,'c') X=(C-B)*(A^(-1)) X*A+B==C     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(2,2,'a') B=matquelc(2,3,'b') I=I3=identity_matrix(2) X=-((A-I)^(-1))*B A*X+B==X     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(3,3,'a') B=matquelc(2,2,'b') D=matquelc(3,2,'d') X=(A^(-1))*D*(B^(-1)) A*X*B==D     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(2,2,'a') B=matquelc(2,2,'b') C=matquelc(2,2,'c') X=((C-B)^(-1))*A A*(X^(-1))+B==C        Une fonction pour trouver l'inverse Dans cet exercice, on cherche à créer une fonction qui donne automatiquement la réponse à un exemple de la figure interactive en fonction des informations données. On appellera la fonction inversecompo(T11,T12,C1,C2) où sont respectivement les première et deuxième colonnes de la matrice de la transformation et sont respectivement les première et deuxième colonnes de la matrice de la transformation .  Créer cette fonction et utiliser la figure pour la tester.     Le code solution pour l'exercice   def inversecompo(T11,T12,C1,C2): T1=column_matrix([T11,T12]) T1inv=T1.inverse() C=column_matrix([C1,C2]) T2=T1inv*C return T2        "
},
{
  "id": "def-transfoinverseprelim",
  "level": "2",
  "url": "sec-matinverse.html#def-transfoinverseprelim",
  "type": "Définition",
  "number": "2.3.1",
  "title": "La transformation inverse, définition préliminaire.",
  "body": " La transformation inverse, définition préliminaire  Soit , une transformation linéaire. La transformation inverse de , notée , est une transformation telle que pour tout dans le domaine de .  "
},
{
  "id": "rem-invprelim",
  "level": "2",
  "url": "sec-matinverse.html#rem-invprelim",
  "type": "Remarque",
  "number": "2.3.2",
  "title": "Une précision sur l’inverse.",
  "body": " Une précision sur l'inverse  Dans la définition, il n'est pas mentionné que la transformation inverse est une transformation linéaire. Comme on peut interpréter l'équation de manière matricielle, on cherche l'existence d'une matrice telle que pour tout vecteur dans le domaine de , c'est-à-dire une transformation telle que . En vertu de la proposition , si une telle matrice existe, alors est une transformation linéaire.  "
},
{
  "id": "ex-transfor2inv",
  "level": "2",
  "url": "sec-matinverse.html#ex-transfor2inv",
  "type": "Exemple",
  "number": "2.3.3",
  "title": "L’inverse de transformations géométriques.",
  "body": " L'inverse de transformations géométriques  On considère les transformations de la liste et l'on cherche à les inverser, si possible.   La transformation identité n'a aucun effet sur les vecteurs de . Ainsi, si l'on la compose avec elle-même, on restera avec l'identité. L'inverse de est donc .    Afin de défaire une réflexion par rapport à l'axe des , il semble suffisant d'appliquer à nouveau la réflexion. On aurait donc . On vérifie algébriquement que c'est le cas. . L'inverse de cette réflexion est donc en effet la réflexion même.    Pour défaire une rotation de , il semble logique de faire une rotation de , correspondant en fait à une rotation dans le sens horaire. Selon l'équation , cette matrice serait . Algébriquement, on a . La transformation inverse de la rotation de est donc bel et bien une rotation dans le sens opposé. Il est intéressant de remarquer que et qu'on a aussi . On vérifiera plus tard si cela se produit toujours.    Un étirement horizontal multiplie la première composante d'un vecteur par . Pour défaire cette transformation, on devrait diviser cette composante par , ce qui donnerait un étirement de facteur . Ici se présente un premier problème dans la recherche d'inverse. En effet, si , il est impossible de diviser par et donc l'inverse, s'il existe, ne serait pas un étirement de facteur . On débute par considérer le cas avant de réfléchir à ce que représente un étirement de facteur et son inverse. Ainsi, si , on a . Ainsi, si .  On considère maintenant le cas . La matrice de l'étirement est . On affirme dès le départ qu'il ne peut exister d'inverse pour cette transformation. En effet, soit , la matrice représentant l'inverse. Selon la définition , il faut que . En particulier, il faudrait que selon la définition du produit matriciel , puisque est la première colonne de et la première colonne de la matrice identité. Selon la proposition , l'image du vecteur nul sera toujours le vecteur nul et en conséquence, il est impossible d'avoir comme résultat.  Il est cependant possible que l'inverse existe, mais ne soit pas une transformation linéaire. Quand on précisera la définition , cette possibilité sera invalidée.    La solution pour l'inverse de est donnée à l'exercice .    Il est évident que, si les composantes d'un vecteur ont été permutées, cette même permutation redonnera le vecteur initial. Ainsi, . La vérification algébrique est laissée au lecteur.    On est forcé, une fois de plus, à réfléchir à la signification de l'inverse d'une transformation avec le cas de la projection orthogonale. Si l'on pense aux fonctions réelles traditionnelles et à leur inverse, il en quelque ressort chose de commun. L'inverse de la fonction est , pour autant que . La fonction a pour inverse le logarithme naturel, . Dans chacun de ces cas, on remarque pour chacun des dans le domaine, il correspond un seul dans l'image tel que . Si l'on regarde la fonction , celle-ci ne respecte pas cette condition. Par exemple, .  Lorsqu'on veut inverser la fonction , on parle souvent de la racine carrée. Cet inverse ne fonctionne toutefois que pour des valeurs de (un choix a été fait de considérer cette branche plutôt que l'autre). De même, pour inverser la fonction , on ne considère que les valeurs de . Sur chacune de ces branches, il n'existe qu'une seule paire de nombres tels que . Ainsi, on peut inverser la fonction sans problème.  On revient à la projection. Pour un vecteur parallèle à , il existe une infinité de vecteurs tels que . Comment choisir l'inverse de dans ce cas, parmi l'infinité de possibilités? On préfère ne pas choisir dans ce cas et dire que la projection orthogonale ne possède pas d'inverse.  En approfondissant notre intuition géométrique dans les prochaines sections, on comprendra davantage la raison de l'inexistence de l'inverse de la projection. On peut s'imaginer, en quelque sorte, qu'il y a une perte d'information lorsque la projection est appliquée et qu'il n'est pas possible de revenir en arrière.  L'analogie de l'ombre, souvent utilisée pour les projections orthogonales ou autres, peut aider. En effet, il est facile de réaliser qu'on ne peut pas reconstruire l'objet initial à partir seulement de son ombre. Qui n'a jamais utilisé ses mains pour créer des ombres de monstres effrayants à l'aide d'une lampe de poche?   "
},
{
  "id": "ex-matinverse1",
  "level": "2",
  "url": "sec-matinverse.html#ex-matinverse1",
  "type": "Exemple",
  "number": "2.3.4",
  "title": "Un premier calcul de matrice inverse.",
  "body": " Un premier calcul de matrice inverse   On considère la matrice . On cherche l'inverse de cette transformation, dans l'hypothèse que l'inverse existe.    On cherche une matrice telle que . En appliquant la définition de la multiplication, on trouve deux équations vectorielles et . Si l'on pose , on obtient une paire de systèmes à deux équations deux inconnues. D'une part, et d'autre part .  En prenant la première composante des équations et , qui ne contiennent que les variables et , on obtient . La seconde de ces équations permet d'obtenir , puis en substituant dans la première, on détermine . On a alors .  En prenant la deuxième composante des équations et , qui ne contiennent que les variables et , on obtient . La première de ces équations permet d'obtenir , puis en substituant dans la seconde, on détermine . On a alors .  Ainsi, la matrice inverse doit être . Une vérification ne fait jamais de tort: .   "
},
{
  "id": "ex-matinverse2",
  "level": "2",
  "url": "sec-matinverse.html#ex-matinverse2",
  "type": "Exemple",
  "number": "2.3.5",
  "title": "Calcul de l’inverse avec la formule.",
  "body": " Calcul de l'inverse avec la formule  On reprend la matrice de l'exemple et l'on détermine son inverse avec la formule . On obtient , qui correspond à ce qui a été obtenu plus tôt.  "
},
{
  "id": "sageex-inv2x2",
  "level": "2",
  "url": "sec-matinverse.html#sageex-inv2x2",
  "type": "Calcul",
  "number": "2.3.6",
  "title": "Les matrices inverses sur Sage.",
  "body": " Les matrices inverses sur Sage  Sur Sage, on peut calculer facilement l'inverse d'une matrice  en utilisant la commande A.inverse() . On pourra bien entendu vérifer avec la multiplication matricielle que le calcul est bon.   Si l'inverse n'existe pas, Sage retourne une erreur, comme le montre le code suivant     On fait maintenant un exemple en référence à l'équation , qui stipule que si l'on connait l'effet d'une transformation sur deux vecteurs, alors on peut déterminer la matrice associée à la transformation sans calculer directement l'image des vecteurs et (pour le cas ).  On considère donc une transformation linéaire telle que et . On cherche la matrice représentant . Avec Sage et l'équation , on a   Afin de vérifier, on peut calculer les images des vecteurs et .   Évidemment, on aurait pu calculer et vérifier que l'on obtient , mais on s'est permis ici de rappeler la commande U.column() qui permet d'accéder aux colonnes d'une matrice. Il est pratique de travailler de cette manière plutôt que, par exemple, définir manuellement u1=vector([2,4]) . L'idée est que si, pour une raison quelconque, on décidait de changer la matrice , il suffirait de changer seulement la ligne où est définie. Ceci est résumé dans le conseil ci-dessous.  "
},
{
  "id": "con-defefficace",
  "level": "2",
  "url": "sec-matinverse.html#con-defefficace",
  "type": "Conseil",
  "number": "2.3.7",
  "title": "Utilisation efficace de l’informatique.",
  "body": " Utilisation efficace de l'informatique  L'un des buts de utilisation de l'informatique est de lui déléguer certains calculs, afin de se concentrer davantage sur les concepts. Il faut toutefois être efficace dans son utilisation afin de bénéficier de sa flexibilité et de toute sa puissance. On illustre avec un exemple.  Soit . On cherche à calculer la quantité pour cette matrice. Si ce nombre n'est pas zéro, on veut calculer . Voici une première option.   Présentée ainsi, la séquence d'instructions ressemble à ce qui serait fait sur une feuille, les commandes étant effectuées dans l'ordre où l'on se pose les questions pertinentes lors de la résolution. Maintenant si l'on pose les mêmes questions pour la matrice , on s'imagine recopier le code et corriger les lignes 2-5 et la ligne 8 .  Voici une deuxième option pour répondre aux questions initiales.   Maintenant, pour répondre aux questions avec la matrice , seule la ligne 2 doit être éditée.  "
},
{
  "id": "rem-transfodomim",
  "level": "2",
  "url": "sec-matinverse.html#rem-transfodomim",
  "type": "Remarque",
  "number": "2.3.8",
  "title": "Le domaine et l’image d’une transformation linéaire.",
  "body": " Le domaine et l'image d'une transformation linéaire  Les prochains résultats concernent le domaine et l'image d'une transformation linéaire. On rappelle que selon la proposition , une matrice est une transformation linéaire de vers . Le chapitre explore en profondeur domaine, image et zéros d'une transformation linéaire.  Pour ce qui suit, on s'intéresse seulement aux matrices carrées .  "
},
{
  "id": "prop-investsurj",
  "level": "2",
  "url": "sec-matinverse.html#prop-investsurj",
  "type": "Proposition",
  "number": "2.3.9",
  "title": "Les transformations inversibles atteignent tous les vecteurs de leur image.",
  "body": " Les transformations inversibles atteignent tous les vecteurs de leur image   Si est une matrice possédant un inverse au sens de la définition et de la remarque , alors pour tout , il existe tel que . Cela signifie que chaque vecteur de (l'image) est atteint par la transformation d'un vecteur de (domaine). De plus, le vecteur est unique.    Soit , un vecteur de l'image de . On cherche tel que . Puisque possède un inverse , on a .  Ainsi, il existe tel que et l'on peut explicitement le calculer à l'aide de l'inverse.  L'unicité est une conséquence du fait que la matrice inverse est unique, ce qui sera démontré à la proposition . Ainsi, si était tel que , on aurait aussi . L'unicité de l'inverse assure que .   "
},
{
  "id": "prop-surjestinv",
  "level": "2",
  "url": "sec-matinverse.html#prop-surjestinv",
  "type": "Proposition",
  "number": "2.3.10",
  "title": "Les transformations atteignant chaque vecteur de leur image sont l’inverse d’une transformation.",
  "body": " Les transformations atteignant chaque vecteur de leur image sont l'inverse d'une transformation  Soit , une matrice telle que pour tout , il existe telle que , alors est l'inverse d'une matrice , au sens de la définition et de la remarque . Cela signifie qu'il existe une matrice telle que .   Soit , les vecteurs colonnes de la matrice identité. Par hypothèse sur , il existe des vecteurs tels que pour chacun des .  On pose . On a alors puisque la colonne de est donnée par .   "
},
{
  "id": "thm-invgauchedroite",
  "level": "2",
  "url": "sec-matinverse.html#thm-invgauchedroite",
  "type": "Théorème",
  "number": "2.3.11",
  "title": "L’inverse d’une matrice carrée est bilatéral.",
  "body": " L'inverse d'une matrice carrée est bilatéral   Soit , une matrice carrée pour laquelle il existe telle que . Alors .    Puisque possède un inverse au sens de la définition , la proposition dit que chaque valeur de son image est atteinte par une valeur de son domaine.  De plus, la proposition affirme qu'il existe une matrice telle que , c'est-à-dire que est l'inverse d'une matrice au sens de la définition . On a alors . Ainsi l'inverse de l'inverse de est . On dira aussi que l'inverse à gauche de est le même que son inverse à droite.   "
},
{
  "id": "def-matcarreeinverse",
  "level": "2",
  "url": "sec-matinverse.html#def-matcarreeinverse",
  "type": "Définition",
  "number": "2.3.12",
  "title": "L’inverse d’une matrice carrée.",
  "body": " L'inverse d'une matrice carrée  Soit , une matrice carrée. On dit que est inversible s'il existe une matrice telle que .  En ce qui concerne les transformations linéaires, on dit que la transformation de vers est inversible s'il existe une transformation linéaire de vers telle que pour tout vecteur .  "
},
{
  "id": "rem-obtenirinverse",
  "level": "2",
  "url": "sec-matinverse.html#rem-obtenirinverse",
  "type": "Remarque",
  "number": "2.3.13",
  "title": "Obtenir l’inverse d’une matrice.",
  "body": " Obtenir l'inverse d'une matrice  Ensemble, les propositions et , combinées à la définition donnent un critère pour déterminer si une matrice carrée possède un inverse. Il faut que l'équation possède une solution pour tout . L'exercice montre qu'en fait, il est suffisant d'avoir une solution pour les vecteurs .  De plus, la proposition donne une démarche explicite pour obtenir l'inverse. Pour chaque vecteur , on cherche un vecteur tel que . La matrice inverse est alors .  "
},
{
  "id": "ex-matinverse3",
  "level": "2",
  "url": "sec-matinverse.html#ex-matinverse3",
  "type": "Exemple",
  "number": "2.3.14",
  "title": "Calcul d’une matrice inverse.",
  "body": " Calcul d'une matrice inverse  On considère la matrice de l'exemple . On calcule son inverse à l'aide de la méthode de la proposition , en tenant compte de la précision faite à la remarque .  Il est intéressant de s'attarder à la différence entre la méthode explicitée à l'exemple , et dans le paragraphe qui suit cet exemple, et la méthode effectuée ci-dessous basée sur la remarque .  Bien entendu, pour une matrice , la formule permet d'obtenir l'inverse sans faire beaucoup de calculs, mais on verra qu'avec une matrice de taille plus grande, il est plus difficile de trouver une formule générale et il est plus simple de rechercher les vecteurs colonnes de l'inverse.    On cherche un vecteur tel que et un vecteur tel que . On a et . Pour le premier système, on trouve en comparant les deuxièmes composantes des vecteurs de l'équation que . En remplaçant dans l'équation , on trouve , ce qui donne . On déduit alors   Pour le second système, en suivant une méthode similaire, on trouve et . Cela correspond évidemment à ce qui avait été trouvé aux exemples et .   "
},
{
  "id": "thm-delamatriceinversev1",
  "level": "2",
  "url": "sec-matinverse.html#thm-delamatriceinversev1",
  "type": "Théorème",
  "number": "2.3.15",
  "title": "Théorème de la matrice inverse, première version.",
  "body": " Théorème de la matrice inverse, première version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .     Le fait que la matrice inverse implique l'existence d'une solution unique à l'équation est le résultat de la proposition .  Le fait qu'une solution unique à l'équation implique que la matrice soit inversible est le résultat de la proposition .  "
},
{
  "id": "sageex-matinv",
  "level": "2",
  "url": "sec-matinverse.html#sageex-matinv",
  "type": "Calcul",
  "number": "2.3.16",
  "title": "Retour sur les matrices inverses sur Sage.",
  "body": " Retour sur les matrices inverses sur Sage  Avec l'aide de la définition , on regarde à nouveau des calculs de matrices inverses sur Sage. Plus précisément, on compare la multiplication à gauche et à droite par l'inverse afin de vérifier l'égalité avec la matrice identité.   Il peut être utile aussi de savoir que, pour calculer l'inverse, on peut utiliser A^(-1) , qui se rapproche davantage de la notation mathématique usuelle.   "
},
{
  "id": "prop-inverseunique",
  "level": "2",
  "url": "sec-matinverse.html#prop-inverseunique",
  "type": "Proposition",
  "number": "2.3.17",
  "title": "L’inverse d’une matrice carrée est unique.",
  "body": " L'inverse d'une matrice carrée est unique  Soit , une matrice carrée et , deux matrices telles que et . Alors .   L'égalité suit des propriétés de la multiplication matricielle et du fait que si , alors (théorème ). .   "
},
{
  "id": "prop-inverseproduit",
  "level": "2",
  "url": "sec-matinverse.html#prop-inverseproduit",
  "type": "Proposition",
  "number": "2.3.18",
  "title": "L’inverse d’un produit.",
  "body": " L'inverse d'un produit  Soit et , deux matrices carrées d'ordre . Alors le produit est inversible si et seulement si les matrices sont inversibles. De plus, on a .   On commence en supposant que les matrices sont inversibles. Avant de s'embarquer dans des manipulations algébriques abstraites, on réfléchit un instant sur la signification de la proposition. Si deux transformations sont inversibles et qu'on les compose, c'est-à-dire qu'on les fait l'une après l'autre, il n'y a alors pas de raison apparente qui ferait en sorte que cette composition ne soit pas inversible. De plus, il semble que pour revenir sur le vecteur original, il suffit de faire les transformations inverses dans l'ordre inverse. Il paraît donc assez intuitif que D'un point de vue algébrique, on vérifie facilement que . Il ne reste donc qu'à vérifier l'existence de l'inverse.  Soit un vecteur de l'image de . On cherche telle que . En vertu de la proposition , si existe, la matrice est inversible. On construit en inversant successivement les matrices et . Tel qu'attendu . Comme les matrices et existent, le vecteur existe. Ainsi, la matrice possède toujours un inverse.  On suppose maintenant que et sont deux matrices telles que leur produit est inversible. Il existe alors une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire ce qui donne, toujours selon la définition , que la matrice est inversible.  La preuve que possède un inverse est laissée à l'exercice .   "
},
{
  "id": "prop-invdeinv",
  "level": "2",
  "url": "sec-matinverse.html#prop-invdeinv",
  "type": "Proposition",
  "number": "2.3.19",
  "title": "L’inverse de l’inverse.",
  "body": " L'inverse de l'inverse   Soit , une matrice inversible qui possède un inverse . Alors .    Cela découle directement du théorème .    "
},
{
  "id": "prop-invdematscalaire",
  "level": "2",
  "url": "sec-matinverse.html#prop-invdematscalaire",
  "type": "Proposition",
  "number": "2.3.20",
  "title": "L’inverse pour la multiplication par un scalaire.",
  "body": " L'inverse pour la multiplication par un scalaire  Soit , une matrice inversible qui possède un inverse et , un scalaire non-nul. Alors, .   La preuve est laissée au lecteur à l'exercice .  "
},
{
  "id": "ex-algmat1",
  "level": "2",
  "url": "sec-matinverse.html#ex-algmat1",
  "type": "Exemple",
  "number": "2.3.21",
  "title": "Algèbre matricielle.",
  "body": " Algèbre matricielle  Soit et , des matrices. On cherche à isoler dans l'équation .  Quelles sont les conditions sur les matrices pour qu'il soit possible d'isoler .   On isole , sans se soucier des conditions sur les matrices. On les déterminera après avoir effectué les opérations algébriques. On a donc .  Il faut donc que et soient de même format, puisqu'on les soustrait. De plus, on utilise l'inverse de . Il faut donc que soit une matrice carrée. Techniquement, ce n'est pas vrai, pourrait posséder un inverse à droite si elle est rectangulaire. Voir la section . Si est une matrice , il faut que ait lignes. Sans obligation sur le nombre de colonnes, on peut supposer qu'il y en a . Les matrices sont donc de format .  Le produit sera une matrice et donc, le format de sera . C'est également compatible avec l'équation initiale puisque est de format et qu'on additionne à ce produit la matrice ( ) pour avoir la matrice (aussi ).   "
},
{
  "id": "ex-algmat2",
  "level": "2",
  "url": "sec-matinverse.html#ex-algmat2",
  "type": "Exemple",
  "number": "2.3.22",
  "title": "Algèbre matricielle, deuxième partie.",
  "body": " Algèbre matricielle, deuxième partie   Pour chaque équation ci-dessous, isoler la matrice , en supposant que les formats sont appropriés et que les matrices devant être inversées sont inversibles.           Similairement à l'exemple , on a .    On commence par regrouper les termes ayant la matrice d'un côté. On obtient alors .    On a .    On commence par poser . L'expression devient , équivalente à celle de l'exemple . On a donc . Puisque , on a .    "
},
{
  "id": "sageex-algmat",
  "level": "2",
  "url": "sec-matinverse.html#sageex-algmat",
  "type": "Calcul",
  "number": "2.3.23",
  "title": "L’algèbre matricielle avec Sage.",
  "body": " L'algèbre matricielle avec Sage  Parfois, il est pratique de travailler avec des matrices génériques, de manière purement algébrique, sans se soucier des entrées spécifiques des matrices. Malheureusement, Sage ne permet pas (encore) l'utilisation de variables pour des matrices comme on l'a fait dans les exemples et . On fait un compromis en se créant une matrice arbitraire de taille fixe. Les calculs faits ainsi ne pourront donc pas être considérés comme des preuves des identités, mais au moins une vérification qui est plus générale qu'un exemple précis.  On doit, dans un premier temps, créer une matrice dont les entrées seront arbitraires, par exemple .  Pour cela, on se sert du constructeur de matrices à partir d'une liste. Par exemple, pour créer une matrice dont les entrées seraient les nombres de à , enumérées ligne par ligne, on peut utiliser la suite d'instructions suivante.   On veut donc créer une fonction Sage qui, étant donné des dimensions et un paramètre alphabétique, retournera une matrice de taille dont les entrées seront dénotées par la lettre choisie indicée de la position, comme à l'équation . Voici une manière d'y arriver, avec commentaire dans le code.   On appelle maintenant le code pour créer deux matrices avec des indices respectifs et .   On remarque que les fonctions sage utilisées ne permettent pas d'écrire . Les entrées pourraient porter à confusion si la taille était supérieure à .   On peut ensuite \"vérifier\" l'équation de l'exemple de la manière suivante.   On a choisi pour la taille des matrices, mais on aurait pu choisir d'autres valeurs, respectant les conditions énumérées dans l'exemple . Un rappel s'impose aussi sur sage. Si l'expression avec le == renvoie true , alors on a l'assurance que c'est vrai. Par contre, un false ne signifie pas que l'expression est fausse, mais que sage est incapable de la vérifier.  "
},
{
  "id": "exo-SEL2x2matinverse",
  "level": "2",
  "url": "sec-matinverse.html#exo-SEL2x2matinverse",
  "type": "Exercice",
  "number": "2.3.6.1",
  "title": "",
  "body": " Dans la section, on a déterminé une formule pour l'inverse d'une matrice quelconque qui n'est valide que si . On a toutefois laissé à compléter les détails de la résolution du système d'équations .  Montrer que la solution à ce système est et .   S'inspirer de la résolution du système dans le texte.   On multiplie la première équation par et la seconde par . On obtient . En soustrayant l'équation de l'équation , on obtient . Toujours dans l'hypothèse que , on obtient .  En multipliant maintenant la première équation du premier système par et la seconde par , on obtient . En soustrayant cette fois l'équation de l'équation , on obtient . On trouve .  "
},
{
  "id": "exo-vecteursesuffisants",
  "level": "2",
  "url": "sec-matinverse.html#exo-vecteursesuffisants",
  "type": "Exercice",
  "number": "2.3.6.2",
  "title": "",
  "body": " Dans la remarque , il est mentionné qu'une matrice possède un inverse si pour tous les dans , il existe un vecteur tel que . Montrer qu'en fait, il suffit que les équations possèdent des solutions.   Essayer de montrer que si des solutions existent pour ces équations, alors une solution existe pour n'importe quel .   En suivant l'indication, on cherche à démontrer que si une solution existe pour chacune de ces équations, il découle qu'une solution existe pour , peu importe le vecteur .  Soit , un vecteur quelconque de dimension . Alors, si les équations données dans la question possèdent des solutions, on peut écrire: où les sont ces solutions. Alors, Cela implique donc qu'il existe un vecteur solution à l'équation pour la matrice et un vecteur quelconque . possède donc un inverse.  "
},
{
  "id": "exo-Ainverseprod",
  "level": "2",
  "url": "sec-matinverse.html#exo-Ainverseprod",
  "type": "Exercice",
  "number": "2.3.6.3",
  "title": "",
  "body": "Soit , deux matrices carrées telles que est inversible. Compléter la preuve de la proposition en montrant que est inversible. Puisque est inversible, il existe une matrice telle que , selon la définition . On peut alors écrire à l'aide de l'associativité de la multiplication matricielle . Toujours selon la définition , la matrice est inversible. "
},
{
  "id": "exercise-92",
  "level": "2",
  "url": "sec-matinverse.html#exercise-92",
  "type": "Exercice",
  "number": "2.3.6.4",
  "title": "",
  "body": " Généraliser la proposition à trois matrices. Est-il possible de généraliser davantage?   On énonce la proposition à trois matrices:  Soit , et , trois matrices carrées d'ordre . Le produit est inversible si et seulement si les matrices sont inversibles. De plus, on a .  On commence en supposant que les matrices sont inversibles. Il est assez intuitif que On le vérifie algébriquement: . Il ne reste donc qu'à vérifier l'existence de l'inverse.  Soit un vecteur de l'image de . On cherche tel que . En vertu de la proposition , si existe, la matrice est inversible. On construit en inversant successivement les matrices , et . Tel qu'attendu, . Comme les matrices , et existent, le vecteur existe. Ainsi, la matrice possède toujours un inverse.  On suppose maintenant que , et sont trois matrices telles que leur produit est inversible. On a alors existence d'une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire et donc, toujours selon la définition , la matrice est inversible.  De façon semblable, si , et sont trois matrices telles que leur produit est inversible, on a alors existence d'une matrice telle que selon la définition . Selon l'associativité du produit matriciel, on peut écrire et donc, toujours selon la définition , la matrice est inversible.  Finalement, en regroupant les matrices , on a que qu'on suppose inversible. Par la proposition à deux matrices, cela implique que et sont inversibles. Si est inversible, cela implique, encore par le même proposition, que et sont inversibles.  On voit clairement que, bien que cela prenne de plus en plus de temps, on pourrait continuer de généraliser la proposition à l'infini en multipliant simplement plus de fois.  "
},
{
  "id": "exercise-93",
  "level": "2",
  "url": "sec-matinverse.html#exercise-93",
  "type": "Exercice",
  "number": "2.3.6.5",
  "title": "",
  "body": " Expliquer pourquoi une projection orthogonale sur un vecteur est une transformation linéaire non inversible.   La proposition dit qu'une transformation inversible doit atteindre tous les vecteurs de son image. Comme la projection envoie les vecteurs sur une droite, elle ne peut atteindre tous les vecteurs. Elle est donc non inversible.  "
},
{
  "id": "exercise-94",
  "level": "2",
  "url": "sec-matinverse.html#exercise-94",
  "type": "Exercice",
  "number": "2.3.6.6",
  "title": "",
  "body": " Soit , une matrice qui n'est pas nécessairement carrée et , la matrice nulle de dimension appropriée. Montrer que     Si la matrice est de format , alors la première matrice doit être de format et la seconde de format . La matrice nulle est la matrice de transformation linéaire qui amène tous les vecteurs au vecteur nul, toujours de formats appropriés. On démontre que la transformation amène tous les vecteurs à l'origine. On précise les dimensions des matrices et des vecteurs. Soit un vecteur . Alors, Donc, puisque la matrice amène tous les vecteurs à l'origine, c'est donc la matrice nulle. Ainsi, .     On procède de façon semblable. Soit un vecteur . Alors, Donc, puisque la matrice amène tous les vecteurs à l'origine, c'est donc la matrice nulle. Ainsi, .  "
},
{
  "id": "exo-prop-invdematscalaire",
  "level": "2",
  "url": "sec-matinverse.html#exo-prop-invdematscalaire",
  "type": "Exercice",
  "number": "2.3.6.7",
  "title": "",
  "body": " Considérer la matrice inversible et le nombre réel non nul . Démontrer que . Noter que cet exercice est la démonstration de la propriété .   Pour démontrer qu'une matrice est l'inverse d'une matrice , il faut démontrer que .   Tel que suggéré dans l'indication, on montre que est bel et bien l'inverse de en les multipliant. Si le résultat donne la matrice identité, on aura démontré que .   "
},
{
  "id": "exercise-96",
  "level": "2",
  "url": "sec-matinverse.html#exercise-96",
  "type": "Exercice",
  "number": "2.3.6.8",
  "title": "",
  "body": " Pour chacun des énoncés suivants, les matrices sont censées être carrées, de format approprié et inversibles lorsque nécessaire. Donner une preuve si l'énoncé est vrai, ou donner un contrexemple si l'énoncé est faux.     Cet énoncé est faux, en général. On en donne un contrexemple. Pour se simplifier la tâche, on utilise des matrices . Soit et , alors   Si est inversible et que , alors .   Cet énoncé est vrai. En effet,   Si n'est pas inversible et que , alors .   Cet énoncé est faux. On donne un contrexemple avec des matrices . Soit , et , alors Mais, .   Si est inversible et qu'on interchange deux colonnes (ou deux lignes) pour obtenir la matrice , alors est inversible.   Trouver une matrice telle que ou et utiliser la proposition .   Cet énoncé est vrai. On considère que si une matrice est carrée, alors elle est inversible. Soit , une matrice carrée inversible d'ordre . On définit , une matrice qui permet de permuter ou d'interchanger deux colonnes. La démarche serait très semblable pour les lignes en multipliant au lieu de . Pour les matrices , cette matrice est toujours : , puisque l'on n'a qu'une seule option. En effet, pour , on voit que: . Cette matrice est toujours inversible et est même sa propre inverse, puisqu'en réfléchissant en termes de transformations linéaires, comment fait-on pour ramener les colonnes permutées à leur emplacement initial? On les permute à nouveau et de la même manière. C'est toujours une matrice de symétrie que l'on construit. Lorsqu'on trouve une telle matrice pour effectuer les permutations, on montre immédiatement que est inversible. En effet, . Bref, afin de généraliser cette situation, il ne nous reste qu'à fournir une matrice de permutation qui permet d'échanger la colonne avec la colonne . Cette matrice est simplement la matrice identité où l'on a interchangé les colonnes et . Bref, . Par exemple, dans , la matrice de permutation des colonnes et est: . On remarque finalement que, puisque permuter deux colonnes de la matrice identité ou deux lignes de la matrice identité donne exactement la même matrice, les matrices de permutation de lignes et de colonnes sont les mêmes. La permutation des lignes ou des colonnes d'une matrice se produira selon si l'on multiplie à droite ou à gauche. On pourrait en dire beaucoup plus long, mais on s'arrête ici!   Si possède une ligne de zéros, alors n'est pas inversible.   Utiliser la propriété .   Cet énoncé est vrai. Comme suggéré dans l'indication, on utilise la propriété . Il faut trouver un vecteur pour lequel il est impossible de trouver un vecteur tel que . Un exemple simple est un vecteur qui ne possède que des zéros, sauf à la position correspondant à la ligne de zéros de la matrice. Ce vecteur est en fait où la i-ème ligne de la matrice est nulle. Sans perdre trop de généralité, si la première ligne de est nulle, on écrit Quand on multiplie cette matrice par , par l'équation , on peut faire , peu importe le vecteur choisi. La preuve serait semblable si l'on choisissait une autre ligne nulle dans la matrice .   Si , alors .   Cet énoncé est vrai. On le démontre en multipliant avec pour obtenir la matrice identité et ainsi démontrer que est bien l'inverse de .  "
},
{
  "id": "exo-2x2inverse",
  "level": "2",
  "url": "sec-matinverse.html#exo-2x2inverse",
  "type": "Exercice",
  "number": "2.3.6.9",
  "title": "",
  "body": " En utilisant, lorsque c'est possible, le fait que peut s'écrire sous la forme , répondre aux questions suivantes:   Trouver un vecteur tel que .     On calcule simplement la matrice à l'aide de la formule et on la multiplie à gauche par le vecteur . Puis, on fait la multiplication.   Trouver un vecteur tel que .     On calcule simplement la matrice à l'aide de la formule et on la multiplie à gauche par le vecteur . Puis, on fait la multiplication.   Trouver un vecteur tel que son image par une rotation de est le vecteur .     C'est essentiellement la même question, mais la matrice est une matrice de rotation de . On pourrait simplement utiliser la formule pour obtenir l'inverse. Cependant, en réfléchissant, on réalise que l'inverse d'une rotation de est une rotation de . Ainsi, Et donc, on calcule le vecteur :    Trouver deux vecteurs tels que et .   et   On effectue d'abord l'inversion de matrice suivie de la multiplication de cet inverse par les vecteurs voulus pour calculer et . Ainsi, et    Trouver un vecteur tel que , sans calculer la matrice inverse.     Cette transformation linéaire est un étirement vertical de facteur , selon l'équation . Ainsi, la question est de savoir quel vecteur, si on l'étire verticalement de facteur , donnera le vecteur . Puisque l'étirement n'affecte pas la coordonnée en , on sait que la première composante du vecteur cherchée est . Pour la seconde, il faut simplement diviser par , ce qui donne aussi . Bref, le vecteur est . Vérifions que c'est la bonne réponse.  "
},
{
  "id": "exo-cisaillement",
  "level": "2",
  "url": "sec-matinverse.html#exo-cisaillement",
  "type": "Exercice",
  "number": "2.3.6.10",
  "title": "",
  "body": " Du point de vue géométrique, une matrice de la forme ou est une matrice de cisaillement, dont l'effet est illustré à l'activité interactive . Donner l'effet algébrique d'un cisaillement et son inverse, en justifiant géométriquement et algébriquement.   Les transformations \"cisaillement\"     Pour la partie algébrique, multiplier les matrices par un vecteur quelconque et analyser l'effet.   Géométriquement, on peut observer qu'un cisaillement horizontal, par exemple, prend le carré original et déplace son côté supérieur vers la droite créant ainsi un parallélogramme de côtés supérieurs et inférieurs égaux aux côtés du carré original. Cependant, les côtés verticaux deviennent beaucoup plus longs. Essentiellement, si l'on regarde l'effet sur les vecteurs de base, on voit, dans les colonnes de la matrice, que et n'est donc pas déplacé. Pour l'autre colonne, on apprend que . Géométriquement, c'est un déplacement du vecteur vers la droite. Il conserve sa coordonnée en , mais on lui ajoute une coordonnée en de valeur . En résumé, Ainsi, pour un vecteur quelconque , on a: Dans cette dernière équation, on voit ce que le mot horizontal signifie dans l'expression cisaillement horizontal . C'est la coordonnée qui changera ( ), de façon proportionnelle à la coordonnée . Une analogie pour ce genre de cisaillement est celle du vent. On s'imagine un vent se dirigeant vers la droite sur la figure. Si le carré est fait d'un matériau assez souple, mais qu'il est bien ancré dans le sol (axe des ), alors il se déplacera selon le cisaillement horizontal illustré en bleu. Plus la valeur est grande, plus le vent est fort!  Pour ce qui est de l'inverse, on peut intuitivement penser que, pour défaire un cisaillement, on doit avoir le déplacement en sens inverse. Ainsi, on a:   Le cisaillement vertical est défini de façon semblable. On le résume ainsi: ou bien ainsi: Son inverse sera:   "
},
{
  "id": "exo-prodmatinversegeo",
  "level": "2",
  "url": "sec-matinverse.html#exo-prodmatinversegeo",
  "type": "Exercice",
  "number": "2.3.6.11",
  "title": "",
  "body": " La figure montre un vecteur , de même que son effet par une transformation et la composition des transformations . On cherche à déterminer la matrice de la transformation .   La transformation intérieure d'une composition, géométriquement    Répondre aux questions suivantes:   Expliquer comment trouver la transformation à partir des informations données.   On peut procéder de diverses façons, mais généralement, on veut trouver l'effet de sur les vecteurs et . Cependant, pour y arriver, il faudra d'abord trouver la matrice . En plaçant en premier lieu le vecteur sur , on obtient , qui sera la première colonne de . Ensuite, en déplaçant le vecteur sur , on obtient , qui sera la deuxième colonne de . Maintenant que nous avons la matrice , si l'on observe attentivement l'autre information fournie, on réalise qu'en multipliant à gauche par , il est possible d'obtenir et donc ainsi que , en repositionnant aux endroits voulus.   Comparer cet exercice à l'exemple . Pourquoi à ce moment n'a-t-on pas demandé de trouver sachant l'effet de et de la composition .   La réponse est simple: nous ne connaissions pas l'inversion matricielle. C'était donc impossible à ce moment-là!  "
},
{
  "id": "exo-algmatpropex",
  "level": "2",
  "url": "sec-matinverse.html#exo-algmatpropex",
  "type": "Exercice",
  "number": "2.3.6.12",
  "title": "",
  "body": " Déterminer les dimensions possibles de chaque matrice de l'exemple .    Pour l'équation , on avait obtenu . La matrice doit être carrée (disons ) puisqu'on calcule son inverse. Les matrices et doivent être de même format et, puisqu'on les multiplie à gauche par , leur format sera . Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et sont de même format et elles sont carrées, disons . La matrice doit donc être de format pour être compatible. Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et sont inversées, elles doivent donc être carrées, par exemple et respectivement. Pour être compatible, la matrice doit donc être de format . Finalement, sera également de format .  Pour l'équation , on avait obtenu . Les matrices et étant soustraites puis inversées, elles se doivent d'être de même format et carrées, par exemple . La matrice doit donc être de format pour être compatible. Finalement, doit être carrée puisqu'on l'inverse dans l'équation de départ. Son format devrait être de , mais puisqu'elle doit être carrée, elle devra être de . La conséquence est que doit être de format pour être compatible. Bref, toutes les matrices doivent être carrées et de même format ( ).    "
},
{
  "id": "exo-etirquelcr2",
  "level": "2",
  "url": "sec-matinverse.html#exo-etirquelcr2",
  "type": "Exercice",
  "number": "2.3.6.13",
  "title": "Un étirement quelconque dans <span class=\"process-math\">\\(\\R^2\\)<\/span>.",
  "body": "Un étirement quelconque dans Dans , un étirement de direction et de facteur est une transformation linéaire telle que et . Autrement dit, la transformation étire la direction d'un facteur et laisse la direction perpendiculaire inchangée.  On considère un étirement dans la direction et de facteur . Déterminer la matrice de cette transformation en utilisant la formule .     On Commençe par énoncer l'effet de notre transformation sur les vecteurs et . Si est la matrice de transformation de l'étirement , alors On écrit ces résultats sous forme matricielle en incluant les deux vecteurs. Il ne reste qu'à isoler . Donc, on obtient  "
},
{
  "id": "exosage-matinverse-1",
  "level": "2",
  "url": "sec-matinverse.html#exosage-matinverse-1",
  "type": "Exercice",
  "number": "2.3.6.14",
  "title": "",
  "body": " Donner l'inverse des matrices suivantes. Vérifier en effectuant la multiplication pour obtenir l'identité.      Le code solution pour la matrice A de l'exercice   A=matrix([[3,-1],[0,-3]]) Ainv=A.inverse() show(\"A=\",A) show(\"A^(-1)=\",Ainv) show(\"AA^(-1)=\",A*Ainv)    On peut simplement remplacer la matrice initiale et exécuter le code à nouveau pour calculer l'inverse de B, puis de C.  "
},
{
  "id": "exercise-103",
  "level": "2",
  "url": "sec-matinverse.html#exercise-103",
  "type": "Exercice",
  "number": "2.3.6.15",
  "title": "",
  "body": "Considérer les matrices et de l'exercice . Vérifier que à l'aide de Sage (équation ). Il est possible de calculer les résultats ou simplement de comparer en utilisant la double égalité == .    Le code solution pour l'exercice   B=matrix([[2,-2,1],[-1,5,1],[2,1,3]]) Binv=B.inverse() show(\"B=\",B) show(\"B^(-1)=\",Binv) C=matrix([[1\/2,-1,-2],[2,0,1\/5],[1\/3,3,4\/3]]) Cinv=C.inverse() show(\"C=\",C) show(\"C^(-1)=\",Cinv) BC=B*C BCinv=BC.inverse() show(\"C^(-1)B^(-1)=\",Cinv*Binv) show(\"(BC)^(-1)\",BCinv) show(Cinv*Binv==BCinv)    On a vérifié l'équation des deux façons proposées.  "
},
{
  "id": "exosage-etirquelcR2",
  "level": "2",
  "url": "sec-matinverse.html#exosage-etirquelcR2",
  "type": "Exercice",
  "number": "2.3.6.16",
  "title": "Les étirements quelconques.",
  "body": "Les étirements quelconques  En se basant sur l'exercice , on souhaite trouver la formule d'un étirement dans de direction et de facteur .  Utiliser Sage pour déterminer la matrice. Essayer de le faire en créant une fonction etirR2(u,k) qui retournera la matrice.       Le code solution pour l'exercice   u1,u2,k =var('u1,u2,k') def etirR2(u,k): uperp=vector([-u[1],u[0]]) #Le vecteur u perpendiculaire U=column_matrix([u,uperp]) #La matrice U V=column_matrix([k*u,uperp]) #La matrice V T=V*(U.inverse()) #La transformation return T show(etirR2(vector([u1,u2]),k).simplify_full())    Remarquer qu'on a utilisé la commande simplify_full() afin d'avoir une forme plus compacte.  "
},
{
  "id": "exercise-105",
  "level": "2",
  "url": "sec-matinverse.html#exercise-105",
  "type": "Exercice",
  "number": "2.3.6.17",
  "title": "",
  "body": " On s'intéresse à la matrice inverse des matrices de permutation.   À l'aide du code de l'exercice , déterminer combien de matrices de permutation sont leur propre inverse. Faire une liste des matrices de permutation qui sont leur propre inverse et une autre liste des matrices qui ne le sont pas.     Le code solution pour l'exercice   def perm_matrix(n): Id=identity_matrix(n) col=Id.columns() p=Permutations(n).list() L=list() for perm in p: colperm=list() for j in range(len(perm)): colperm.append(col[perm[j]-1]) P=column_matrix(colperm) L.append(P) return L P4=perm_matrix(4) P4propreinverse=list() #Nouvelle liste vide for M in P4: if M*M==identity_matrix(4): #Si la matrice de permutation au carrée donne l'identité, alors ... P4propreinverse.append(M) #... on l'ajoute à la liste. P4propreinverse P4autreinverse=P4.copy() #Voir la remarque en bas sur la création de copies for M in P4propreinverse: #Si la matrice se trouve dans la liste des matrices qui sont leur propre inverse, alors... P4autreinverse.remove(M) #... on la retire de la liste complète copiée. show(\"Le nombre de matrices de permutation 4x4 est de \", len(P4)) show(\"Voici ces matrices de permutation 4x4 :\",P4) show(\"Le nombre de matrices de permutation 4x4 qui sont leur propre inverse est de \", len(P4propreinverse)) show(\"Voici ces matrices qui sont leur propre inverse :\", P4propreinverse) show(\"Le nombre de matrices de permutation 4x4 qui ne sont pas leur propre inverse est de \", len(P4autreinverse)) show(\"Celles-ci ne sont pas leur propre inverse :\",P4autreinverse)     Une remarque concernant les copies créées simplement avec \"=\"   L1=[1,2,3,4,5] L2=L1 #On veut créer une copie de travail de la liste L1 L2.remove(4) show(L1) #Malheureusement, on a altéré L1 en voulant uniquement modifier L2. L3=L1.copy() #Cette commande permet d'éviter que les deux listes deviennent liées. L3.remove(3) show(L1) show(L2) show(L3)     Qu'est-ce qui caractérise une matrice de permutation qui est son propre inverse?    La principale caractéristique des matrices de permutation qui sont leur propre inverse est que les permutations ne se font que deux à deux. Par exemple, considérer les matrices . On regarde l'effet de ces matrices dans Sage sur un vecteur .   On voit que les matrices permutent les composantes et du vecteur entre elles, avec qui permute également avec . Par contre, envoie à la position de , à la position de et à la position de . Le lecteur intéressé d'en apprendre plus peut se renseigner sur les cycles d'une permutation. On applique une seconde fois les matrices au vecteur . Peut-on prédire ce qui va se passer?   Puisque dans et les entrées permutent en paires, une application double de la permutation revient à ne rien faire. Par contre, pour , les entrées permutent selon un cycle de longueur trois. On a donc besoin d'une troisième application pour revenir à l'identité.   "
},
{
  "id": "exercise-106",
  "level": "2",
  "url": "sec-matinverse.html#exercise-106",
  "type": "Exercice",
  "number": "2.3.6.18",
  "title": "",
  "body": " On souhaite utiliser Sage pour vérifier certaines des égalités de l'exemple , en utilisant des matrices compatibles d'une taille \"arbitraire\", un peu comme on l'a fait dans l'exemple .  Pour chaque énoncé de l'exemple , utiliser Sage pour \"vérifier\" l'égalité. Les dimensions des matrices ont été trouvées à l'exercice .    On recopie la définition de la fonction de l'exemple que l'on utilisera pour chaque équation. On doit donc la recopier au début du code. On conseille de réutiliser le même code chaque fois et de modifier uniquement les matrices et l'équation à vérifier. Attention: l'exécution du code peut prendre un certain temps, surtout si l'on choisit des matrices de grands formats. Noter qu'on n'a pas à définir la matrice puisqu'elle est créée par l'équation où on l'a isolée.   Le code où l'on définit la fonction matquelc   def matquelc(m,n,lettre): a=str(lettre) #On s'assure que lettre est un caractère de la forme \"a\" liste=[] #Création d'une liste vide for i in range(m): for j in range(n): #On itère sur les lignes (i de 0 à m-1) et les colonnes (j de 0 à n-1) liste.append('%s_%d%d'%(a,i+1,j+1)) #On ajoute à la fin de la liste (append) la chaine a_i+1j+1 , les +1 paliant au fait que range(k) va de 0 à k-1 M=matrix(SR,m,n,liste) #On crée une matrice mxn à partir de liste (Le SR dit à sage que la matrice est symbolique. Il n'est pas nécessaire de comprendre son rôle) return M #La fonction retourne la matrice M      Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   #Ne pas oublier de recopier la définition de la fonction matquelc donnée plus haut. A=matquelc(3,3,'a') B=matquelc(2,3,'b') C=matquelc(2,3,'c') X=(C-B)*(A^(-1)) X*A+B==C     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(2,2,'a') B=matquelc(2,3,'b') I=I3=identity_matrix(2) X=-((A-I)^(-1))*B A*X+B==X     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(3,3,'a') B=matquelc(2,2,'b') D=matquelc(3,2,'d') X=(A^(-1))*D*(B^(-1)) A*X*B==D     Pour l'équation , on avait obtenu . Les dimensions des matrices sont , et . On choisit donc , et .   Le code solution pour l'exercice   A=matquelc(2,2,'a') B=matquelc(2,2,'b') C=matquelc(2,2,'c') X=((C-B)^(-1))*A A*(X^(-1))+B==C       "
},
{
  "id": "exercise-107",
  "level": "2",
  "url": "sec-matinverse.html#exercise-107",
  "type": "Exercice",
  "number": "2.3.6.19",
  "title": "Une fonction pour trouver l’inverse.",
  "body": "Une fonction pour trouver l'inverse Dans cet exercice, on cherche à créer une fonction qui donne automatiquement la réponse à un exemple de la figure interactive en fonction des informations données. On appellera la fonction inversecompo(T11,T12,C1,C2) où sont respectivement les première et deuxième colonnes de la matrice de la transformation et sont respectivement les première et deuxième colonnes de la matrice de la transformation .  Créer cette fonction et utiliser la figure pour la tester.     Le code solution pour l'exercice   def inversecompo(T11,T12,C1,C2): T1=column_matrix([T11,T12]) T1inv=T1.inverse() C=column_matrix([C1,C2]) T2=T1inv*C return T2    "
},
{
  "id": "sec-transfodimsup",
  "level": "1",
  "url": "sec-transfodimsup.html",
  "type": "Section",
  "number": "2.4",
  "title": "Transformations linéaires de dimension supérieure",
  "body": "  Transformations linéaires de dimension supérieure    Aller aux exercices de la section.  On propose maintenant une courte section exploratoire sur les transformations linéaires de plus grandes dimensions . Les concepts géométriques devront être précisés afin d'avoir une signification dans les espaces plus abstraits et des questions, comme quand il s'agit de trouver l'inverse d'une matrice, mettront à l'avant-plan la nécessité de développer les outils techniques du chapitre .  On commence la section en terrain familier, soit avec les transformations linéaires de nature géométrique, mais dans . On verra rapidement que le calcul de l'inverse implique un niveau de difficulté supérieur à ce qui a été vu jusqu'ici.  Finalement, on généralise en considérant les matrices de taille où n'est pas nécessairement égal à . On se questionne sur la signification d'un inverse pour ces transformations, présentant par le fait même des concepts qui seront détaillés au chapitre suivant.    Transformations linéaires dans l'espace à trois dimensions  N'importe quel vecteur de peut être écrit de manière unique comme une combinaison linéaire des vecteurs et . On peut donc décrire une transformation linéaire dans par une matrice où chaque colonne représente l'image de ces trois vecteurs. La transformation identité, qui consiste à ne rien faire, est donnée par la matrice .  Un étirement de facteurs dans la direction des vecteurs et est un exemple plus élaboré d'une transformation de l'espace.   Étirements dans   On considère une transformation linéaire qui étire dans la direction des abscisses d'un facteur , dans la direction des ordonnées d'un facteur et dans la direction des cotes d'un facteur . On veut déterminer la matrice de cette transformation.   L'image des vecteurs et est respectivement et . La matrice est donc .    Une homothétie est un étirement simultané pour lequel .  On s'intéresse maintenant aux rotations dans . Dans le plan, une rotation s'effectue autour d'un point. Comme on veut que l'origine reste fixe, il n'y a qu'un choix possible: tourner autour du point . Dans , les rotations s'effectuent autour d'une droite, appelée l'axe de rotation. On commence par déterminer les matrices de rotation par rapport aux axes de coordonnées.    Rotation par rapport aux axes de coordonnées   On note les matrices de rotation par rapport aux axes de coordonnées respectivement et . On cherche à déterminer ces matrices en fonction d'un angle . La figure interactive peut être pratique pour visualiser les situations.   Les rotations standards dans    Dans chacun des cas, on choisit de mesurer l'angle à partir du raisonnement suivant. On écrit la séquence . On choisit l'axe de rotation et l'on supprime la première occurrence de cet axe dans la séquence. L'angle est mesuré entre les demi-axes positifs selon la première flèche à sa droite. Ainsi, l'angle pour une rotation par rapport à l'axe des est mesuré de l'axe des vers l'axe des positifs.    On débute avec la rotation selon l'axe des , car c'est celle qui est le plus près de la rotation dans . Dans un premier temps, l'image du vecteur est car celui-ci est sur l'axe de rotation. Comme l'angle est mesuré de l'axe des vers l'axe des , l'image du vecteur sera de la forme . La figure illustre l'image du vecteur si l'on clique sur rotation selon l'axe des  .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens anithoraire et sera aussi dans le plan . En suivant un raisonnement similaire à celui de l'exemple , on obtient . La matrice est donc .    On considère maintenant la rotation selon l'axe des . Selon la séquence, l'angle sera mesuré de l'axe des positifs vers l'axe des positifs. Évidemment, l'image du vecteur est le vecteur lui-même puisque celui-ci est sur l'axe de rotation.  On commence par trouver l'image du vecteur . La figure peut être pratique pour visualiser les situations. Un clic sur rotation selon l'axe des  fera apparaitre l'image du vecteur . L'image du vecteur est .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens antihoraire et sera aussi dans le plan . En suivant un raisonnement similaire à celui de l'exemple , on obtient . La matrice est donc .    La matrice de rotation selon l'axe des est obtenue à l'exercice .    Les rotations par rapport à des droites quelconques sont un peu plus difficiles à analyser. On explore le sujet dans l'exemple calculatoire et l'on s'y intéressera davantage dans la section .  On regarde maintenant les réflexions de l'espace. Dans le plan, la réflexion s'effectue selon une droite, mais, dans l'espace, c'est selon un plan que la réflexion s'effectue. On détermine les matrices de réflexion selon les plans , et .   Réflexion par rapport aux plans , et   On note par , , les matrices de réflexion par rapport aux plans respectifs , et . Dans , on avait noté la réflexion par rapport à l'axe des , correspondant à . On a choisi la notation pour faire un parallèle avec cette notation pour décrire la réflexion dans par rapport au plan .   On cherche les matrices , , .    On commence par la réflexion selon le plan . Comme le vecteur est perpendiculaire au plan (c'est un vecteur normal de ce plan), sa réflexion est donnée par . Les vecteurs et , quant à eux sont, sur le plan et ne sont pas affectés par la réflexion. La matrice est donc .  De manière similaire, on obtient et .    Les réflexions par rapport à des plans quelconques sont plus difficiles à analyser. On explore le sujet dans l'exercice et l'on s'y intéressera davantage dans la section .  En quoi consiste l'inverse des rotations et réflexions dans ? Comme c'était le cas dans , l'inverse d'une rotation d'angle et d'axe de rotation est une rotation d'angle , aussi d'axe . Pour la réflexion, il suffit de refaire la même réflexion. On vérifie cette intuition avec des rotations et des réflexions simples calculées aux exemples et .   L'inverse de rotations et réflexions simples  On vérifie que l'inverse des matrices et est respectivement et .   On commence par l'inverse de la rotation. Il suffit de vérifier que . On a .  Pour la réflexion, on remarque que les deuxième et troisième colonnes de  sont respectivement et . Les produits et seront donc égaux, respectivement à la deuxième et la troisième colonne de la matrice . De plus, comme le produit donne l'opposé de la première colonne, on a .  En fonction du théorème , on a .    On termine avec un exemple Sage en lien avec la sous-section.   Les rotations selon une droite passant par l'origine dans  Il existe différentes manières de calculer ou d'obtenir la matrice d'une transformation linéaire. La méthode décrite à l'équation fonctionne si l'on peut trouver l'image d'un nombre suffisant de vecteurs indépendants. L'exemple montre une autre manière en se ramenant à un cas connu (voir aussi )  On utilise la seconde méthode pour trouver la matrice d'une rotation dans dont l'axe de rotation est une droite quelconque, passant par l'origine. L'idée est d'effectuer des rotations connues pour superposer l'axe de rotation sur l'axe des , faire une rotation selon l'axe des et défaire les rotations qui ont déplacé l'axe de rotation original. Le processus est illustré en étape dans la figure .   Les rotations dans    L'animation effectue les étapes suivantes au fil des clics:  On commence par ramener l'axe de rotation dans le plan généré par les vecteurs et . On ramène ensuite l'axe sur l'axe des .  Pour cela, on calcule l'angle que fait la projection de l'axe de rotation sur le plan avec l'axe des . On note cet angle .  Une rotation par rapport à l'axe des d'angle ramènera l'axe de rotation dans le plan .  On fait subir cette même rotation au vecteur .   On veut ensuite ramener le nouvel axe sur l'axe des . Pour cela, on calcule l'angle entre l'axe des et le vecteur dans le plan .  Une rotation par rapport à l'axe des d'angle ramènera le vecteur sur l'axe des .  On fait aussi subir cette rotation au vecteur précédemment transformé.   Ensuite, on effectue la rotation du vecteur ayant subi les deux rotations, par rapport à l'axe des . Ceci est équivalent à la rotation par rapport à l'axe original, mais le vecteur transformé n'est pas au bon endroit.  Finalement, on défait les rotations par rapport à l'axe des et à l'axe des d'angle et (dans cet ordre) pour remettre en place le vecteur transformé et l'axe de rotation déplacé.   On fait un exemple concret avec le vecteur autour de l'axe et un angle de . On effectue les calculs avec Sage.  Dans un premier temps, on veut déterminer l'angle que fait la projection de l'axe de rotation sur le plan avec l'axe des .  On utilise la fonction définie à l'exercice pour calculer l'angle entre deux vecteurs.    On calcule ensuite la rotation de l'axe et du vecteur autour de l'axe des d'un angle . Cela amène l'axe de rotation dans le plan . On remarque l'application de la fonction .apply_map(lambda x: x.trig_reduce()) pour simplifier les expressions trigonométriques.   La prochaine étape implique de calculer l'angle que fait le vecteur avec l'axe des afin de le ramener sur celui-ci par une rotation appropriée selon l'axe des . On applique aussi cette rotation au vecteur .   On remarque que, pour la suite, il n'était pas nécessaire de calculer le vecteur , mais qu'il s'agit d'une bonne manière de valider les calculs.  Il reste maintenant à calculer l'image du vecteur par une rotation selon l'axe des d'un angle de degrés. Par la suite, on défait les rotations afin de replacer le vecteur au bon endroit.   Pour terminer, on replace le vecteur au bon endroit en lui appliquant les rotations inverses et , dans cet ordre.        Transformations de dimension quelconque  On considère la matrice . Cet exemple simple est une transformation linéaire qui transforme des vecteurs de en les associant à des vecteurs de en faisant correspondre les coordonnées de l'image à celles du domaine et en additionnant les valeurs pour obtenir la valeur de : .  La question du produit matriciel de deux matrices a déjà été considérée à la section , bien que ces exemples concernaient principalement un contexte géométrique avec des matrices ou .  Toutefois, la question de l'inverse demeure. Une première question se pose si l'on se souvient de la proposition qui dit que les transformations inversibles atteignent tous les vecteurs de leur image. Comme la matrice est restreinte aux vecteurs tels que , elle n'atteint pas l'ensemble des vecteurs de . Serait-elle donc non inversible?  Un calcul simple montre pourtant que .  On pourrait alors penser que la matrice est un inverse et que la proposition n'est vraie que pour les matrices carrées.  Un autre problème survient lorsqu'on regarde si le théorème est satisfait. Un autre calcul simple montre que . Comme cela ne coïncide pas avec la matrice identité dans , on conclut que n'est pas l'inverse de , au sens de la définition , bien que semble être l'inverse de selon cette même définition. Afin de distinguer les choses, on propose la définition suivante.   Les inverses d'une matrice qui n'est pas carrée  Soit , une matrice . Une matrice de taille est un inverse à gauche de la matrice si . De même, une matrice de taille est un inverse à droite de la matrice si .    La symétrie des inverses à gauche et à droite  Si est un inverse à gauche de , alors on peut aussi dire que est un inverse à droite de . De même, si est un inverse à droite de , alors on peut aussi dire que est un inverse à gauche de . De plus, si , alors le théorème est satisfait et .   Un autre malheureux problème se pose lorsque les matrices ne sont pas carrées. Prenons la matrice . Un calcul simple montre qu'on a aussi et pourtant . L'inverse à gauche d'une matrice n'est donc pas unique. Il en est de même pour l'inverse à droite. La proposition ne s'applique donc réellement qu'aux matrices carrées.  Est-ce qu'une matrice avec peut avoir à la fois un inverse à gauche et un inverse à droite? Comment calculer les inverses lorsqu'ils existent? Ces questions, en apparence simples, s'avèrent complexes et motivent la nécessité de définir des concepts plus abstraits de la théorie matricielle. Avec les outils du chapitre , on sera en mesure de démontrer le théorème , qui stipule que seules les matrices carrées peuvent avoir un inverse à gauche et un inverse à droite et l'on aura une manière de calculer les inverses à gauche ou à droite de matrices arbitraires, lorsque cela s'avère possible.  On propose une démonstration partielle du résultat, qui sera revisité dans la section . Les deux propositions suivantes seront utiles.   L'inverse à gauche et l'image de la transformation  Soit , une matrice possédant un inverse à gauche . Alors pour tout vecteur , il existe au plus un vecteur tel que . En termes plus simples, si un vecteur de l'image est atteint par la transformation , il ne l'est que par un seul vecteur du domaine.   Si un vecteur existe tel que , alors on a . Ainsi, est obtenu en prenant le produit de l'inverse à gauche de par . Or l'inverse de , peut ne pas être unique. Si, pour on a également , alors peut-être que est aussi une solution puisque . Mais dans ce cas, et donc, la solution est unique.     L'inverse à droite et l'image de la transformation  Soit , une matrice possédant un inverse à droite . Alors pour tout vecteur , il existe au moins un vecteur tel que . En termes plus simples, tout vecteur de l'image est atteint par au moins un vecteur du domaine.   Soit , un vecteur de l'image. On pose . Alors . et donc, il existe au moins un vecteur du domaine atteignant .    L'existence d'un inverse à gauche et d'un inverse à droite est réservée uniquement aux matrices carrées. À l'aide des deux propositions précédentes, on arrive à montrer le résultat suivant.   Une matrice rectangulaire ne peut avoir d'inverse à gauche et à droite   Soit une matrice . Alors  si , alors n'a pas d'inverse à gauche;  si , alors n'a pas d'inverse à droite.      Soit , une matrice avec . Pour simplifier, on suppose que . On considère l'équation . Évidemment, est une solution à l'équation. Soit et , les trois premières colonnes de (on se rappelle que ). Si deux de ces vecteurs sont parallèles, disons , alors en prenant , on obtient une solution à l'équation différente du vecteur . Si aucun des vecteurs n'est parallèle à un autre, alors l'exercice garantit l'existence d'une combinaison linéaire où ne sont pas tous nuls. En prenant les trois premières composantes de égales à et en prenant le reste des composantes nulles (si nécessaire) pour que le vecteur soit de dimension , on obtient aussi une solution à l'équation différente du vecteur . Si possédait un inverse à gauche, ceci contredirait la proposition .  Maintenant soit , une matrice avec . Par simplicité, on suppose que . On considère l'équation . Soit , les colonnes de la matrice . Alors l'équation revient à exprimer le vecteur comme . C'est donc dire que le vecteur est dans le plan engendré par les colonnes de . Or, le plan est un objet à deux dimensions et le vecteur vit dans un espace à dimensions. Il y a donc certainement des vecteurs dans qui ne peuvent satisfaire l'équation . Si possédait un inverse à droite, ceci contredirait la proposition .  Évidemment, cette preuve n'est pas complète et veut seulement donner une idée intuitive de la véracité du résultat. On reviendra sur ce dernier lorsque des notions plus précises auront été présentées dans les chapitres subséquents.       Les points importants de cette section sont:  Les rotations selon les trois axes de coordonnées, définies à l'exemple ;  Les réflexions par rapport aux trois plans standards, définies à l'exemple ;  Les inverses de ces transformations, obtenus de manière géométrique à l'exemple ;  Une matrice rectangulaire peut avoir des inverses à gauche ou des inverses à droite, mais pas les deux.       Exercices    Donner un exemple d'une matrice qui ne possède pas d'inverse à gauche, mais qui possède un inverse à droite.     La matrice possède un inverse à droite. Voici un exemple d'inverse à droite possible: . On vérifie qu'effectivement, on a : Le théorème garantit qu'il est impossible que cette matrice possède également un inverse à gauche. On a donc terminé.   Donner un exemple d'une matrice qui ne possède pas d'inverse à droite, mais qui possède un inverse à gauche.     La matrice possède un inverse à gauche. Voici un exemple d'inverse à gauche possible: . On vérifie qu'effectivement, on a : Le théorème garantit qu'il est impossible que cette matrice possède également un inverse à gauche. On a donc terminé.    Trouver un inverse à gauche pour la matrice     Trouver un inverse juste comme ça, sans avoir une idée claire de la manière de procéder, peut sembler très difficile à première vue. Cependant, la matrice initiale est suffisamment simple et contient beaucoup de zéros, ce qui rend la tâche plus facile, sans être évidente. La façon la plus systématique de procéder est de créer une matrice des bonnes dimensions avec des variables et de les multiplier. On écrit et l'on obtient un système d'équations à quatre équations et six inconnues. Ainsi, En posant et , on obtient et et la matrice inverse à gauche est:   Trouver un inverse à droite pour la matrice  On procède de façon semblable. Voici la résolution algébrique: Ainsi, En posant et , on obtient et et la matrice inverse à droite est:    Soit , une matrice et un inverse à droite de . Montrer que est aussi un inverse à droite pour si et seulement si où les matrices sont de formats appropriés.  D'abord, soit , une matrice et un inverse à droite de . Par la définition , on sait que . Le format de l'identité ( ) et celui de la matrice sont dictés par la multiplication matricielle.  Si, dans un premier temps, , on a Cela implique que est un inverse à droite de .  Inversement, on n'a qu'à remonter et faire le raisonnement dans l'autre sens puisqu'on a utilisé des équivalences tout au long de la démonstration.   Soit , des matrices carrées telles que  et sont inversibles  .  Montrer que la matrice est inversible  On comprend le mot inversible partout dans la question au sens qu'on lui donne dans la définition , qu'il convient de relire avant de commencer.   Par la définition et les hypothèses du problème, les matrices et possèdent des inverses (à droite et à gauche) que l'on note, respectivement et . Pour démontrer que est inversible, il faut montrer qu'il existe une matrice telle que . En fait, par le théorème , il suffit de montrer un des deux côtés. On part de l'équation donnée et l'on tente d'obtenir la définition de l'inverse : On a obtenu une matrice telle que et donc est inversible.  Exprimer et en fonction de et leur inverse.    On est arrivé assez près de ces matrices dans la preuve précédente. On peut simplement isoler de l'équation initiale donnée en multipliant à gauche par et l'on avait trouvé une expression pour . Celà mène à .   En utilisant la définition du produit matriciel , déterminer l'inverse des matrices . Quel serait un inverse pour ? Considérer l'équation et déterminer colonne par colonne les entrées de .      On procède comme il est conseillé dans l'indice. On commence par . Pour simplifier la notation, on utilise la notation donnée dans la définition à chaque matrice. Soit , la matrice inverse voulue. On sait que Alors, on calcule la première colonne: On obtient les équations: On calcule ensuite la deuxième colonne de façon semblable et l'on obtient: Finalement, Ce qui donne On obtient avec une démarche semblable: On remarque la tendance. On peut donc conclure avec confiance que:     Déterminer la matrice d'une rotation dans autour de l'axe des . Ceci complètera l'exemple . La figure pourra être utile.     Selon la séquence, l'angle sera mesuré de l'axe des positifs vers l'axe des positifs. Évidemment, l'image du vecteur est ce même vecteur puisque celui-ci est sur l'axe de rotation.  On commence par trouver l'image du vecteur . La figure peut être pratique pour visualiser la situation. Un clic sur rotation selon l'axe des  fera apparaitre l'image du vecteur . L'image du vecteur est .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens antihoraire et sera aussi dans le plan . En suivant un raisonnement semblable à celui de l'exemple , on obtient . La matrice est donc .   Dans , si et sont deux matrices de rotation, alors . Est-ce aussi vrai dans ? Si oui, pourquoi, et si non, donner un exemple.  En général, ce ne sera pas commutatif. Par exemple, une rotation de selon l'axe des et une rotation de selon l'axe des .   Voici une animation qui permet de visualiser les transformations données dans la réponse.   Les rotations dans ne sont pas commutatives en général      L'effet d'un cisaillement horizontal ou vertical a été illustré à l'exercice . Qu'en est-il des cisaillements dans ? Algébriquement, on peut voir l'effet d'un cisaillement selon l'un des axes comme l'ajout d'un multiple d'une coordonnée à l'autre. Ainsi, le cisaillement a pour effet d'ajouter à la composante deux fois la composante : .  Pour avoir un comportement analogue dans , deux situations sont possibles:  On veut ajouter un multiple d'une seule composante à une autre composante;  On veut ajouter des multiples des autres composantes à une composante.    Soit , les transformations qui ajoutent à la composante respectivement fois la composante en ou . D'une manière analogue, on définit les transformations  Donner la matrice de chacune de ces six transformations.          La transformation est définie ainsi: On peut donc inférer facilement, par la multiplication matrice-vecteur en lignes , que la matrice est: De façon semblable, on obtient toutes les autres matrices.       On veut maintenant définir trois cisaillements pour lesquels on ajoute à une composante des multiples des deux autres composantes. Quelles seraient une notation appropriée et la matrice de ces transformations?        On propose la notation pour le cisaillement pour lequel on ajoute à la composante un multiple des deux autres composantes. En suivant le raisonnement précédent, il est logique que la matrice de cisaillement soit: Les deux autres matrices seront donc: et   Pour chacun des cisaillements, déterminer sans calculer l'inverse de la transformation. Justifier.              Logiquement, les transformations inverses seront toujours les transformations où, au lieu d'additionner des multiples d'autres composantes, on va soustraire ces multiples pour annuler l'effet. Par exemple, pour le cisaillement on propose que la matrice inverse est: On vérifie en multipliant les deux matrices et l'on obtient la matrice identité. On donne les autres matrices des transformations inverses.            Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    On considère le plan d'équation normale . On cherche à déterminer la matrice de réflexion autour de ce plan.   Utiliser le principe derrière l'équation pour trouver la matrice de la transformation en considérant l'image de trois vecteurs précis.    Considérer le vecteur normal et deux vecteurs directeurs quelconques.      On considère les trois vecteurs suivants: le vecteur normal et deux vecteurs directeurs quelconques et . Remarquer que les vecteurs directeurs ont été devinés simplement en cherchant des valeurs de qui fonctionnent dans l'équation normale. On connait l'effet de cette réflexion sur ces trois vecteurs. En effet, le vecteur normal sera transformé en son vecteur opposé et les vecteurs directeurs ne bougeront pas puisqu'ils sont dans le plan de réflexion. Ainsi, On résume tout cela sous forme matricielle où est la matrice des vecteurs initiaux et celle des vecteurs transformés et l'on isole la matrice de . Le calcul de l'inverse d'une matrice n'a pas été fait explicitement dans les exemples. On pourrait procéder comme dans l'exemple , mais cela mènerait à résoudre trois systèmes d'équations linéaires à 3 équations et 3 inconnues chacun. On verra, dans le chapitre , comment y arriver de façon efficace. Pour l'instant, on a fait les calculs avec Sage.   Le code solution pour l'exercice   U=matrix([[1,3,2],[2,0,-1],[-3,1,0]]) V=matrix([[-1,3,2],[-2,0,-1],[3,1,0]]) Uinv=U.inverse() show(\"U=\",U) show(\"V=\",V) show(\"U^(-1)=\",Uinv) show(\"T=\",V*Uinv)    La matrice de est donc:    Déterminer directement la matrice en calculant l'image des vecteurs . Pour cela, considérer la projection orthogonale de ces vecteurs sur le plan. La figure peut être utile, en considérant la droite comme le plan vu dans une certaine perspective.       La projection orthogonale sur le plan pour chaque vecteur s'obtient en considérant d'abord la projection sur le vecteur normal. En effet, si l'on utilise la lettre pour désigner le plan de réflexion, Une fois qu'on a obtenu la projection sur le plan , le vecteur transformé sera obtenu par La dernière équation porte à croire qu'il aurait été beaucoup plus simple projeter directement sur le vecteur normal plutôt que sur le plan. On effectuera ensuite tous les calculs sur Sage pour trouver les images des trois vecteurs. On rappelle la formule pour la projection.   Le code solution pour l'exercice   i=vector([1,0,0]) j=vector([0,1,0]) k=vector([0,0,1]) n=vector([1,2,-3]) Ti=i-2*((i*n)\/(n*n))*n #la réflexion de (1,0,0) sur le plan, qui utilise la projection orthogonale Tj=j-2*((j*n)\/(n*n))*n Tk=k-2*((k*n)\/(n*n))*n T=column_matrix([Ti,Tj,Tk]) #on met les résultats en colonnes pour obtenir T show(T)    La matrice de est donc:   Répéter les démarches précédentes avec le plan .      Les démarches seront les mêmes, mais on doit ajouter une étape au début. En effet, notre plan est défini par son équation vectorielle. Il faut trouver un vecteur normal pour effectuer nos projections.   Le code solution pour trouver le vecteur normal   var(\"x,y,z\") v1=vector([-1,2,1]) v2=vector([3,0,-4]) #Le vecteur voulu n est solution des deux équations suivantes puisqu'il est perpendiculaire aux deux vecteurs directeurs en même temps sol=solve([v1*vector([x,y,z])==0,v2*vector([x,y,z])==0],x,y,z,solution_dict=True) show(\"n=\",sol) #La procédure suivante permet de remplacer la variable libre par une valeur choisie, disons 6 pour éviter les fractions l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l: #On ne veut pas que les variables soient la plusieurs fois l.append(var) n=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:6}) show(\"n=\",n)    On considère les trois vecteurs suivants: le vecteur normal et deux vecteurs directeurs quelconques et . En effet, le vecteur normal sera transformé en son vecteur opposé et les vecteurs directeurs ne bougeront pas puisqu'ils sont dans le plan de réflexion. Ainsi, On résume tout cela sous forme matricielle où est la matrice des vecteurs initiaux et celle des vecteurs transformés et l'on isole la matrice de . On a fait les calculs avec Sage.   Le code solution pour l'exercice   U=matrix([[8,-1,3],[1,2,0],[6,1,-4]]) V=matrix([[-8,-1,3],[-1,2,0],[-6,1,-4]]) Uinv=U.inverse() show(\"U=\",U) show(\"V=\",V) show(\"U^(-1)=\",Uinv) show(\"T=\",V*Uinv)    La matrice de est donc:   Autrement, la projection orthogonale sur le plan pour chaque vecteur s'obtient en considérant d'abord la projection sur le vecteur normal. On avait obtenu la formule: On effectue ensuite tous les calculs sur Sage pour trouver les images des trois vecteurs. On rappelle la formule pour la projection.   Le code solution pour l'exercice   i=vector([1,0,0]) j=vector([0,1,0]) k=vector([0,0,1]) n=vector([8,1,6]) Ti=i-2*((i*n)\/(n*n))*n #la réflexion de (1,0,0) sur le plan, qui utilise la projection orthogonale Tj=j-2*((j*n)\/(n*n))*n Tk=k-2*((k*n)\/(n*n))*n T=column_matrix([Ti,Tj,Tk]) #on met les résultats en colonnes pour obtenir T show(T)    La matrice de est donc bel et bien:    On s'intéresse à la matrice d'un étirement quelconque dans . Un étirement de direction et de facteur est une transformation linéaire telle que et pour tout vecteur tel que  Quels sont les vecteurs qui demeurent inchangés par l'étirement.  Ce sont les vecteurs perpendiculaires à , donc ceux qui se retrouvent dans le plan . Déterminer la matrice d'un étirement dans la direction de facteur .       Le code solution pour l'exercice   var(\"x,y,z\") #Recherche de vecteurs perpendiculaires à n n=vector([1,3,5]) sol=solve(n*vector([x,y,z])==0,x,y,z,solution_dict=True) l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l: #On ne veut pas que les variables soient la plusieurs fois l.append(var) u=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:1,l[1]:0}) v=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:0,l[1]:1}) #Ceci crée deux vecteurs non parallèles qui seront nos vecteurs directeurs. #Recherche de la matrice de transformation k=1\/2 U=column_matrix([n,u,v]) V=column_matrix([k*n,u,v]) T=V*(U.inverse()) show(T)    Adapter la fonction de la partie précédente pour créer une fonction etirR3 , similaire à celle qui est développée à l'exercice , qui détermine la matrice d'un étirement dans la direction et de facteur . Vérifier la solution avec l'exercice précédent.   Le code solution pour l'exercice   var(\"x,y,z,n1,n2,n3,k\") #Recherche de vecteurs perpendiculaires à n def etirR3(n,k): sol=solve(n*vector([x,y,z])==0,x,y,z,solution_dict=True) l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l and var not in [n1,n2,n3]: #On ne veut pas que les variables soient la plusieurs fois l.append(var) u=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:1,l[1]:0}) v=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:0,l[1]:1}) #Ceci crée deux vecteurs non parallèles qui seront nos vecteurs directeurs. #Recherche de la matrice de transformation U=column_matrix([n,u,v]) V=column_matrix([k*n,u,v]) T=V*(U.inverse()) return T show(etirR3(vector([1,3,5]),1\/2)) show(etirR3(vector([n1,n2,n3]),k).simplify_full())      Dans l'esprit de l'exercice , vérifier que la réponse donnée correspond bien pour les matrices et .      "
},
{
  "id": "ex-etirementr3",
  "level": "2",
  "url": "sec-transfodimsup.html#ex-etirementr3",
  "type": "Exemple",
  "number": "2.4.1",
  "title": "Étirements dans <span class=\"process-math\">\\(\\R^3\\)<\/span>.",
  "body": " Étirements dans   On considère une transformation linéaire qui étire dans la direction des abscisses d'un facteur , dans la direction des ordonnées d'un facteur et dans la direction des cotes d'un facteur . On veut déterminer la matrice de cette transformation.   L'image des vecteurs et est respectivement et . La matrice est donc .   "
},
{
  "id": "ex-rotR3axes",
  "level": "2",
  "url": "sec-transfodimsup.html#ex-rotR3axes",
  "type": "Exemple",
  "number": "2.4.2",
  "title": "Rotation par rapport aux axes de coordonnées.",
  "body": " Rotation par rapport aux axes de coordonnées   On note les matrices de rotation par rapport aux axes de coordonnées respectivement et . On cherche à déterminer ces matrices en fonction d'un angle . La figure interactive peut être pratique pour visualiser les situations.   Les rotations standards dans    Dans chacun des cas, on choisit de mesurer l'angle à partir du raisonnement suivant. On écrit la séquence . On choisit l'axe de rotation et l'on supprime la première occurrence de cet axe dans la séquence. L'angle est mesuré entre les demi-axes positifs selon la première flèche à sa droite. Ainsi, l'angle pour une rotation par rapport à l'axe des est mesuré de l'axe des vers l'axe des positifs.    On débute avec la rotation selon l'axe des , car c'est celle qui est le plus près de la rotation dans . Dans un premier temps, l'image du vecteur est car celui-ci est sur l'axe de rotation. Comme l'angle est mesuré de l'axe des vers l'axe des , l'image du vecteur sera de la forme . La figure illustre l'image du vecteur si l'on clique sur rotation selon l'axe des  .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens anithoraire et sera aussi dans le plan . En suivant un raisonnement similaire à celui de l'exemple , on obtient . La matrice est donc .    On considère maintenant la rotation selon l'axe des . Selon la séquence, l'angle sera mesuré de l'axe des positifs vers l'axe des positifs. Évidemment, l'image du vecteur est le vecteur lui-même puisque celui-ci est sur l'axe de rotation.  On commence par trouver l'image du vecteur . La figure peut être pratique pour visualiser les situations. Un clic sur rotation selon l'axe des  fera apparaitre l'image du vecteur . L'image du vecteur est .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens antihoraire et sera aussi dans le plan . En suivant un raisonnement similaire à celui de l'exemple , on obtient . La matrice est donc .    La matrice de rotation selon l'axe des est obtenue à l'exercice .   "
},
{
  "id": "ex-refR3plans0",
  "level": "2",
  "url": "sec-transfodimsup.html#ex-refR3plans0",
  "type": "Exemple",
  "number": "2.4.4",
  "title": "Réflexion par rapport aux plans <span class=\"process-math\">\\(x=0\\text{,}\\)<\/span> <span class=\"process-math\">\\(y=0\\)<\/span> et <span class=\"process-math\">\\(z=0\\)<\/span>.",
  "body": " Réflexion par rapport aux plans , et   On note par , , les matrices de réflexion par rapport aux plans respectifs , et . Dans , on avait noté la réflexion par rapport à l'axe des , correspondant à . On a choisi la notation pour faire un parallèle avec cette notation pour décrire la réflexion dans par rapport au plan .   On cherche les matrices , , .    On commence par la réflexion selon le plan . Comme le vecteur est perpendiculaire au plan (c'est un vecteur normal de ce plan), sa réflexion est donnée par . Les vecteurs et , quant à eux sont, sur le plan et ne sont pas affectés par la réflexion. La matrice est donc .  De manière similaire, on obtient et .   "
},
{
  "id": "ex-rotrefR3simpleinverse",
  "level": "2",
  "url": "sec-transfodimsup.html#ex-rotrefR3simpleinverse",
  "type": "Exemple",
  "number": "2.4.5",
  "title": "L’inverse de rotations et réflexions simples.",
  "body": " L'inverse de rotations et réflexions simples  On vérifie que l'inverse des matrices et est respectivement et .   On commence par l'inverse de la rotation. Il suffit de vérifier que . On a .  Pour la réflexion, on remarque que les deuxième et troisième colonnes de  sont respectivement et . Les produits et seront donc égaux, respectivement à la deuxième et la troisième colonne de la matrice . De plus, comme le produit donne l'opposé de la première colonne, on a .  En fonction du théorème , on a .   "
},
{
  "id": "sageex-transfodimsup",
  "level": "2",
  "url": "sec-transfodimsup.html#sageex-transfodimsup",
  "type": "Calcul",
  "number": "2.4.6",
  "title": "Les rotations selon une droite passant par l’origine dans <span class=\"process-math\">\\(\\R^3\\)<\/span>.",
  "body": " Les rotations selon une droite passant par l'origine dans  Il existe différentes manières de calculer ou d'obtenir la matrice d'une transformation linéaire. La méthode décrite à l'équation fonctionne si l'on peut trouver l'image d'un nombre suffisant de vecteurs indépendants. L'exemple montre une autre manière en se ramenant à un cas connu (voir aussi )  On utilise la seconde méthode pour trouver la matrice d'une rotation dans dont l'axe de rotation est une droite quelconque, passant par l'origine. L'idée est d'effectuer des rotations connues pour superposer l'axe de rotation sur l'axe des , faire une rotation selon l'axe des et défaire les rotations qui ont déplacé l'axe de rotation original. Le processus est illustré en étape dans la figure .   Les rotations dans    L'animation effectue les étapes suivantes au fil des clics:  On commence par ramener l'axe de rotation dans le plan généré par les vecteurs et . On ramène ensuite l'axe sur l'axe des .  Pour cela, on calcule l'angle que fait la projection de l'axe de rotation sur le plan avec l'axe des . On note cet angle .  Une rotation par rapport à l'axe des d'angle ramènera l'axe de rotation dans le plan .  On fait subir cette même rotation au vecteur .   On veut ensuite ramener le nouvel axe sur l'axe des . Pour cela, on calcule l'angle entre l'axe des et le vecteur dans le plan .  Une rotation par rapport à l'axe des d'angle ramènera le vecteur sur l'axe des .  On fait aussi subir cette rotation au vecteur précédemment transformé.   Ensuite, on effectue la rotation du vecteur ayant subi les deux rotations, par rapport à l'axe des . Ceci est équivalent à la rotation par rapport à l'axe original, mais le vecteur transformé n'est pas au bon endroit.  Finalement, on défait les rotations par rapport à l'axe des et à l'axe des d'angle et (dans cet ordre) pour remettre en place le vecteur transformé et l'axe de rotation déplacé.   On fait un exemple concret avec le vecteur autour de l'axe et un angle de . On effectue les calculs avec Sage.  Dans un premier temps, on veut déterminer l'angle que fait la projection de l'axe de rotation sur le plan avec l'axe des .  On utilise la fonction définie à l'exercice pour calculer l'angle entre deux vecteurs.    On calcule ensuite la rotation de l'axe et du vecteur autour de l'axe des d'un angle . Cela amène l'axe de rotation dans le plan . On remarque l'application de la fonction .apply_map(lambda x: x.trig_reduce()) pour simplifier les expressions trigonométriques.   La prochaine étape implique de calculer l'angle que fait le vecteur avec l'axe des afin de le ramener sur celui-ci par une rotation appropriée selon l'axe des . On applique aussi cette rotation au vecteur .   On remarque que, pour la suite, il n'était pas nécessaire de calculer le vecteur , mais qu'il s'agit d'une bonne manière de valider les calculs.  Il reste maintenant à calculer l'image du vecteur par une rotation selon l'axe des d'un angle de degrés. Par la suite, on défait les rotations afin de replacer le vecteur au bon endroit.   Pour terminer, on replace le vecteur au bon endroit en lui appliquant les rotations inverses et , dans cet ordre.   "
},
{
  "id": "def-invmn",
  "level": "2",
  "url": "sec-transfodimsup.html#def-invmn",
  "type": "Définition",
  "number": "2.4.8",
  "title": "Les inverses d’une matrice qui n’est pas carrée.",
  "body": " Les inverses d'une matrice qui n'est pas carrée  Soit , une matrice . Une matrice de taille est un inverse à gauche de la matrice si . De même, une matrice de taille est un inverse à droite de la matrice si .  "
},
{
  "id": "rem-invmn",
  "level": "2",
  "url": "sec-transfodimsup.html#rem-invmn",
  "type": "Remarque",
  "number": "2.4.9",
  "title": "La symétrie des inverses à gauche et à droite.",
  "body": " La symétrie des inverses à gauche et à droite  Si est un inverse à gauche de , alors on peut aussi dire que est un inverse à droite de . De même, si est un inverse à droite de , alors on peut aussi dire que est un inverse à gauche de . De plus, si , alors le théorème est satisfait et .  "
},
{
  "id": "prop-invgauche",
  "level": "2",
  "url": "sec-transfodimsup.html#prop-invgauche",
  "type": "Proposition",
  "number": "2.4.10",
  "title": "L’inverse à gauche et l’image de la transformation.",
  "body": " L'inverse à gauche et l'image de la transformation  Soit , une matrice possédant un inverse à gauche . Alors pour tout vecteur , il existe au plus un vecteur tel que . En termes plus simples, si un vecteur de l'image est atteint par la transformation , il ne l'est que par un seul vecteur du domaine.   Si un vecteur existe tel que , alors on a . Ainsi, est obtenu en prenant le produit de l'inverse à gauche de par . Or l'inverse de , peut ne pas être unique. Si, pour on a également , alors peut-être que est aussi une solution puisque . Mais dans ce cas, et donc, la solution est unique.   "
},
{
  "id": "prop-invdroite",
  "level": "2",
  "url": "sec-transfodimsup.html#prop-invdroite",
  "type": "Proposition",
  "number": "2.4.11",
  "title": "L’inverse à droite et l’image de la transformation.",
  "body": " L'inverse à droite et l'image de la transformation  Soit , une matrice possédant un inverse à droite . Alors pour tout vecteur , il existe au moins un vecteur tel que . En termes plus simples, tout vecteur de l'image est atteint par au moins un vecteur du domaine.   Soit , un vecteur de l'image. On pose . Alors . et donc, il existe au moins un vecteur du domaine atteignant .   "
},
{
  "id": "thm-invrect",
  "level": "2",
  "url": "sec-transfodimsup.html#thm-invrect",
  "type": "Théorème",
  "number": "2.4.12",
  "title": "Une matrice rectangulaire ne peut avoir d’inverse à gauche et à droite.",
  "body": " Une matrice rectangulaire ne peut avoir d'inverse à gauche et à droite   Soit une matrice . Alors  si , alors n'a pas d'inverse à gauche;  si , alors n'a pas d'inverse à droite.      Soit , une matrice avec . Pour simplifier, on suppose que . On considère l'équation . Évidemment, est une solution à l'équation. Soit et , les trois premières colonnes de (on se rappelle que ). Si deux de ces vecteurs sont parallèles, disons , alors en prenant , on obtient une solution à l'équation différente du vecteur . Si aucun des vecteurs n'est parallèle à un autre, alors l'exercice garantit l'existence d'une combinaison linéaire où ne sont pas tous nuls. En prenant les trois premières composantes de égales à et en prenant le reste des composantes nulles (si nécessaire) pour que le vecteur soit de dimension , on obtient aussi une solution à l'équation différente du vecteur . Si possédait un inverse à gauche, ceci contredirait la proposition .  Maintenant soit , une matrice avec . Par simplicité, on suppose que . On considère l'équation . Soit , les colonnes de la matrice . Alors l'équation revient à exprimer le vecteur comme . C'est donc dire que le vecteur est dans le plan engendré par les colonnes de . Or, le plan est un objet à deux dimensions et le vecteur vit dans un espace à dimensions. Il y a donc certainement des vecteurs dans qui ne peuvent satisfaire l'équation . Si possédait un inverse à droite, ceci contredirait la proposition .  Évidemment, cette preuve n'est pas complète et veut seulement donner une idée intuitive de la véracité du résultat. On reviendra sur ce dernier lorsque des notions plus précises auront été présentées dans les chapitres subséquents.   "
},
{
  "id": "exercise-108",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-108",
  "type": "Exercice",
  "number": "2.4.3.1",
  "title": "",
  "body": " Donner un exemple d'une matrice qui ne possède pas d'inverse à gauche, mais qui possède un inverse à droite.     La matrice possède un inverse à droite. Voici un exemple d'inverse à droite possible: . On vérifie qu'effectivement, on a : Le théorème garantit qu'il est impossible que cette matrice possède également un inverse à gauche. On a donc terminé.   Donner un exemple d'une matrice qui ne possède pas d'inverse à droite, mais qui possède un inverse à gauche.     La matrice possède un inverse à gauche. Voici un exemple d'inverse à gauche possible: . On vérifie qu'effectivement, on a : Le théorème garantit qu'il est impossible que cette matrice possède également un inverse à gauche. On a donc terminé.  "
},
{
  "id": "exercise-109",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-109",
  "type": "Exercice",
  "number": "2.4.3.2",
  "title": "",
  "body": " Trouver un inverse à gauche pour la matrice     Trouver un inverse juste comme ça, sans avoir une idée claire de la manière de procéder, peut sembler très difficile à première vue. Cependant, la matrice initiale est suffisamment simple et contient beaucoup de zéros, ce qui rend la tâche plus facile, sans être évidente. La façon la plus systématique de procéder est de créer une matrice des bonnes dimensions avec des variables et de les multiplier. On écrit et l'on obtient un système d'équations à quatre équations et six inconnues. Ainsi, En posant et , on obtient et et la matrice inverse à gauche est:   Trouver un inverse à droite pour la matrice  On procède de façon semblable. Voici la résolution algébrique: Ainsi, En posant et , on obtient et et la matrice inverse à droite est:   "
},
{
  "id": "exercise-110",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-110",
  "type": "Exercice",
  "number": "2.4.3.3",
  "title": "",
  "body": "Soit , une matrice et un inverse à droite de . Montrer que est aussi un inverse à droite pour si et seulement si où les matrices sont de formats appropriés.  D'abord, soit , une matrice et un inverse à droite de . Par la définition , on sait que . Le format de l'identité ( ) et celui de la matrice sont dictés par la multiplication matricielle.  Si, dans un premier temps, , on a Cela implique que est un inverse à droite de .  Inversement, on n'a qu'à remonter et faire le raisonnement dans l'autre sens puisqu'on a utilisé des équivalences tout au long de la démonstration.  "
},
{
  "id": "exercise-111",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-111",
  "type": "Exercice",
  "number": "2.4.3.4",
  "title": "",
  "body": "Soit , des matrices carrées telles que  et sont inversibles  .  Montrer que la matrice est inversible  On comprend le mot inversible partout dans la question au sens qu'on lui donne dans la définition , qu'il convient de relire avant de commencer.   Par la définition et les hypothèses du problème, les matrices et possèdent des inverses (à droite et à gauche) que l'on note, respectivement et . Pour démontrer que est inversible, il faut montrer qu'il existe une matrice telle que . En fait, par le théorème , il suffit de montrer un des deux côtés. On part de l'équation donnée et l'on tente d'obtenir la définition de l'inverse : On a obtenu une matrice telle que et donc est inversible.  Exprimer et en fonction de et leur inverse.    On est arrivé assez près de ces matrices dans la preuve précédente. On peut simplement isoler de l'équation initiale donnée en multipliant à gauche par et l'on avait trouvé une expression pour . Celà mène à .  "
},
{
  "id": "exo-invspecial",
  "level": "2",
  "url": "sec-transfodimsup.html#exo-invspecial",
  "type": "Exercice",
  "number": "2.4.3.5",
  "title": "",
  "body": "En utilisant la définition du produit matriciel , déterminer l'inverse des matrices . Quel serait un inverse pour ? Considérer l'équation et déterminer colonne par colonne les entrées de .      On procède comme il est conseillé dans l'indice. On commence par . Pour simplifier la notation, on utilise la notation donnée dans la définition à chaque matrice. Soit , la matrice inverse voulue. On sait que Alors, on calcule la première colonne: On obtient les équations: On calcule ensuite la deuxième colonne de façon semblable et l'on obtient: Finalement, Ce qui donne On obtient avec une démarche semblable: On remarque la tendance. On peut donc conclure avec confiance que:   "
},
{
  "id": "exo-rotR3x",
  "level": "2",
  "url": "sec-transfodimsup.html#exo-rotR3x",
  "type": "Exercice",
  "number": "2.4.3.6",
  "title": "",
  "body": " Déterminer la matrice d'une rotation dans autour de l'axe des . Ceci complètera l'exemple . La figure pourra être utile.     Selon la séquence, l'angle sera mesuré de l'axe des positifs vers l'axe des positifs. Évidemment, l'image du vecteur est ce même vecteur puisque celui-ci est sur l'axe de rotation.  On commence par trouver l'image du vecteur . La figure peut être pratique pour visualiser la situation. Un clic sur rotation selon l'axe des  fera apparaitre l'image du vecteur . L'image du vecteur est .  Comme le vecteur est perpendiculaire au vecteur dans le sens antihoraire, son image sera perpendiculaire à , aussi dans le sens antihoraire et sera aussi dans le plan . En suivant un raisonnement semblable à celui de l'exemple , on obtient . La matrice est donc .  "
},
{
  "id": "exercise-114",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-114",
  "type": "Exercice",
  "number": "2.4.3.7",
  "title": "",
  "body": "Dans , si et sont deux matrices de rotation, alors . Est-ce aussi vrai dans ? Si oui, pourquoi, et si non, donner un exemple.  En général, ce ne sera pas commutatif. Par exemple, une rotation de selon l'axe des et une rotation de selon l'axe des .   Voici une animation qui permet de visualiser les transformations données dans la réponse.   Les rotations dans ne sont pas commutatives en général    "
},
{
  "id": "exercise-115",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-115",
  "type": "Exercice",
  "number": "2.4.3.8",
  "title": "",
  "body": " L'effet d'un cisaillement horizontal ou vertical a été illustré à l'exercice . Qu'en est-il des cisaillements dans ? Algébriquement, on peut voir l'effet d'un cisaillement selon l'un des axes comme l'ajout d'un multiple d'une coordonnée à l'autre. Ainsi, le cisaillement a pour effet d'ajouter à la composante deux fois la composante : .  Pour avoir un comportement analogue dans , deux situations sont possibles:  On veut ajouter un multiple d'une seule composante à une autre composante;  On veut ajouter des multiples des autres composantes à une composante.    Soit , les transformations qui ajoutent à la composante respectivement fois la composante en ou . D'une manière analogue, on définit les transformations  Donner la matrice de chacune de ces six transformations.          La transformation est définie ainsi: On peut donc inférer facilement, par la multiplication matrice-vecteur en lignes , que la matrice est: De façon semblable, on obtient toutes les autres matrices.       On veut maintenant définir trois cisaillements pour lesquels on ajoute à une composante des multiples des deux autres composantes. Quelles seraient une notation appropriée et la matrice de ces transformations?        On propose la notation pour le cisaillement pour lequel on ajoute à la composante un multiple des deux autres composantes. En suivant le raisonnement précédent, il est logique que la matrice de cisaillement soit: Les deux autres matrices seront donc: et   Pour chacun des cisaillements, déterminer sans calculer l'inverse de la transformation. Justifier.              Logiquement, les transformations inverses seront toujours les transformations où, au lieu d'additionner des multiples d'autres composantes, on va soustraire ces multiples pour annuler l'effet. Par exemple, pour le cisaillement on propose que la matrice inverse est: On vérifie en multipliant les deux matrices et l'on obtient la matrice identité. On donne les autres matrices des transformations inverses.          "
},
{
  "id": "exo-refR3",
  "level": "2",
  "url": "sec-transfodimsup.html#exo-refR3",
  "type": "Exercice",
  "number": "2.4.3.9",
  "title": "",
  "body": " On considère le plan d'équation normale . On cherche à déterminer la matrice de réflexion autour de ce plan.   Utiliser le principe derrière l'équation pour trouver la matrice de la transformation en considérant l'image de trois vecteurs précis.    Considérer le vecteur normal et deux vecteurs directeurs quelconques.      On considère les trois vecteurs suivants: le vecteur normal et deux vecteurs directeurs quelconques et . Remarquer que les vecteurs directeurs ont été devinés simplement en cherchant des valeurs de qui fonctionnent dans l'équation normale. On connait l'effet de cette réflexion sur ces trois vecteurs. En effet, le vecteur normal sera transformé en son vecteur opposé et les vecteurs directeurs ne bougeront pas puisqu'ils sont dans le plan de réflexion. Ainsi, On résume tout cela sous forme matricielle où est la matrice des vecteurs initiaux et celle des vecteurs transformés et l'on isole la matrice de . Le calcul de l'inverse d'une matrice n'a pas été fait explicitement dans les exemples. On pourrait procéder comme dans l'exemple , mais cela mènerait à résoudre trois systèmes d'équations linéaires à 3 équations et 3 inconnues chacun. On verra, dans le chapitre , comment y arriver de façon efficace. Pour l'instant, on a fait les calculs avec Sage.   Le code solution pour l'exercice   U=matrix([[1,3,2],[2,0,-1],[-3,1,0]]) V=matrix([[-1,3,2],[-2,0,-1],[3,1,0]]) Uinv=U.inverse() show(\"U=\",U) show(\"V=\",V) show(\"U^(-1)=\",Uinv) show(\"T=\",V*Uinv)    La matrice de est donc:    Déterminer directement la matrice en calculant l'image des vecteurs . Pour cela, considérer la projection orthogonale de ces vecteurs sur le plan. La figure peut être utile, en considérant la droite comme le plan vu dans une certaine perspective.       La projection orthogonale sur le plan pour chaque vecteur s'obtient en considérant d'abord la projection sur le vecteur normal. En effet, si l'on utilise la lettre pour désigner le plan de réflexion, Une fois qu'on a obtenu la projection sur le plan , le vecteur transformé sera obtenu par La dernière équation porte à croire qu'il aurait été beaucoup plus simple projeter directement sur le vecteur normal plutôt que sur le plan. On effectuera ensuite tous les calculs sur Sage pour trouver les images des trois vecteurs. On rappelle la formule pour la projection.   Le code solution pour l'exercice   i=vector([1,0,0]) j=vector([0,1,0]) k=vector([0,0,1]) n=vector([1,2,-3]) Ti=i-2*((i*n)\/(n*n))*n #la réflexion de (1,0,0) sur le plan, qui utilise la projection orthogonale Tj=j-2*((j*n)\/(n*n))*n Tk=k-2*((k*n)\/(n*n))*n T=column_matrix([Ti,Tj,Tk]) #on met les résultats en colonnes pour obtenir T show(T)    La matrice de est donc:   Répéter les démarches précédentes avec le plan .      Les démarches seront les mêmes, mais on doit ajouter une étape au début. En effet, notre plan est défini par son équation vectorielle. Il faut trouver un vecteur normal pour effectuer nos projections.   Le code solution pour trouver le vecteur normal   var(\"x,y,z\") v1=vector([-1,2,1]) v2=vector([3,0,-4]) #Le vecteur voulu n est solution des deux équations suivantes puisqu'il est perpendiculaire aux deux vecteurs directeurs en même temps sol=solve([v1*vector([x,y,z])==0,v2*vector([x,y,z])==0],x,y,z,solution_dict=True) show(\"n=\",sol) #La procédure suivante permet de remplacer la variable libre par une valeur choisie, disons 6 pour éviter les fractions l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l: #On ne veut pas que les variables soient la plusieurs fois l.append(var) n=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:6}) show(\"n=\",n)    On considère les trois vecteurs suivants: le vecteur normal et deux vecteurs directeurs quelconques et . En effet, le vecteur normal sera transformé en son vecteur opposé et les vecteurs directeurs ne bougeront pas puisqu'ils sont dans le plan de réflexion. Ainsi, On résume tout cela sous forme matricielle où est la matrice des vecteurs initiaux et celle des vecteurs transformés et l'on isole la matrice de . On a fait les calculs avec Sage.   Le code solution pour l'exercice   U=matrix([[8,-1,3],[1,2,0],[6,1,-4]]) V=matrix([[-8,-1,3],[-1,2,0],[-6,1,-4]]) Uinv=U.inverse() show(\"U=\",U) show(\"V=\",V) show(\"U^(-1)=\",Uinv) show(\"T=\",V*Uinv)    La matrice de est donc:   Autrement, la projection orthogonale sur le plan pour chaque vecteur s'obtient en considérant d'abord la projection sur le vecteur normal. On avait obtenu la formule: On effectue ensuite tous les calculs sur Sage pour trouver les images des trois vecteurs. On rappelle la formule pour la projection.   Le code solution pour l'exercice   i=vector([1,0,0]) j=vector([0,1,0]) k=vector([0,0,1]) n=vector([8,1,6]) Ti=i-2*((i*n)\/(n*n))*n #la réflexion de (1,0,0) sur le plan, qui utilise la projection orthogonale Tj=j-2*((j*n)\/(n*n))*n Tk=k-2*((k*n)\/(n*n))*n T=column_matrix([Ti,Tj,Tk]) #on met les résultats en colonnes pour obtenir T show(T)    La matrice de est donc bel et bien:   "
},
{
  "id": "exercise-117",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-117",
  "type": "Exercice",
  "number": "2.4.3.10",
  "title": "",
  "body": "On s'intéresse à la matrice d'un étirement quelconque dans . Un étirement de direction et de facteur est une transformation linéaire telle que et pour tout vecteur tel que  Quels sont les vecteurs qui demeurent inchangés par l'étirement.  Ce sont les vecteurs perpendiculaires à , donc ceux qui se retrouvent dans le plan . Déterminer la matrice d'un étirement dans la direction de facteur .       Le code solution pour l'exercice   var(\"x,y,z\") #Recherche de vecteurs perpendiculaires à n n=vector([1,3,5]) sol=solve(n*vector([x,y,z])==0,x,y,z,solution_dict=True) l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l: #On ne veut pas que les variables soient la plusieurs fois l.append(var) u=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:1,l[1]:0}) v=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:0,l[1]:1}) #Ceci crée deux vecteurs non parallèles qui seront nos vecteurs directeurs. #Recherche de la matrice de transformation k=1\/2 U=column_matrix([n,u,v]) V=column_matrix([k*n,u,v]) T=V*(U.inverse()) show(T)    Adapter la fonction de la partie précédente pour créer une fonction etirR3 , similaire à celle qui est développée à l'exercice , qui détermine la matrice d'un étirement dans la direction et de facteur . Vérifier la solution avec l'exercice précédent.   Le code solution pour l'exercice   var(\"x,y,z,n1,n2,n3,k\") #Recherche de vecteurs perpendiculaires à n def etirR3(n,k): sol=solve(n*vector([x,y,z])==0,x,y,z,solution_dict=True) l=[] #Liste vide des variables libres for v in sol[0].keys(): # vérifier ce que sol[0].keys() donne pour comprendre cette étape for var in sol[0][v].variables(): #Vérifier aussi cette étape if var not in l and var not in [n1,n2,n3]: #On ne veut pas que les variables soient la plusieurs fois l.append(var) u=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:1,l[1]:0}) v=vector([sol[0][x],sol[0][y],sol[0][z]]).subs({l[0]:0,l[1]:1}) #Ceci crée deux vecteurs non parallèles qui seront nos vecteurs directeurs. #Recherche de la matrice de transformation U=column_matrix([n,u,v]) V=column_matrix([k*n,u,v]) T=V*(U.inverse()) return T show(etirR3(vector([1,3,5]),1\/2)) show(etirR3(vector([n1,n2,n3]),k).simplify_full())    "
},
{
  "id": "exercise-118",
  "level": "2",
  "url": "sec-transfodimsup.html#exercise-118",
  "type": "Exercice",
  "number": "2.4.3.11",
  "title": "",
  "body": " Dans l'esprit de l'exercice , vérifier que la réponse donnée correspond bien pour les matrices et .   "
},
{
  "id": "sec-transfolabos",
  "level": "1",
  "url": "sec-transfolabos.html",
  "type": "Section",
  "number": "2.5",
  "title": "Activités et laboratoires",
  "body": "  Activités et laboratoires    Dans cette section, on regarde des activités et des laboratoires en lien avec des concepts présentés dans le chapitre.    De l'art géométrique   On a vu à l'exemple qu'on pouvait appliquer une transformation à une liste de points. Dans ce projet, on souhaite créer une œuvre artistique à l'aide des transformations linéaires. Afin de bien comprendre, on divise le projet en deux étapes.    Le but de cette étape est de reproduire la figure ci-dessous à partir d'une liste de points initiaux.   Une belle étoile      La commande polygon permet de tracer un polygone à partir d'une liste de points. L'étoile de la figure a été obtenue en utilisant également les options color=\"gold\" et edgecolor=\"black\" . À partir de la liste de points suivants et d'une réflexion selon l'axe des , créer la seconde moitié de l'étoile en arrière-plan (On peut utiliser la commande Listetransformees=[T*P for P in Listepoints] pour obtenir l'image par la transformation ).    Pour créer la partie en avant-plan de l'étoile, on procède en deux étapes:  Dans un premier temps, on applique à la liste des points initiaux une rotation de .  Pour l'autre partie, on applique la réflexion selon l'axe des aux points après la rotation ci-dessus.     En général, la composition d'une réflexion et d'une rotation n'est pas commutative, comme le montre l'exemple . Toutefois, dans ce cas-ci, la rotation et la réflexion le sont. Démontrer avec Sage que cette affirmation est exacte et utiliser ce fait pour obtenir la partie en avant-plan par une autre méthode que celle de l'étape .     À partir d'une liste de points quelconques, créer un objet artistique. Les restrictions sont minimes, mais on demande au minimum:  un polygone créé à partir d'au moins huit points;  L'utilisation d'au moins deux transformations linéaires différentes.    Utiliser couleurs et autres options au choix. La page d'aide de Sage sur les polygones peut servir de sources d'inspiration que ce soit pour des idées de figures ou d'options: .      Anaglyphe   Ce laboratoire est une adaptation sur Sage du projet Anaglyphe et visualisation 3D , disponible sur , sous licence creative commons.  Le cerveau humain est capable de grandes choses. À partir d'images sur une feuille ou un écran, il est capable de percevoir de la profondeur et du relief. La stéréoscopie est l'ensemble des techniques mises en œuvre pour reproduire une perception de ce relief à partir d'images planes. Un anaglyphe est une paire d'images, chacune étant de la couleur complémentaire à l'autre, qui est regardée au travers d'un filtre. Chaque image représente la même figure, mais légèrement décalée. Le plus répandu des anaglyphes est celui où l'œil gauche est affecté d'un filtre rouge et l'œil droit d'un filtre cyan. Dans ce laboratoire, on construit, dans un premier temps, l'anaglyphe d'un objet commun, que l'on animera. Dans un deuxième temps, après s'être familiarisé avec la création, on construit une maquette, pouvant être composée de plusieurs objets.   Pour commencer, on choisit de construire un objet simple afin de bien comprendre le fonctionnement d'un anaglyphe et sa construction sur Sage. La commande line permet de relier une série de points, formant ainsi un objet connecté. On trace ensuite une ligne entre chaque point et le suivant dans la liste, jusqu'à l'avant-dernier point. Compléter la commande ci-dessous afin de construire une pyramide à base carrée dont les côtés mesurent unités, centrée à l'origine et de hauteur $6$ unités. Il faudra répéter des points afin de produire un dessin complet.   Il est possible de déplacer le point de vue en manipulant la figure créée. Les options projection=\"orthographic\",viewpoint=[[-1,-1,-1],120] ont été choisies afin qu'il n'y ait pas d'effet de perspective et pour que l'angle de vue par défaut soit celui correspondant au plan - , qui est l'écran de l'utilisateur dans le repère utilisé.   La projection sur l'écran de l'objet proposé n'est pas très intéressante à regarder, puisqu'il d'un triangle qui ne rend pas l'impression des trois dimensions. On s'imagine un repère dont l'origine est au centre de l'écran d'ordinateur. L'axe des pointe vers l'utilisateur, entre ses deux yeux. L'axe des et l'axe des forment le plan représentant l'écran. On peut choisir de déplacer le point de vue, par rapport à ce repère, ou encore de transformer l'objet en utilisant des transformations linéaires ou des translations. La première option peut être effectuée en manipulant la figure ou en modifiant l'option viewpoint dans la command line . Dans le but d'explorer les transformations linéaires, on choisit la deuxième option. On va transformer l'objet en utilisant deux transformations linéaires ainsi qu'une translation. D'abord, on lui applique une rotation par rapport à l'axe des . Par défaut, on choisit un angle de , mais il sera possible de modifier cet angle plus tard. Ensuite, on applique une rotation par rapport à l'axe des , d'un angle de cette fois. Enfin, on termine avec une translation de , ce qui a pour effet d'amener l'objet « devant » l'écran. Compléter le code ci-dessous afin de transformer l'objet. Pour appliquer une ou plusieurs matrices à une liste d'objets, on peut utiliser la commande Pointstransformes=[T*P+t for P in Listepoints] où est la combinaison des transformations linéaires et est la translation.    Maintenant que l'objet est en place, dans une orientation intéressante, on le projette sur le plan à deux dimensions formé des axes et . Afin de créer les maquettes qui composent l'anaglyphe, on a le choix de le faire dans l'espace à trois dimensions ou de voir le plan sur lequel les maquettes se trouvent comme une copie de . On choisit la deuxième option. Pour arriver à effectuer la projection, on doit établir la position de chacun des yeux de l'observateur. On rappelle que dans le repère, l'axe des pointe en plein milieu des deux yeux de l'utilisateur. La composante des deux yeux est donc la distance entre l'utilisateur et l'écran. Pour les composantes , elles sont, respectivement pour l'œil gauche et l'œil droit, la moitié de la distance entre le centre des yeux de l'utilisateur. Finalement, la composante des yeux est zéro. Compléter le code ci-dessous avec les mesures correspondantes.    Pour la première projection, on regarde l'œil gauche. Le côté gauche de la lunette est normalement monté d'un filtre rouge. Parmi les deux projections, l'œil gauche ne verra donc que l'objet cyan. On va créer la projection de l'objet sur l'écran telle que vue par l'œil gauche pour ensuite le colorer en cyan. Pour cela, on imagine une droite passant par l'œil gauche, situé au point , et chacun des points de l'objet. Cette droite intersecte le plan - en un point.   Créer une fonction qui prend comme argument un paramètre $k$ et un point $P$ et qui retourne l'équation vectorielle de la droite passant par $G$ et $P$;   Créer une liste qui, pour chaque point $P$, contient la valeur de $k$ nécessaire pour que le point sur la droite soit également sur le plan $y$-$z$;   Créer la liste pointscyans contenant la liste des points projetés sur le plan $x$-$y$;   Créer la maquette cyan   Pour chaque point , on veut déterminer la valeur du paramètre qui correspond au point sur le plan. On utilise la commande solve pour déterminer la valeur de . Cette commande retourne une liste d'équations. Puisqu'on sait qu'il n'y aura qu'une solution à l'équation que l'on veut résoudre, on utilise [0] pour faire ressortir la première et seule équation et la commande .rhs() afin d'obtenir le côté droit de l'égalité, qui correspond à la valeur de .   La commande zip permet de combiner deux listes en une seule en joignant les éléments correspondants. Par exemple, list(zip([1,2,3],[4,5,6])) produit la liste [(1,4),(2,5),(3,6)] .   On utilise cette commande pour grouper les listes Pointstransformes et paramk .   La liste pointscyans est créée en allant chercher les bonnes composantes dans l'équation de la droite Dgauche(k,P) pour la valeur de associée au point . On cherche à obtenir une liste de listes. Chacune des listes intérieures représente les composantes de la projection d'un point $P$ sur le plan $y$-$z$ vue comme si elle était dans un espace à deux dimensions. Compléter la cellule ci-dessous.   Finalement, on crée la maquette cyan.    Pour la deuxième projection, on regarde l'œil droit. Le côté droit de la lunette est normalement monté d'un filtre cyan. Parmi les deux projections, l'œil droit ne verra donc que l'objet rouge. On va créer la projection de l'objet sur l'écran telle que vu par l'œil droit et le colorer en rouge. Pour cela, on imagine une droite passant par l'œil droit, situé au point , et chacun des points de l'objet. Cette droite intersecte le plan - en un point.  Créer une fonction qui prend comme argument un paramètre et un point et qui retourne l'équation vectorielle de la droite passant par et .  Créer une liste qui, pour chaque point , contient la valeur de nécessaire pour que le point sur la droite soit également sur le plan - .  Créer la liste pointsrouges contenant la liste des points projetés sur le plan - .  Créer la maquette rouge   Enfin, on veut afficher les deux morceaux de l'anaglyphe en un seul graphique.    Pour explorer davantage, on utilise Sage pour animer l'anaglyphe à l'aide de curseurs. Les curseurs permettent de modifier les angles des rotations, la translation choisie ainsi que les paramètres de distance avec l'écran et de distance entre les yeux. Pour cela, on utilise un interact , objet Sage permettant, entre autres, de créer des curseurs et de produire du contenu dynamique. Le squelette est fourni avec une partie à compléter. Le code commence par @interact , ce qui active le mode interactif de Sage. Ensuite, on définit la fonction `anaglyphe` dont les arguments sont un ensemble de curseurs ( slider ) et une boite d'entrée ( input_box ). Des valeurs par défauts sont fournies. Sous la ligne initialisant la fonction, on applique une commande Sage qui convertit la liste des points en objet Sage et l'on crée un graphique vide dans lequel on ajoutera l'anaglyphe. Compléter le code afin de créer l'application interactive.  La commande line relie tous les points d'une liste. Il peut être utile de privilégier des objets distincts afin de créer une maquette plus intéressante. La manière dont la fonction anaglyphe ci-dessus a été créée permet d'avoir plusieurs objets et de construire leur anaglyphe respectif. La fonction anaglype prend comme entrée un dictionnaire composé d'objets et leurs points. Dans la boite d'entrée, écrire {\"cube\":[[0, 0, 0],[1, 0, 0],[1, 1, 0],[0, 1, 0],[0, 0, 0],[0, 0, 1],[1, 0, 1],[1, 1, 1],[0, 1, 1],[0, 0, 1],[0, 1, 1],[1, 1, 1],[1, 1, 0],[1, 0, 0],[1, 0, 1],[0, 0, 1],[1, 0, 1],[1, 1, 1],[1, 1, 0],[0, 1, 0],[0, 1, 1]],\"tetraedre\":[[-1,-1,-1],[1,-1,-1],[0,1,-1],[-1,-1,-1],[0,0,2],[1,-1,-1],[0,0,2],[0,1,-1],[1,-1,-1],[0,1,-1],[0,0,2],[-1,-1,-1]]} afin de voir un cube et un tétraèdre en anaglyphe.  Créer un objet artistique. Les restrictions sont peu nombreuses, mais on demande au minimum une maquette composée d'au moins deux objets distincts, chacun formé d'au moins dix points.     "
},
{
  "id": "project-2",
  "level": "2",
  "url": "sec-transfolabos.html#project-2",
  "type": "Projet",
  "number": "2.5.1",
  "title": "De l’art géométrique.",
  "body": " De l'art géométrique   On a vu à l'exemple qu'on pouvait appliquer une transformation à une liste de points. Dans ce projet, on souhaite créer une œuvre artistique à l'aide des transformations linéaires. Afin de bien comprendre, on divise le projet en deux étapes.    Le but de cette étape est de reproduire la figure ci-dessous à partir d'une liste de points initiaux.   Une belle étoile      La commande polygon permet de tracer un polygone à partir d'une liste de points. L'étoile de la figure a été obtenue en utilisant également les options color=\"gold\" et edgecolor=\"black\" . À partir de la liste de points suivants et d'une réflexion selon l'axe des , créer la seconde moitié de l'étoile en arrière-plan (On peut utiliser la commande Listetransformees=[T*P for P in Listepoints] pour obtenir l'image par la transformation ).    Pour créer la partie en avant-plan de l'étoile, on procède en deux étapes:  Dans un premier temps, on applique à la liste des points initiaux une rotation de .  Pour l'autre partie, on applique la réflexion selon l'axe des aux points après la rotation ci-dessus.     En général, la composition d'une réflexion et d'une rotation n'est pas commutative, comme le montre l'exemple . Toutefois, dans ce cas-ci, la rotation et la réflexion le sont. Démontrer avec Sage que cette affirmation est exacte et utiliser ce fait pour obtenir la partie en avant-plan par une autre méthode que celle de l'étape .     À partir d'une liste de points quelconques, créer un objet artistique. Les restrictions sont minimes, mais on demande au minimum:  un polygone créé à partir d'au moins huit points;  L'utilisation d'au moins deux transformations linéaires différentes.    Utiliser couleurs et autres options au choix. La page d'aide de Sage sur les polygones peut servir de sources d'inspiration que ce soit pour des idées de figures ou d'options: .    "
},
{
  "id": "project-3",
  "level": "2",
  "url": "sec-transfolabos.html#project-3",
  "type": "Projet",
  "number": "2.5.2",
  "title": "Anaglyphe.",
  "body": " Anaglyphe   Ce laboratoire est une adaptation sur Sage du projet Anaglyphe et visualisation 3D , disponible sur , sous licence creative commons.  Le cerveau humain est capable de grandes choses. À partir d'images sur une feuille ou un écran, il est capable de percevoir de la profondeur et du relief. La stéréoscopie est l'ensemble des techniques mises en œuvre pour reproduire une perception de ce relief à partir d'images planes. Un anaglyphe est une paire d'images, chacune étant de la couleur complémentaire à l'autre, qui est regardée au travers d'un filtre. Chaque image représente la même figure, mais légèrement décalée. Le plus répandu des anaglyphes est celui où l'œil gauche est affecté d'un filtre rouge et l'œil droit d'un filtre cyan. Dans ce laboratoire, on construit, dans un premier temps, l'anaglyphe d'un objet commun, que l'on animera. Dans un deuxième temps, après s'être familiarisé avec la création, on construit une maquette, pouvant être composée de plusieurs objets.   Pour commencer, on choisit de construire un objet simple afin de bien comprendre le fonctionnement d'un anaglyphe et sa construction sur Sage. La commande line permet de relier une série de points, formant ainsi un objet connecté. On trace ensuite une ligne entre chaque point et le suivant dans la liste, jusqu'à l'avant-dernier point. Compléter la commande ci-dessous afin de construire une pyramide à base carrée dont les côtés mesurent unités, centrée à l'origine et de hauteur $6$ unités. Il faudra répéter des points afin de produire un dessin complet.   Il est possible de déplacer le point de vue en manipulant la figure créée. Les options projection=\"orthographic\",viewpoint=[[-1,-1,-1],120] ont été choisies afin qu'il n'y ait pas d'effet de perspective et pour que l'angle de vue par défaut soit celui correspondant au plan - , qui est l'écran de l'utilisateur dans le repère utilisé.   La projection sur l'écran de l'objet proposé n'est pas très intéressante à regarder, puisqu'il d'un triangle qui ne rend pas l'impression des trois dimensions. On s'imagine un repère dont l'origine est au centre de l'écran d'ordinateur. L'axe des pointe vers l'utilisateur, entre ses deux yeux. L'axe des et l'axe des forment le plan représentant l'écran. On peut choisir de déplacer le point de vue, par rapport à ce repère, ou encore de transformer l'objet en utilisant des transformations linéaires ou des translations. La première option peut être effectuée en manipulant la figure ou en modifiant l'option viewpoint dans la command line . Dans le but d'explorer les transformations linéaires, on choisit la deuxième option. On va transformer l'objet en utilisant deux transformations linéaires ainsi qu'une translation. D'abord, on lui applique une rotation par rapport à l'axe des . Par défaut, on choisit un angle de , mais il sera possible de modifier cet angle plus tard. Ensuite, on applique une rotation par rapport à l'axe des , d'un angle de cette fois. Enfin, on termine avec une translation de , ce qui a pour effet d'amener l'objet « devant » l'écran. Compléter le code ci-dessous afin de transformer l'objet. Pour appliquer une ou plusieurs matrices à une liste d'objets, on peut utiliser la commande Pointstransformes=[T*P+t for P in Listepoints] où est la combinaison des transformations linéaires et est la translation.    Maintenant que l'objet est en place, dans une orientation intéressante, on le projette sur le plan à deux dimensions formé des axes et . Afin de créer les maquettes qui composent l'anaglyphe, on a le choix de le faire dans l'espace à trois dimensions ou de voir le plan sur lequel les maquettes se trouvent comme une copie de . On choisit la deuxième option. Pour arriver à effectuer la projection, on doit établir la position de chacun des yeux de l'observateur. On rappelle que dans le repère, l'axe des pointe en plein milieu des deux yeux de l'utilisateur. La composante des deux yeux est donc la distance entre l'utilisateur et l'écran. Pour les composantes , elles sont, respectivement pour l'œil gauche et l'œil droit, la moitié de la distance entre le centre des yeux de l'utilisateur. Finalement, la composante des yeux est zéro. Compléter le code ci-dessous avec les mesures correspondantes.    Pour la première projection, on regarde l'œil gauche. Le côté gauche de la lunette est normalement monté d'un filtre rouge. Parmi les deux projections, l'œil gauche ne verra donc que l'objet cyan. On va créer la projection de l'objet sur l'écran telle que vue par l'œil gauche pour ensuite le colorer en cyan. Pour cela, on imagine une droite passant par l'œil gauche, situé au point , et chacun des points de l'objet. Cette droite intersecte le plan - en un point.   Créer une fonction qui prend comme argument un paramètre $k$ et un point $P$ et qui retourne l'équation vectorielle de la droite passant par $G$ et $P$;   Créer une liste qui, pour chaque point $P$, contient la valeur de $k$ nécessaire pour que le point sur la droite soit également sur le plan $y$-$z$;   Créer la liste pointscyans contenant la liste des points projetés sur le plan $x$-$y$;   Créer la maquette cyan   Pour chaque point , on veut déterminer la valeur du paramètre qui correspond au point sur le plan. On utilise la commande solve pour déterminer la valeur de . Cette commande retourne une liste d'équations. Puisqu'on sait qu'il n'y aura qu'une solution à l'équation que l'on veut résoudre, on utilise [0] pour faire ressortir la première et seule équation et la commande .rhs() afin d'obtenir le côté droit de l'égalité, qui correspond à la valeur de .   La commande zip permet de combiner deux listes en une seule en joignant les éléments correspondants. Par exemple, list(zip([1,2,3],[4,5,6])) produit la liste [(1,4),(2,5),(3,6)] .   On utilise cette commande pour grouper les listes Pointstransformes et paramk .   La liste pointscyans est créée en allant chercher les bonnes composantes dans l'équation de la droite Dgauche(k,P) pour la valeur de associée au point . On cherche à obtenir une liste de listes. Chacune des listes intérieures représente les composantes de la projection d'un point $P$ sur le plan $y$-$z$ vue comme si elle était dans un espace à deux dimensions. Compléter la cellule ci-dessous.   Finalement, on crée la maquette cyan.    Pour la deuxième projection, on regarde l'œil droit. Le côté droit de la lunette est normalement monté d'un filtre cyan. Parmi les deux projections, l'œil droit ne verra donc que l'objet rouge. On va créer la projection de l'objet sur l'écran telle que vu par l'œil droit et le colorer en rouge. Pour cela, on imagine une droite passant par l'œil droit, situé au point , et chacun des points de l'objet. Cette droite intersecte le plan - en un point.  Créer une fonction qui prend comme argument un paramètre et un point et qui retourne l'équation vectorielle de la droite passant par et .  Créer une liste qui, pour chaque point , contient la valeur de nécessaire pour que le point sur la droite soit également sur le plan - .  Créer la liste pointsrouges contenant la liste des points projetés sur le plan - .  Créer la maquette rouge   Enfin, on veut afficher les deux morceaux de l'anaglyphe en un seul graphique.    Pour explorer davantage, on utilise Sage pour animer l'anaglyphe à l'aide de curseurs. Les curseurs permettent de modifier les angles des rotations, la translation choisie ainsi que les paramètres de distance avec l'écran et de distance entre les yeux. Pour cela, on utilise un interact , objet Sage permettant, entre autres, de créer des curseurs et de produire du contenu dynamique. Le squelette est fourni avec une partie à compléter. Le code commence par @interact , ce qui active le mode interactif de Sage. Ensuite, on définit la fonction `anaglyphe` dont les arguments sont un ensemble de curseurs ( slider ) et une boite d'entrée ( input_box ). Des valeurs par défauts sont fournies. Sous la ligne initialisant la fonction, on applique une commande Sage qui convertit la liste des points en objet Sage et l'on crée un graphique vide dans lequel on ajoutera l'anaglyphe. Compléter le code afin de créer l'application interactive.  La commande line relie tous les points d'une liste. Il peut être utile de privilégier des objets distincts afin de créer une maquette plus intéressante. La manière dont la fonction anaglyphe ci-dessus a été créée permet d'avoir plusieurs objets et de construire leur anaglyphe respectif. La fonction anaglype prend comme entrée un dictionnaire composé d'objets et leurs points. Dans la boite d'entrée, écrire {\"cube\":[[0, 0, 0],[1, 0, 0],[1, 1, 0],[0, 1, 0],[0, 0, 0],[0, 0, 1],[1, 0, 1],[1, 1, 1],[0, 1, 1],[0, 0, 1],[0, 1, 1],[1, 1, 1],[1, 1, 0],[1, 0, 0],[1, 0, 1],[0, 0, 1],[1, 0, 1],[1, 1, 1],[1, 1, 0],[0, 1, 0],[0, 1, 1]],\"tetraedre\":[[-1,-1,-1],[1,-1,-1],[0,1,-1],[-1,-1,-1],[0,0,2],[1,-1,-1],[0,0,2],[0,1,-1],[1,-1,-1],[0,1,-1],[0,0,2],[-1,-1,-1]]} afin de voir un cube et un tétraèdre en anaglyphe.  Créer un objet artistique. Les restrictions sont peu nombreuses, mais on demande au minimum une maquette composée d'au moins deux objets distincts, chacun formé d'au moins dix points.    "
},
{
  "id": "sec-GJ",
  "level": "1",
  "url": "sec-GJ.html",
  "type": "Section",
  "number": "3.1",
  "title": "Les systèmes d’équations linéaires et la méthode de Gauss-Jordan",
  "body": "  Les systèmes d'équations linéaires et la méthode de Gauss-Jordan    Aller aux exercices de la section.  Un système d'équations linéaires (SEL) est un ensemble d'équations comprenant un certain nombre de variables qui sont multipliées par des constantes. Par exemple, les équations forment un système d'équations linéaires, tout comme . Par contre, le système n'est pas linéaire, dû à la présence des termes et .  Dans cette section, on définit la notion de système d'équations linéaires, la matrice associée à un tel système et l'on explore la résolution de ces systèmes à l'aide de la méthode de Gauss-Jordan.    Définition et exemples simples  On considère les solutions qui satisfont la paire d'équations . C'est un système d'équations linéaires à deux équations et à deux inconnues. On y reconnait aussi les équations normales de deux droites de . Satisfaire ces deux équations simultanément serait donc équivalent à trouver l'intersection des deux droites. On se demander, étant données deux droites de , quel est le nombre de configurations possibles? Combien de points d'intersection y a-t-il dans chaque cas?  Pour illustrer les autres possibilités, on change le SEL précédent en remplaçant le de la seconde équation par un . On a donc le système et les deux droites sont maintenant parallèles et distinctes (les vecteurs normaux sont parallèles).  Si, à partir de ce deuxième système, on change le pour un , on obtient . On remarque que la seconde équation n'est rien d'autre que la première multipliée par . Les deux droites sont donc en fait la même droite, puisqu'on peut simplifier l'écriture de l'une et obtenir l'autre. On peut aussi les voir comme des droites parallèles confondues. Ces trois cas sont en fait les seules possibilités pour un SEL à deux équations et à deux inconnues. Ils sont illustrés aux figures .    Des droites sécantes dans .       Des droites parallèles distinctes dans .       Des droites parallèles confondues dans .       Qu'en est-il du cas de trois équations et trois inconnues? Puisqu'une équation de la forme représente l'équation d'un plan dans , on peut voir un système d'équations linéaires à trois équations et trois inconnues comme l'intersection de trois plans dans l'espace. Pour l'intersection de deux droites dans , on avait aucune, une seule ou une infinité de solutions. L'exercice explorera la géométrie des cas possibles pour des plans dans .  Au-delà de la géométrie, on s'intéresse au cas plus général: équations linéaires avec inconnues. Quelques définitions sont nécessaires.   Une équation linéaire  Soit , des variables. Une équation de ces variables est linéaire si elle est de la forme , où . Si l'on pose , il est possible de réécrire l'équation comme .    Système d'équations linéaires  Un système d'équations linéaires (SEL) est un ensemble de équations linéaires comportant chacune inconnues. Typiquement, on écrira .  En posant , on reconnait dans le SEL la multiplication matrice et vecteur . Donc, pour , le SEL peut s'écrire comme .  L'ensemble des valeurs qui satisfont un SEL est appelé l'ensemble solution .    Avant de déterminer de quelle manière il est possible de résoudre les systèmes d'équations linéaires, on donne quelques exemples.   De la forme SEL à la forme matricielle  On considère les systèmes d'équations linéaires introduits en début de sous-section. On avait , et .  On veut écrire chacun de ces systèmes d'équations linéaires sous forme matricielle.   Si l'on pose et , les SEL s'écrivent respectivement comme , où .    Il est aussi important de traduire une situation sous la forme d'un SEL.   De la forme matricielle à la forme SEL  Soit . On cherche à écrire trois systèmes d'équations linéaires qui permettent de déterminer l'inverse de .  Selon l'équation , les colonnes de la matrice inverse sont les vecteurs qui satisfont les équations . Ces réponses représentent un système d'équations linéaires sous leur forme actuelle et répondent à la question, mais, pour montrer la forme en équations, on peut effectuer les multiplications. Les trois systèmes deviennent alors : , : et : .    Il peut aussi y avoir un nombre différent de variables et d'équations.   Un système d'équations linéaires rectangulaire  On considère le système . La matrice associée à ce système est .      Opérations et matrices élémentaires  On regarde le système simplifié . La solution à un tel système se lit directement dans équations, soit .   Voici une variante de ce système qui possède la même solution: . Dans ce système, on peut directement lire la valeur de la variable , soit . En la remplaçant dans la première équation, on peut ensuite trouver . Un tel système est dit triangulaire.  Finalement, on considère à nouveau le SEL du début de section : . Une vérification rapide montre que le couple satisfait cette paire d'équations. Plusieurs méthodes peuvent être utilisées pour résoudre ce système, que ce soit par comparaison, par substitution, par réduction ou par une combinaison de ces trois techniques.  Le but de cette section est de développer une méthode générale, par le biais d'un algorithme qui permettra de trouver la ou les solutions à n'importe quel système d'équations linéaires. De plus, si le système n'a aucune solution, la méthode le dira.  On s'intéresse au système . Ce système est identique au précédent, mais l'ordre des équations a été inversé. On s'attend toutefois à ce que la solution trouvée soit encore valide.  De même, le système devrait aussi posséder la même solution, puisqu'en divisant la première équation par et la seconde par , on obtient le système précédent. Une simple vérification permet de constater que est bel et bien une solution.  Finalement, on considère le système . Ce système a la même première équation que le premier système, mais la seconde est différente. En fait, géométriquement, c'est une tout autre droite. Pourtant, la solution est encore valide. Les trois droites sont illustrées à la figure .   Les trois droites sécantes en un même point.      Quelqu'un de perspicace aura peut-être remarqué que, si l'on soustrait l'équation de l'équation , on obtient l'équation . On peut faire ici l'hypothèse que, si l'on additionne (ou soustrait) à une ligne un multiple d'une autre ligne, la solution ne change pas. On détaillera cette propriété sous peu.   Les opérations élémentaires   On considère un système d'équations linéaires quelconque à équations et inconnues. Les trois opérations suivantes sont appelées les opérations élémentaires:  Interchanger la position de deux équations;  Multiplier une équation par une constante non nulle;  Ajouter à une équation un multiple d'une autre.    Si est la matrice du système, alors les trois opérations élémentaires se traduisent en forme matricielle par:  Interchanger la position de deux lignes;  Multiplier une ligne par une constante non nulle;  Ajouter à une ligne un multiple d'une autre.    Un SEL (ou une matrice) qui s'obtient à partir d'un autre par une suite d'opérations élémentaires est dit équivalent à ce dernier. Si une matrice est équivalente à , on écrit .    Les opérations élémentaires  On considère le système . On tente de résoudre ce système en le transformant en un autre, plus simple, à l'aide des opérations élémentaires. La proposition justifiera ces étapes, et l'algorithme de Gauss-Jordan saura donner une structure aux étapes effectuées ici. L'algorithme clarifiera aussi le moment convenable pour arrêter.   On obtient, en soustrayant de la ligne deux le double de la ligne un, le SEL équivalent . À partir de ce nouveau système, on additionne la ligne un à la ligne trois pour obtenir le SEL équivalent . On multiplie maintenant la ligne deux par , ce qui donne . On poursuit avec la soustraction du triple de la ligne deux à la ligne trois: . On effectue finalement une dernière étape qui consiste à multiplier la ligne trois par , pour avoir le système d'équations linéaires .  On écrit sous forme d'équations linéaires le dernier système. .  Même si les étapes pour y arriver ne sont peut-être pas encore claires, on remarque que le SEL est maintenant triangulaire et qu'on peut lire directement la valeur de la composante de la solution, soit . En substituant cette valeur pour dans la seconde équation du SEL, on détermine et finalement, en remplaçant dans la première ligne, on trouve .  Une vérification finale permettra de voir que le vecteur est une solution du système original.    La solution de l'exemple précédent montre que si l'on arrive à transformer un SEL en utilisant les opérations élémentaires, on peut espérer arriver à un SEL équivalent qui sera plus simple à résoudre. Toutefois, des questions demeurent. Est-on assuré que les solutions du nouveau système seront les mêmes que celles du système initial? Qui plus est, si l'on avait effectué un choix différent d'opérations élémentaires, aurait-on obtenu la même solution? Combien de solutions peut-il y avoir?  La méthode de Gauss-Jordan, qu'on présentera à la section , donne une manière algorithmique de trouver toutes les solutions à un SEL, peu importe les opérations élémentaires effectuées. Elle fonctionne, entre autres, grâce à la proposition suivante.   Les opérations élémentaires préservent les solutions  Soit et , deux matrices telles que les systèmes et sont équivalents. Alors l'ensemble solution à ces systèmes est le même.    Il suffit de montrer que chacune des trois opérations élémentaires préserve les solutions.  Dans un premier temps, si les deux systèmes n'ont pas de solution, alors l'ensemble solution est le même, c'est-à-dire que c'est l'ensemble vide. Si toutefois un des systèmes a au moins une solution, on raisonne comme suit.  Il est clair qu'interchanger deux lignes ne changera pas la solution, puisque ce sont exactement les mêmes équations. Leur position est un choix arbitraire.  Soit , une solution au système .  On suppose que soit obtenu à partir du premier système en multipliant la ligne par la constante . Puisque est une solution à , on a .  Comme les autres lignes du SEL sont les mêmes, on conclut que est aussi une solution du système . Si, au contraire, on connait une solution au système , on peut renverser l'ordre du calcul précédent pour montrer que est aussi une solution au système .  On suppose maintenant que la ligne du système est obtenue en ajoutant fois la ligne à la ligne . Puisque est une solution de , en additionnant fois la ligne à la ligne , on a . Ainsi, est aussi une solution du système . Si, au contraire, on connait une solution au système , on peut renverser l'ordre du calcul précédent pour montrer que est aussi une solution au système .   L'écriture à chaque ligne de la matrice, du vecteur et du vecteur était un peu encombrante. On constate, en regardant les calculs, que seuls la matrice et le vecteur changent pendant le calcul. On propose la notation suivante, pour simplifier l'écriture.   La matrice augmentée  Soit , un système d'équation linéaire . On définit la matrice augmentée de ce système comme étant la matrice .   Lors du calcul d'un SEL équivalent, il est possible de travailler uniquement avec la matrice augmentée seulement et de facilement la convertir sous la forme SEL par la suite. Ceci sera illustré dans les exemples subséquents.  Avant de terminer cette sous-section, on montre que les opérations élémentaires peuvent être vues comme étant tout simplement une application du produit matriciel. Cette constatation a des applications plus théoriques que pratiques, mais on en verra l'utilité prochainement.   Les matrices élémentaires  Considérons la matrice identité d'ordre . Une matrice élémentaire est une matrice obtenue à partir de la matrice identité en effectuant sur celle-ci une et une seule opération élémentaire.   On regarde les matrices élémentaires associées à l'exemple .   Les matrices élémentaires   Pour chaque opération élémentaire de l'exemple , on donne la matrice élémentaire associée. Leur utilité sera explorée dans l'exemple calculatoire .   La première opération élémentaire effectuée soustrayait le double de la ligne un à la ligne deux. Si l'on effectue cette opération élémentaire sur la matrice identité, on obtient . En fait, on profite de cet exemple pour introduire un élément de notation. Plutôt que de décrire en mot chaque opération élémentaire effectuée, on utilise l'une des variantes de notation suivante, qu'on écrira au-dessus du symbole .  Pour illustrer la permutation de la ligne avec la ligne , on utilise la notation .  Pour illustrer que la ligne est multipliée par la constante non nulle , on utilise la notation .  Finalement, pour illustrer qu'on ajoute fois la ligne à la ligne , on utilise la notation .    En poursuivant avec les opérations de l'exemple , on a, dans l'ordre .    Chaque opération élémentaire mène donc à une matrice. Qui plus est, ces matrices sont inversibles.    Les matrices élémentaires sont toutes inversibles. De plus, si  est la matrice élémentaire qui interchange la ligne avec la ligne , alors  est la matrice qui multiplie la ligne par , alors .  est la matrice élémentaire qui ajoute à la ligne , fois la ligne , alors .     Voir l'exercice .    On termine avec des commandes Sage en lien avec la sous-section.   Les matrices élémentaires sur Sage  Les matrices élémentaires peuvent être codées avec Sage. La syntaxe est elementary_matrix(n, row1=i,row2=j, scale=r) , où est la taille de la matrice carrée. Selon l'opération que l'on veut effectuer, certains arguments ne seront pas utilisés. Par exemple, si l'on ne met pas , l'opération est d'interchanger les lignes. Si l'on omet le , l'opération est de multiplier la ligne par , et si les trois arguments sont présents, l'opération est .  On regarde l'utilisation de ces matrices avec Sage, en utilisant les matrices élémentaires de l'exemple .   L'avantage de ces matrices, c'est que les opérations élémentaires peuvent être vues comme la multiplication par la gauche d'une matrice élémentaire. Pour l'observer, on propose de refaire la simplification de l'exemple à l'aide des matrices à . On introduit également la matrice augmentée avec Sage.   Comme chacune des étapes suivantes est effectuée après les précédentes, il est important de bien faire les multiplications.   Le résultat est bel et bien le même que la matrice à la fin de l'exemple .     La méthode de Gauss-Jordan  Dans la dernière sous-section, on a vu que les opérations élémentaires permettent de prendre un système d'équations linéaires et de le transformer en un système équivalent, plus simple. Il serait intéressant d'avoir une méthode applicable dans tous les cas, avec un critère clair pour savoir quand arrêter. Pour cela, on définit la forme échelonnée réduite d'une matrice.   Forme échelonnée réduite d'une matrice   Soit , une matrice de taille . Le premier élément non nul de chaque ligne est appelé le pivot de cette ligne.  On dit que est échelonnée réduite si elle satisfait chacune des caractéristiques suivantes:   Condition pour être échelonnée réduite   Si la matrice contient des lignes dont toutes les entrées sont nulles (donc sans pivot), ces lignes sont dans le bas de la matrice.  Le pivot de chaque ligne non nulle est égal à .  De haut en bas, les pivots sont à la droite (pas nécessairement directement) les uns des autres.  Les entrées d'une colonne pivot sont toutes égales à , sauf le pivot.     Lorsqu'une matrice est sous la forme échelonnée réduite, la position de ses pivots sera particulièrement importante.   Pivots, variables liées et variables libres  Soit , une matrice et sa forme échelonnée réduite. La proposition confirmera qu'il n'y a qu'une forme échelonnée réduite pour une matrice donnée. Si la colonne de la matrice contient un pivot, on dit que la colonne est une colonne pivot pour la matrice et que la variable est une variable pivot, ou liée.  Les variables qui ne sont pas des variables liées sont dites libres.   La notion de variables libres jouera un plus grand rôle dans la sous-section . Pour l'instant, on regarde des exemples de matrices respectant certaines des conditions de la définition afin de bien comprendre ce concept.   Matrice échelonnée réduite   Parmi les matrices suivantes, déterminer quelle(s) condition(s) de la définition est(sont) respectée(s).          La matrice contient une ligne nulle et celle-ci est dans le bas de la matrice. La première condition est donc satisfaite. La deuxième condition n'est pas satisfaite. Le pivot de la première ligne est égal à et non à . La condition trois est respectée, car il n'y a qu'un seul pivot. Finalement, la colonne , correspondant au pivot de la première ligne, ne contient que des zéros, sauf pour l'entrée pivot. La condition quatre est donc respectée.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.   La matrice respecte la première condition par défaut, car elle ne possède pas de ligne nulle. De plus, les deux pivots sont égaux à et le second se trouve à la droite du premier, donc les conditions deux et trois sont respectées. Par contre, la deuxième colonne est pivot et contient des entrées non nulles (le ) autres que le pivot de la deuxième ligne. Elle ne respecte donc pas la condition quatre.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.  La matrice ne possède pas de ligne nulle, donc elle respecte la condition un. Les pivots sont tous égaux à , ce qui fait que la condition deux est respectée. Par contre, le second pivot est à gauche du premier. La troisième condition n'est donc pas respectée. La dernière condition l'est toutefois, car toutes les colonnes pivots ne contiennent que des zéros aux endroits non-pivots.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.   La matrice contient une ligne de zéros qui se trouve dans le bas de la matrice. La première condition est respectée. De plus, les pivots sont tous égaux à et se trouvent à droite les uns des autres, lorsqu'on regarde les lignes de haut en bas. Les conditions deux et trois sont aussi respectées. Finalement, les colonnes pivots et ne contiennent que des zéros aux endroits non-pivots. La condition quatre est donc aussi respectée.  Comme les quatre conditions sont respectées, la matrice est échelonnée réduite.    La matrice contient une ligne de zéro, soit la deuxième. Toutefois, la ligne trois contient des entrées non nulles. La première condition n'est donc pas respectée. Il y a deux pivots égaux à , dans la ligne un et dans la ligne trois. Le pivot de la ligne trois se trouvant à droite de celui de la ligne un, les conditions deux et trois sont respectées. Finalement, les colonnes pivots (un et trois) ne contiennent que des zéros aux endroits non-pivot. La quatrième condition est aussi respectée.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.     Origine du terme \"échelon\"  Le mot échelonnée dans la forme échelonnée réduite vient d' échelle . On peut en effet percevoir un certain effet d'escalier en regardant les pivots d'une matrice échelonnée réduite.   Justification du mot \"échelon\"   Les pivots de la forme échelonnée réduite d'une matrice sont donnés. Comme ces pivots se trouvent à la droite les uns des autres lorsqu'on lit la matrice de haut en bas, on peut y voir un escalier.     À ce stade-ci, on se doute bien qu'il est possible de transformer une matrice en une matrice équivalente qui sera échelonnée réduite en utilisant les opérations élémentaires. S'il s'avérait que la forme échelonnée réduite d'une matrice était unique, on aurait alors une façon de savoir quand arrêter les opérations élémentaires.   La forme échelonnée réduite d'une matrice est unique   Soit , une matrice de taille . Par une suite d'opérations élémentaires, on peut arriver à une forme échelonnée réduite. Peu importe le choix des opérations élémentaires ou l'ordre de celles-ci, la forme échelonnée réduite sera toujours la même. Pour cette raison, on définit  L'expression erl signifie \"échelonnée réduite ligne\", alors que rref vient de l'anglais \"row reduced echelon form\". Par choix, on utilisera la version anglaise, car elle est identique à la commande Sage qui sera utilisée. comme étant l'unique forme échelonnée réduite de la matrice .    On utilise une preuve par induction sur le nombre de colonnes de la matrice .   Le cas : Si la matrice n'est qu'un vecteur colonne, alors ce vecteur peut être est nul, auquel cas il est déjà sous la forme rref. Toutes les opérations sur les lignes ne changent pas le vecteur nul et donc sa forme rref est unique. Si le vecteur n'est pas le vecteur nul, alors il existe au moins une entrée non nulle. On prend la première composante non nulle du vecteur, disons en position . Celle-ci est forcément un pivot de sa ligne. Peu importe sa valeur , on peut la normaliser à en effectuant l'opération . Par la suite, chaque entrée non nulle en position peut facilement être transformée en à l'aide d'une application de l'opération . Le vecteur obtenu à la suite de ces opérations contient un en position , la première entrée non nulle, et doit nécessairement avoir des en dessous. La forme rref est aussi unique dans ce cas.  On suppose que, pour une matrice de taille , la forme rref est unique.  Soit , une matrice de taille et soit , deux matrices échelonnées réduites équivalentes à De plus, on pose , la matrice que l'on obtient de en supprimant la dernière colonne. Peu importe la chaine d'opérations élémentaires menant à ou , la matrice est aussi transformée sous une forme échelonnée réduite lorsque ces opérations sont appliquées à .  Parce que est une matrice de taille , l'hypothèse d'induction affirme que sa forme rref est unique. Donc si et sont différentes, elles le sont uniquement dans la dernière colonne.  On considère maintenant un vecteur tel que . On sait qu'au moins le vecteur est une solution à cette équation, mais qu'il n'est pas nécessairement la seule solution. Dans tous les cas, la proposition dit que et . En particulier . En rappelant l'équation et le fait que les premières colonnes des matrices et concordent, la seule équation qui reste dans le produit est .  Si , alors les colonnes des matrices et sont aussi égales, donnant et l'unicité de la forme échelonnée réduite. Sinon, comme les matrices et sont rref, elles doivent n'avoir que des et un . Ce est forcément à la même position, car une des conditions d'être rref est que les lignes de soient dans le bas de la matrice. Les se trouvent donc sous la dernière ligne de ayant un pivot. Dans ce cas aussi, la dernière colonne concorde et l'on a .       Comme les opérations élémentaires préservent les solutions et que la forme échelonnée réduite est unique, la technique choisie pour résoudre un système d'équations linéaires est d'échelonner la matrice augmentée du système jusqu'à sa forme rref. Ceci donne une manière simple Dans les prochaines sous-sections, on verra quelques subtilités de la lecture de ces solutions. de lire la solution. Voici maintenant en détail l'algorithme de Gauss-Jordan.   La méthode de Gauss-Jordan   Soit , une matrice de taille . Il est possible d'obtenir la forme échelonnée réduite de , en suivant le processus suivant:   Algorithme de Gauss-Jordan   Si n'est pas encore défini, on pose . Si , on saute à l'étape suivante. Sinon, si , on augmente de .  Si possible, échanger la ligne avec une autre ligne ( ) de manière à avoir un pivot non nul dans la colonne la plus à gauche possible.  Si nécessaire, multiplier la nouvelle ligne par la constante appropriée pour avoir son pivot égal à .  Utiliser l'opération pour que chaque entrée sous le pivot soit nulle. ( ).  Retourner à la première étape.    Pour chaque pivot, utiliser la troisième opération élémentaire pour avoir des zéros au-dessus du pivot.       L'efficacité de l'algorithme  Dans certaines étapes de l'algorithme de Gauss-Jordan , il peut être avantageux de sélectionner une ligne en particulier afin de simplifier les calculs. Aussi, on peut vouloir retarder afin d'éviter de travailler avec des fractions. L'algorithme décrit une manière automatique d'obtenir la forme échelonnée réduite, un peu comme le ferait un ordinateur.  De même, si l'on se limite à ne faire que l'étape , sans nécessairement avoir les pivots égaux à , on obtient l'algorithme de Gauss. Une matrice ainsi transformée serait alors sous forme échelonnée seulement (pas réduite). L'exemple était un exemple d'application de l'algorithme de Gauss seulement, soit sans faire l'étape .   On illustre maintenant l'algorithme de Gauss-Jordan, en précisant les étapes pour référence. On ne va pas faire cette correspondance dans le futur.   L'algorithme de Gauss-Jordan en action  On considère le système d'équations linéaires suivant. . On cherche à trouver la solution de ce système en utilisant l'algorithme de Gauss-Jordan pour réduire la matrice augmentée.   La matrice augmentée associée au SEL est . C'est une matrice , en comptant la partie augmentée. On a donc .  On commence l'algorithme de Gauss-Jordan.  Comme n'est pas défini, on pose .  Puisque la première colonne contient des valeurs non nulles, ce sera une colonne pivot. Toutefois, l'entrée de la première colonne dans la ligne est nulle. Il faut donc permuter deux lignes: .  Afin de rendre le pivot de la nouvelle ligne un égal à , on multiplie la ligne un par .   On veut maintenant avoir des sous le pivot de la ligne un. Ici, il n'y a qu'une opération à effectuer, car la deuxième ligne a déjà son . On utilise l'opération . .  On retourne à la première étape.   On a maintenant .   Les entrées de la seconde colonne à partir de la ligne deux ne sont pas toutes nulles, il y aura donc un pivot dans la colonne deux. En principe, l'algorithme dit de passer à l'étape suivante et de multiplier par . On se sert ici de la remarque pour simplifier les calculs, en permutant les lignes deux et trois. .  On veut maintenant avoir un zéro sous le pivot de la ligne deux. Pour cela, on utilise l'opération . .   On retourne à la première étape.   On a maintenant .    Il est possible d'avoir un pivot dans la dernière colonne. On met ce pivot égal à . .  Comme il n'y a plus d'entrée sous le pivot, on retourne à la première étape.    Puisque , on passe à la deuxième étape de l'algorithme.  Pour chaque pivot, on veut obtenir des zéros au-dessus de la valeur qui est pivot. On a trois pivots.  On commence avec le pivot sur la deuxième ligne. On souhaite transformer le de la ligne un en en utilisant la ligne deux. .  En utilisant la dernière ligne, on veut transformer le de la ligne deux et le de la ligne un en . .      Ceci complète l'algorithme de Gauss-Jordan, la matrice étant échelonnée réduite. On peut y lire la solution .   On poursuit avec un autre exemple relié à l'exemple . Cette fois-ci, on se contente d'échelonner la matrice en écrivant les opérations élémentaires, sans préciser les étapes de l'algorithme.   Gauss-Jordan: chaine d'équivalences   On s'intéresse aux systèmes et , en lien avec le système similaire résolu à l'exemple . On cherche les solutions à ces deux systèmes. On remarque qu'en vertu de la proposition , la solution à ces trois systèmes donnera aussi la matrice inverse de .    On peut travailler de manière efficace. Il n'est pas nécessaire d'échelonner la matrice pour chaque système. En effet, peu importe la chaine d'opérations élémentaires effectuées pour échelonner le SEL dans le cas du premier système, cette chaine fonctionnera aussi pour le deuxième SEL. On peut donc augmenter la matrice des deux vecteurs et effectuer les opérations sur cette matrice augmentée. De plus, les opérations élémentaires ayant servies à trouver la solution dans l'exemple peuvent être réutilisées ici, puisqu'elles constituent l'étape un de l'algorithme de Gauss-Jordan , hormis le fait que les pivots ne sont pas égaux à . Il faut, par contre, refaire les calculs sur la partie augmentée. .  La solution au premier système est donc et celle du second est . De plus, en reprenant la réponse de l'exemple , on obtient     Les possibilités d'opérations  En combinant plusieurs opérations élémentaires, on obtient une opération valide (qui n'est généralement pas élémentaire) pour échelonner une matrice. Ainsi, l'opération peut être vue comme la combinaison des opérations élémentaires suivie de l'opération . Bien qu'elle ne soit pas élémentaire, cette opération s'avère pratique pour échelonner des matrices, comme dans l'exemple suivant. . L'opération permet d'obtenir le sous le pivot de la ligne un, sans que ce pivot soit égal à , ce qui aurait introduit une fraction dans la seconde colonne.  Bien que permises, on fait le choix d'éviter ces opérations. On voudra de toute manière déléguer beaucoup des calculs à l'ordinateur. On choisit donc de se concentrer sur les opérations élémentaires. Il est toutefois possible d'éviter les fractions avec les opérations élémentaires, comme dans l'exemple suivant. . Cette opération rend le pivot de la première ligne égal à sans créer de fraction dans la deuxième colonne.  Finalement, on peut se permettre de faire plusieurs opérations en une étape, comme lors de l'équation de l'exemple . Par contre, il est important de retenir qu'on ne doit pas utiliser une ligne qui a été modifiée auparavant dans la même étape pour modifier une autre ligne. Voir l'exercice   On termine avec des commandes Sage en lien avec la sous-section.   La forme échelonnée réduite sur Sage  Pour une matrice quelconque, on peut obtenir sa forme échelonnée réduite avec Sage à l'aide de la commande A.rref() .   Pour résoudre un système d'équations linéaires , il existe plusieurs possibilités. En plus de la solution au système, les informations supplémentaires que l'on peut obtenir guideront le choix parmi les possibilités. Dans un premier temps, on peut augmenter la matrice avec le vecteur et obtenir la forme échelonnée réduite de la matrice augmentée. La dernière colonne contient alors la solution.   Une autre option consiste à utiliser la commande A.solve_right(b) (le _right fait référence à l'équation , où le vecteur est à droite, plutôt qu'à l'équation ). Cette commande ne donne que la solution au système, pas la matrice échelonnée. Donc, s'il est pratique de l'avoir, on utilisera l'échelonnage.   La commande A.pivots() retourne la position des colonnes pivots. Attention, on rappelle que Sage commence sa numérotation à , la deuxième colonne sera donc indicée par .       Les points importants de cette section sont:  La définition d'un système d'équations linéaires et la matrice associée au SEL;  Les opérations et les matrices élémentaires;  Le fait que les opérations élémentaires préservent les solutions d'un système;  La notion de matrice augmentée ;  La notion de variable pivot et libre et la forme échelonnée réduite d'une matrice;  L'algorithme de Gauss-Jordan , pour échelonner des matrices.    De plus, les commandes Sage utiles sont  la commande A.augment(b) pour augmenter la matrice du vecteur ;  la commande elementary_matrix pour obtenir une matrice élémentaire;  la commande A.rref() pour avoir la forme échelonnée réduite d'une matrice;  la commande A.solve_right(b) pour résoudre un SEL;  la commande A.solve_right(b) pour résoudre un SEL et A.pivots() pour avoir la position des colonnes pivots.       Exercices    Pour chacune des opérations élémentaires suivantes, donner la matrice élémentaire qui lui est associée.   L'opération pour un système à cinq équations.   On procède de façon semblable à l'exemple . On doit prendre la matrice identité d'ordre , correspondant au nombre d'équations du système. Puis, on applique l'opération élémentaire demandée à cette matrice. Le résultat est la matrice élémentaire voulue.     L'opération pour un système à huit équations.     L'opération pour un système à trois équations et deux inconnues.     L'opération pour un système à trois équations et trois inconnues.    On remarque que cette réponse est identique à la précédente, ce qui signifie que le nombre d'inconnues n'est pas important. Pour construire une matrice élémentaire, il faut uniquement regarder l'opération élémentaire que l'on veut effectuer sur les lignes. La taille de la matrice dépend donc du nombre de lignes, mais de du nombre de colonnes.   L'opération pour un système à cinq équations.     Parmi les matrices suivantes, lesquelles sont élémentaires? Donner l'opération élémentaire le cas échéant.    Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .     Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .     Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .    Montrer que les matrices de permutation, définies à l'exercice , peuvent s'écrire comme un produit de matrices élémentaires en utilisant uniquement les matrices de type .   Comme défini dans l'exercice, une matrice de permutation est une matrice telle que chaque colonne et chaque ligne ne contient qu'une entrée non nulle égale à . On constate assez facilement qu'une telle matrice sera toujours obtenue à partir de la matrice identité en permutant des lignes. En effet, pour que la matrice ait exactement un et que des dans chaque ligne et colonne, on doit avoir le dans une colonne différente pour chaque ligne. Ce sont donc les lignes de l'identité, mais positionnées à différentes lignes.  Différents cas de figure sont possibles. D'abord, on considère le cas où la matrice est l'identité et seulement deux lignes ont été permutées, par exemple les lignes et . On constate que . Ensuite, on considère le cas où la matrice est l'identité et exactement trois lignes ont été permutées, par exemple les lignes , et . Seulement deux options sont alors possibles:   .  On peut effectuer ces permutations triples en deux étapes. Par exemple, pour effectuant , on peut effectuer puis . Remarquer que la seconde permutation permute en réalité les lignes et de la matrice initiale, mais que est positionnée à . Ainsi, Le principe qui semble se dégager est qu'on utilise une matrice de permutation pour positionner la première ligne , puis une seconde pour positionner la seconde ligne . La dernière ligne est nécessairement permutée par une de ces deux permutations puisque sinon, ce ne serait pas une permutation triple.  On établit maintenant le principe pour permuter lignes, soient les lignes . La matrice sera formée de la multiplication d'au maximum matrices élémentaires. La première (en partant de la droite) permettra de positionner la ligne . La seconde permettra de positionner la ligne (initialement positionnée à) . Ainsi de suite, jusqu'à la , qui permettra de positionner la ligne (initialement positionnée à) . Alors, on écrit, avec une notation discutable puisqu'on ne sait pas toujours si la ligne a été modifiée ou pas: .    Une matrice carrée inversible est équivalente à la matrice identité. Cela signifie qu'il existe des matrices élémentaires telles que . On peut donc dire que .  En utilisant cette forme pour l'inverse, donner une preuve alternative aux résultats suivants.   Montrer que si , alors , donnant ainsi une preuve alternative à la proposition .   Par l'hypothèse et l'énoncé de l'exercice, on sait que l'on peut écrire ainsi : . Puisque les matrices élémentaires sont toutes inversibles, par la proposition , on peut donc faire les opérations suivantes: Ainsi, on obtient une expression pour qui ne dépend que des inverses des matrices élémentaires. On peut donc démontrer le résultat voulu rapidement:    Montrer que , donnant ainsi une preuve alternative à la proposition .   Pour obtenir cette propriété, on peut supposer que les matrices et sont toutes les deux inversibles. Bref, suivant l'énoncé de l'exercice et la réponse de la partie précédente, on peut écrire les matrices , , et des façons suivantes: , où les matrices sont matrices élémentaires telles que l'on peut écrire pour la matrice inversible .  Ainsi, on peut démontrer l'équation proposée. On y arrive en multipliant par et en montrant qu'on obtient bien la matrice identité. .   Montrer que , donnant ainsi une preuve alternative à la proposition .   On veut démontrer que la matrice fait bien office d'inverse pour la matrice . Ainsi, la matrice fait bien office d'inverse pour la matrice . Ainsi, .   Une grille de sudoku résolue peut être vue comme une matrice . Soit une telle matrice. Parmi les opérations élémentaires , lesquelles gardent la matrice transformée comme une solution recevable selon les règles d'une grille sudoku? (Bonus: comment arriver à matrices, sans les énumérer?)  Pour connaitre comment fonctionne un sudoku, on conseille de faire une recherche sur Google .     On sait que les sudokus résolus ont les trois propriétés suivantes:  Chaque ligne contient tous les chiffres de à une fois chacun.  Chaque colonne contient tous les chiffres de à une fois chacun.  Chaque sous-matrice obtenue en divisant la grille en contient tous les chiffres de à une fois chacun.  Les première et deuxième propriétés ne seront jamais perdues par la multiplication d'une matrice élémentaire puisqu'en interchangeant les lignes, on ne les change pas et les colonnes demeurent entièrement constituées des mêmes chiffres.  On doit donc préserver la troisième propriété. Pour ce faire, on doit accepter seulement les permutations de lignes à l'intérieur des trois sous-groupes de lignes: à , à et à . Le nombre de permutations pour chaque sous-groupe est de trois, par exemple, , et . On en a donc au total. Voici la liste: .  BONUS: On obtient le nombre de permutations possibles au total en calculant d'abord les permutations impliquant la ligne , puis celles impliquant la seconde, mais excluant la première, et ainsi de suite. On obtient donc : permutations possibles.  On pose . Que vaut ?    On rappelle une définition du produit matrice vecteur donnée en fonction des lignes. La définition usuelle pourrait aussi nous amener au résultat rapidement, mais, dans ce cas-ci, on préfère la première.    Démontrer la proposition .   Par la définition , toutes les matrices élémentaires sont le résultat d'une seule opération élémentaire. Ainsi, si l'on démontre la deuxième portion de la proposition, en donnant la matrice inverse de chaque matrice élémentaire, on aura montré la première portion qui dit que les matrices élémentaires sont toutes inversibles. On démontre donc pour chaque matrice élémentaire que son inverse est celui donné dans la proposition . est la matrice élémentaire qui permute la ligne avec la ligne , alors pour défaire cette opération, il faut en réalité refaire la même opération. En effet, on considère la matrice décrite, et l'on se questionne à savoir quelle matrice la multipliera pour donner la matrice identité. On réalise que est, par la définition , la matrice identité où l'on a permuté la ligne et la ligne . Il est donc évident que c'est cette même matrice qui, lorsque multipliée avec , permutra à nouveau la ligne et la ligne pour obtenir l'identité. Ainsi, .  est la matrice qui multiplie la ligne par , alors, par la définition , c'est la matrice identité où l'on a multiplié la ligne par . Afin d'obtenir à nouveau la matrice identité, il faut la multiplier par une matrice qui effectuera l'opération élémentaire suivante: multiplier la ligne par . C'est donc, encore par la définition , la matrice identité où l'on a multiplié la ligne par . Ainsi, .  est la matrice élémentaire qui ajoute à la ligne , fois la ligne , on construit alors un raisonnement semblable aux deux précédents pour montrer qu'effectivement , en se servant de la même définition.     Montrer que l'opération élémentaire qui consiste à permuter deux lignes n'est pas essentielle, c'est-à-dire qu'il est possible de permuter deux lignes en utilisant uniquement les deux autres opérations élémentaires.   Voici une séquence d'opérations élémentaires qui permet d'échanger la ligne avec la ligne , en n'utilisant que l'opération de combinaison linéaire et celle de multiplication par une constante. On fait, dans l'ordre     .    Parmi les matrices suivantes, déterminer celles qui sont sous la forme échelonnée réduite. Pour chaque matrice qui n'est pas échelonnée réduite, effectuer les opérations élémentaires pour la rendre échelonnée réduite. Finalement, pour chaque matrice, identifier les colonnes pivots.    Cette matrice n'est pas échelonnée réduite. On effectue les opérations. Son unique colonne pivot est la deuxième.     Cette matrice n'est pas échelonnée réduite. On effectue les opérations manquantes. Ses colonnes pivots sont la première et la troisième.     Cette matrice est échelonnée réduite. Ses colonnes pivots sont la deuxième et la troisième. Cette matrice est échelonnée réduite. Son unique colonne pivot est la troisième.  Faire la liste de toutes les matrices échelonnées réduites. Il y en a une infinité, mais elles peuvent se classer en quatre types.  Les quatre types sont: , , et     On s'intéresse aux caractéristiques des matrices échelonnées réduites, telles qu'énoncées à la liste .  Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .  Il existe évidemment une infinité de bonnes réponses. Essayer de comparer la réponse donnée aux propriétés et voir si votre réponse est valide.  Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .   Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .   Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .   Soit , une matrice , et , des vecteurs tels que . Quelles sont les dimensions des vecteurs ? est de dimension et et sont de dimension . Si l'on voit la matrice ainsi que les vecteurs comme représentant les différentes composantes de SEL décrits par les équations , on peut voir les dimensions des vecteurs en s'aidant de la définition ou, plus simplement, de l'exemple . Le format de la matrice étant , la dimension du vecteur correspondra au nombre de lignes, soit , et la dimension des vecteurs et correspondra au nombre de colonnes, soit .  En résumé, est de dimension et et sont de dimension .  Montrer que est une solution de .   On voit donc que est une solution de .   Soit tel que . Montrer que est une solution de .   De façon semblable, .   Si est une matrice sous forme échelonnée réduite, quel est le nombre maximal de pivots que peut posséder? La matrice peut posséder pivots au maximum. Si la matrice est une matrice carrée, il est clair qu'elle peut avoir un nombre de pivots égal à son ordre. Cependant, si elle est rectangulaire ( ), le nombre de pivots sera limité par la valeur la plus petite entre et . En effet, il faut avoir une ligne et une colonne associée à chaque pivot.  Pour chacun des cas suivants, donner une ou deux matrices échelonnées réduites de format demandé qui respectent les conditions additionnelles: Deux matrices pour lesquelles la variable est libre. Deux matrices pour lesquelles la variable est libre. Deux matrices pour lesquelles les variables sont pivots et est libre.  Deux matrices pour lesquelles les variables sont pivots et est libre.  Une seule matrice  pour laquelle les variables sont pivots et est libre.  Une seule matrice  pour laquelle les variables sont libres et est pivot.  Deux matrices pour lesquelles les variables sont libres et est pivot.  Deux matrices pour lesquelles les variables sont libres et est pivot.  Deux matrices pour lesquelles exactement deux variables sont pivots.   Considérer la matrice . Quelle est la solution de ce système dans le cas où la valeur de fait en sorte qu'il est nécessaire d'effectuer l'opération élémentaire ?  La solution est dans le cas où . On commence l'algorithme de Gauss-Jordan et l'on verra à quel moment cette opération sera nécessaire et quelle valeur de cela prendra. On constate déjà, à ce stade, que la deuxième ligne pourrait être un pivot dans le cas où . Inversement, il sera impossible que cette ligne soit un pivot si et il faudra faire l'opération élémentaire . On pose donc et l'on poursuit avec cette opération et le reste de l'algorithme. La solution est donc .   Mettre la matrice sous la forme échelonnée réduite. Quelles sont les hypothèses additionnelles qui sont faites si    ?  Si , on peut donc se servir de l'algorithme de Gauss-Jordan pour échelonner en gardant le comme premier pivot. On n'aura pas à permuter les lignes entre elles. La seule hypothèse additionnelle est que puisqu'on retrouve cette expression au dénominateur. On a vu à la section que les matrices étaient inversibles à condition que cette quantité soit non-nulle. Nous verrons au chapitre qu'il s'agit du déterminant d'une matrice .   ?  et Si , on peut donc se servir de l'algorithme de Gauss-Jordan pour échelonner en commençant par permuter les deux lignes. Les deux hypothèses additionnelles sont que et puisqu'on retrouve ces expressions au dénominateur. Quel est le nombre maximum d'opérations élémentaires à effectuer pour échelonner une matrice . Quatre opérations au maximum. Quatre opérations au maximum. On l'a démontré en répondant aux deux questions précédentes. En effet, en couvrant les cas où et où , on couvre tous les cas possibles. Les deux cas ont exigé quatre opérations élémentaires. C'est donc le maximum.  À la section , on a établi qu'une matrice était inversible si . Montrer que toute matrice équivalente à une matrice telle que possède aussi cette condition.  Il suffit d'appliquer chaque opération élémentaire à la matrice et de vérifier la condition.  On procède comme suggéré dans l'indice. On vérifie donc, pour chacune des trois opérations élémentaires, que l'on obtient encore la condition. La condition est: qui est entièrement équivalente à en réorganisant les termes.  La seconde opération de multiplication par un scalaire doit être vérifiée pour chaque ligne. et La condition est donc: ou bien qui sont équivalentes à , pourvu que , ce qui est le cas par la définition .  Finalement, la dernière opération élémentaire doit également être vérifiée pour chaque ligne. et La condition est donc: ou bien qui sont toutes les deux exactement pareilles à .    Dans le début de la sous-section , on a établi qu'un système à deux équations et deux inconnues devait avoir aucune, une seule ou une infinité de solutions, en faisant le parallèle avec la géométrie des droites. Dans cet exercice, on essaie de faire la même chose avec des plans.   Considérer un système à deux équations et trois inconnues. Chaque équation peut être vue comme l'équation normale d'un plan dans .   Quelle peut être la position relative de deux plans dans l'espace? Illustrer tous les cas possibles.  On peut avoir deux plans parallèles distincts, parallèles confondus ou sécants. Les illustrations sont à venir. Combien de solutions peut-il y avoir à l'équation si est une matrice ? Donner un exemple pour chaque cas possible. Il peut y avoir soit une infinité de solutions, soit aucune solution. Il n'y aura jamais de solution unique. Géométriquement, il y a deux façons d'avoir une infinité de solutions: deux plans sécants (les solutions seront sur la droite formée par l'intersection des deux plans) ou deux plans parallèles confondus (les solutions seront l'ensemble des plans confondus). L'équation n'aura pas de solution si elle représente deux plans parallèles distincts. On donne un exemple pour chaque cas possible:  Le système représente deux plans sécants ayant une infinité de solutions.  Le système représente deux plans parallèles confondus ayant une infinité de solutions.  Le système représente deux plans parallèles distincts n'ayant aucune solution. On considère maintenant trois plans dans l'espace. Quelle peut être la position relative de trois plans distincts dans l'espace? Trois plans dans l'espace peuvent être :  tous parallèles distincts  deux parallèles distincts et le troisième sécant aux deux  aucunement parallèles, mais sécants deux à deux  sécants tous les trois sur une droite  sécants tous les trois sur un point.  Déduire géométriquement que le système possède aucune, une seule ou une infinité de solutions. On reprend les différentes situations décrites et on attribue le nombre de solutions :  Tous parallèles distincts: aucune solution.  Deux parallèles distincts et le troisième sécant aux deux: aucune solution.  Aucunement parallèles, mais sécants deux à deux: aucune solution.  Sécants tous les trois sur une droite: infinité de solutions.  Sécants tous les trois sur un point: une seule solution.  Expliquer algébriquement pourquoi si sont des solutions au système (peu importe la taille de la matrice !), alors il existe une infinité de solutions. Si sont des solutions au système , on peut écrire et . Ainsi, on peut créer une infinité de solutions : où  On a donc la possibilité de créer une infinité de différentes solutions en posant différentes valeurs de et .   En se basant sur l'exemple , trouver l'inverse des matrices suivantes en les augmentant de la matrice identité de format approprié.    L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:  Une matrice est telle que , et . Trouver telle que . Que vaut ?  et .  Puisque les vecteurs ont trois composantes et que les vecteurs en ont trois également, on sait que la matrice est de taille . De plus, les équations données dans l'exercice permettent de dire que la matrice est inversible et que , en vertu de la remarque . On a donc . On peut calculer ce produit matrice vecteur directement ou avec l'approche par colonne. Dans tous les cas, on obtient .  Pour trouver la matrice , on peut utiliser une démarche semblable à l'exemple pour échelonner la matrice augmentée . On a .    On considère la matrice . Pour quelle(s) valeurs de la matrice possède-t-elle un seul pivot?  et Afin de répondre à cette question, on va échelonner la matrice et voir sous quelles conditions elle ne possèdera qu'un seul pivot. Pour n'avoir qu'un seul pivot, il faut que . Cela arrivera pour deux valeurs de , soient et .   Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.   Pour chaque matrice de l'exercice , utiliser la commande elementary_matrix pour obtenir la matrice élémentaire associée à l'opération.     Le code pour les matrices élémentaires   show(elementary_matrix(5,row1=2,row2=4)) #On se rapelle que la première ligne est indicée à 0 show(elementary_matrix(8,row1=2,row2=4)) show(elementary_matrix(3,row1=1,scale=4)) show(elementary_matrix(3,row1=1,scale=4)) show(elementary_matrix(5,row1=3,row2=0,scale=-4))      Utiliser Sage pour résoudre les systèmes d'équations linéaires suivants,  en utilisant une matrice augmentée et sa forme échelonnée réduite.     Le code solution   A=matrix([[3,2,-5,1],[0,8,2,0],[1,-7,5,0],[2,3,1,-1]])# La matrice b=vector([-1,3,-2,5]) #Le vecteur sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout    Les systèmes où et   Si , alors   Le code solution   A=matrix([[0,1,4,-1,2,7],[-1,3,3,1,12,3],[11,0,2,5,0,-4],[9,5,-1,11,-7,4],[1,2,3,-4,5,7],[-3,2,5,7,8,-13]]) b1=vector([1,2,3,4,5,6]) b2=vector([6,5,4,3,2,1]) b3=vector([1,-2,3,-4,5,-6]) b4=vector([-6,5,-4,3,-2,1]) #Pour augmenter une matrice de plusieurs vecteurs, on peut procéder comme suit: Aug=((((A.augment(b1)).augment(b2)).augment(b3)).augment(b4)) show(Aug) #Ou encore en définissant une matrice au préalable B=column_matrix([b1,b2,b3,b4]) Augm=A.augment(B,subdivide=True) show(Augm) sol=(Augm.rref()) show(sol) vecsol1=sol.column(-4) vecsol2=sol.column(-3) vecsol3=sol.column(-2) vecsol4=sol.column(-1) pretty_print(\"La solution de Ax=b1 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol1) pretty_print(\"La solution de Ax=b2 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol2) pretty_print(\"La solution de Ax=b3 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol3) pretty_print(\"La solution de Ax=b4 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol4)     Le système .    Le code solution   A=matrix([[1,1,1,1],[1,2,3,4],[1,4,9,16],[1,8,27,64]])# La matrice b=vector([1,2,3,4]) #Le vecteur show(A.augment(b)) #Optionnel: pour vérifier qu'on a bien écrit le système dans Sage sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout    Le système .  On voit qu'il est très simple de résoudre une légère modification d'un problème déjà résolu avec l'ordinateur, alors qu'à la main, le travail aurait dû être refait en grande partie.    Le code solution   A=matrix([[1,-1,1,-1],[1,-2,3,-4],[1,-4,9,-16],[1,-8,27,-64]])# La matrice b=vector([1,-2,3,-4]) #Le vecteur show(A.augment(b)) #Optionnel: pour vérifier qu'on a bien écrit le système dans Sage sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout   en utilisant la commande solve_right .  Le système .    Le code solution   A=matrix([[1,1,1,1],[1,2,3,4],[1,4,9,16],[1,8,27,64]])# La matrice b=vector([1,2,3,4]) #Le vecteur sol=(A.solve_right(b)) pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",sol)    Le système .    Le code solution   A=matrix([[1,-1,1,-1],[1,-2,3,-4],[1,-4,9,-16],[1,-8,27,-64]])# La matrice b=vector([1,-2,3,-4]) #Le vecteur sol=(A.solve_right(b)) pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",sol)    La parabole revisitée Dans l'exercice , on a automatisé le calcul de l'équation d'une parabole connaissant sa droite directrice et son foyer. Si la parabole est aussi une fonction, soit , alors il est possible à l'aide de trois points de la parabole de trouver l'équation.   Soit et trois points sur une parabole d'équation .  En utilisant un système d'équations linéaires, déterminer l'équation de la parabole. Tracer celle-ci, ainsi que les points sur un même graphique.     Le code solution permettant de trouver l'équation et de tracer la parabole et les trois points   P=vector([-1,22]) Q=vector([2,19]) R=vector([3,34]) A=matrix([[P[0]^2,P[0],1],[Q[0]^2,Q[0],1],[R[0]^2,R[0],1]]) v=vector([P[1],Q[1],R[1]]) sol=A.solve_right(v) print(\"L'équation de la parabole est \",sol[0]*x^2+sol[1]*x+sol[2]) para=plot(sol[0]*x^2+sol[1]*x+sol[2],(x,-2,4)) #On trace les points et on les identifie de belle façon ptP=plot(point(P))+text(' P(%s,%s)'%(P[0],P[1]),P,horizontal_alignment='left') ptQ=plot(point(Q))+text(' Q(%s,%s)'%(Q[0],Q[1]),Q,horizontal_alignment='left') ptR=plot(point(R))+text(' R(%s,%s)'%(R[0],R[1]),R,horizontal_alignment='left') show(para+ptP+ptQ+ptR)    On veut maintenant créer une fonction qui va retourner l'équation d'une parabole passant par trois points donnés. La fonction doit d'abord vérifier si les trois points sont différents et ensuite retourner son équation. Tester la fonction avec la réponse à la partie précédente et avec des points pareils. Finalement, observer le résultat lorsqu'on calcule l'équation pour trois points alignés.     La fonction qui donne l'équation de la parabole passant par trois points donnés   def eqparapoints(P1,P2,P3): v1=P2-P1 v2=P3-P1 if P1==P2 or P1==P3 or P2==P3: print(\"Il faut fournir trois points différents pour définir une parabole.\") else: #On veut résoudre ax^2+bx+c=y avec x,y=P1,P2,P3. On résoute le système A(a,b,c)=v où v=(y1,y2,y3) A=matrix([[P1[0]^2,P1[0],1],[P2[0]^2,P2[0],1],[P3[0]^2,P3[0],1]]) v=vector([P1[1],P2[1],P3[1]]) sol=A.solve_right(v) print(\"L'équation de la parabole est \",sol[0]*x^2+sol[1]*x+sol[2]) P1=vector([-1,22]) P2=vector([2,19]) P3=vector([3,34]) P4=(P1+P2)\/2 eqparapoints(P1,P2,P3) eqparapoints(P1,P1,P3) #On teste avec deux points pareils eqparapoints(P1,P2,P4) #On teste avec trois points sur une droite    On remarque que l'équation obtenue pour trois points alignés est l'équation d'une droite.     "
},
{
  "id": "fig-sel2x2geo-1",
  "level": "2",
  "url": "sec-GJ.html#fig-sel2x2geo-1",
  "type": "Figure",
  "number": "3.1.1",
  "title": "",
  "body": " Des droites sécantes dans .     "
},
{
  "id": "fig-sel2x2geo-3",
  "level": "2",
  "url": "sec-GJ.html#fig-sel2x2geo-3",
  "type": "Figure",
  "number": "3.1.2",
  "title": "",
  "body": " Des droites parallèles distinctes dans .     "
},
{
  "id": "fig-sel2x2geo-2",
  "level": "2",
  "url": "sec-GJ.html#fig-sel2x2geo-2",
  "type": "Figure",
  "number": "3.1.3",
  "title": "",
  "body": " Des droites parallèles confondues dans .     "
},
{
  "id": "def-eqlin",
  "level": "2",
  "url": "sec-GJ.html#def-eqlin",
  "type": "Définition",
  "number": "3.1.4",
  "title": "Une équation linéaire.",
  "body": " Une équation linéaire  Soit , des variables. Une équation de ces variables est linéaire si elle est de la forme , où . Si l'on pose , il est possible de réécrire l'équation comme .  "
},
{
  "id": "def-SEL",
  "level": "2",
  "url": "sec-GJ.html#def-SEL",
  "type": "Définition",
  "number": "3.1.5",
  "title": "Système d’équations linéaires.",
  "body": " Système d'équations linéaires  Un système d'équations linéaires (SEL) est un ensemble de équations linéaires comportant chacune inconnues. Typiquement, on écrira .  En posant , on reconnait dans le SEL la multiplication matrice et vecteur . Donc, pour , le SEL peut s'écrire comme .  L'ensemble des valeurs qui satisfont un SEL est appelé l'ensemble solution .   "
},
{
  "id": "ex-sel2x2intro",
  "level": "2",
  "url": "sec-GJ.html#ex-sel2x2intro",
  "type": "Exemple",
  "number": "3.1.6",
  "title": "De la forme SEL à la forme matricielle.",
  "body": " De la forme SEL à la forme matricielle  On considère les systèmes d'équations linéaires introduits en début de sous-section. On avait , et .  On veut écrire chacun de ces systèmes d'équations linéaires sous forme matricielle.   Si l'on pose et , les SEL s'écrivent respectivement comme , où .   "
},
{
  "id": "example-54",
  "level": "2",
  "url": "sec-GJ.html#example-54",
  "type": "Exemple",
  "number": "3.1.7",
  "title": "De la forme matricielle à la forme SEL.",
  "body": " De la forme matricielle à la forme SEL  Soit . On cherche à écrire trois systèmes d'équations linéaires qui permettent de déterminer l'inverse de .  Selon l'équation , les colonnes de la matrice inverse sont les vecteurs qui satisfont les équations . Ces réponses représentent un système d'équations linéaires sous leur forme actuelle et répondent à la question, mais, pour montrer la forme en équations, on peut effectuer les multiplications. Les trois systèmes deviennent alors : , : et : .   "
},
{
  "id": "example-55",
  "level": "2",
  "url": "sec-GJ.html#example-55",
  "type": "Exemple",
  "number": "3.1.8",
  "title": "Un système d’équations linéaires rectangulaire.",
  "body": " Un système d'équations linéaires rectangulaire  On considère le système . La matrice associée à ce système est .  "
},
{
  "id": "fig-sel2x2geo-4",
  "level": "2",
  "url": "sec-GJ.html#fig-sel2x2geo-4",
  "type": "Figure",
  "number": "3.1.9",
  "title": "",
  "body": " Les trois droites sécantes en un même point.     "
},
{
  "id": "def-opelem",
  "level": "2",
  "url": "sec-GJ.html#def-opelem",
  "type": "Définition",
  "number": "3.1.10",
  "title": "Les opérations élémentaires.",
  "body": " Les opérations élémentaires   On considère un système d'équations linéaires quelconque à équations et inconnues. Les trois opérations suivantes sont appelées les opérations élémentaires:  Interchanger la position de deux équations;  Multiplier une équation par une constante non nulle;  Ajouter à une équation un multiple d'une autre.    Si est la matrice du système, alors les trois opérations élémentaires se traduisent en forme matricielle par:  Interchanger la position de deux lignes;  Multiplier une ligne par une constante non nulle;  Ajouter à une ligne un multiple d'une autre.    Un SEL (ou une matrice) qui s'obtient à partir d'un autre par une suite d'opérations élémentaires est dit équivalent à ce dernier. Si une matrice est équivalente à , on écrit .  "
},
{
  "id": "ex-opelem",
  "level": "2",
  "url": "sec-GJ.html#ex-opelem",
  "type": "Exemple",
  "number": "3.1.11",
  "title": "Les opérations élémentaires.",
  "body": " Les opérations élémentaires  On considère le système . On tente de résoudre ce système en le transformant en un autre, plus simple, à l'aide des opérations élémentaires. La proposition justifiera ces étapes, et l'algorithme de Gauss-Jordan saura donner une structure aux étapes effectuées ici. L'algorithme clarifiera aussi le moment convenable pour arrêter.   On obtient, en soustrayant de la ligne deux le double de la ligne un, le SEL équivalent . À partir de ce nouveau système, on additionne la ligne un à la ligne trois pour obtenir le SEL équivalent . On multiplie maintenant la ligne deux par , ce qui donne . On poursuit avec la soustraction du triple de la ligne deux à la ligne trois: . On effectue finalement une dernière étape qui consiste à multiplier la ligne trois par , pour avoir le système d'équations linéaires .  On écrit sous forme d'équations linéaires le dernier système. .  Même si les étapes pour y arriver ne sont peut-être pas encore claires, on remarque que le SEL est maintenant triangulaire et qu'on peut lire directement la valeur de la composante de la solution, soit . En substituant cette valeur pour dans la seconde équation du SEL, on détermine et finalement, en remplaçant dans la première ligne, on trouve .  Une vérification finale permettra de voir que le vecteur est une solution du système original.   "
},
{
  "id": "prop-opelemsol",
  "level": "2",
  "url": "sec-GJ.html#prop-opelemsol",
  "type": "Proposition",
  "number": "3.1.12",
  "title": "Les opérations élémentaires préservent les solutions.",
  "body": " Les opérations élémentaires préservent les solutions  Soit et , deux matrices telles que les systèmes et sont équivalents. Alors l'ensemble solution à ces systèmes est le même.  "
},
{
  "id": "proof-26",
  "level": "2",
  "url": "sec-GJ.html#proof-26",
  "type": "Démonstration",
  "number": "3.1.2.1",
  "title": "",
  "body": " Il suffit de montrer que chacune des trois opérations élémentaires préserve les solutions.  Dans un premier temps, si les deux systèmes n'ont pas de solution, alors l'ensemble solution est le même, c'est-à-dire que c'est l'ensemble vide. Si toutefois un des systèmes a au moins une solution, on raisonne comme suit.  Il est clair qu'interchanger deux lignes ne changera pas la solution, puisque ce sont exactement les mêmes équations. Leur position est un choix arbitraire.  Soit , une solution au système .  On suppose que soit obtenu à partir du premier système en multipliant la ligne par la constante . Puisque est une solution à , on a .  Comme les autres lignes du SEL sont les mêmes, on conclut que est aussi une solution du système . Si, au contraire, on connait une solution au système , on peut renverser l'ordre du calcul précédent pour montrer que est aussi une solution au système .  On suppose maintenant que la ligne du système est obtenue en ajoutant fois la ligne à la ligne . Puisque est une solution de , en additionnant fois la ligne à la ligne , on a . Ainsi, est aussi une solution du système . Si, au contraire, on connait une solution au système , on peut renverser l'ordre du calcul précédent pour montrer que est aussi une solution au système .  "
},
{
  "id": "def-mataug",
  "level": "2",
  "url": "sec-GJ.html#def-mataug",
  "type": "Définition",
  "number": "3.1.13",
  "title": "La matrice augmentée.",
  "body": " La matrice augmentée  Soit , un système d'équation linéaire . On définit la matrice augmentée de ce système comme étant la matrice .  "
},
{
  "id": "def-matelem",
  "level": "2",
  "url": "sec-GJ.html#def-matelem",
  "type": "Définition",
  "number": "3.1.14",
  "title": "Les matrices élémentaires.",
  "body": " Les matrices élémentaires  Considérons la matrice identité d'ordre . Une matrice élémentaire est une matrice obtenue à partir de la matrice identité en effectuant sur celle-ci une et une seule opération élémentaire.  "
},
{
  "id": "ex-matelem",
  "level": "2",
  "url": "sec-GJ.html#ex-matelem",
  "type": "Exemple",
  "number": "3.1.15",
  "title": "Les matrices élémentaires.",
  "body": " Les matrices élémentaires   Pour chaque opération élémentaire de l'exemple , on donne la matrice élémentaire associée. Leur utilité sera explorée dans l'exemple calculatoire .   La première opération élémentaire effectuée soustrayait le double de la ligne un à la ligne deux. Si l'on effectue cette opération élémentaire sur la matrice identité, on obtient . En fait, on profite de cet exemple pour introduire un élément de notation. Plutôt que de décrire en mot chaque opération élémentaire effectuée, on utilise l'une des variantes de notation suivante, qu'on écrira au-dessus du symbole .  Pour illustrer la permutation de la ligne avec la ligne , on utilise la notation .  Pour illustrer que la ligne est multipliée par la constante non nulle , on utilise la notation .  Finalement, pour illustrer qu'on ajoute fois la ligne à la ligne , on utilise la notation .    En poursuivant avec les opérations de l'exemple , on a, dans l'ordre .   "
},
{
  "id": "prop-mateleminverse",
  "level": "2",
  "url": "sec-GJ.html#prop-mateleminverse",
  "type": "Proposition",
  "number": "3.1.16",
  "title": "",
  "body": "  Les matrices élémentaires sont toutes inversibles. De plus, si  est la matrice élémentaire qui interchange la ligne avec la ligne , alors  est la matrice qui multiplie la ligne par , alors .  est la matrice élémentaire qui ajoute à la ligne , fois la ligne , alors .     Voir l'exercice .   "
},
{
  "id": "sageex-matelem",
  "level": "2",
  "url": "sec-GJ.html#sageex-matelem",
  "type": "Calcul",
  "number": "3.1.17",
  "title": "Les matrices élémentaires sur Sage.",
  "body": " Les matrices élémentaires sur Sage  Les matrices élémentaires peuvent être codées avec Sage. La syntaxe est elementary_matrix(n, row1=i,row2=j, scale=r) , où est la taille de la matrice carrée. Selon l'opération que l'on veut effectuer, certains arguments ne seront pas utilisés. Par exemple, si l'on ne met pas , l'opération est d'interchanger les lignes. Si l'on omet le , l'opération est de multiplier la ligne par , et si les trois arguments sont présents, l'opération est .  On regarde l'utilisation de ces matrices avec Sage, en utilisant les matrices élémentaires de l'exemple .   L'avantage de ces matrices, c'est que les opérations élémentaires peuvent être vues comme la multiplication par la gauche d'une matrice élémentaire. Pour l'observer, on propose de refaire la simplification de l'exemple à l'aide des matrices à . On introduit également la matrice augmentée avec Sage.   Comme chacune des étapes suivantes est effectuée après les précédentes, il est important de bien faire les multiplications.   Le résultat est bel et bien le même que la matrice à la fin de l'exemple .  "
},
{
  "id": "def-matrref",
  "level": "2",
  "url": "sec-GJ.html#def-matrref",
  "type": "Définition",
  "number": "3.1.18",
  "title": "Forme échelonnée réduite d’une matrice.",
  "body": " Forme échelonnée réduite d'une matrice   Soit , une matrice de taille . Le premier élément non nul de chaque ligne est appelé le pivot de cette ligne.  On dit que est échelonnée réduite si elle satisfait chacune des caractéristiques suivantes:   Condition pour être échelonnée réduite   Si la matrice contient des lignes dont toutes les entrées sont nulles (donc sans pivot), ces lignes sont dans le bas de la matrice.  Le pivot de chaque ligne non nulle est égal à .  De haut en bas, les pivots sont à la droite (pas nécessairement directement) les uns des autres.  Les entrées d'une colonne pivot sont toutes égales à , sauf le pivot.    "
},
{
  "id": "def-pivlib",
  "level": "2",
  "url": "sec-GJ.html#def-pivlib",
  "type": "Définition",
  "number": "3.1.20",
  "title": "Pivots, variables liées et variables libres.",
  "body": " Pivots, variables liées et variables libres  Soit , une matrice et sa forme échelonnée réduite. La proposition confirmera qu'il n'y a qu'une forme échelonnée réduite pour une matrice donnée. Si la colonne de la matrice contient un pivot, on dit que la colonne est une colonne pivot pour la matrice et que la variable est une variable pivot, ou liée.  Les variables qui ne sont pas des variables liées sont dites libres.  "
},
{
  "id": "example-58",
  "level": "2",
  "url": "sec-GJ.html#example-58",
  "type": "Exemple",
  "number": "3.1.21",
  "title": "Matrice échelonnée réduite.",
  "body": " Matrice échelonnée réduite   Parmi les matrices suivantes, déterminer quelle(s) condition(s) de la définition est(sont) respectée(s).          La matrice contient une ligne nulle et celle-ci est dans le bas de la matrice. La première condition est donc satisfaite. La deuxième condition n'est pas satisfaite. Le pivot de la première ligne est égal à et non à . La condition trois est respectée, car il n'y a qu'un seul pivot. Finalement, la colonne , correspondant au pivot de la première ligne, ne contient que des zéros, sauf pour l'entrée pivot. La condition quatre est donc respectée.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.   La matrice respecte la première condition par défaut, car elle ne possède pas de ligne nulle. De plus, les deux pivots sont égaux à et le second se trouve à la droite du premier, donc les conditions deux et trois sont respectées. Par contre, la deuxième colonne est pivot et contient des entrées non nulles (le ) autres que le pivot de la deuxième ligne. Elle ne respecte donc pas la condition quatre.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.  La matrice ne possède pas de ligne nulle, donc elle respecte la condition un. Les pivots sont tous égaux à , ce qui fait que la condition deux est respectée. Par contre, le second pivot est à gauche du premier. La troisième condition n'est donc pas respectée. La dernière condition l'est toutefois, car toutes les colonnes pivots ne contiennent que des zéros aux endroits non-pivots.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.   La matrice contient une ligne de zéros qui se trouve dans le bas de la matrice. La première condition est respectée. De plus, les pivots sont tous égaux à et se trouvent à droite les uns des autres, lorsqu'on regarde les lignes de haut en bas. Les conditions deux et trois sont aussi respectées. Finalement, les colonnes pivots et ne contiennent que des zéros aux endroits non-pivots. La condition quatre est donc aussi respectée.  Comme les quatre conditions sont respectées, la matrice est échelonnée réduite.    La matrice contient une ligne de zéro, soit la deuxième. Toutefois, la ligne trois contient des entrées non nulles. La première condition n'est donc pas respectée. Il y a deux pivots égaux à , dans la ligne un et dans la ligne trois. Le pivot de la ligne trois se trouvant à droite de celui de la ligne un, les conditions deux et trois sont respectées. Finalement, les colonnes pivots (un et trois) ne contiennent que des zéros aux endroits non-pivot. La quatrième condition est aussi respectée.  Comme une des quatre conditions n'est pas respectée, la matrice n'est pas échelonnée réduite.   "
},
{
  "id": "remark-10",
  "level": "2",
  "url": "sec-GJ.html#remark-10",
  "type": "Remarque",
  "number": "3.1.22",
  "title": "Origine du terme \"échelon\".",
  "body": " Origine du terme \"échelon\"  Le mot échelonnée dans la forme échelonnée réduite vient d' échelle . On peut en effet percevoir un certain effet d'escalier en regardant les pivots d'une matrice échelonnée réduite.   Justification du mot \"échelon\"   Les pivots de la forme échelonnée réduite d'une matrice sont donnés. Comme ces pivots se trouvent à la droite les uns des autres lorsqu'on lit la matrice de haut en bas, on peut y voir un escalier.    "
},
{
  "id": "prop-erlunique",
  "level": "2",
  "url": "sec-GJ.html#prop-erlunique",
  "type": "Proposition",
  "number": "3.1.24",
  "title": "La forme échelonnée réduite d’une matrice est unique.",
  "body": " La forme échelonnée réduite d'une matrice est unique   Soit , une matrice de taille . Par une suite d'opérations élémentaires, on peut arriver à une forme échelonnée réduite. Peu importe le choix des opérations élémentaires ou l'ordre de celles-ci, la forme échelonnée réduite sera toujours la même. Pour cette raison, on définit  L'expression erl signifie \"échelonnée réduite ligne\", alors que rref vient de l'anglais \"row reduced echelon form\". Par choix, on utilisera la version anglaise, car elle est identique à la commande Sage qui sera utilisée. comme étant l'unique forme échelonnée réduite de la matrice .    On utilise une preuve par induction sur le nombre de colonnes de la matrice .   Le cas : Si la matrice n'est qu'un vecteur colonne, alors ce vecteur peut être est nul, auquel cas il est déjà sous la forme rref. Toutes les opérations sur les lignes ne changent pas le vecteur nul et donc sa forme rref est unique. Si le vecteur n'est pas le vecteur nul, alors il existe au moins une entrée non nulle. On prend la première composante non nulle du vecteur, disons en position . Celle-ci est forcément un pivot de sa ligne. Peu importe sa valeur , on peut la normaliser à en effectuant l'opération . Par la suite, chaque entrée non nulle en position peut facilement être transformée en à l'aide d'une application de l'opération . Le vecteur obtenu à la suite de ces opérations contient un en position , la première entrée non nulle, et doit nécessairement avoir des en dessous. La forme rref est aussi unique dans ce cas.  On suppose que, pour une matrice de taille , la forme rref est unique.  Soit , une matrice de taille et soit , deux matrices échelonnées réduites équivalentes à De plus, on pose , la matrice que l'on obtient de en supprimant la dernière colonne. Peu importe la chaine d'opérations élémentaires menant à ou , la matrice est aussi transformée sous une forme échelonnée réduite lorsque ces opérations sont appliquées à .  Parce que est une matrice de taille , l'hypothèse d'induction affirme que sa forme rref est unique. Donc si et sont différentes, elles le sont uniquement dans la dernière colonne.  On considère maintenant un vecteur tel que . On sait qu'au moins le vecteur est une solution à cette équation, mais qu'il n'est pas nécessairement la seule solution. Dans tous les cas, la proposition dit que et . En particulier . En rappelant l'équation et le fait que les premières colonnes des matrices et concordent, la seule équation qui reste dans le produit est .  Si , alors les colonnes des matrices et sont aussi égales, donnant et l'unicité de la forme échelonnée réduite. Sinon, comme les matrices et sont rref, elles doivent n'avoir que des et un . Ce est forcément à la même position, car une des conditions d'être rref est que les lignes de soient dans le bas de la matrice. Les se trouvent donc sous la dernière ligne de ayant un pivot. Dans ce cas aussi, la dernière colonne concorde et l'on a .      "
},
{
  "id": "algo-GJ",
  "level": "2",
  "url": "sec-GJ.html#algo-GJ",
  "type": "Algorithme",
  "number": "3.1.25",
  "title": "La méthode de Gauss-Jordan.",
  "body": " La méthode de Gauss-Jordan   Soit , une matrice de taille . Il est possible d'obtenir la forme échelonnée réduite de , en suivant le processus suivant:   Algorithme de Gauss-Jordan   Si n'est pas encore défini, on pose . Si , on saute à l'étape suivante. Sinon, si , on augmente de .  Si possible, échanger la ligne avec une autre ligne ( ) de manière à avoir un pivot non nul dans la colonne la plus à gauche possible.  Si nécessaire, multiplier la nouvelle ligne par la constante appropriée pour avoir son pivot égal à .  Utiliser l'opération pour que chaque entrée sous le pivot soit nulle. ( ).  Retourner à la première étape.    Pour chaque pivot, utiliser la troisième opération élémentaire pour avoir des zéros au-dessus du pivot.     "
},
{
  "id": "rem-GJeff",
  "level": "2",
  "url": "sec-GJ.html#rem-GJeff",
  "type": "Remarque",
  "number": "3.1.27",
  "title": "L’efficacité de l’algorithme.",
  "body": " L'efficacité de l'algorithme  Dans certaines étapes de l'algorithme de Gauss-Jordan , il peut être avantageux de sélectionner une ligne en particulier afin de simplifier les calculs. Aussi, on peut vouloir retarder afin d'éviter de travailler avec des fractions. L'algorithme décrit une manière automatique d'obtenir la forme échelonnée réduite, un peu comme le ferait un ordinateur.  De même, si l'on se limite à ne faire que l'étape , sans nécessairement avoir les pivots égaux à , on obtient l'algorithme de Gauss. Une matrice ainsi transformée serait alors sous forme échelonnée seulement (pas réduite). L'exemple était un exemple d'application de l'algorithme de Gauss seulement, soit sans faire l'étape .  "
},
{
  "id": "ex-GJ",
  "level": "2",
  "url": "sec-GJ.html#ex-GJ",
  "type": "Exemple",
  "number": "3.1.28",
  "title": "L’algorithme de Gauss-Jordan en action.",
  "body": " L'algorithme de Gauss-Jordan en action  On considère le système d'équations linéaires suivant. . On cherche à trouver la solution de ce système en utilisant l'algorithme de Gauss-Jordan pour réduire la matrice augmentée.   La matrice augmentée associée au SEL est . C'est une matrice , en comptant la partie augmentée. On a donc .  On commence l'algorithme de Gauss-Jordan.  Comme n'est pas défini, on pose .  Puisque la première colonne contient des valeurs non nulles, ce sera une colonne pivot. Toutefois, l'entrée de la première colonne dans la ligne est nulle. Il faut donc permuter deux lignes: .  Afin de rendre le pivot de la nouvelle ligne un égal à , on multiplie la ligne un par .   On veut maintenant avoir des sous le pivot de la ligne un. Ici, il n'y a qu'une opération à effectuer, car la deuxième ligne a déjà son . On utilise l'opération . .  On retourne à la première étape.   On a maintenant .   Les entrées de la seconde colonne à partir de la ligne deux ne sont pas toutes nulles, il y aura donc un pivot dans la colonne deux. En principe, l'algorithme dit de passer à l'étape suivante et de multiplier par . On se sert ici de la remarque pour simplifier les calculs, en permutant les lignes deux et trois. .  On veut maintenant avoir un zéro sous le pivot de la ligne deux. Pour cela, on utilise l'opération . .   On retourne à la première étape.   On a maintenant .    Il est possible d'avoir un pivot dans la dernière colonne. On met ce pivot égal à . .  Comme il n'y a plus d'entrée sous le pivot, on retourne à la première étape.    Puisque , on passe à la deuxième étape de l'algorithme.  Pour chaque pivot, on veut obtenir des zéros au-dessus de la valeur qui est pivot. On a trois pivots.  On commence avec le pivot sur la deuxième ligne. On souhaite transformer le de la ligne un en en utilisant la ligne deux. .  En utilisant la dernière ligne, on veut transformer le de la ligne deux et le de la ligne un en . .      Ceci complète l'algorithme de Gauss-Jordan, la matrice étant échelonnée réduite. On peut y lire la solution .  "
},
{
  "id": "ex-GJchaine",
  "level": "2",
  "url": "sec-GJ.html#ex-GJchaine",
  "type": "Exemple",
  "number": "3.1.29",
  "title": "Gauss-Jordan: chaine d’équivalences.",
  "body": " Gauss-Jordan: chaine d'équivalences   On s'intéresse aux systèmes et , en lien avec le système similaire résolu à l'exemple . On cherche les solutions à ces deux systèmes. On remarque qu'en vertu de la proposition , la solution à ces trois systèmes donnera aussi la matrice inverse de .    On peut travailler de manière efficace. Il n'est pas nécessaire d'échelonner la matrice pour chaque système. En effet, peu importe la chaine d'opérations élémentaires effectuées pour échelonner le SEL dans le cas du premier système, cette chaine fonctionnera aussi pour le deuxième SEL. On peut donc augmenter la matrice des deux vecteurs et effectuer les opérations sur cette matrice augmentée. De plus, les opérations élémentaires ayant servies à trouver la solution dans l'exemple peuvent être réutilisées ici, puisqu'elles constituent l'étape un de l'algorithme de Gauss-Jordan , hormis le fait que les pivots ne sont pas égaux à . Il faut, par contre, refaire les calculs sur la partie augmentée. .  La solution au premier système est donc et celle du second est . De plus, en reprenant la réponse de l'exemple , on obtient   "
},
{
  "id": "remark-12",
  "level": "2",
  "url": "sec-GJ.html#remark-12",
  "type": "Remarque",
  "number": "3.1.30",
  "title": "Les possibilités d’opérations.",
  "body": " Les possibilités d'opérations  En combinant plusieurs opérations élémentaires, on obtient une opération valide (qui n'est généralement pas élémentaire) pour échelonner une matrice. Ainsi, l'opération peut être vue comme la combinaison des opérations élémentaires suivie de l'opération . Bien qu'elle ne soit pas élémentaire, cette opération s'avère pratique pour échelonner des matrices, comme dans l'exemple suivant. . L'opération permet d'obtenir le sous le pivot de la ligne un, sans que ce pivot soit égal à , ce qui aurait introduit une fraction dans la seconde colonne.  Bien que permises, on fait le choix d'éviter ces opérations. On voudra de toute manière déléguer beaucoup des calculs à l'ordinateur. On choisit donc de se concentrer sur les opérations élémentaires. Il est toutefois possible d'éviter les fractions avec les opérations élémentaires, comme dans l'exemple suivant. . Cette opération rend le pivot de la première ligne égal à sans créer de fraction dans la deuxième colonne.  Finalement, on peut se permettre de faire plusieurs opérations en une étape, comme lors de l'équation de l'exemple . Par contre, il est important de retenir qu'on ne doit pas utiliser une ligne qui a été modifiée auparavant dans la même étape pour modifier une autre ligne. Voir l'exercice  "
},
{
  "id": "sageex-GJ",
  "level": "2",
  "url": "sec-GJ.html#sageex-GJ",
  "type": "Calcul",
  "number": "3.1.31",
  "title": "La forme échelonnée réduite sur Sage.",
  "body": " La forme échelonnée réduite sur Sage  Pour une matrice quelconque, on peut obtenir sa forme échelonnée réduite avec Sage à l'aide de la commande A.rref() .   Pour résoudre un système d'équations linéaires , il existe plusieurs possibilités. En plus de la solution au système, les informations supplémentaires que l'on peut obtenir guideront le choix parmi les possibilités. Dans un premier temps, on peut augmenter la matrice avec le vecteur et obtenir la forme échelonnée réduite de la matrice augmentée. La dernière colonne contient alors la solution.   Une autre option consiste à utiliser la commande A.solve_right(b) (le _right fait référence à l'équation , où le vecteur est à droite, plutôt qu'à l'équation ). Cette commande ne donne que la solution au système, pas la matrice échelonnée. Donc, s'il est pratique de l'avoir, on utilisera l'échelonnage.   La commande A.pivots() retourne la position des colonnes pivots. Attention, on rappelle que Sage commence sa numérotation à , la deuxième colonne sera donc indicée par .   "
},
{
  "id": "exo-matelem",
  "level": "2",
  "url": "sec-GJ.html#exo-matelem",
  "type": "Exercice",
  "number": "3.1.4.1",
  "title": "",
  "body": " Pour chacune des opérations élémentaires suivantes, donner la matrice élémentaire qui lui est associée.   L'opération pour un système à cinq équations.   On procède de façon semblable à l'exemple . On doit prendre la matrice identité d'ordre , correspondant au nombre d'équations du système. Puis, on applique l'opération élémentaire demandée à cette matrice. Le résultat est la matrice élémentaire voulue.     L'opération pour un système à huit équations.     L'opération pour un système à trois équations et deux inconnues.     L'opération pour un système à trois équations et trois inconnues.    On remarque que cette réponse est identique à la précédente, ce qui signifie que le nombre d'inconnues n'est pas important. Pour construire une matrice élémentaire, il faut uniquement regarder l'opération élémentaire que l'on veut effectuer sur les lignes. La taille de la matrice dépend donc du nombre de lignes, mais de du nombre de colonnes.   L'opération pour un système à cinq équations.    "
},
{
  "id": "exercise-120",
  "level": "2",
  "url": "sec-GJ.html#exercise-120",
  "type": "Exercice",
  "number": "3.1.4.2",
  "title": "",
  "body": "Parmi les matrices suivantes, lesquelles sont élémentaires? Donner l'opération élémentaire le cas échéant.    Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .     Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .     Ce n'est pas une matrice élémentaire.     C'est une matrice élémentaire. L'opération élémentaire qu'elle décrit est: .  "
},
{
  "id": "exo-matpermuelem",
  "level": "2",
  "url": "sec-GJ.html#exo-matpermuelem",
  "type": "Exercice",
  "number": "3.1.4.3",
  "title": "",
  "body": " Montrer que les matrices de permutation, définies à l'exercice , peuvent s'écrire comme un produit de matrices élémentaires en utilisant uniquement les matrices de type .   Comme défini dans l'exercice, une matrice de permutation est une matrice telle que chaque colonne et chaque ligne ne contient qu'une entrée non nulle égale à . On constate assez facilement qu'une telle matrice sera toujours obtenue à partir de la matrice identité en permutant des lignes. En effet, pour que la matrice ait exactement un et que des dans chaque ligne et colonne, on doit avoir le dans une colonne différente pour chaque ligne. Ce sont donc les lignes de l'identité, mais positionnées à différentes lignes.  Différents cas de figure sont possibles. D'abord, on considère le cas où la matrice est l'identité et seulement deux lignes ont été permutées, par exemple les lignes et . On constate que . Ensuite, on considère le cas où la matrice est l'identité et exactement trois lignes ont été permutées, par exemple les lignes , et . Seulement deux options sont alors possibles:   .  On peut effectuer ces permutations triples en deux étapes. Par exemple, pour effectuant , on peut effectuer puis . Remarquer que la seconde permutation permute en réalité les lignes et de la matrice initiale, mais que est positionnée à . Ainsi, Le principe qui semble se dégager est qu'on utilise une matrice de permutation pour positionner la première ligne , puis une seconde pour positionner la seconde ligne . La dernière ligne est nécessairement permutée par une de ces deux permutations puisque sinon, ce ne serait pas une permutation triple.  On établit maintenant le principe pour permuter lignes, soient les lignes . La matrice sera formée de la multiplication d'au maximum matrices élémentaires. La première (en partant de la droite) permettra de positionner la ligne . La seconde permettra de positionner la ligne (initialement positionnée à) . Ainsi de suite, jusqu'à la , qui permettra de positionner la ligne (initialement positionnée à) . Alors, on écrit, avec une notation discutable puisqu'on ne sait pas toujours si la ligne a été modifiée ou pas: .  "
},
{
  "id": "exo-matinversibleeqid",
  "level": "2",
  "url": "sec-GJ.html#exo-matinversibleeqid",
  "type": "Exercice",
  "number": "3.1.4.4",
  "title": "",
  "body": " Une matrice carrée inversible est équivalente à la matrice identité. Cela signifie qu'il existe des matrices élémentaires telles que . On peut donc dire que .  En utilisant cette forme pour l'inverse, donner une preuve alternative aux résultats suivants.   Montrer que si , alors , donnant ainsi une preuve alternative à la proposition .   Par l'hypothèse et l'énoncé de l'exercice, on sait que l'on peut écrire ainsi : . Puisque les matrices élémentaires sont toutes inversibles, par la proposition , on peut donc faire les opérations suivantes: Ainsi, on obtient une expression pour qui ne dépend que des inverses des matrices élémentaires. On peut donc démontrer le résultat voulu rapidement:    Montrer que , donnant ainsi une preuve alternative à la proposition .   Pour obtenir cette propriété, on peut supposer que les matrices et sont toutes les deux inversibles. Bref, suivant l'énoncé de l'exercice et la réponse de la partie précédente, on peut écrire les matrices , , et des façons suivantes: , où les matrices sont matrices élémentaires telles que l'on peut écrire pour la matrice inversible .  Ainsi, on peut démontrer l'équation proposée. On y arrive en multipliant par et en montrant qu'on obtient bien la matrice identité. .   Montrer que , donnant ainsi une preuve alternative à la proposition .   On veut démontrer que la matrice fait bien office d'inverse pour la matrice . Ainsi, la matrice fait bien office d'inverse pour la matrice . Ainsi, .  "
},
{
  "id": "exercise-123",
  "level": "2",
  "url": "sec-GJ.html#exercise-123",
  "type": "Exercice",
  "number": "3.1.4.5",
  "title": "",
  "body": "Une grille de sudoku résolue peut être vue comme une matrice . Soit une telle matrice. Parmi les opérations élémentaires , lesquelles gardent la matrice transformée comme une solution recevable selon les règles d'une grille sudoku? (Bonus: comment arriver à matrices, sans les énumérer?)  Pour connaitre comment fonctionne un sudoku, on conseille de faire une recherche sur Google .     On sait que les sudokus résolus ont les trois propriétés suivantes:  Chaque ligne contient tous les chiffres de à une fois chacun.  Chaque colonne contient tous les chiffres de à une fois chacun.  Chaque sous-matrice obtenue en divisant la grille en contient tous les chiffres de à une fois chacun.  Les première et deuxième propriétés ne seront jamais perdues par la multiplication d'une matrice élémentaire puisqu'en interchangeant les lignes, on ne les change pas et les colonnes demeurent entièrement constituées des mêmes chiffres.  On doit donc préserver la troisième propriété. Pour ce faire, on doit accepter seulement les permutations de lignes à l'intérieur des trois sous-groupes de lignes: à , à et à . Le nombre de permutations pour chaque sous-groupe est de trois, par exemple, , et . On en a donc au total. Voici la liste: .  BONUS: On obtient le nombre de permutations possibles au total en calculant d'abord les permutations impliquant la ligne , puis celles impliquant la seconde, mais excluant la première, et ainsi de suite. On obtient donc : permutations possibles.  On pose . Que vaut ?    On rappelle une définition du produit matrice vecteur donnée en fonction des lignes. La définition usuelle pourrait aussi nous amener au résultat rapidement, mais, dans ce cas-ci, on préfère la première.  "
},
{
  "id": "exo-mateleminverse",
  "level": "2",
  "url": "sec-GJ.html#exo-mateleminverse",
  "type": "Exercice",
  "number": "3.1.4.6",
  "title": "",
  "body": " Démontrer la proposition .   Par la définition , toutes les matrices élémentaires sont le résultat d'une seule opération élémentaire. Ainsi, si l'on démontre la deuxième portion de la proposition, en donnant la matrice inverse de chaque matrice élémentaire, on aura montré la première portion qui dit que les matrices élémentaires sont toutes inversibles. On démontre donc pour chaque matrice élémentaire que son inverse est celui donné dans la proposition . est la matrice élémentaire qui permute la ligne avec la ligne , alors pour défaire cette opération, il faut en réalité refaire la même opération. En effet, on considère la matrice décrite, et l'on se questionne à savoir quelle matrice la multipliera pour donner la matrice identité. On réalise que est, par la définition , la matrice identité où l'on a permuté la ligne et la ligne . Il est donc évident que c'est cette même matrice qui, lorsque multipliée avec , permutra à nouveau la ligne et la ligne pour obtenir l'identité. Ainsi, .  est la matrice qui multiplie la ligne par , alors, par la définition , c'est la matrice identité où l'on a multiplié la ligne par . Afin d'obtenir à nouveau la matrice identité, il faut la multiplier par une matrice qui effectuera l'opération élémentaire suivante: multiplier la ligne par . C'est donc, encore par la définition , la matrice identité où l'on a multiplié la ligne par . Ainsi, .  est la matrice élémentaire qui ajoute à la ligne , fois la ligne , on construit alors un raisonnement semblable aux deux précédents pour montrer qu'effectivement , en se servant de la même définition.   "
},
{
  "id": "exo-opelemperm",
  "level": "2",
  "url": "sec-GJ.html#exo-opelemperm",
  "type": "Exercice",
  "number": "3.1.4.7",
  "title": "",
  "body": " Montrer que l'opération élémentaire qui consiste à permuter deux lignes n'est pas essentielle, c'est-à-dire qu'il est possible de permuter deux lignes en utilisant uniquement les deux autres opérations élémentaires.   Voici une séquence d'opérations élémentaires qui permet d'échanger la ligne avec la ligne , en n'utilisant que l'opération de combinaison linéaire et celle de multiplication par une constante. On fait, dans l'ordre     .   "
},
{
  "id": "exercise-126",
  "level": "2",
  "url": "sec-GJ.html#exercise-126",
  "type": "Exercice",
  "number": "3.1.4.8",
  "title": "",
  "body": "Parmi les matrices suivantes, déterminer celles qui sont sous la forme échelonnée réduite. Pour chaque matrice qui n'est pas échelonnée réduite, effectuer les opérations élémentaires pour la rendre échelonnée réduite. Finalement, pour chaque matrice, identifier les colonnes pivots.    Cette matrice n'est pas échelonnée réduite. On effectue les opérations. Son unique colonne pivot est la deuxième.     Cette matrice n'est pas échelonnée réduite. On effectue les opérations manquantes. Ses colonnes pivots sont la première et la troisième.     Cette matrice est échelonnée réduite. Ses colonnes pivots sont la deuxième et la troisième. Cette matrice est échelonnée réduite. Son unique colonne pivot est la troisième. "
},
{
  "id": "exercise-127",
  "level": "2",
  "url": "sec-GJ.html#exercise-127",
  "type": "Exercice",
  "number": "3.1.4.9",
  "title": "",
  "body": "Faire la liste de toutes les matrices échelonnées réduites. Il y en a une infinité, mais elles peuvent se classer en quatre types.  Les quatre types sont: , , et   "
},
{
  "id": "exercise-128",
  "level": "2",
  "url": "sec-GJ.html#exercise-128",
  "type": "Exercice",
  "number": "3.1.4.10",
  "title": "",
  "body": " On s'intéresse aux caractéristiques des matrices échelonnées réduites, telles qu'énoncées à la liste .  Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .  Il existe évidemment une infinité de bonnes réponses. Essayer de comparer la réponse donnée aux propriétés et voir si votre réponse est valide.  Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .   Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .   Donner un exemple d'une matrice qui respecte les propriétés , et , mais pas la propriété .  "
},
{
  "id": "exercise-129",
  "level": "2",
  "url": "sec-GJ.html#exercise-129",
  "type": "Exercice",
  "number": "3.1.4.11",
  "title": "",
  "body": "Soit , une matrice , et , des vecteurs tels que . Quelles sont les dimensions des vecteurs ? est de dimension et et sont de dimension . Si l'on voit la matrice ainsi que les vecteurs comme représentant les différentes composantes de SEL décrits par les équations , on peut voir les dimensions des vecteurs en s'aidant de la définition ou, plus simplement, de l'exemple . Le format de la matrice étant , la dimension du vecteur correspondra au nombre de lignes, soit , et la dimension des vecteurs et correspondra au nombre de colonnes, soit .  En résumé, est de dimension et et sont de dimension .  Montrer que est une solution de .   On voit donc que est une solution de .   Soit tel que . Montrer que est une solution de .   De façon semblable, .  "
},
{
  "id": "exercise-130",
  "level": "2",
  "url": "sec-GJ.html#exercise-130",
  "type": "Exercice",
  "number": "3.1.4.12",
  "title": "",
  "body": "Si est une matrice sous forme échelonnée réduite, quel est le nombre maximal de pivots que peut posséder? La matrice peut posséder pivots au maximum. Si la matrice est une matrice carrée, il est clair qu'elle peut avoir un nombre de pivots égal à son ordre. Cependant, si elle est rectangulaire ( ), le nombre de pivots sera limité par la valeur la plus petite entre et . En effet, il faut avoir une ligne et une colonne associée à chaque pivot. "
},
{
  "id": "exercise-131",
  "level": "2",
  "url": "sec-GJ.html#exercise-131",
  "type": "Exercice",
  "number": "3.1.4.13",
  "title": "",
  "body": "Pour chacun des cas suivants, donner une ou deux matrices échelonnées réduites de format demandé qui respectent les conditions additionnelles: Deux matrices pour lesquelles la variable est libre. Deux matrices pour lesquelles la variable est libre. Deux matrices pour lesquelles les variables sont pivots et est libre.  Deux matrices pour lesquelles les variables sont pivots et est libre.  Une seule matrice  pour laquelle les variables sont pivots et est libre.  Une seule matrice  pour laquelle les variables sont libres et est pivot.  Deux matrices pour lesquelles les variables sont libres et est pivot.  Deux matrices pour lesquelles les variables sont libres et est pivot.  Deux matrices pour lesquelles exactement deux variables sont pivots. "
},
{
  "id": "exo-forceechange",
  "level": "2",
  "url": "sec-GJ.html#exo-forceechange",
  "type": "Exercice",
  "number": "3.1.4.14",
  "title": "",
  "body": " Considérer la matrice . Quelle est la solution de ce système dans le cas où la valeur de fait en sorte qu'il est nécessaire d'effectuer l'opération élémentaire ?  La solution est dans le cas où . On commence l'algorithme de Gauss-Jordan et l'on verra à quel moment cette opération sera nécessaire et quelle valeur de cela prendra. On constate déjà, à ce stade, que la deuxième ligne pourrait être un pivot dans le cas où . Inversement, il sera impossible que cette ligne soit un pivot si et il faudra faire l'opération élémentaire . On pose donc et l'on poursuit avec cette opération et le reste de l'algorithme. La solution est donc . "
},
{
  "id": "exercise-133",
  "level": "2",
  "url": "sec-GJ.html#exercise-133",
  "type": "Exercice",
  "number": "3.1.4.15",
  "title": "",
  "body": " Mettre la matrice sous la forme échelonnée réduite. Quelles sont les hypothèses additionnelles qui sont faites si    ?  Si , on peut donc se servir de l'algorithme de Gauss-Jordan pour échelonner en gardant le comme premier pivot. On n'aura pas à permuter les lignes entre elles. La seule hypothèse additionnelle est que puisqu'on retrouve cette expression au dénominateur. On a vu à la section que les matrices étaient inversibles à condition que cette quantité soit non-nulle. Nous verrons au chapitre qu'il s'agit du déterminant d'une matrice .   ?  et Si , on peut donc se servir de l'algorithme de Gauss-Jordan pour échelonner en commençant par permuter les deux lignes. Les deux hypothèses additionnelles sont que et puisqu'on retrouve ces expressions au dénominateur. Quel est le nombre maximum d'opérations élémentaires à effectuer pour échelonner une matrice . Quatre opérations au maximum. Quatre opérations au maximum. On l'a démontré en répondant aux deux questions précédentes. En effet, en couvrant les cas où et où , on couvre tous les cas possibles. Les deux cas ont exigé quatre opérations élémentaires. C'est donc le maximum. "
},
{
  "id": "exercise-134",
  "level": "2",
  "url": "sec-GJ.html#exercise-134",
  "type": "Exercice",
  "number": "3.1.4.16",
  "title": "",
  "body": "À la section , on a établi qu'une matrice était inversible si . Montrer que toute matrice équivalente à une matrice telle que possède aussi cette condition.  Il suffit d'appliquer chaque opération élémentaire à la matrice et de vérifier la condition.  On procède comme suggéré dans l'indice. On vérifie donc, pour chacune des trois opérations élémentaires, que l'on obtient encore la condition. La condition est: qui est entièrement équivalente à en réorganisant les termes.  La seconde opération de multiplication par un scalaire doit être vérifiée pour chaque ligne. et La condition est donc: ou bien qui sont équivalentes à , pourvu que , ce qui est le cas par la définition .  Finalement, la dernière opération élémentaire doit également être vérifiée pour chaque ligne. et La condition est donc: ou bien qui sont toutes les deux exactement pareilles à .  "
},
{
  "id": "exo-sel3x3geo",
  "level": "2",
  "url": "sec-GJ.html#exo-sel3x3geo",
  "type": "Exercice",
  "number": "3.1.4.17",
  "title": "",
  "body": " Dans le début de la sous-section , on a établi qu'un système à deux équations et deux inconnues devait avoir aucune, une seule ou une infinité de solutions, en faisant le parallèle avec la géométrie des droites. Dans cet exercice, on essaie de faire la même chose avec des plans.   Considérer un système à deux équations et trois inconnues. Chaque équation peut être vue comme l'équation normale d'un plan dans .   Quelle peut être la position relative de deux plans dans l'espace? Illustrer tous les cas possibles.  On peut avoir deux plans parallèles distincts, parallèles confondus ou sécants. Les illustrations sont à venir. Combien de solutions peut-il y avoir à l'équation si est une matrice ? Donner un exemple pour chaque cas possible. Il peut y avoir soit une infinité de solutions, soit aucune solution. Il n'y aura jamais de solution unique. Géométriquement, il y a deux façons d'avoir une infinité de solutions: deux plans sécants (les solutions seront sur la droite formée par l'intersection des deux plans) ou deux plans parallèles confondus (les solutions seront l'ensemble des plans confondus). L'équation n'aura pas de solution si elle représente deux plans parallèles distincts. On donne un exemple pour chaque cas possible:  Le système représente deux plans sécants ayant une infinité de solutions.  Le système représente deux plans parallèles confondus ayant une infinité de solutions.  Le système représente deux plans parallèles distincts n'ayant aucune solution. On considère maintenant trois plans dans l'espace. Quelle peut être la position relative de trois plans distincts dans l'espace? Trois plans dans l'espace peuvent être :  tous parallèles distincts  deux parallèles distincts et le troisième sécant aux deux  aucunement parallèles, mais sécants deux à deux  sécants tous les trois sur une droite  sécants tous les trois sur un point.  Déduire géométriquement que le système possède aucune, une seule ou une infinité de solutions. On reprend les différentes situations décrites et on attribue le nombre de solutions :  Tous parallèles distincts: aucune solution.  Deux parallèles distincts et le troisième sécant aux deux: aucune solution.  Aucunement parallèles, mais sécants deux à deux: aucune solution.  Sécants tous les trois sur une droite: infinité de solutions.  Sécants tous les trois sur un point: une seule solution.  Expliquer algébriquement pourquoi si sont des solutions au système (peu importe la taille de la matrice !), alors il existe une infinité de solutions. Si sont des solutions au système , on peut écrire et . Ainsi, on peut créer une infinité de solutions : où  On a donc la possibilité de créer une infinité de différentes solutions en posant différentes valeurs de et . "
},
{
  "id": "exercise-136",
  "level": "2",
  "url": "sec-GJ.html#exercise-136",
  "type": "Exercice",
  "number": "3.1.4.18",
  "title": "",
  "body": " En se basant sur l'exemple , trouver l'inverse des matrices suivantes en les augmentant de la matrice identité de format approprié.    L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc:   L'inverse de cette matrice est donc: "
},
{
  "id": "exercise-137",
  "level": "2",
  "url": "sec-GJ.html#exercise-137",
  "type": "Exercice",
  "number": "3.1.4.19",
  "title": "",
  "body": "Une matrice est telle que , et . Trouver telle que . Que vaut ?  et .  Puisque les vecteurs ont trois composantes et que les vecteurs en ont trois également, on sait que la matrice est de taille . De plus, les équations données dans l'exercice permettent de dire que la matrice est inversible et que , en vertu de la remarque . On a donc . On peut calculer ce produit matrice vecteur directement ou avec l'approche par colonne. Dans tous les cas, on obtient .  Pour trouver la matrice , on peut utiliser une démarche semblable à l'exemple pour échelonner la matrice augmentée . On a .  "
},
{
  "id": "exo-mat2x2unpivot",
  "level": "2",
  "url": "sec-GJ.html#exo-mat2x2unpivot",
  "type": "Exercice",
  "number": "3.1.4.20",
  "title": "",
  "body": " On considère la matrice . Pour quelle(s) valeurs de la matrice possède-t-elle un seul pivot?  et Afin de répondre à cette question, on va échelonner la matrice et voir sous quelles conditions elle ne possèdera qu'un seul pivot. Pour n'avoir qu'un seul pivot, il faut que . Cela arrivera pour deux valeurs de , soient et . "
},
{
  "id": "exercise-139",
  "level": "2",
  "url": "sec-GJ.html#exercise-139",
  "type": "Exercice",
  "number": "3.1.4.21",
  "title": "",
  "body": "Pour chaque matrice de l'exercice , utiliser la commande elementary_matrix pour obtenir la matrice élémentaire associée à l'opération.     Le code pour les matrices élémentaires   show(elementary_matrix(5,row1=2,row2=4)) #On se rapelle que la première ligne est indicée à 0 show(elementary_matrix(8,row1=2,row2=4)) show(elementary_matrix(3,row1=1,scale=4)) show(elementary_matrix(3,row1=1,scale=4)) show(elementary_matrix(5,row1=3,row2=0,scale=-4))    "
},
{
  "id": "exercise-140",
  "level": "2",
  "url": "sec-GJ.html#exercise-140",
  "type": "Exercice",
  "number": "3.1.4.22",
  "title": "",
  "body": " Utiliser Sage pour résoudre les systèmes d'équations linéaires suivants,  en utilisant une matrice augmentée et sa forme échelonnée réduite.     Le code solution   A=matrix([[3,2,-5,1],[0,8,2,0],[1,-7,5,0],[2,3,1,-1]])# La matrice b=vector([-1,3,-2,5]) #Le vecteur sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout    Les systèmes où et   Si , alors   Le code solution   A=matrix([[0,1,4,-1,2,7],[-1,3,3,1,12,3],[11,0,2,5,0,-4],[9,5,-1,11,-7,4],[1,2,3,-4,5,7],[-3,2,5,7,8,-13]]) b1=vector([1,2,3,4,5,6]) b2=vector([6,5,4,3,2,1]) b3=vector([1,-2,3,-4,5,-6]) b4=vector([-6,5,-4,3,-2,1]) #Pour augmenter une matrice de plusieurs vecteurs, on peut procéder comme suit: Aug=((((A.augment(b1)).augment(b2)).augment(b3)).augment(b4)) show(Aug) #Ou encore en définissant une matrice au préalable B=column_matrix([b1,b2,b3,b4]) Augm=A.augment(B,subdivide=True) show(Augm) sol=(Augm.rref()) show(sol) vecsol1=sol.column(-4) vecsol2=sol.column(-3) vecsol3=sol.column(-2) vecsol4=sol.column(-1) pretty_print(\"La solution de Ax=b1 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol1) pretty_print(\"La solution de Ax=b2 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol2) pretty_print(\"La solution de Ax=b3 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol3) pretty_print(\"La solution de Ax=b4 est (x_1,x_2,x_3,x_4,x_5,x_6)=\",vecsol4)     Le système .    Le code solution   A=matrix([[1,1,1,1],[1,2,3,4],[1,4,9,16],[1,8,27,64]])# La matrice b=vector([1,2,3,4]) #Le vecteur show(A.augment(b)) #Optionnel: pour vérifier qu'on a bien écrit le système dans Sage sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout    Le système .  On voit qu'il est très simple de résoudre une légère modification d'un problème déjà résolu avec l'ordinateur, alors qu'à la main, le travail aurait dû être refait en grande partie.    Le code solution   A=matrix([[1,-1,1,-1],[1,-2,3,-4],[1,-4,9,-16],[1,-8,27,-64]])# La matrice b=vector([1,-2,3,-4]) #Le vecteur show(A.augment(b)) #Optionnel: pour vérifier qu'on a bien écrit le système dans Sage sol=(A.augment(b).rref()) #La matrice augmentée échelonnée réduite show(sol) vecsol=sol.column(-1) #-1 permet d'avoir la dernière colonne pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",vecsol) #L'ajout de pretty devant le print fait en sorte que les fractions soient debout   en utilisant la commande solve_right .  Le système .    Le code solution   A=matrix([[1,1,1,1],[1,2,3,4],[1,4,9,16],[1,8,27,64]])# La matrice b=vector([1,2,3,4]) #Le vecteur sol=(A.solve_right(b)) pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",sol)    Le système .    Le code solution   A=matrix([[1,-1,1,-1],[1,-2,3,-4],[1,-4,9,-16],[1,-8,27,-64]])# La matrice b=vector([1,-2,3,-4]) #Le vecteur sol=(A.solve_right(b)) pretty_print(\"La solution est (x_1,x_2,x_3,x_4)=\",sol)   "
},
{
  "id": "exo-parabolerevisitee",
  "level": "2",
  "url": "sec-GJ.html#exo-parabolerevisitee",
  "type": "Exercice",
  "number": "3.1.4.23",
  "title": "La parabole revisitée.",
  "body": "La parabole revisitée Dans l'exercice , on a automatisé le calcul de l'équation d'une parabole connaissant sa droite directrice et son foyer. Si la parabole est aussi une fonction, soit , alors il est possible à l'aide de trois points de la parabole de trouver l'équation.   Soit et trois points sur une parabole d'équation .  En utilisant un système d'équations linéaires, déterminer l'équation de la parabole. Tracer celle-ci, ainsi que les points sur un même graphique.     Le code solution permettant de trouver l'équation et de tracer la parabole et les trois points   P=vector([-1,22]) Q=vector([2,19]) R=vector([3,34]) A=matrix([[P[0]^2,P[0],1],[Q[0]^2,Q[0],1],[R[0]^2,R[0],1]]) v=vector([P[1],Q[1],R[1]]) sol=A.solve_right(v) print(\"L'équation de la parabole est \",sol[0]*x^2+sol[1]*x+sol[2]) para=plot(sol[0]*x^2+sol[1]*x+sol[2],(x,-2,4)) #On trace les points et on les identifie de belle façon ptP=plot(point(P))+text(' P(%s,%s)'%(P[0],P[1]),P,horizontal_alignment='left') ptQ=plot(point(Q))+text(' Q(%s,%s)'%(Q[0],Q[1]),Q,horizontal_alignment='left') ptR=plot(point(R))+text(' R(%s,%s)'%(R[0],R[1]),R,horizontal_alignment='left') show(para+ptP+ptQ+ptR)    On veut maintenant créer une fonction qui va retourner l'équation d'une parabole passant par trois points donnés. La fonction doit d'abord vérifier si les trois points sont différents et ensuite retourner son équation. Tester la fonction avec la réponse à la partie précédente et avec des points pareils. Finalement, observer le résultat lorsqu'on calcule l'équation pour trois points alignés.     La fonction qui donne l'équation de la parabole passant par trois points donnés   def eqparapoints(P1,P2,P3): v1=P2-P1 v2=P3-P1 if P1==P2 or P1==P3 or P2==P3: print(\"Il faut fournir trois points différents pour définir une parabole.\") else: #On veut résoudre ax^2+bx+c=y avec x,y=P1,P2,P3. On résoute le système A(a,b,c)=v où v=(y1,y2,y3) A=matrix([[P1[0]^2,P1[0],1],[P2[0]^2,P2[0],1],[P3[0]^2,P3[0],1]]) v=vector([P1[1],P2[1],P3[1]]) sol=A.solve_right(v) print(\"L'équation de la parabole est \",sol[0]*x^2+sol[1]*x+sol[2]) P1=vector([-1,22]) P2=vector([2,19]) P3=vector([3,34]) P4=(P1+P2)\/2 eqparapoints(P1,P2,P3) eqparapoints(P1,P1,P3) #On teste avec deux points pareils eqparapoints(P1,P2,P4) #On teste avec trois points sur une droite    On remarque que l'équation obtenue pour trois points alignés est l'équation d'une droite.  "
},
{
  "id": "sec-SELtheo",
  "level": "1",
  "url": "sec-SELtheo.html",
  "type": "Section",
  "number": "3.2",
  "title": "Les systèmes qui n’ont aucune ou  ayant une infinité de solutions",
  "body": "  Les systèmes qui n'ont aucune ou ayant une infinité de solutions    Aller aux exercices de la section.  Dans la section , on a introduit l'algorithme de Gauss-Jordan que l'on a utilisé pour résoudre des systèmes d'équations linéaires, en échelonnant la matrice augmentée du système. Dans tous les exemples, on a réussi à trouver une solution. On sait toutefois qu'on peut associer un système d'équations linéaires à deux équations et deux inconnues à la position relative de deux droites dans et un système à trois équations et trois inconnues à la position relative de trois plans dans . Dans certaines situations, il peut n'y avoir aucune solution,par exemple si les droites sont parallèles , ou une infinité de solutions. Comment cela se manifeste-t-il dans la forme échelonnée réduite d'une matrice?  On considère les deux matrices échelonnées réduites suivantes:  . La forme de la première matrice indique une infinité de solutions au système d'équations associé, alors que la forme de la seconde révèle qu'il n'y a pas de solution au système.  Dans cette section, on décrit comment on peut déterminer si un système possède ou non des solutions. On définit la notion de rang d'une matrice.    Le nombre de solutions  On considère le système associé à la matrice , sous forme d'équations: . La dernière équation de ce système se simplifie à et elle est toujours vraie, peu importe les valeurs de . Dans les deux autres équations, on peut remarquer que la variable est présente dans chacune et que les coefficients de et valent . Si l'on isole et dans ces équations, on obtient .  Les variables sont liées à , qui elle, ne possède pas de restrictions. Un point qui satisfait le système d'équations linéaires associé à la matrice doit donc être de la forme .  On reconnait l'équation vectorielle d'une droite de vecteur directeur passant par le point . Ainsi, la solution au système est constituée de l'ensemble des points se trouvant sur cette droite. Il y en a donc une infinité.  On considère maintenant le système associé à la matrice , celle-ci traduite sous la forme d'équation permet d'obtenir . Cette fois-ci, la dernière équation se simplifie à . Évidemment, il n'y a aucune valeur de qui peut rendre cette équation vraie. La conclusion est donc qu'il n'y a pas de solutions.   Cohérence d'un système d'équations linéaires   Un système d'équations linéaires pour lequel il existe une ou plusieurs solutions est dit compatible, cohérent . Si aucune solution n'existe, le système est dit incompatible, incohérent .    Comme vu dans l'exercice , si un système compatible admet plus d'une solution, alors il y en a nécessairement une infinité. On a donc la proposition suivante.   Le nombre de solutions à un système d'équations linéaires  Soit , un système d'équations linéaires. Une seule des trois situations suivantes est possible:  Le système est incompatible et n'admet pas de solutions;  Le système est compatible et admet une solution unique;  Le système est compatible et admet une infinité de solutions.     Le système est soit incompatible, soit compatible. S'il est incompatible, il n'y a rien à démontrer.  On suppose que le système est compatible. Dans ce cas, il existe au moins une solution telle que . Si est un vecteur différent de tel que , alors est aussi une solution différente, car . De plus,  On peut ensuite répéter ce processus à l'infini et obtenir des vecteurs différents qui constituent tous des solutions du système. Donc, soit la solution est unique, soit il en existe une infinité.   On reconnait un système incompatible à l'existence d'un pivot dans la partie augmentée, comme pour la matrice . En effet, un pivot dans la partie augmentée signifie que tous les coefficients des variables sont nuls et que le membre de droite (augmenté) est, quant à lui, non nul.  Lorsque le système est cohérent, on aura une solution unique si le nombre de pivots correspond au nombre de variables. S'il est plus petit, il y aura alors une infinité de solutions. Le nombre de pivots d'une matrice est appelé le rang et sera défini au début de la prochaine sous-section.   Un système qui n'a aucune solution   On reprend le système du début de la section , qui correspond à des droites parallèles distinctes: . On veut montrer que ce système ne possède pas de solution en échelonnant la matrice augmentée qui lui est associée.   On utilise Gauss-Jordan pour échelonner la matrice augmentée de ce système, afin de repérer le pivot dans la partie augmentée: .  La dernière ligne étant équivalente à , il ne peut y avoir de solution. On aurait pu poursuivre l'algorithme de Gauss-Jordan pour faire en sorte que la partie augmentée soit aussi échelonnée réduite, mais ce n'est jamais nécessaire. Dès que l'on obtient une ligne de incompatible dans la matrice augmentée, on peut conclure que le système lui-même est incompatible.     Un système avec une infinité de solutions   On reprend l'autre système au début de la section , qui correspond à des droites parallèles confondues: . On veut montrer que ce système possède une infinité de solutions en échelonnant la matrice augmentée qui lui est associée.   On utilise Gauss-Jordan pour échelonner la matrice augmentée de ce système: .  La dernière ligne étant équivalente à , elle ne donne aucune information sur la solution. La première équation s'écrit et l'on y reconnait l'équation de la droite de départ. Pour avoir la forme vectorielle et suivre l'exemple de l'introduction de cette sous-section, on isole dans l'équation: .  Une solution à ce système d'équations doit donc être de la forme . La solution est une droite de vecteur directeur passant par le point . On vérifiera facilement que ce vecteur directeur est bien perpendiculaire au vecteur normal de l'équation et que le point satisfait bel et bien cette équation.    Évidemment, ces deux exemples peuvent se résoudre facilement en ne considérant que la géométrie du système. Toutefois, lorsque le nombre d'équations et d'inconnues devient plus élevé, l'avantage de la méthode algébrique devient plus évident.   Des systèmes à quatre équations et trois inconnues   Soit les matrices , et les vecteurs . On cherche la solution des systèmes suivants:  ,  ,  ,  .      Les systèmes avec la matrice sont équivalents à la matrice augmentée . On peut résoudre simultanément ces systèmes puisque la matrice est la même. On a .  Après tous ces calculs (vive l'ordinateur!), on constate que le système ne possède pas de solution et que pour le système , il y en aura une infinité. On peut les obtenir en isolant en fonction de dans le SEL équivalent à la matrice échelonnée réduite. On a alors . L'ensemble solution est donc l'ensemble des points tels que . On reconnait ici l'équation d'une droite de vecteur directeur passant par le point .    Les systèmes avec la matrice sont équivalents à la matrice augmentée . L'échelonnage est fait à l'exercice . On obtient la matrice .  Cette fois, le vecteur est celui pour lequel il n'y a pas de solution, car la deuxième ligne n'est pas compatible. Pour le vecteur , des solutions existent. Les variables et sont libres. On a donc . L'ensemble solution est donc composé de tous les vecteurs tels que .  On reconnait l'équation vectorielle d'un plan de vecteurs directeurs et passant par le point .    On résume la procédure pour obtenir les solutions d'un système d'équations linéaires dans l'algorithme .   Déterminer les solutions d'un système d'équations linéaires   Soit un système d'équations linéaires correspondant à l'équation matricielle , où est une matrice . On peut obtenir les solutions du SEL en suivant les étapes suivantes:   Échelonner la matrice augmentée à l'aide de l'algorithme de Gauss-Jordan .   Déterminer la solution selon la procédure suivante:  Si la matrice en tant que matrice elle-même contient un pivot dans sa forme échelonnée réduite, alors le système est incompatible. Il n'y a pas de solution.  Si la partie augmentée ne contient pas de pivot et que toutes les variables sont pivots, alors la solution est unique et se lit directement de la forme échelonnée réduite.  Si la partie augmentée ne contient pas de pivot et qu'au moins une des variables est libre, alors on réécrit le système d'équations linéaires correspondant à la forme échelonnée réduite de la matrice , en isolant chaque variable pivot en fonction des variables libres. On obtient une forme paramétrique de la solution où le ou les paramètres correspondent aux variables libres.        On termine avec des commandes Sage en lien avec la sous-section.   Aucune et une infinité de solutions avec Sage  On a vu à l'exemple qu'on peut résoudre les systèmes d'équations avec Sage, avec l'une des commandes rref() ou solve_right() . Toutefois, dans les exemples de la section , il y avait toujours une solution unique. On regarde maintenant comment se comporte Sage lorsqu'un système n'a aucune ou a une infinité de solutions.  Le premier exemple que l'on considère est un exemple qui ne possède aucune solution. Pour cela, on prend deux plans parallèles distincts et l'on essaie de trouver leur intersection. Les plans sont et . La cellule suivante devrait donner une erreur.   Lorsque le système n'a pas de solution, la commande solve_right() produit une erreur. La commande rref() fonctionne, mais il faut réaliser soi-même qu'il n'y a pas de solution en observant le pivot dans la colonne augmentée.   On regarde maintenant ce qu'on obtient lorsque le système possède une infinité de solutions. Pour cela, on prend deux plans non parallèles dans . Ceux-ci vont se croiser en une droite. On peut anticiper la solution en utilisant la géométrie. Une droite est un objet à une dimension, avec une variable libre. On s'attend donc à une matrice augmentée contenant deux variables pivots et une variable libre. La forme paramétrique de la solution devrait être quelque chose du genre , où le vecteur est le vecteur directeur de la droite et est un point de celle-ci. On commence par regarder la forme échelonnée de la matrice augmentée, avec et .   Comme attendu, la matrice a la bonne forme. Les variables sont liées et la variable est libre. On remarque, par contre, que la commande rref() ne donne pas explicitement la solution (c'était le cas aussi pour une solution unique), il faut la déduire de la forme échelonnée. Dans ce cas-ci, on obtient la droite .  On essaie maintenant la commande solve_right() pour le même système.   La réponse obtenue est peut-être surprenante. On sait à partir des connaissances en géométrie qu'il devrait y avoir une infinité de solutions, mais Sage n'en retourne qu'une. En fait, en observant l'équation ci-dessus, on peut remarquer que la solution donnée par Sage correspond à celle où les variables libres valent .  Comment obtenir toutes les solutions dans ce cas? Pour l'instant, on se rabat sur la commande rref() . La section donnera une réponse plus satisfaisante.    Lecture des messages d'erreur Sage  Les messages d'erreur Sage peuvent paraitre étranges lorsqu'on les rencontre pour la première fois. Il peut être utile de commencer sa lecture par le bas. Souvent, on peut détecter le problème à partir de la dernière phrase du message. Si celle-ci n'est pas suffisante, chercher les lignes avec des flèches comme celle-ci ----> . Elles indiquent souvent quelle(s) ligne(s) du code cause(nt) un problème.     Le rang d'une matrice  On a déjà mentionné que le nombre de variables pivots d'une matrice avait une importance particulière. On explore quelques résultats associés à cette notion. D'abord, une définition du rang d'une matrice.   Le rang d'une matrice   Soit , une matrice quelconque. On définit le rang de la matrice comme étant le nombre où correspond au nombre de variables pivots dans la forme échelonnée réduite de la matrice .    Le rang et les lignes d'une matrice  Le rang correspond au nombre de pivots d'une matrice, et, par le fait même au nombre de colonnes pivots. On peut aussi lui associer un sens en fonction du nombre de lignes. En effet, comme chaque pivot est sur une ligne différente, le rang d'une matrice correspond aussi au nombre de lignes non nulles de la forme échelonnée réduite.   Parce que la forme échelonnée réduite est unique , le rang est bien défini, puisque, pour une matrice donnée, elle ne peut avoir qu'une seule valeur pour . On donne maintenant un résultat qui sera réinterprété géométriquement dans la section suivante .   Rang et existence de solutions  Soit , une matrice de rang et , un vecteur. Le système est compatible si et seulement si le rang de la matrice augmentée est aussi égal à .   Soit , la forme échelonnée réduite de la matrice augmentée, où et correspond au vecteur obtenu de en appliquant les opérations élémentaires menant à . Pour être compatible, chaque ligne nulle de doit correspondre avec une entrée nulle du vecteur . Ceci survient si et seulement si le nombre de lignes non nulles de la matrice est égal à celui de la matrice , qui est égal à .    Quelles sont les valeurs possibles pour le rang? La matrice nulle est par défaut, sous la forme échelonnée réduite, mais ne contient pas de pivots. On peut donc avoir . La proposition suivante établit la valeur maximale que peut prendre le rang d'une matrice .   Le rang maximal  Soit , une matrice . Alors . La valeur maximale du rang est donc bornée par le nombre de lignes ou de colonnes, le plus petit de ces deux nombres.   Le rang correspond au nombre de colonnes pivots. Ce nombre ne peut donc pas dépasser . Selon la remarque , le rang est aussi le nombre de lignes non nulles de la matrice. Ce nombre ne peut donc pas dépasser . Ainsi, on a .    Le prochain résultat ne s'applique qu'aux matrices carrées. Il lie le rang d'une matrice à l'existence de son inverse. Cela nous donne la seconde version du théorème de la matrice inverse .   Théorème de la matrice inverse, seconde version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots.     L'équivalence des énoncés un et deux provient de la première version du théorème. L'énoncé trois et l'énoncé quatre sont équivalents, par définition du rang . Il faut donc montrer que l'un des deux premiers énoncés implique que le rang soit égal à et qu'avoir un rang de implique un des deux premiers énoncés.  On commence par prendre une matrice inversible. Soit , son inverse et , ses colonnes. Si l'on note le vecteur dont toutes les entrées sont nulles sauf celle en position qui vaut , alors, selon la définition de la matrice inverse et de la multiplication, on a . Puisque l'inverse d'une matrice est unique, c'est aussi la seule solution. On note la matrice augmentée de l'identité. La forme échelonnée réduite de cette matrice augmentée correspond aux solutions des systèmes d'équations linéaires . Ces solutions sont les (uniques) colonnes de , ce qui signifie que . Cela signifie donc que et donc, .  On suppose maintenant que . Ceci signifie que chaque colonne est pivot et de même, chaque ligne, car la matrice est carrée. On a donc . Soit , un vecteur de . Le système se résout en échelonnant la matrice augmentée , ce qui donne , où est obtenu de à partir des opérations élémentaires effectuées pour échelonner . Comme toutes les variables sont pivots, il n'y a qu'une solution. Cela montre que le rang égal à implique le second énoncé.     La forme échelonnée réduite d'une matrice carrée inversible   Soit , une matrice carrée inversible. Alors .   La preuve a été faite dans la démonstration du théorème , dans la deuxième partie.   On termine avec des commandes Sage en lien avec la sous-section.   Le rang et Sage  Sage possède la commande rank qui permet de calculer le rang d'une matrice. Elle s'utilise soit comme rank(A) , soit A.rank() .        Les points importants de cette section sont:  Les systèmes compatibles et incompatibles ;  Les trois seules possibilités quant au nombre de solutions du système d'équations linéaires ;   L'algorithme permettant de trouver toutes les solutions d'un système d'équations linéaires.  Le rang d'une matrice et son lien avec l'existence de solutions;  L'ajout de l'équivalence entre matrice inversible et rang maximal.  De plus, avec Sage, lors de l'utilisation de la commande solve_right() , on a vu qu'un système qui n'a aucune solution donne une erreur et qu'un système avec une infinité de solutions n'en donne qu'une. Il est préférable d'utiliser la commande rref() et de déduire la solution de la forme échelonnée réduite, du moins pour le moment. On a aussi vu la commande rank() , qui retourne le rang d'une matrice.     Exercices  Reprendre le système de l'exemple et effectuer l'échelonnage. On commence par la matrice du système et l'on effectue l'échelonnage. La matrice augmentée du système une fois échelonnée donne donc: .  On considère les quatre systèmes d'équations linéaires suivants:  ,  ,  ,  .    Dans chaque cas, donner toutes les valeurs de telles que  Les SEL n'ont pas de solution;  et  et  et   Pour déterminer les valeurs de et de ne permettant d'avoir aucune solution, il faut échelonner les matrices de ces systèmes et bien interpréter les résultats. On se rappelle, par l'algorithme , qu'un pivot dans la partie augmentée de la matrice échelonnée réduite indique l'absence de solution.  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que .  Les SEL ont une infinité de solutions.  et  et  et   Pour déterminer les valeurs de et de permettant d'avoir une infinité de solutions, il faut échelonner les matrices de ces systèmes et bien interpréter les résultats. On ne refera pas l'échelonnage, car il a déjà été fait pour trouver les situations sans solutions. On se rappelle, par l'algorithme , qu'une absence de pivot dans la partie augmentée ainsi que la présence d'une variable libre impliquera l'infinité de solutions. Puisque les SEL de cet exercice ont tous deux équations et deux variables, il faut donc absolument que la seconde ligne comporte uniquement des zéros une fois échelonnée.  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que .   Considérer à nouveau la matrice de l'exercice . Quelle devrait être la valeur de pour que le rang de la matrice soit égal à ? Dans ce cas-ci, est-ce que le système possède une solution, une infinité de solutions ou ne possède aucune solution? et aucune solution On recommence l'algorithme de Gauss-Jordan et l'on verra quelle valeur de cela prendra pour que la matrice soit de rang . Pour que la matrice soit de rang , il faut absolument éliminer une ligne entière. En observant que les valeurs de la troisième colonne sont les mêmes dans les deuxième et troisième lignes, on réalise que le seul moyen qu'une de ces deux lignes s'élimine est que les valeurs de la deuxième colonne correspondent aussi. Bref, il faut que . On observe que la matrice est de rang , mais qu'il y a un pivot additionnel dans la partie augmentée. Cela signifie qu'il n'y a aucune solution.  Considérer maintenant la matrice . Quelle devrait être la valeur de pour que le rang de la matrice soit égal à ? Dans ce cas-ci, est-ce que le système possède une solution, une infinité de solutions ou ne possède aucune solution? et infinité de solutions On commence l'algorithme de Gauss-Jordan et l'on verra quelle valeur de cela prendra pour que la matrice soit de rang . Pour que la matrice soit de rang , il faut absolument éliminer une ligne entière. Il est clair que la deuxième ligne s'éliminera uniquement si . On observe que la matrice est de rang et qu'il n'y a pas de pivot additionnel dans la partie augmentée. Cela signifie qu'il y a une infinité de solutions.   Pour chaque matrice échelonnée réduite ci-dessous, donner l'ensemble solution. De plus, lorsque possible, déterminer une solution pour laquelle la variable est égale à .   et   La seule ligne non nulle se résume à l'équation . La variable est libre puisqu'il n'y a pas de pivot dans la première colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière: .   et il est impossible de donner une solution telle que .   La seule ligne non nulle se résume à l'équation . La variable est libre puisqu'il n'y a pas de pivot dans la deuxième colonne. On écrit donc: . L'ensemble solution est donc: . La valeur de la variable étant déjà fixée par le système, il est impossible de donner une solution telle que .     et   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Ainsi, la solution particulière donne: .      et   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la première colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière: .     et il est impossible de donner une solution telle que .   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . La valeur de la variable étant déjà fixée par le système, il est impossible de donner une solution telle que .     et   Les deux seules lignes se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Ainsi, la solution particulière donne: .   et   Les deux lignes non nulles se résument aux équations et . Les variables et sont libres puisqu'il n'y a pas de pivot dans les troisième et quatrième colonnes. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Il existe une infinité de valeurs de et qui pourraient fonctionner. On choisit des valeurs entières pour simplifier les calculs. Ainsi, en posant et , la solution particulière donne: .   et .   Les deux lignes non nulles se résument aux équations et . Les variables et sont libres puisqu'il n'y a pas de pivot dans les deuxième et quatrième colonnes. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Il existe quand même une infinité de solutions puisque la variable n'est pas fixée. On pose donc et la solution particulière est: .  Aucune solution n'existe. Puisque la matrice échelonnée réduite a un pivot dans sa partie augmentée, il n'existe aucune solution à ce système.   Trouver si possible l'intersection des plans suivants :   ;  L'intersection de ces plans est la droite d'équation: . Les équations normales de ces deux plans constituent un SEL à deux équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Les deux lignes se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . On reconnait dans cette solution l'équation d'une droite. Ainsi, l'intersection des deux plans et est une droite d'équation vectorielle: .  ;  L'intersection de ces trois plans n'existe pas. Ils sont donc sécants deux à deux, mais pas tous les trois. Les équations normales de ces trois plans constituent un SEL à trois équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Noter qu'on aurait pu procéder différemment pour l'échelonnage, mais qu'on voulait profiter des étapes d'échelonnage déjà effectuées précédemment dans l'étude de l'intersection des plans et . La matrice échelonnée réduite possédant un pivot dans sa partie augmentée. Il n'y a donc aucune solution. Les trois plans sont donc sécants deux à deux, mais pas tous les trois.  .  L'intersection de ces trois plans est la droite d'équation: . Les équations normales de ces trois plans constituent un SEL à trois équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . On reconnait dans cette solution l'équation d'une droite. Ainsi, l'intersection des trois plans et est une droite d'équation vectorielle: .   Trouver l'intersection des droites suivantes, si possible.  La droite   et la droite L'intersection de ces droites est le point : . Les équations vectorielles de ces deux droites cachent un système à trois équations et deux inconnues. En effet, en comparant le membre de droite de chacune, et en écrivant les équations séparément pour chaque variable, on obtiendra un système qu'on écrit de la façon standard . On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Attention, les inconnues sont et , plutôt que les variables habituelles. Les deux lignes se résument aux équations et . En remplaçant dans l'une ou l'autre des équations vectorielles initiales, on obtient le point: Ainsi, l'intersection des deux droites et est un point. La droite   et la droite L'intersection de ces droites est le point : . Les équations vectorielles de ces deux droites cachent un système à trois équations et deux inconnues. En effet, en comparant le membre de droite de chacune, et en écrivant les équations séparément pour chaque variable, on obtiendra un système qu'on écrit de la façon standard. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Attention, les inconnues sont et , plutôt que les variables habituelles. Les deux lignes se résument aux équations et . En remplaçant dans l'une ou l'autre des équations vectorielles initiales, on obtient le point: Ainsi, l'intersection des deux droites et est un point.   Des solutions à un système d'équations linéaires où est une matrice non nulle sont données ci-dessous. Donner toutes les formes augmentées de matrices échelonnées réduites équivalentes à .  Les solutions sont .   A.solve_right(b) pour résoudre un SEL et A.pivots() pour avoir la position des colonnes pivots reconstruire le système à partir de la solution. Pour avoir une variable libre, on doit avoir une ligne de zéros (la deuxième ligne, pour respecter les conditions d'une matrice échelonnée réduite ). La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Pour avoir une variable libre, on doit avoir une ligne de zéros (la deuxième ligne, pour respecter les conditions d'une matrice échelonnée réduite ). La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Ici, on fait face à une difficulté supplémentaire du fait qu'aucune des variables ne pourra être simplement égale à la variable libre. Cela est dû au fait qu'une équation vectorielle peut avoir n'importe quel point sur l'objet comme point de départ. On doit donc trouver un point sur la droite où la coordonnée en est égale à .  On peut réécrire l'équation de départ ainsi: . La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Ici, on fait face à une difficulté supplémentaire du fait qu'aucune des variables ne pourra être simplement égale à la variable libre. Cela est dû au fait qu'une équation vectorielle peut avoir n'importe quel point sur l'objet comme point de départ. On doit donc trouver un point sur la droite où la coordonnée en est égale à .  On peut réécrire l'équation de départ ainsi: . La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: .  Les points et sont des solutions.    On doit d'abord créer la droite passant par ces deux points. Il existe une infinité de vecteurs directeurs valables (pourvu qu'ils soient tous parallèles) et de points de départ (pourvu qu'ils soient sur la droite). Par contre, la manière la plus évidente est de prendre un des points donnés et le vecteur les reliant. On a appris, des lettres précédentes, qu'on veut un vecteur avec une composante égale à et idéalement un point de départ où cette même variable aura un . et Ainsi, La première ligne sera donc constituée pour communiquer l'information que . Cela donne une matrice qui n'est pas échelonnée réduite, on fait alors l'opération nécessaire: . L'unique bonne réponse est donc: .  Les points et sont des solutions.    On doit d'abord créer la droite passant par ces deux points. Il existe une infinité de vecteurs directeurs valables (pourvu qu'ils soient tous parallèles) et de points de départ (pourvu qu'ils soient sur la droite). Par contre, la manière la plus évidente est de prendre un des points donnés et le vecteur les reliant. On a appris, des lettres précédentes, qu'on veut un vecteur avec une composante égale à et idéalement un point de départ où cette même variable aura un . et Ainsi, La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: .   Donner le rang des matrices suivantes.     On doit échelonner la matrice et donner le nombre de pivots. La matrice est donc de rang , puisque sa forme échelonnée réduite possède deux pivots.   On doit échelonner la matrice et donner le nombre de variables pivots, selon la définition . La matrice est donc de rang , puisque sa forme échelonnée réduite possède un seul pivot.   On doit échelonner la matrice et donner le nombre de pivots. La matrice est donc de rang , puisque sa forme échelonnée réduite possède deux pivots. La matrice , représentant une rotation de degrés dans . Plutôt que d'échelonner la matrice de rotation comportant une variable, on choisit de se servir du théorème de la matrice inverse . Ce dernier spécifie que, si une matrice carrée est inversible, alors elle est de rang maximal. Or, on a appris dans la section que les rotations sont des transformations linéaires inversibles. On avait même trouvé que . Ainsi, cette matrice est de rang maximal donc .  La matrice d'une réflexion quelconque dans .  On n'a pas développé de forme générale pour une réflexion quelconque dans , on ne peut donc pas échelonner la matrice . On choisit donc de se servir encore du théorème de la matrice inverse . Ce dernier spécifie que, si une matrice carrée est inversible, alors elle est de rang maximal. Or, on a appris que les réflexions sont des transformations linéaires inversibles. On avait trouvé que , peu importe l'axe de réflexion. Ainsi, cette matrice est de rang maximal donc . La matrice qui envoie tout vecteur sur le vecteur . On pourrait déduire le rang en réfléchissant au fait qu'on perd une dimension dans ce genre de projection. Cependant, on peut facilement construire cette matrice en se souvenant du fait que les colonnes d'une matrice de transformation linéaire correspondent aux images des vecteurs de la base canonique sous cette transformation tel qu'utilisé, entre autres, dans l'exemple . Puisque , on remarque que: . La matrice est donc qui est déjà échelonnée et de rang . La matrice qui envoie tout vecteur sur le vecteur . On pourrait déduire le rang en réfléchissant au fait qu'on perd deux dimensions dans ce genre de projection. Cependant, on peut facilement construire cette matrice en se souvenant du fait que les colonnes d'une matrice de transformation linéaire correspondent aux images des vecteurs de la base canonique sous cette transformation tel qu'utilisé, entre autres, dans l'exemple . Puisque , on remarque que: . La matrice est donc qui, une fois échelonnée, est clairement de rang .  Pour chaque énoncé, donner au moins deux matrices échelonnées réduites qui satisfont l'énoncé. S'il n'y en a pas deux, expliquer pourquoi, et s'il y en a plus de deux, déterminer combien. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type ayant la forme . On en donne deux. La matrice correspond aussi aux critères, mais a une forme différente des autres. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . La seule réponse valable est la matrice identité: . Toute matrice carrée de rang maximal est inversible et l'on peut donc faire des opérations élémentaires et arriver à la matrice identité (voir l'exercice ). Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme ou de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme . On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice identité: . Toute matrice carrée de rang maximal est inversible et l'on peut donc faire des opérations élémentaires et arriver à la matrice identité (voir l'exercice ). Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . La seule matrice possible est . Toute autre forme pourrait être ramenée à celle-ci en utilisant une des trois opérations élémentaires. Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. En effet, pour avoir un rang de , il doit y avoir trois pivots. Les pivots correspondant aux colonnes, il est impossible d'y arriver avec seulement deux colonnes. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme ou de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme . On en donne deux. . Il y a aussi les matrices de la forme pour n'importe quelle valeur réelle de . La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. En effet, pour avoir un rang de , il doit y avoir trois pivots. Les pivots devant être sur des lignes différentes, il doit y en avoir trois pour y arriver.  Refaire l'exercice , cette fois sans que les réponses soient des matrices échelonnées réduites. Nul besoin de redonner les explications, qui seront les mêmes. Les matrices sont de rang et de taille . Essentiellement, on reprend toutes nos réponses de l'exercice et l'on donne une matrice non échelonnée correspondante. On rappelle que, pour qu'une ligne non nulle devienne nulle lorsqu'échelonnée, il faut qu'elle soit multiple d'une autre ligne ou, plus généralement, combinaison linéaire des autres lignes. Il existe bien entendu une infinité de réponses possibles.  Les matrices sont de rang et de taille . Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .   Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. Les matrices sont de rang et de taille . Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille . Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères.   Remplacer tous les de la matrice par des entiers non nuls afin que la matrice soit  de rang ; Pour être de rang , il faut que la dernière ligne soit complètement remplacée par des zéros lorsqu'on fera l'échelonnage. En effet, les deux premières lignes n'étant pas multiples l'une de l'autre, on aura deux pivots. Une façon simple d'y arriver est de donner une ligne qui est égale à une des deux autres ou même à l'un de leur multiple. On peut aussi y arriver si la ligne choisie est une combinaison linéaire des deux autres. On y va simplement. Cette matrice échelonnée réduite a deux pivots. Elle est donc de rang . équivalente à la matrice identité. Pour être équivalente à la matrice identité, il faut qu'elle soit de rang et donc de rang maximal. Pour être de rang , il faut que les trois lignes ne soient pas combinables pour être éliminées entièrement. Ce concept se nomme indépendance linéaire et sera élaboré plus en détail à la section . Cette matrice échelonnée réduite est la matrice identité. La matrice initiale lui est donc équivalente.   Soit , une matrice carrée d'ordre .  On s'intéresse aux lignes de la matrice Si possède deux lignes identiques, montrer que le rang de n'est pas maximal. On se contente d'une preuve en mots puisque l'on ne gagnera rien en clarté si l'on écrit des matrices arbitraires au long. On rappelle quand même la définition du rang , la remarque par rapport aux lignes ainsi que la proposition sur le rang maximal.  Si la matrice possède deux lignes identiques (disons et ), alors, par la seule opération élémentaire visant à éliminer le premier élément ( ), on éliminera toute la ligne. Une matrice ayant une ligne de zéros ne peut avoir de pivots sur cette ligne. Elle ne peut donc pas avoir pivots puisqu'on n'a jamais plus qu'un pivot par ligne. Si possède deux lignes parallèles, montrer que le rang de n'est pas maximal. Si l'on a deux lignes parallèles, alors la preuve est exactement la même que précédemment, mais on utilise l'opération où est le facteur de parallélisme. La ligne entière deviendra nulle et la preuve se fait de façon identique. Si possède une ligne qui soit une combinaison linéaire des autres lignes, montrer que le rang de n'est pas maximal. Si possède une ligne (disons ) qui est une combinaison linéaire des autres lignes (disons ), alors, on peut écrire: On utilise ensuite les opérations élémentaires successives suivantes: Au bout de ce processus, on aura inévitablement une ligne de zéros là où était . Le reste de la preuve est identique. Refaire les questions précédentes en remplaçant ligne par colonne dans chaque énoncé. Si possède deux colonnes identiques, montrer que le rang de n'est pas maximal. On se contente d'une preuve en mots puisque l'on ne gagnera rien clarté si l'on écrit des matrices arbitraires au long. On rappelle quand même la définition du rang , la remarque par rapport aux lignes ainsi que la proposition sur le rang maximal.  Si la matrice possède deux colonnes identiques, alors, lorsqu'on fera des opérations élémentaires visant à obtenir un pivot dans la première des deux colonnes et des zéros en haut et en bas, l'effet de ces opérations sera le même sur les éléments de la deuxième colonne. On se retrouvera donc avec deux colonnes identiques avec un pivot dans la première, mais pas de pivot dans la seconde. Dans ce cas, on ne peut avoir le rang maximal puisqu'on va manquer de colonnes. Si possède deux colonnes parallèles, montrer que le rang de n'est pas maximal. Les opérations que l'on fait pour obtenir un pivot dans la première colonne et des zéros en haut et en bas du pivot amèneront également une seule valeur non nulle dans la deuxième colonne. Il est donc impossible d'avoir un pivot sur cette seconde colonne. Si possède une colonne qui est une combinaison linéaire des autres colonnes , montrer que le rang de n'est pas maximal. La solution suivra. Déduire des énoncés précédents la troisième version du théorème de la matrice inverse.   Théorème de la matrice inverse, troisième version  Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .  Le rang de la matrice est égal à .  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité.  Aucune ligne n'est une combinaison linéaire des autres lignes.  Aucune colonne n'est une combinaison linéaire des autres colonnes.    Il n'y a rien à ajouter. On a démontré les deux points additionnels dans cette version du théorème.  Montrer, en trouvant son inverse, qu'une matrice carrée de rang est inversible. Ceci constitue une preuve alternative du fait que rang implique inverse fait au théorème .  L'inverse est .   On se souvient, par la définition du rang , qu'une matrice carrée de rang , et donc de rang maximal, a pivots. Cela signifie que sa forme échelonnée réduite est l'identité. Ainsi, il est possible de trouver des matrices élémentaires inversibles telles que la matrice peut être échelonnée jusqu'à donner l'identité. On a donc: . Cela implique que la matrice inverse de est la multiplication des matrices élémentaires:    Dans cet exercice, on considère un vecteur comme une matrice ayant une seule colonne. Une matrice ayant une seule ligne est, quant à elle, notée Le en exposant est lié avec la notion de transposée, qui sera définie plus loin. , où est le vecteur représentant la ligne. Considérer la matrice et la matrice . Quel est le rang des matrices et ? et Comparer les produits et . Quelle autre opération le produit représente-t-il? On calcule les produits: et . Le premier résultat est donc une matrice et le deuxième une matrice  . On comprend que le deuxième résultat a beau être entre parenthèses, une matrice qui ne possède qu'une ligne et une colonne est en réalité un nombre, souvent appelé un scalaire. Cette opération correspond donc au produit scalaire. Quel est le rang des matrices et ? et Le rang de est de , puisque c'est un nombre non nul qui est, par le fait même, un pivot. Le rang de s'obtiendra de diverses façons (échelonner ou bien utiliser le théorème de la matrice inverse ). On voit immédiatement que la matrice a deux lignes (ou colonnes) parallèles. Par le théorème, elle n'est donc pas de rang maximal. Elle est de rang . Utiliser Sage pour vérifier le rang de pour différents vecteurs de .    Le code solution pour les vecteurs initiaux   u=matrix([[2],[1]]) vT=matrix([[3,4]]) uvT=u*vT show(uvT) show(rank(uvT))    On remarque qu'il suffit de remplacer les vecteurs initiaux par d'autres vecteurs pour tester. On laisse les observations à l'élève.  Si sont n'importe quel vecteur non nul de , quel est le rang du produit ? Le rang est toujours de . Si sont n'importe quel vecteur non nul de , quel est le rang du produit ? Le rang est toujours de .    Cet exercice s'intéresse au rang du produit d'une matrice par rapport aux rangs des matrices composant le produit. La section donnera la signification du rang dans le contexte des transformations linéaires.  Considérer les matrices . Quel est le rang des matrices et ? , et On se sert chaque fois du théorème de la matrice inverse plutôt que d'échelonner et de compter le nombre de pivots. On a que , puisque la deuxième ligne est le double de la première (parallèles et donc une combinaison linéaire de la première ligne). On peut écrire .  On a que , puisque les lignes ne sont pas parallèles et donc pas combinaison linéaire.  Finalement, on a que , puisque la deuxième ligne est un multiple de la première (parallèles et donc combinaison linéaire de la première ligne). On peut écrire . Quel est le rang des matrices et ? et Calculons d'abord les produits demandés. et Les rangs de ces deux matrices sont de puisque, dans les deux cas, la deuxième ligne est multiple de la première. En effet, tant pour que pour , on a . Dans l'exercice , on montrera un cas plus général du fait suivant: Si est de rang , alors il existe deux vecteurs tels que . On utilise ce fait dans cet exercice. Soit et , deux matrices de rang . Montrer que . On a pu mettre en évidence du produit matriciel le produit scalaire, puisque son résultat est un scalaire. Si aucun des vecteurs ne peut être nul, quelle est la condition pour que ? Il faut que le produit scalaire soit nul et donc que les vecteurs et soient orthogonaux. De cette façon, le produit donnera la matrice nulle qui est la seule matrice de rang . Montrer que, si la colonne de la matrice est une combinaison linéaire des colonnes précédentes de la matrice , alors la colonne de la matrice est la même combinaison linéaire des colonnes précédentes de .  Ceci implique que la matrice ne peut pas avoir plus de colonnes pivots que la matrice . On écrit d'abord la colonne comme une combinaison linéaire des colonnes précédentes: . On écrit ensuite le produit suivant la définition : La colonne de la matrice est donc la même combinaison linéaire des colonnes à de . Conclure que . L'exercice viendra compléter ce résultat pour avoir . C'est une conséquence directe de ce qu'on vient de montrer et des preuves de l'exercice .    Considérer la matrice ci-dessous où est un nombre réel quelconque .  Si possible, compléter la matrice pour qu'elle soit de   rang ;  Une matrice de rang possède des lignes qui sont toutes multiples les unes des autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros aux deux lignes du bas, et donc un seul pivot. Un exemple de réponse, obtenue en remplissant les valeurs pour que toutes les lignes soient parallèles est: . La matrice échelonnée donne: qui n'a qu'un seul pivot.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent éliminer complètement une des trois lignes. Cela peut se faire en ayant deux lignes parallèles (notre approche) ou en ayant une ligne qui soit une combinaison linéaire des deux autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros à la ligne du bas et des pivots aux deux autres lignes. Le second pivot peut se retrouver dans la deuxième ou la troisième colonne. Un exemple de réponse est: . La matrice échelonnée est et possède deux pivots.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent ne jamais pouvoir s'éliminer complètement. Pour ce faire, il faut qu'aucune des lignes ne soit une combinaison linéaire des autres lignes. On verra plus loin à la section que ce que l'on veut c'est que ces lignes soient linéairement indépendantes. Les opérations élémentaires vont nécessairement amener l'échelonnage à la matrice identité. Cependant, il peut être difficile de voir quelles valeurs on doit avoir pour que ce soit le cas. Un exemple de réponse est: . La matrice échelonnée est et possède trois pivots.   Considérer la matrice ci-dessous où est un nombre réel quelconque .  Si possible, compléter la matrice pour qu'elle soit de   rang ;  C'est impossible. Il est impossible d'obtenir un seul pivot puisque les deux premières lignes ne seront jamais parallèles, peu importe ce qu'on pose à l'emplacement de l'étoile.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent éliminer complètement une des trois lignes. Cela peut se faire en ayant deux lignes parallèles (notre approche) ou en ayant une ligne qui soit combinaison linéaire des deux autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros à la ligne du bas et des pivots aux deux autres lignes. Le second pivot peut se retrouver dans la deuxième ou la troisième colonne. Un exemple de réponse est: . La matrice échelonnée est et possède deux pivots.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent ne jamais pouvoir s'éliminer complètement. Pour ce faire, il faut qu'aucune des lignes ne soit une combinaison linéaire des autres lignes. On verra plus loin à la section que ce que l'on veut, c'est que ces lignes soient linéairement indépendantes. Les opérations élémentaires vont nécessairement ramener la matrice à la matrice identité. Cependant, il peut être difficile de voir quelles valeurs on doit poser pour que ce soit le cas. Un exemple de réponse est: . La matrice échelonnée est qui possède trois pivots.   Dans cet exercice, on cherche à préciser davantage le nombre de solutions possibles qu'une équation matricielle peut avoir en fonction de son rang et de ses dimensions.  Donner, si possible, des exemples de matrices échelonnées réduites augmentées d'un vecteur qui satisfont les conditions suivantes. La matrice est carrée et le système possède: Une solution unique; Aucune solution; Une infinité de solutions. La matrice est , de rang et le système possède: Une solution unique; Impossible. Il y aura nécessairement des variables libres. Aucune solution; Impossible. On ne peut avoir de pivot supplémentaire dans la partie augmentée puisqu'il n'y a que trois lignes et la matrice étant déjà de rang , on ne peut avoir un ou des lignes de zéros. Une infinité de solutions. La matrice est , de rang et le système possède: Une solution unique; Aucune solution; Une infinité de solutions. Impossible. Si la matrice n'a que colonnes et qu'elle doit être de rang , il ne reste pas d'espace pour une colonne sans pivot et donc il est impossible d'avoir une variable libre. La matrice est , de rang et le système possède: Une solution unique; Impossible. Il y aura nécessairement des variables libres. Aucune solution; Une infinité de solutions. Soit , une matrice de rang . Déterminer et expliquer le nombre de solutions possibles au système selon les conditions suivantes. On a et , c'est-à-dire une matrice carrée et inversible . Il y aura toujours une solution unique puisque la matrice a pivots et donc aucune variable libre. Le vecteur étant de dimension , il n'y a pas d'espace pour un pivot additionnel dans la partie augmentée. On peut même isoler la solution puisque la matrice est inversible: On a et , c'est-à-dire une matrice « large ». Puisque l'on a plus de colonnes que de lignes, on a de l'espace pour des colonnes sans pivot. Cela veut dire qu'on aura une infinité de solutions, s'il y en a. De même, le vecteur étant de dimension , il n'y a pas d'espace pour un pivot additionnel dans la partie augmentée. On aura donc toujours une infinité de solutions. On a et , c'est-à-dire une « grande » matrice . Puisque l'on a plus de lignes que de colonnes, mais que , chaque colonne contient un pivot. Il n'y a donc pas de variable libre. Par contre, il est possible d'avoir un pivot additionnel dans la partie augmentée, ce qui mènerait à n'avoir aucune solution. Sinon, il y aura une solution unique. On a et , c'est-à-dire une matrice qui n'est pas de rang maximal pour sa taille. Dans ce cas, il va obligatoirement y avoir au moins une variable libre, puisque . Cela mène donc à une infinité de solutions. Cependant, s'il y a un pivot additionnel dans la partie augmentée, ce qui est possible, puisque , on n'aura aucune solution.  Soit , une matrice quelconque et m un vecteur tel que le système est compatible. De plus, soit , une matrice de format approprié telle que . Montrer que est une solution à l'équation . Une telle matrice est souvent appelée un inverse généralisé de la matrice . Si a des solutions, poser une de ces solutions. On a donc . On démontre que est une solution en remplaçant dans le membre de gauche de l'équation et en montrant que c'est bien égal à .   Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.   Résoudre les systèmes d'équations suivants.    On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[5,-3,2,7],[3,0,3,-1],[6,2,1,-2],[2,-1,-6,8],[8,-1,0,6]]) b=vector([-3,2,0,-9,-5]) show((A.augment(b,subdivide=True))) #Pour vérifier qu'on a le bon système show((A.augment(b,subdivide=True)).rref())    On interprète cette solution ainsi:      Il n'y a aucune solution à ce système. On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[2,-4,-1,3],[1,0,4,1],[1,2,-4,-1],[0,1,7,4],[4,-1,0,7]]) b=vector([-1,-12,5,4,-1]) show((A.augment(b,subdivide=True))) show((A.augment(b,subdivide=True)).rref())    Il n'y a donc aucune solution à ce système, puisqu'il y a un pivot dans la partie augmentée.    On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[3,-5,0,3,-1],[-2,3,-1,4,0],[-3,0,5,1,2]]) b=vector([7,-1,-3]) show((A.augment(b,subdivide=True))) show((A.augment(b,subdivide=True)).rref())    On interprète cette solution ainsi:    Utiliser la commande rank et la proposition pour déterminer si les systèmes de l'exercice précédent sont compatibles. On sait déjà que des trois systèmes de l'exercice précédent, seul le deuxième est incompatible. On le montrera en calculant le rang de la matrice et le rang de la matrice augmentée. Si ces rangs sont égaux, le système est compatible.   Le code solution pour la lettre (a)   A=matrix([[5,-3,2,7],[3,0,3,-1],[6,2,1,-2],[2,-1,-6,8],[8,-1,0,6]]) b=vector([-3,2,0,-9,-5]) show(rank(A)==rank(A.augment(b,subdivide=True))) #si l'on obtient True, cela veut dire que les rangs sont égaux et donc le système est compatible     Le code solution pour la lettre (b)   A=matrix([[2,-4,-1,3],[1,0,4,1],[1,2,-4,-1],[0,1,7,4],[4,-1,0,7]]) b=vector([-1,-12,5,4,-1]) show(rank(A)==rank(A.augment(b,subdivide=True)))     Le code solution pour la lettre (c)   A=matrix([[3,-5,0,3,-1],[-2,3,-1,4,0],[-3,0,5,1,2]]) b=vector([7,-1,-3]) show(rank(A)==rank(A.augment(b,subdivide=True)))      Les coniques Les paraboles font partie d'une famille plus générale de courbes appelées les coniques. Les coniques tirent d'ailleurs leur nom du fait qu'elles peuvent être obtenues par l'intersection d'un cône avec un plan. L'équation cartésienne d'une conique est , avec qui ne sont pas tous nuls. Avec cinq points sur une conique, il est possible de déterminer une équation cartésienne. Cet exercice vise à explorer la recherche d'une équation de coniques par la résolution de systèmes d'équations linéaires appropriés. Cinq points dont aucun triplet n'est sur une ligne déterminent une unique conique. Toutefois, les systèmes d'équations utilisés ci-dessous auront une infinité de solutions. Pourquoi? Si l'on prend l'équation , on peut la multiplier par n'importe quelle constante et obtenir une équation décrivant la même conique.  Chacun des ensembles de points suivants est sur une conique d'équation . En utilisant un système d'équations linéaires, déterminer l'équation de chaque conique. Tracer celle-ci, ainsi que les points, sur un même graphique.          Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,0]) P2=vector([0,-1]) P3=vector([-1,0]) P4=vector([1\/3,-2\/3]) P5=vector([-1\/3,(sqrt(3)-1)\/3]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique1=1*x^2+1*x*y+1*y^2+1*x+1*y==0 implicit_plot(conique1,(x,-1,1),(y,-1,1),color=\"blue\")+points(P,color=\"black\",size=30)            Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,2]) P2=vector([2,2]) P3=vector([-2,4]) P4=vector([4,0]) P5=vector([4,4]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique2=-x^2+2*y^2+2*x-8*y+8==0 implicit_plot(conique2,(x,-10,10),(y,-10,10),color=\"blue\")+points(P,color=\"black\",size=30)            Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,0]) P2=vector([3*sqrt(3)\/2+9\/2,9\/2*sqrt(3)-3\/2]) P3=vector([sqrt(3)+2,2*sqrt(3)-1]) P4=vector([-1\/2*sqrt(3)+1\/2,1\/2*sqrt(3)+1\/2]) P5=vector([-sqrt(3)+2,2*sqrt(3)+1]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique3=-2\/3*sqrt(3)*x*y + x^2 + 1\/3*y^2 - 2\/3*sqrt(3)*y - 2\/3*x == 0 implicit_plot(conique3,(x,-8,8),(y,-8,8),color=\"blue\")+points(P,color=\"black\",size=30)         Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([4,-5]) P2=vector([13,-2]) P3=vector([4,1]) P4=vector([8,3]) P5=vector([8,-7]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique4=x^2+y^2-16*x+4*y+43==0 implicit_plot(conique4,(x,0,16),(y,-10,4),color=\"blue\")+points(P,color=\"black\",size=30)       "
},
{
  "id": "def-SELcomp",
  "level": "2",
  "url": "sec-SELtheo.html#def-SELcomp",
  "type": "Définition",
  "number": "3.2.1",
  "title": "Cohérence d’un système d’équations linéaires.",
  "body": " Cohérence d'un système d'équations linéaires   Un système d'équations linéaires pour lequel il existe une ou plusieurs solutions est dit compatible, cohérent . Si aucune solution n'existe, le système est dit incompatible, incohérent .   "
},
{
  "id": "prop-nbsol",
  "level": "2",
  "url": "sec-SELtheo.html#prop-nbsol",
  "type": "Proposition",
  "number": "3.2.2",
  "title": "Le nombre de solutions à un système d’équations linéaires.",
  "body": " Le nombre de solutions à un système d'équations linéaires  Soit , un système d'équations linéaires. Une seule des trois situations suivantes est possible:  Le système est incompatible et n'admet pas de solutions;  Le système est compatible et admet une solution unique;  Le système est compatible et admet une infinité de solutions.     Le système est soit incompatible, soit compatible. S'il est incompatible, il n'y a rien à démontrer.  On suppose que le système est compatible. Dans ce cas, il existe au moins une solution telle que . Si est un vecteur différent de tel que , alors est aussi une solution différente, car . De plus,  On peut ensuite répéter ce processus à l'infini et obtenir des vecteurs différents qui constituent tous des solutions du système. Donc, soit la solution est unique, soit il en existe une infinité.  "
},
{
  "id": "example-61",
  "level": "2",
  "url": "sec-SELtheo.html#example-61",
  "type": "Exemple",
  "number": "3.2.3",
  "title": "Un système qui n’a aucune solution.",
  "body": " Un système qui n'a aucune solution   On reprend le système du début de la section , qui correspond à des droites parallèles distinctes: . On veut montrer que ce système ne possède pas de solution en échelonnant la matrice augmentée qui lui est associée.   On utilise Gauss-Jordan pour échelonner la matrice augmentée de ce système, afin de repérer le pivot dans la partie augmentée: .  La dernière ligne étant équivalente à , il ne peut y avoir de solution. On aurait pu poursuivre l'algorithme de Gauss-Jordan pour faire en sorte que la partie augmentée soit aussi échelonnée réduite, mais ce n'est jamais nécessaire. Dès que l'on obtient une ligne de incompatible dans la matrice augmentée, on peut conclure que le système lui-même est incompatible.   "
},
{
  "id": "example-62",
  "level": "2",
  "url": "sec-SELtheo.html#example-62",
  "type": "Exemple",
  "number": "3.2.4",
  "title": "Un système avec une infinité de solutions.",
  "body": " Un système avec une infinité de solutions   On reprend l'autre système au début de la section , qui correspond à des droites parallèles confondues: . On veut montrer que ce système possède une infinité de solutions en échelonnant la matrice augmentée qui lui est associée.   On utilise Gauss-Jordan pour échelonner la matrice augmentée de ce système: .  La dernière ligne étant équivalente à , elle ne donne aucune information sur la solution. La première équation s'écrit et l'on y reconnait l'équation de la droite de départ. Pour avoir la forme vectorielle et suivre l'exemple de l'introduction de cette sous-section, on isole dans l'équation: .  Une solution à ce système d'équations doit donc être de la forme . La solution est une droite de vecteur directeur passant par le point . On vérifiera facilement que ce vecteur directeur est bien perpendiculaire au vecteur normal de l'équation et que le point satisfait bel et bien cette équation.   "
},
{
  "id": "ex-4eq3inc",
  "level": "2",
  "url": "sec-SELtheo.html#ex-4eq3inc",
  "type": "Exemple",
  "number": "3.2.5",
  "title": "Des systèmes à quatre équations et trois inconnues.",
  "body": " Des systèmes à quatre équations et trois inconnues   Soit les matrices , et les vecteurs . On cherche la solution des systèmes suivants:  ,  ,  ,  .      Les systèmes avec la matrice sont équivalents à la matrice augmentée . On peut résoudre simultanément ces systèmes puisque la matrice est la même. On a .  Après tous ces calculs (vive l'ordinateur!), on constate que le système ne possède pas de solution et que pour le système , il y en aura une infinité. On peut les obtenir en isolant en fonction de dans le SEL équivalent à la matrice échelonnée réduite. On a alors . L'ensemble solution est donc l'ensemble des points tels que . On reconnait ici l'équation d'une droite de vecteur directeur passant par le point .    Les systèmes avec la matrice sont équivalents à la matrice augmentée . L'échelonnage est fait à l'exercice . On obtient la matrice .  Cette fois, le vecteur est celui pour lequel il n'y a pas de solution, car la deuxième ligne n'est pas compatible. Pour le vecteur , des solutions existent. Les variables et sont libres. On a donc . L'ensemble solution est donc composé de tous les vecteurs tels que .  On reconnait l'équation vectorielle d'un plan de vecteurs directeurs et passant par le point .   "
},
{
  "id": "algo-SELsol",
  "level": "2",
  "url": "sec-SELtheo.html#algo-SELsol",
  "type": "Algorithme",
  "number": "3.2.6",
  "title": "Déterminer les solutions d’un système d’équations linéaires.",
  "body": " Déterminer les solutions d'un système d'équations linéaires   Soit un système d'équations linéaires correspondant à l'équation matricielle , où est une matrice . On peut obtenir les solutions du SEL en suivant les étapes suivantes:   Échelonner la matrice augmentée à l'aide de l'algorithme de Gauss-Jordan .   Déterminer la solution selon la procédure suivante:  Si la matrice en tant que matrice elle-même contient un pivot dans sa forme échelonnée réduite, alors le système est incompatible. Il n'y a pas de solution.  Si la partie augmentée ne contient pas de pivot et que toutes les variables sont pivots, alors la solution est unique et se lit directement de la forme échelonnée réduite.  Si la partie augmentée ne contient pas de pivot et qu'au moins une des variables est libre, alors on réécrit le système d'équations linéaires correspondant à la forme échelonnée réduite de la matrice , en isolant chaque variable pivot en fonction des variables libres. On obtient une forme paramétrique de la solution où le ou les paramètres correspondent aux variables libres.       "
},
{
  "id": "sageex-nbsol",
  "level": "2",
  "url": "sec-SELtheo.html#sageex-nbsol",
  "type": "Calcul",
  "number": "3.2.7",
  "title": "Aucune et une infinité de solutions avec Sage.",
  "body": " Aucune et une infinité de solutions avec Sage  On a vu à l'exemple qu'on peut résoudre les systèmes d'équations avec Sage, avec l'une des commandes rref() ou solve_right() . Toutefois, dans les exemples de la section , il y avait toujours une solution unique. On regarde maintenant comment se comporte Sage lorsqu'un système n'a aucune ou a une infinité de solutions.  Le premier exemple que l'on considère est un exemple qui ne possède aucune solution. Pour cela, on prend deux plans parallèles distincts et l'on essaie de trouver leur intersection. Les plans sont et . La cellule suivante devrait donner une erreur.   Lorsque le système n'a pas de solution, la commande solve_right() produit une erreur. La commande rref() fonctionne, mais il faut réaliser soi-même qu'il n'y a pas de solution en observant le pivot dans la colonne augmentée.   On regarde maintenant ce qu'on obtient lorsque le système possède une infinité de solutions. Pour cela, on prend deux plans non parallèles dans . Ceux-ci vont se croiser en une droite. On peut anticiper la solution en utilisant la géométrie. Une droite est un objet à une dimension, avec une variable libre. On s'attend donc à une matrice augmentée contenant deux variables pivots et une variable libre. La forme paramétrique de la solution devrait être quelque chose du genre , où le vecteur est le vecteur directeur de la droite et est un point de celle-ci. On commence par regarder la forme échelonnée de la matrice augmentée, avec et .   Comme attendu, la matrice a la bonne forme. Les variables sont liées et la variable est libre. On remarque, par contre, que la commande rref() ne donne pas explicitement la solution (c'était le cas aussi pour une solution unique), il faut la déduire de la forme échelonnée. Dans ce cas-ci, on obtient la droite .  On essaie maintenant la commande solve_right() pour le même système.   La réponse obtenue est peut-être surprenante. On sait à partir des connaissances en géométrie qu'il devrait y avoir une infinité de solutions, mais Sage n'en retourne qu'une. En fait, en observant l'équation ci-dessus, on peut remarquer que la solution donnée par Sage correspond à celle où les variables libres valent .  Comment obtenir toutes les solutions dans ce cas? Pour l'instant, on se rabat sur la commande rref() . La section donnera une réponse plus satisfaisante.  "
},
{
  "id": "insight-6",
  "level": "2",
  "url": "sec-SELtheo.html#insight-6",
  "type": "Conseil",
  "number": "3.2.8",
  "title": "Lecture des messages d’erreur Sage.",
  "body": " Lecture des messages d'erreur Sage  Les messages d'erreur Sage peuvent paraitre étranges lorsqu'on les rencontre pour la première fois. Il peut être utile de commencer sa lecture par le bas. Souvent, on peut détecter le problème à partir de la dernière phrase du message. Si celle-ci n'est pas suffisante, chercher les lignes avec des flèches comme celle-ci ----> . Elles indiquent souvent quelle(s) ligne(s) du code cause(nt) un problème.  "
},
{
  "id": "def-rang",
  "level": "2",
  "url": "sec-SELtheo.html#def-rang",
  "type": "Définition",
  "number": "3.2.9",
  "title": "Le rang d’une matrice.",
  "body": " Le rang d'une matrice   Soit , une matrice quelconque. On définit le rang de la matrice comme étant le nombre où correspond au nombre de variables pivots dans la forme échelonnée réduite de la matrice .  "
},
{
  "id": "rem-ranglignenulle",
  "level": "2",
  "url": "sec-SELtheo.html#rem-ranglignenulle",
  "type": "Remarque",
  "number": "3.2.10",
  "title": "Le rang et les lignes d’une matrice.",
  "body": " Le rang et les lignes d'une matrice  Le rang correspond au nombre de pivots d'une matrice, et, par le fait même au nombre de colonnes pivots. On peut aussi lui associer un sens en fonction du nombre de lignes. En effet, comme chaque pivot est sur une ligne différente, le rang d'une matrice correspond aussi au nombre de lignes non nulles de la forme échelonnée réduite.  "
},
{
  "id": "prop-rangmcomp",
  "level": "2",
  "url": "sec-SELtheo.html#prop-rangmcomp",
  "type": "Proposition",
  "number": "3.2.11",
  "title": "Rang et existence de solutions.",
  "body": " Rang et existence de solutions  Soit , une matrice de rang et , un vecteur. Le système est compatible si et seulement si le rang de la matrice augmentée est aussi égal à .   Soit , la forme échelonnée réduite de la matrice augmentée, où et correspond au vecteur obtenu de en appliquant les opérations élémentaires menant à . Pour être compatible, chaque ligne nulle de doit correspondre avec une entrée nulle du vecteur . Ceci survient si et seulement si le nombre de lignes non nulles de la matrice est égal à celui de la matrice , qui est égal à .   "
},
{
  "id": "prop-rangmaximal",
  "level": "2",
  "url": "sec-SELtheo.html#prop-rangmaximal",
  "type": "Proposition",
  "number": "3.2.12",
  "title": "Le rang maximal.",
  "body": " Le rang maximal  Soit , une matrice . Alors . La valeur maximale du rang est donc bornée par le nombre de lignes ou de colonnes, le plus petit de ces deux nombres.   Le rang correspond au nombre de colonnes pivots. Ce nombre ne peut donc pas dépasser . Selon la remarque , le rang est aussi le nombre de lignes non nulles de la matrice. Ce nombre ne peut donc pas dépasser . Ainsi, on a .   "
},
{
  "id": "thm-delamatriceinversev2",
  "level": "2",
  "url": "sec-SELtheo.html#thm-delamatriceinversev2",
  "type": "Théorème",
  "number": "3.2.13",
  "title": "Théorème de la matrice inverse, seconde version.",
  "body": " Théorème de la matrice inverse, seconde version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots.     L'équivalence des énoncés un et deux provient de la première version du théorème. L'énoncé trois et l'énoncé quatre sont équivalents, par définition du rang . Il faut donc montrer que l'un des deux premiers énoncés implique que le rang soit égal à et qu'avoir un rang de implique un des deux premiers énoncés.  On commence par prendre une matrice inversible. Soit , son inverse et , ses colonnes. Si l'on note le vecteur dont toutes les entrées sont nulles sauf celle en position qui vaut , alors, selon la définition de la matrice inverse et de la multiplication, on a . Puisque l'inverse d'une matrice est unique, c'est aussi la seule solution. On note la matrice augmentée de l'identité. La forme échelonnée réduite de cette matrice augmentée correspond aux solutions des systèmes d'équations linéaires . Ces solutions sont les (uniques) colonnes de , ce qui signifie que . Cela signifie donc que et donc, .  On suppose maintenant que . Ceci signifie que chaque colonne est pivot et de même, chaque ligne, car la matrice est carrée. On a donc . Soit , un vecteur de . Le système se résout en échelonnant la matrice augmentée , ce qui donne , où est obtenu de à partir des opérations élémentaires effectuées pour échelonner . Comme toutes les variables sont pivots, il n'y a qu'une solution. Cela montre que le rang égal à implique le second énoncé.   "
},
{
  "id": "corollary-1",
  "level": "2",
  "url": "sec-SELtheo.html#corollary-1",
  "type": "Corollaire",
  "number": "3.2.14",
  "title": "La forme échelonnée réduite d’une matrice carrée inversible.",
  "body": " La forme échelonnée réduite d'une matrice carrée inversible   Soit , une matrice carrée inversible. Alors .   La preuve a été faite dans la démonstration du théorème , dans la deuxième partie.  "
},
{
  "id": "computation-22",
  "level": "2",
  "url": "sec-SELtheo.html#computation-22",
  "type": "Calcul",
  "number": "3.2.15",
  "title": "Le rang et Sage.",
  "body": " Le rang et Sage  Sage possède la commande rank qui permet de calculer le rang d'une matrice. Elle s'utilise soit comme rank(A) , soit A.rank() .   "
},
{
  "id": "exo-4eq3inc",
  "level": "2",
  "url": "sec-SELtheo.html#exo-4eq3inc",
  "type": "Exercice",
  "number": "3.2.3.1",
  "title": "",
  "body": "Reprendre le système de l'exemple et effectuer l'échelonnage. On commence par la matrice du système et l'on effectue l'échelonnage. La matrice augmentée du système une fois échelonnée donne donc: . "
},
{
  "id": "exercise-143",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-143",
  "type": "Exercice",
  "number": "3.2.3.2",
  "title": "",
  "body": "On considère les quatre systèmes d'équations linéaires suivants:  ,  ,  ,  .    Dans chaque cas, donner toutes les valeurs de telles que  Les SEL n'ont pas de solution;  et  et  et   Pour déterminer les valeurs de et de ne permettant d'avoir aucune solution, il faut échelonner les matrices de ces systèmes et bien interpréter les résultats. On se rappelle, par l'algorithme , qu'un pivot dans la partie augmentée de la matrice échelonnée réduite indique l'absence de solution.  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que et que .  On donne la matrice augmentée associée et on l'échelonne: Pour avoir un pivot dans la partie augmentée, il faut que .  Les SEL ont une infinité de solutions.  et  et  et   Pour déterminer les valeurs de et de permettant d'avoir une infinité de solutions, il faut échelonner les matrices de ces systèmes et bien interpréter les résultats. On ne refera pas l'échelonnage, car il a déjà été fait pour trouver les situations sans solutions. On se rappelle, par l'algorithme , qu'une absence de pivot dans la partie augmentée ainsi que la présence d'une variable libre impliquera l'infinité de solutions. Puisque les SEL de cet exercice ont tous deux équations et deux variables, il faut donc absolument que la seconde ligne comporte uniquement des zéros une fois échelonnée.  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que et que .  Pour avoir la deuxième ligne seulement constituée de zéros, il faut que .  "
},
{
  "id": "exercise-144",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-144",
  "type": "Exercice",
  "number": "3.2.3.3",
  "title": "",
  "body": "Considérer à nouveau la matrice de l'exercice . Quelle devrait être la valeur de pour que le rang de la matrice soit égal à ? Dans ce cas-ci, est-ce que le système possède une solution, une infinité de solutions ou ne possède aucune solution? et aucune solution On recommence l'algorithme de Gauss-Jordan et l'on verra quelle valeur de cela prendra pour que la matrice soit de rang . Pour que la matrice soit de rang , il faut absolument éliminer une ligne entière. En observant que les valeurs de la troisième colonne sont les mêmes dans les deuxième et troisième lignes, on réalise que le seul moyen qu'une de ces deux lignes s'élimine est que les valeurs de la deuxième colonne correspondent aussi. Bref, il faut que . On observe que la matrice est de rang , mais qu'il y a un pivot additionnel dans la partie augmentée. Cela signifie qu'il n'y a aucune solution. "
},
{
  "id": "exercise-145",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-145",
  "type": "Exercice",
  "number": "3.2.3.4",
  "title": "",
  "body": "Considérer maintenant la matrice . Quelle devrait être la valeur de pour que le rang de la matrice soit égal à ? Dans ce cas-ci, est-ce que le système possède une solution, une infinité de solutions ou ne possède aucune solution? et infinité de solutions On commence l'algorithme de Gauss-Jordan et l'on verra quelle valeur de cela prendra pour que la matrice soit de rang . Pour que la matrice soit de rang , il faut absolument éliminer une ligne entière. Il est clair que la deuxième ligne s'éliminera uniquement si . On observe que la matrice est de rang et qu'il n'y a pas de pivot additionnel dans la partie augmentée. Cela signifie qu'il y a une infinité de solutions. "
},
{
  "id": "exercise-146",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-146",
  "type": "Exercice",
  "number": "3.2.3.5",
  "title": "",
  "body": " Pour chaque matrice échelonnée réduite ci-dessous, donner l'ensemble solution. De plus, lorsque possible, déterminer une solution pour laquelle la variable est égale à .   et   La seule ligne non nulle se résume à l'équation . La variable est libre puisqu'il n'y a pas de pivot dans la première colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière: .   et il est impossible de donner une solution telle que .   La seule ligne non nulle se résume à l'équation . La variable est libre puisqu'il n'y a pas de pivot dans la deuxième colonne. On écrit donc: . L'ensemble solution est donc: . La valeur de la variable étant déjà fixée par le système, il est impossible de donner une solution telle que .     et   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Ainsi, la solution particulière donne: .      et   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la première colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière: .     et il est impossible de donner une solution telle que .   Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . La valeur de la variable étant déjà fixée par le système, il est impossible de donner une solution telle que .     et   Les deux seules lignes se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Ainsi, la solution particulière donne: .   et   Les deux lignes non nulles se résument aux équations et . Les variables et sont libres puisqu'il n'y a pas de pivot dans les troisième et quatrième colonnes. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Il existe une infinité de valeurs de et qui pourraient fonctionner. On choisit des valeurs entières pour simplifier les calculs. Ainsi, en posant et , la solution particulière donne: .   et .   Les deux lignes non nulles se résument aux équations et . Les variables et sont libres puisqu'il n'y a pas de pivot dans les deuxième et quatrième colonnes. On écrit donc: . L'ensemble solution est donc: . En posant , on obtient une solution particulière pour laquelle il faut travailler un peu. On observe, à partir de l'équation correspondant à la variable , que . Il existe quand même une infinité de solutions puisque la variable n'est pas fixée. On pose donc et la solution particulière est: .  Aucune solution n'existe. Puisque la matrice échelonnée réduite a un pivot dans sa partie augmentée, il n'existe aucune solution à ce système. "
},
{
  "id": "exercise-147",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-147",
  "type": "Exercice",
  "number": "3.2.3.6",
  "title": "",
  "body": " Trouver si possible l'intersection des plans suivants :   ;  L'intersection de ces plans est la droite d'équation: . Les équations normales de ces deux plans constituent un SEL à deux équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Les deux lignes se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . On reconnait dans cette solution l'équation d'une droite. Ainsi, l'intersection des deux plans et est une droite d'équation vectorielle: .  ;  L'intersection de ces trois plans n'existe pas. Ils sont donc sécants deux à deux, mais pas tous les trois. Les équations normales de ces trois plans constituent un SEL à trois équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Noter qu'on aurait pu procéder différemment pour l'échelonnage, mais qu'on voulait profiter des étapes d'échelonnage déjà effectuées précédemment dans l'étude de l'intersection des plans et . La matrice échelonnée réduite possédant un pivot dans sa partie augmentée. Il n'y a donc aucune solution. Les trois plans sont donc sécants deux à deux, mais pas tous les trois.  .  L'intersection de ces trois plans est la droite d'équation: . Les équations normales de ces trois plans constituent un SEL à trois équations et trois inconnues. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Les deux lignes non nulles se résument aux équations et . La variable est libre puisqu'il n'y a pas de pivot dans la troisième colonne. On écrit donc: . L'ensemble solution est donc: . On reconnait dans cette solution l'équation d'une droite. Ainsi, l'intersection des trois plans et est une droite d'équation vectorielle: . "
},
{
  "id": "exercise-148",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-148",
  "type": "Exercice",
  "number": "3.2.3.7",
  "title": "",
  "body": " Trouver l'intersection des droites suivantes, si possible.  La droite   et la droite L'intersection de ces droites est le point : . Les équations vectorielles de ces deux droites cachent un système à trois équations et deux inconnues. En effet, en comparant le membre de droite de chacune, et en écrivant les équations séparément pour chaque variable, on obtiendra un système qu'on écrit de la façon standard . On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Attention, les inconnues sont et , plutôt que les variables habituelles. Les deux lignes se résument aux équations et . En remplaçant dans l'une ou l'autre des équations vectorielles initiales, on obtient le point: Ainsi, l'intersection des deux droites et est un point. La droite   et la droite L'intersection de ces droites est le point : . Les équations vectorielles de ces deux droites cachent un système à trois équations et deux inconnues. En effet, en comparant le membre de droite de chacune, et en écrivant les équations séparément pour chaque variable, on obtiendra un système qu'on écrit de la façon standard. On construit la matrice augmentée du système et on l'échelonne pour pouvoir déterminer la ou les solutions, s'il y a lieu. Attention, les inconnues sont et , plutôt que les variables habituelles. Les deux lignes se résument aux équations et . En remplaçant dans l'une ou l'autre des équations vectorielles initiales, on obtient le point: Ainsi, l'intersection des deux droites et est un point. "
},
{
  "id": "exercise-149",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-149",
  "type": "Exercice",
  "number": "3.2.3.8",
  "title": "",
  "body": " Des solutions à un système d'équations linéaires où est une matrice non nulle sont données ci-dessous. Donner toutes les formes augmentées de matrices échelonnées réduites équivalentes à .  Les solutions sont .   A.solve_right(b) pour résoudre un SEL et A.pivots() pour avoir la position des colonnes pivots reconstruire le système à partir de la solution. Pour avoir une variable libre, on doit avoir une ligne de zéros (la deuxième ligne, pour respecter les conditions d'une matrice échelonnée réduite ). La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Pour avoir une variable libre, on doit avoir une ligne de zéros (la deuxième ligne, pour respecter les conditions d'une matrice échelonnée réduite ). La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Ici, on fait face à une difficulté supplémentaire du fait qu'aucune des variables ne pourra être simplement égale à la variable libre. Cela est dû au fait qu'une équation vectorielle peut avoir n'importe quel point sur l'objet comme point de départ. On doit donc trouver un point sur la droite où la coordonnée en est égale à .  On peut réécrire l'équation de départ ainsi: . La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . Les solutions sont .   On doit essentiellement reconstruire le système à partir de la solution. Ici, on fait face à une difficulté supplémentaire du fait qu'aucune des variables ne pourra être simplement égale à la variable libre. Cela est dû au fait qu'une équation vectorielle peut avoir n'importe quel point sur l'objet comme point de départ. On doit donc trouver un point sur la droite où la coordonnée en est égale à .  On peut réécrire l'équation de départ ainsi: . La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: .  Les points et sont des solutions.    On doit d'abord créer la droite passant par ces deux points. Il existe une infinité de vecteurs directeurs valables (pourvu qu'ils soient tous parallèles) et de points de départ (pourvu qu'ils soient sur la droite). Par contre, la manière la plus évidente est de prendre un des points donnés et le vecteur les reliant. On a appris, des lettres précédentes, qu'on veut un vecteur avec une composante égale à et idéalement un point de départ où cette même variable aura un . et Ainsi, La première ligne sera donc constituée pour communiquer l'information que . Cela donne une matrice qui n'est pas échelonnée réduite, on fait alors l'opération nécessaire: . L'unique bonne réponse est donc: .  Les points et sont des solutions.    On doit d'abord créer la droite passant par ces deux points. Il existe une infinité de vecteurs directeurs valables (pourvu qu'ils soient tous parallèles) et de points de départ (pourvu qu'ils soient sur la droite). Par contre, la manière la plus évidente est de prendre un des points donnés et le vecteur les reliant. On a appris, des lettres précédentes, qu'on veut un vecteur avec une composante égale à et idéalement un point de départ où cette même variable aura un . et Ainsi, La première ligne sera donc constituée pour communiquer l'information que . L'unique bonne réponse est donc: . "
},
{
  "id": "exercise-150",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-150",
  "type": "Exercice",
  "number": "3.2.3.9",
  "title": "",
  "body": " Donner le rang des matrices suivantes.     On doit échelonner la matrice et donner le nombre de pivots. La matrice est donc de rang , puisque sa forme échelonnée réduite possède deux pivots.   On doit échelonner la matrice et donner le nombre de variables pivots, selon la définition . La matrice est donc de rang , puisque sa forme échelonnée réduite possède un seul pivot.   On doit échelonner la matrice et donner le nombre de pivots. La matrice est donc de rang , puisque sa forme échelonnée réduite possède deux pivots. La matrice , représentant une rotation de degrés dans . Plutôt que d'échelonner la matrice de rotation comportant une variable, on choisit de se servir du théorème de la matrice inverse . Ce dernier spécifie que, si une matrice carrée est inversible, alors elle est de rang maximal. Or, on a appris dans la section que les rotations sont des transformations linéaires inversibles. On avait même trouvé que . Ainsi, cette matrice est de rang maximal donc .  La matrice d'une réflexion quelconque dans .  On n'a pas développé de forme générale pour une réflexion quelconque dans , on ne peut donc pas échelonner la matrice . On choisit donc de se servir encore du théorème de la matrice inverse . Ce dernier spécifie que, si une matrice carrée est inversible, alors elle est de rang maximal. Or, on a appris que les réflexions sont des transformations linéaires inversibles. On avait trouvé que , peu importe l'axe de réflexion. Ainsi, cette matrice est de rang maximal donc . La matrice qui envoie tout vecteur sur le vecteur . On pourrait déduire le rang en réfléchissant au fait qu'on perd une dimension dans ce genre de projection. Cependant, on peut facilement construire cette matrice en se souvenant du fait que les colonnes d'une matrice de transformation linéaire correspondent aux images des vecteurs de la base canonique sous cette transformation tel qu'utilisé, entre autres, dans l'exemple . Puisque , on remarque que: . La matrice est donc qui est déjà échelonnée et de rang . La matrice qui envoie tout vecteur sur le vecteur . On pourrait déduire le rang en réfléchissant au fait qu'on perd deux dimensions dans ce genre de projection. Cependant, on peut facilement construire cette matrice en se souvenant du fait que les colonnes d'une matrice de transformation linéaire correspondent aux images des vecteurs de la base canonique sous cette transformation tel qu'utilisé, entre autres, dans l'exemple . Puisque , on remarque que: . La matrice est donc qui, une fois échelonnée, est clairement de rang . "
},
{
  "id": "exo-rangechelon",
  "level": "2",
  "url": "sec-SELtheo.html#exo-rangechelon",
  "type": "Exercice",
  "number": "3.2.3.10",
  "title": "",
  "body": "Pour chaque énoncé, donner au moins deux matrices échelonnées réduites qui satisfont l'énoncé. S'il n'y en a pas deux, expliquer pourquoi, et s'il y en a plus de deux, déterminer combien. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type ayant la forme . On en donne deux. La matrice correspond aussi aux critères, mais a une forme différente des autres. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . La seule réponse valable est la matrice identité: . Toute matrice carrée de rang maximal est inversible et l'on peut donc faire des opérations élémentaires et arriver à la matrice identité (voir l'exercice ). Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme ou de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme . On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice identité: . Toute matrice carrée de rang maximal est inversible et l'on peut donc faire des opérations élémentaires et arriver à la matrice identité (voir l'exercice ). Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . La seule matrice possible est . Toute autre forme pourrait être ramenée à celle-ci en utilisant une des trois opérations élémentaires. Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. En effet, pour avoir un rang de , il doit y avoir trois pivots. Les pivots correspondant aux colonnes, il est impossible d'y arriver avec seulement deux colonnes. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme ou de la forme On en donne deux. La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . La seule réponse valable est la matrice nulle: . Il est impossible de n'avoir aucun pivot s'il y a des valeurs non nulles. Les matrices sont de rang et de taille . Il existe une infinité de matrices de ce type de la forme . On en donne deux. . Il y a aussi les matrices de la forme pour n'importe quelle valeur réelle de . La matrice correspond aussi aux critères, mais est la seule de cette forme. Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. En effet, pour avoir un rang de , il doit y avoir trois pivots. Les pivots devant être sur des lignes différentes, il doit y en avoir trois pour y arriver. "
},
{
  "id": "exercise-152",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-152",
  "type": "Exercice",
  "number": "3.2.3.11",
  "title": "",
  "body": "Refaire l'exercice , cette fois sans que les réponses soient des matrices échelonnées réduites. Nul besoin de redonner les explications, qui seront les mêmes. Les matrices sont de rang et de taille . Essentiellement, on reprend toutes nos réponses de l'exercice et l'on donne une matrice non échelonnée correspondante. On rappelle que, pour qu'une ligne non nulle devienne nulle lorsqu'échelonnée, il faut qu'elle soit multiple d'une autre ligne ou, plus généralement, combinaison linéaire des autres lignes. Il existe bien entendu une infinité de réponses possibles.  Les matrices sont de rang et de taille . Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .   Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. Les matrices sont de rang et de taille . Les matrices sont de rang et de taille .  Les matrices sont de rang et de taille . Les matrices sont de rang et de taille . Aucune matrice ne répond à ces critères. "
},
{
  "id": "exercise-153",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-153",
  "type": "Exercice",
  "number": "3.2.3.12",
  "title": "",
  "body": " Remplacer tous les de la matrice par des entiers non nuls afin que la matrice soit  de rang ; Pour être de rang , il faut que la dernière ligne soit complètement remplacée par des zéros lorsqu'on fera l'échelonnage. En effet, les deux premières lignes n'étant pas multiples l'une de l'autre, on aura deux pivots. Une façon simple d'y arriver est de donner une ligne qui est égale à une des deux autres ou même à l'un de leur multiple. On peut aussi y arriver si la ligne choisie est une combinaison linéaire des deux autres. On y va simplement. Cette matrice échelonnée réduite a deux pivots. Elle est donc de rang . équivalente à la matrice identité. Pour être équivalente à la matrice identité, il faut qu'elle soit de rang et donc de rang maximal. Pour être de rang , il faut que les trois lignes ne soient pas combinables pour être éliminées entièrement. Ce concept se nomme indépendance linéaire et sera élaboré plus en détail à la section . Cette matrice échelonnée réduite est la matrice identité. La matrice initiale lui est donc équivalente. "
},
{
  "id": "exo-rangcomblin",
  "level": "2",
  "url": "sec-SELtheo.html#exo-rangcomblin",
  "type": "Exercice",
  "number": "3.2.3.13",
  "title": "",
  "body": " Soit , une matrice carrée d'ordre .  On s'intéresse aux lignes de la matrice Si possède deux lignes identiques, montrer que le rang de n'est pas maximal. On se contente d'une preuve en mots puisque l'on ne gagnera rien en clarté si l'on écrit des matrices arbitraires au long. On rappelle quand même la définition du rang , la remarque par rapport aux lignes ainsi que la proposition sur le rang maximal.  Si la matrice possède deux lignes identiques (disons et ), alors, par la seule opération élémentaire visant à éliminer le premier élément ( ), on éliminera toute la ligne. Une matrice ayant une ligne de zéros ne peut avoir de pivots sur cette ligne. Elle ne peut donc pas avoir pivots puisqu'on n'a jamais plus qu'un pivot par ligne. Si possède deux lignes parallèles, montrer que le rang de n'est pas maximal. Si l'on a deux lignes parallèles, alors la preuve est exactement la même que précédemment, mais on utilise l'opération où est le facteur de parallélisme. La ligne entière deviendra nulle et la preuve se fait de façon identique. Si possède une ligne qui soit une combinaison linéaire des autres lignes, montrer que le rang de n'est pas maximal. Si possède une ligne (disons ) qui est une combinaison linéaire des autres lignes (disons ), alors, on peut écrire: On utilise ensuite les opérations élémentaires successives suivantes: Au bout de ce processus, on aura inévitablement une ligne de zéros là où était . Le reste de la preuve est identique. Refaire les questions précédentes en remplaçant ligne par colonne dans chaque énoncé. Si possède deux colonnes identiques, montrer que le rang de n'est pas maximal. On se contente d'une preuve en mots puisque l'on ne gagnera rien clarté si l'on écrit des matrices arbitraires au long. On rappelle quand même la définition du rang , la remarque par rapport aux lignes ainsi que la proposition sur le rang maximal.  Si la matrice possède deux colonnes identiques, alors, lorsqu'on fera des opérations élémentaires visant à obtenir un pivot dans la première des deux colonnes et des zéros en haut et en bas, l'effet de ces opérations sera le même sur les éléments de la deuxième colonne. On se retrouvera donc avec deux colonnes identiques avec un pivot dans la première, mais pas de pivot dans la seconde. Dans ce cas, on ne peut avoir le rang maximal puisqu'on va manquer de colonnes. Si possède deux colonnes parallèles, montrer que le rang de n'est pas maximal. Les opérations que l'on fait pour obtenir un pivot dans la première colonne et des zéros en haut et en bas du pivot amèneront également une seule valeur non nulle dans la deuxième colonne. Il est donc impossible d'avoir un pivot sur cette seconde colonne. Si possède une colonne qui est une combinaison linéaire des autres colonnes , montrer que le rang de n'est pas maximal. La solution suivra. Déduire des énoncés précédents la troisième version du théorème de la matrice inverse.   Théorème de la matrice inverse, troisième version  Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .  Le rang de la matrice est égal à .  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité.  Aucune ligne n'est une combinaison linéaire des autres lignes.  Aucune colonne n'est une combinaison linéaire des autres colonnes.    Il n'y a rien à ajouter. On a démontré les deux points additionnels dans cette version du théorème. "
},
{
  "id": "exercise-155",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-155",
  "type": "Exercice",
  "number": "3.2.3.14",
  "title": "",
  "body": "Montrer, en trouvant son inverse, qu'une matrice carrée de rang est inversible. Ceci constitue une preuve alternative du fait que rang implique inverse fait au théorème .  L'inverse est .   On se souvient, par la définition du rang , qu'une matrice carrée de rang , et donc de rang maximal, a pivots. Cela signifie que sa forme échelonnée réduite est l'identité. Ainsi, il est possible de trouver des matrices élémentaires inversibles telles que la matrice peut être échelonnée jusqu'à donner l'identité. On a donc: . Cela implique que la matrice inverse de est la multiplication des matrices élémentaires:   "
},
{
  "id": "exo-vectranspose",
  "level": "2",
  "url": "sec-SELtheo.html#exo-vectranspose",
  "type": "Exercice",
  "number": "3.2.3.15",
  "title": "",
  "body": "Dans cet exercice, on considère un vecteur comme une matrice ayant une seule colonne. Une matrice ayant une seule ligne est, quant à elle, notée Le en exposant est lié avec la notion de transposée, qui sera définie plus loin. , où est le vecteur représentant la ligne. Considérer la matrice et la matrice . Quel est le rang des matrices et ? et Comparer les produits et . Quelle autre opération le produit représente-t-il? On calcule les produits: et . Le premier résultat est donc une matrice et le deuxième une matrice  . On comprend que le deuxième résultat a beau être entre parenthèses, une matrice qui ne possède qu'une ligne et une colonne est en réalité un nombre, souvent appelé un scalaire. Cette opération correspond donc au produit scalaire. Quel est le rang des matrices et ? et Le rang de est de , puisque c'est un nombre non nul qui est, par le fait même, un pivot. Le rang de s'obtiendra de diverses façons (échelonner ou bien utiliser le théorème de la matrice inverse ). On voit immédiatement que la matrice a deux lignes (ou colonnes) parallèles. Par le théorème, elle n'est donc pas de rang maximal. Elle est de rang . Utiliser Sage pour vérifier le rang de pour différents vecteurs de .    Le code solution pour les vecteurs initiaux   u=matrix([[2],[1]]) vT=matrix([[3,4]]) uvT=u*vT show(uvT) show(rank(uvT))    On remarque qu'il suffit de remplacer les vecteurs initiaux par d'autres vecteurs pour tester. On laisse les observations à l'élève.  Si sont n'importe quel vecteur non nul de , quel est le rang du produit ? Le rang est toujours de . Si sont n'importe quel vecteur non nul de , quel est le rang du produit ? Le rang est toujours de . "
},
{
  "id": "exo-rangproduit1",
  "level": "2",
  "url": "sec-SELtheo.html#exo-rangproduit1",
  "type": "Exercice",
  "number": "3.2.3.16",
  "title": "",
  "body": " Cet exercice s'intéresse au rang du produit d'une matrice par rapport aux rangs des matrices composant le produit. La section donnera la signification du rang dans le contexte des transformations linéaires.  Considérer les matrices . Quel est le rang des matrices et ? , et On se sert chaque fois du théorème de la matrice inverse plutôt que d'échelonner et de compter le nombre de pivots. On a que , puisque la deuxième ligne est le double de la première (parallèles et donc une combinaison linéaire de la première ligne). On peut écrire .  On a que , puisque les lignes ne sont pas parallèles et donc pas combinaison linéaire.  Finalement, on a que , puisque la deuxième ligne est un multiple de la première (parallèles et donc combinaison linéaire de la première ligne). On peut écrire . Quel est le rang des matrices et ? et Calculons d'abord les produits demandés. et Les rangs de ces deux matrices sont de puisque, dans les deux cas, la deuxième ligne est multiple de la première. En effet, tant pour que pour , on a . Dans l'exercice , on montrera un cas plus général du fait suivant: Si est de rang , alors il existe deux vecteurs tels que . On utilise ce fait dans cet exercice. Soit et , deux matrices de rang . Montrer que . On a pu mettre en évidence du produit matriciel le produit scalaire, puisque son résultat est un scalaire. Si aucun des vecteurs ne peut être nul, quelle est la condition pour que ? Il faut que le produit scalaire soit nul et donc que les vecteurs et soient orthogonaux. De cette façon, le produit donnera la matrice nulle qui est la seule matrice de rang . Montrer que, si la colonne de la matrice est une combinaison linéaire des colonnes précédentes de la matrice , alors la colonne de la matrice est la même combinaison linéaire des colonnes précédentes de .  Ceci implique que la matrice ne peut pas avoir plus de colonnes pivots que la matrice . On écrit d'abord la colonne comme une combinaison linéaire des colonnes précédentes: . On écrit ensuite le produit suivant la définition : La colonne de la matrice est donc la même combinaison linéaire des colonnes à de . Conclure que . L'exercice viendra compléter ce résultat pour avoir . C'est une conséquence directe de ce qu'on vient de montrer et des preuves de l'exercice .  "
},
{
  "id": "exercise-158",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-158",
  "type": "Exercice",
  "number": "3.2.3.17",
  "title": "",
  "body": " Considérer la matrice ci-dessous où est un nombre réel quelconque .  Si possible, compléter la matrice pour qu'elle soit de   rang ;  Une matrice de rang possède des lignes qui sont toutes multiples les unes des autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros aux deux lignes du bas, et donc un seul pivot. Un exemple de réponse, obtenue en remplissant les valeurs pour que toutes les lignes soient parallèles est: . La matrice échelonnée donne: qui n'a qu'un seul pivot.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent éliminer complètement une des trois lignes. Cela peut se faire en ayant deux lignes parallèles (notre approche) ou en ayant une ligne qui soit une combinaison linéaire des deux autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros à la ligne du bas et des pivots aux deux autres lignes. Le second pivot peut se retrouver dans la deuxième ou la troisième colonne. Un exemple de réponse est: . La matrice échelonnée est et possède deux pivots.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent ne jamais pouvoir s'éliminer complètement. Pour ce faire, il faut qu'aucune des lignes ne soit une combinaison linéaire des autres lignes. On verra plus loin à la section que ce que l'on veut c'est que ces lignes soient linéairement indépendantes. Les opérations élémentaires vont nécessairement amener l'échelonnage à la matrice identité. Cependant, il peut être difficile de voir quelles valeurs on doit avoir pour que ce soit le cas. Un exemple de réponse est: . La matrice échelonnée est et possède trois pivots. "
},
{
  "id": "exercise-159",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-159",
  "type": "Exercice",
  "number": "3.2.3.18",
  "title": "",
  "body": " Considérer la matrice ci-dessous où est un nombre réel quelconque .  Si possible, compléter la matrice pour qu'elle soit de   rang ;  C'est impossible. Il est impossible d'obtenir un seul pivot puisque les deux premières lignes ne seront jamais parallèles, peu importe ce qu'on pose à l'emplacement de l'étoile.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent éliminer complètement une des trois lignes. Cela peut se faire en ayant deux lignes parallèles (notre approche) ou en ayant une ligne qui soit combinaison linéaire des deux autres. Ainsi, lorsqu'on échelonne, on obtiendra des zéros à la ligne du bas et des pivots aux deux autres lignes. Le second pivot peut se retrouver dans la deuxième ou la troisième colonne. Un exemple de réponse est: . La matrice échelonnée est et possède deux pivots.  rang ;  Une matrice de rang possède des lignes qui, lorsqu'on utilise des opérations élémentaires, doivent ne jamais pouvoir s'éliminer complètement. Pour ce faire, il faut qu'aucune des lignes ne soit une combinaison linéaire des autres lignes. On verra plus loin à la section que ce que l'on veut, c'est que ces lignes soient linéairement indépendantes. Les opérations élémentaires vont nécessairement ramener la matrice à la matrice identité. Cependant, il peut être difficile de voir quelles valeurs on doit poser pour que ce soit le cas. Un exemple de réponse est: . La matrice échelonnée est qui possède trois pivots. "
},
{
  "id": "exercise-160",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-160",
  "type": "Exercice",
  "number": "3.2.3.19",
  "title": "",
  "body": " Dans cet exercice, on cherche à préciser davantage le nombre de solutions possibles qu'une équation matricielle peut avoir en fonction de son rang et de ses dimensions.  Donner, si possible, des exemples de matrices échelonnées réduites augmentées d'un vecteur qui satisfont les conditions suivantes. La matrice est carrée et le système possède: Une solution unique; Aucune solution; Une infinité de solutions. La matrice est , de rang et le système possède: Une solution unique; Impossible. Il y aura nécessairement des variables libres. Aucune solution; Impossible. On ne peut avoir de pivot supplémentaire dans la partie augmentée puisqu'il n'y a que trois lignes et la matrice étant déjà de rang , on ne peut avoir un ou des lignes de zéros. Une infinité de solutions. La matrice est , de rang et le système possède: Une solution unique; Aucune solution; Une infinité de solutions. Impossible. Si la matrice n'a que colonnes et qu'elle doit être de rang , il ne reste pas d'espace pour une colonne sans pivot et donc il est impossible d'avoir une variable libre. La matrice est , de rang et le système possède: Une solution unique; Impossible. Il y aura nécessairement des variables libres. Aucune solution; Une infinité de solutions. Soit , une matrice de rang . Déterminer et expliquer le nombre de solutions possibles au système selon les conditions suivantes. On a et , c'est-à-dire une matrice carrée et inversible . Il y aura toujours une solution unique puisque la matrice a pivots et donc aucune variable libre. Le vecteur étant de dimension , il n'y a pas d'espace pour un pivot additionnel dans la partie augmentée. On peut même isoler la solution puisque la matrice est inversible: On a et , c'est-à-dire une matrice « large ». Puisque l'on a plus de colonnes que de lignes, on a de l'espace pour des colonnes sans pivot. Cela veut dire qu'on aura une infinité de solutions, s'il y en a. De même, le vecteur étant de dimension , il n'y a pas d'espace pour un pivot additionnel dans la partie augmentée. On aura donc toujours une infinité de solutions. On a et , c'est-à-dire une « grande » matrice . Puisque l'on a plus de lignes que de colonnes, mais que , chaque colonne contient un pivot. Il n'y a donc pas de variable libre. Par contre, il est possible d'avoir un pivot additionnel dans la partie augmentée, ce qui mènerait à n'avoir aucune solution. Sinon, il y aura une solution unique. On a et , c'est-à-dire une matrice qui n'est pas de rang maximal pour sa taille. Dans ce cas, il va obligatoirement y avoir au moins une variable libre, puisque . Cela mène donc à une infinité de solutions. Cependant, s'il y a un pivot additionnel dans la partie augmentée, ce qui est possible, puisque , on n'aura aucune solution. "
},
{
  "id": "exercise-161",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-161",
  "type": "Exercice",
  "number": "3.2.3.20",
  "title": "",
  "body": "Soit , une matrice quelconque et m un vecteur tel que le système est compatible. De plus, soit , une matrice de format approprié telle que . Montrer que est une solution à l'équation . Une telle matrice est souvent appelée un inverse généralisé de la matrice . Si a des solutions, poser une de ces solutions. On a donc . On démontre que est une solution en remplaçant dans le membre de gauche de l'équation et en montrant que c'est bien égal à . "
},
{
  "id": "exercise-162",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-162",
  "type": "Exercice",
  "number": "3.2.3.21",
  "title": "",
  "body": "Résoudre les systèmes d'équations suivants.    On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[5,-3,2,7],[3,0,3,-1],[6,2,1,-2],[2,-1,-6,8],[8,-1,0,6]]) b=vector([-3,2,0,-9,-5]) show((A.augment(b,subdivide=True))) #Pour vérifier qu'on a le bon système show((A.augment(b,subdivide=True)).rref())    On interprète cette solution ainsi:      Il n'y a aucune solution à ce système. On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[2,-4,-1,3],[1,0,4,1],[1,2,-4,-1],[0,1,7,4],[4,-1,0,7]]) b=vector([-1,-12,5,4,-1]) show((A.augment(b,subdivide=True))) show((A.augment(b,subdivide=True)).rref())    Il n'y a donc aucune solution à ce système, puisqu'il y a un pivot dans la partie augmentée.    On utilise la méthode plus prudente avec la matrice échelonnée réduite du système augmenté. Sinon, on risque d'obtenir une solution unique même s'il y a une infinité de solutions.   Le code solution   A=matrix([[3,-5,0,3,-1],[-2,3,-1,4,0],[-3,0,5,1,2]]) b=vector([7,-1,-3]) show((A.augment(b,subdivide=True))) show((A.augment(b,subdivide=True)).rref())    On interprète cette solution ainsi:   "
},
{
  "id": "exercise-163",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-163",
  "type": "Exercice",
  "number": "3.2.3.22",
  "title": "",
  "body": "Utiliser la commande rank et la proposition pour déterminer si les systèmes de l'exercice précédent sont compatibles. On sait déjà que des trois systèmes de l'exercice précédent, seul le deuxième est incompatible. On le montrera en calculant le rang de la matrice et le rang de la matrice augmentée. Si ces rangs sont égaux, le système est compatible.   Le code solution pour la lettre (a)   A=matrix([[5,-3,2,7],[3,0,3,-1],[6,2,1,-2],[2,-1,-6,8],[8,-1,0,6]]) b=vector([-3,2,0,-9,-5]) show(rank(A)==rank(A.augment(b,subdivide=True))) #si l'on obtient True, cela veut dire que les rangs sont égaux et donc le système est compatible     Le code solution pour la lettre (b)   A=matrix([[2,-4,-1,3],[1,0,4,1],[1,2,-4,-1],[0,1,7,4],[4,-1,0,7]]) b=vector([-1,-12,5,4,-1]) show(rank(A)==rank(A.augment(b,subdivide=True)))     Le code solution pour la lettre (c)   A=matrix([[3,-5,0,3,-1],[-2,3,-1,4,0],[-3,0,5,1,2]]) b=vector([7,-1,-3]) show(rank(A)==rank(A.augment(b,subdivide=True)))    "
},
{
  "id": "exercise-164",
  "level": "2",
  "url": "sec-SELtheo.html#exercise-164",
  "type": "Exercice",
  "number": "3.2.3.23",
  "title": "Les coniques.",
  "body": "Les coniques Les paraboles font partie d'une famille plus générale de courbes appelées les coniques. Les coniques tirent d'ailleurs leur nom du fait qu'elles peuvent être obtenues par l'intersection d'un cône avec un plan. L'équation cartésienne d'une conique est , avec qui ne sont pas tous nuls. Avec cinq points sur une conique, il est possible de déterminer une équation cartésienne. Cet exercice vise à explorer la recherche d'une équation de coniques par la résolution de systèmes d'équations linéaires appropriés. Cinq points dont aucun triplet n'est sur une ligne déterminent une unique conique. Toutefois, les systèmes d'équations utilisés ci-dessous auront une infinité de solutions. Pourquoi? Si l'on prend l'équation , on peut la multiplier par n'importe quelle constante et obtenir une équation décrivant la même conique.  Chacun des ensembles de points suivants est sur une conique d'équation . En utilisant un système d'équations linéaires, déterminer l'équation de chaque conique. Tracer celle-ci, ainsi que les points, sur un même graphique.          Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,0]) P2=vector([0,-1]) P3=vector([-1,0]) P4=vector([1\/3,-2\/3]) P5=vector([-1\/3,(sqrt(3)-1)\/3]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique1=1*x^2+1*x*y+1*y^2+1*x+1*y==0 implicit_plot(conique1,(x,-1,1),(y,-1,1),color=\"blue\")+points(P,color=\"black\",size=30)            Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,2]) P2=vector([2,2]) P3=vector([-2,4]) P4=vector([4,0]) P5=vector([4,4]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique2=-x^2+2*y^2+2*x-8*y+8==0 implicit_plot(conique2,(x,-10,10),(y,-10,10),color=\"blue\")+points(P,color=\"black\",size=30)            Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([0,0]) P2=vector([3*sqrt(3)\/2+9\/2,9\/2*sqrt(3)-3\/2]) P3=vector([sqrt(3)+2,2*sqrt(3)-1]) P4=vector([-1\/2*sqrt(3)+1\/2,1\/2*sqrt(3)+1\/2]) P5=vector([-sqrt(3)+2,2*sqrt(3)+1]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique3=-2\/3*sqrt(3)*x*y + x^2 + 1\/3*y^2 - 2\/3*sqrt(3)*y - 2\/3*x == 0 implicit_plot(conique3,(x,-8,8),(y,-8,8),color=\"blue\")+points(P,color=\"black\",size=30)         Le code solution pour trouver la conique   var(\"a,b,c,d,e,f,x,y\") conique=a*x^2+b*x*y+c*y^2+d*x+e*y+f==0 P1=vector([4,-5]) P2=vector([13,-2]) P3=vector([4,1]) P4=vector([8,3]) P5=vector([8,-7]) P=[P1,P2,P3,P4,P5] eq=[] for p in P: eq.append(conique.substitute(x=p[0],y=p[1])) show(solve(eq,[a,b,c,d,e,f]))    On prend la variable libre égale à pour obtenir la conique . Graphiquement, on obtient l'ellipse suivante.   Le code pour le graphique   conique4=x^2+y^2-16*x+4*y+43==0 implicit_plot(conique4,(x,0,16),(y,-10,4),color=\"blue\")+points(P,color=\"black\",size=30)    "
},
{
  "id": "sec-SELgeo",
  "level": "1",
  "url": "sec-SELgeo.html",
  "type": "Section",
  "number": "3.3",
  "title": "La géométrie des systèmes d’équations linéaires",
  "body": "  La géométrie des systèmes d'équations linéaires    Aller aux exercices de la section.  Dans cette section, on fait le lien entre les systèmes d'équations linéaires et les transformations linéaires. En particulier, on s'intéresse aux zéros de la transformation linéaire , donnés par les solutions au système d'équations et à l'image de la transformation, caractérisée par l'ensemble des vecteurs pour lesquels il existe une solution au système .  Dans cette section, on définit le concept de zéros d'une transformation linéaire, la notion de solutions de base à l'équation et la notion de solution homogène ainsi que la sous-matrice d'une matrice servant à trouver les solutions de base. On s'intéresse aussi à l'image d'une transformation linéaire, à la notion de solution particulière et de solution générale à l'équation .    Les zéros d'une transformation linéaire  On considère une matrice et le système d'équations linéaires . Un tel système est souvent appelé homogène.  En passant Le mot homogène a malheureusement plusieurs significations en mathématiques. Souvent utilisé pour signifier que le membre de droite d'une équation (ou un système) est nul (comme ici), il peut aussi faire référence à une fonction homogène. On ne devrait pas rencontrer d'autres utilisations du mot dans ces notes.  Géométriquement, les solutions à ce système représentent l'ensemble des valeurs du domaine ( ) qui sont envoyées sur le vecteur nul de l'image ( ). Comme on l'a remarqué à la proposition , le vecteur est toujours une solution de ce système. De plus, si la matrice est carrée et inversible, c'est la seule solution .  Dans les autres cas, il peut exister d'autres zéros à la transformation. On pourra les trouver à l'aide de l'algorithme de Gauss-Jordan .   Les zéros de quelques transformations: dynamique  Dans un premier temps, on considère les transformations de l'exemple . Puisque toutes ces transformations sont inversibles sauf la projection orthogonale, on conclut qu'il n'y a que le vecteur nul comme zéro des premières. Pour la projection orthogonale, on peut réfléchir géométriquement. On cherche . Or selon l'équation , un vecteur perpendiculaire à sera projeté sur le vecteur nul. Si , tout vecteur est un zéro de la projection orthogonale.  On regarde maintenant quelques exemples à trois dimensions. On considère les matrices .  La figure interactive suivante permet de visualiser l'image d'un vecteur par chacune des transformations. Les détails algébriques se trouvent dans les solutions ci-dessous.   Les zéros de deux transformations linéaires de l'espace      On utilise Sage pour échelonner la matrice et déterminer les solutions.   Les variables sont pivots et la variable est libre. En isolant les équations de la matrice échelonnée réduite, on trouve . Les vecteurs solutions au système sont donc ceux de la forme . On reconnait l'équation d'une droite dans passant par l'origine et de vecteur directeur .    On utilise Sage pour échelonner la matrice et déterminer les solutions.   La variable est pivot et les variables sont libres. En isolant les équations de la matrice échelonnée réduite, on trouve . Les vecteurs solutions au système sont donc ceux de la forme . On reconnait l'équation d'un plan dans passant par l'origine et de vecteurs directeurs et .    Les zéros d'une transformation linéaire possèdent une propriété particulièrement utile. Celle-ci fait l'objet de la proposition suivante.   Les zéros d'une transformation linéaire sont fermés pour l'addition et la multiplication par un scalaire  Soit , la matrice d'une transformation linéaire, et , des vecteurs tels que . Alors  ,  .    Voir l'exercice .   Si l'on s'attarde aux solutions des systèmes pour les matrices de l'exemple , on peut y détecter une forme particulière des variables libres. Plus spécifiquement, pour l'exemple dont les solutions étaient contenues dans le plan de vecteurs directeurs et , les variables libres étaient et . Ces variables valent respectivement et dans le vecteur et et dans le vecteur . Cette remarque permet d'établir une autre manière de voir les solutions à un système d'équations linéaires .   Les solutions de base à un système   Soit , une matrice quelconque telle que l'équation possède plus d'une solution. On nomme les « solutions de base » les solutions obtenues lorsqu'une seule une des variables libres est égale à et que les autres sont nulles. On verra à la section que l'expression « de base » est reliée à la notion de base d'un espace vectoriel.  Il y a autant de solutions de base que de variables libres. Si la matrice ne possède pas de variables libres, la seule solution à l'équation est le vecteur . Celui-ci n'est pas « spécial ».  L'ensemble de toutes les combinaisons linéaires des solutions de base additionnées du vecteur est appelé la solution homogène . On la note .    Les solutions de base sont un exemple du concept de base d'un espace qui sera défini dans le chapitre . L'ensemble des combinaisons linéaires des solutions de base décrit le lieu « géométrique » où se trouvent tous les zéros d'une transformation linéaire. Suivant le nombre de ces solutions, ce lieu peut être une droite, un plan, un espace tridimensionnel ou un autre espace de dimension supérieure.  Par la nature des opérations élémentaires, toute solution à l'équation doit satisfaire le système équivalent menant à la solution paramétrique des combinaisons linéaires des solutions de base. Ainsi, ces combinaisons génèrent toutes les solutions.  On regarde maintenant des solutions de base de matrices échelonnées réduites.   Solutions de base de matrices échelonnées réduites   On cherche à déterminer les solutions de base pour les matrices suivantes. Les matrices ne sont pas augmentées, car les solutions de base sont toujours obtenues lorsque la partie augmentée est le vecteur nul. L'information additionnelle de la colonne augmentée n'est donc pas utile.          Il n'y a qu'une seule variable libre ici, la troisième. Les équations restantes sont .  Si l'on pose , on obtient la solution de base , la solution homogène est donc pour .   Ici, il y a deux variables libres, la deuxième et la troisième. Les équations restantes sont .  Si l'on pose et , on obtient la première solution de base . Si l'on pose et , on obtient la deuxième solution de base . La solution homogène est pour .    Dans cet exemple, les variables et sont pivots et les variables et sont libres. On écrit les équations de ce système: .  En posant , on obtient la première solution de base . En posant , on obtient la deuxième solution de base . Finalement, en posant , on obtient la troisième et dernière solution de base .  La solution homogène est avec .    Dans cet exemple, toutes les variables sont pivots. Il n'y a donc pas de solution de base. La seule solution à l'équation est le vecteur nul. Donc .    Il ne semble pas pratique de devoir réécrire chaque fois les équations du système pour trouver les solutions de base. On peut, toutefois, lire ces solutions directement dans la matrice.   Lecture des solutions de base à partir de la matrice  On considère à nouveau les matrices et de l'exemple .  On commence par la matrice . Celle-ci avait une seule variable libre, , et la solution de base trouvée était . On regarde la matrice , particulièrement dans la troisième colonne (car la variable est libre), les entrées un et deux (correspondant aux lignes non nulles).   La solution de base de la matrice   La matrice A est réécrite, avec les entrée en position 1,3 et 2,3 colorées respectivement en bleu et en rouge.    On peut y voir la valeur négative des composantes du vecteur de base .  On détaille ci-dessous la lecture des matrices et . La matrice n'est pas analysée, car il n'y a pas de solution de base.   On regarde maintenant la matrice . Cette fois-ci, on s'intéresse à la deuxième et à la troisième colonne, car celles-ci correspondent aux variables libres, plus particulièrement à la première ligne de ces colonnes, car les autres sont nulles.   La solution de base de la matrice   La matrice B est réécrite, avec les entrée en position 1,2 et 1,3 colorées respectivement en bleu et en rouge.      On regarde maintenant la matrice . Cette fois-ci, on s'intéresse aux deuxième, quatrième et cinquième colonnes, car celles-ci correspondent aux variables libres, plus particulièrement aux lignes un et deux de ces colonnes, car la troisième est nulle.   La solution de base de la matrice   La matrice C est réécrite, avec les entrée en position 1,2, 1,4 et 1,5 colorées en bleu et les entrées 2,2, 2,4 et 2,5 en rouge.      Avec l'exemple précédent, on peut distinguer deux matrices à l'intérieur d'une matrice échelonnée réduite. En ne tenant pas compte des lignes nulles, on détecte dans les colonnes pivots une occurrence de la matrice identité. Toujours sans tenir compte des lignes nulles, les colonnes libres donnent lieu à une matrice, notée (pour libre). Cette matrice contient l'information des solutions de base. On l'illustre à l'aide d'un exemple.   Les sous-matrices et   On considère la matrice échelonnée réduite .  Les colonnes et sont pivots et les colonnes et sont libres. En éliminant les lignes nulles et les colonnes libres, on peut observer une matrice identité:   La matrice identité dans la matrice échelonnée   La matrice R est écrite avec les trois dernières lignes rayées, ainsi que les colonnes 2,4 et 6. On voit ensuite une flèche vers la matrice identité de taille 3, correspondant aux valeurs non rayées dans R.    En éliminant à nouveau les lignes nulles, mais en éliminant cette fois-ci les colonnes pivots plutôt que les libres, on obtient une autre sous-matrice :   La matrice dans la matrice échelonnée   La matrice R est écrite avec les trois dernières lignes rayées, ainsi que les colonnes 1,3 et 5. On voit ensuite une flèche vers une matrice de taille 3, correspondant aux valeurs non rayées dans R.    On montre maintenant comment on peut se servir de la matrice pour obtenir les solutions de base. La matrice possède trois variables libres, . Il y aura donc trois solutions de base. On écrit dans trois vecteurs la « matrice identité » de taille Attention, cette matrice identité n'est pas nécessairement celle de la sous-matrice. Elle est de la taille du nombre de variables libres. , où est le rang de la matrice (le nombre de variables pivots), aux positions libres ( ). Dans ce cas-ci, : . La taille des vecteurs est si la matrice est .  Pour compléter les vecteurs , on utilise l'opposé des colonnes de la matrice , la colonne pour le vecteur et ainsi de suite: .  On vérifie à l'aide de Sage que les vecteurs ainsi trouvés sont en effet des solutions à l'équation .     On regarde maintenant un aspect important de la géométrie des solutions à l'équation . Si l'on voit la matrice selon ses lignes, , alors l'équation peut s'interpréter comme le système d'équations .  Géométriquement, cela signifie que le vecteur solution est perpendiculaire à chaque ligne de la matrice. On vérifie ce fait dans l'exemple suivant.   Les zéros sont perpendiculaires aux lignes de la matrice  On considère les matrices et ci-dessous: .  Pour chaque matrice, on cherche les solutions de base et l'on vérifie que celles-ci sont perpendiculaires aux lignes de la matrice.    On échelonne la matrice . L'opération permet d'obtenir la matrice échelonnée réduite équivalente . Il y a une variable libre et donc, une solution de base. Celle-ci est .  La figure suivante permet d'observer la perpendicularité de cette solution (ou ses multiples) et des lignes de la matrice .   Les zéros de sont perpendiculaires aux lignes        On utilise Sage et la méthode de l'exemple pour déterminer les solutions de base de la matrice .   La variable est libre. Il y a une solution de base, qui est . La figure suivante permet de visualier la perpendicularité des multiples de la solution de base avec les lignes de la matrice.      Comme la troisième ligne de la forme échelonnée réduite de est nulle, on peut dire que le troisième vecteur est dans le plan engendré par les deux premières lignes. La géométrie de l'équation semble donc composée du plan engendré par les lignes de , avec les zéros de la transformation linéaire sur le vecteur normal du plan.    On utilise Sage et la méthode de l'exemple pour déterminer les solutions de base de la matrice .   Les variables et sont libres. Il y a deux solutions de base, qui sont et . La figure suivante permet de visualiser la perpendicularité des combinaisons linéaires des solutions de base avec les lignes de la matrice.      Comme la deuxième et la troisième ligne de la forme échelonnée réduite de sont nulles, ces vecteurs sont des multiples de la première ligne. La géométrie de l'équation semble donc composée de la droite engendrée par les lignes de , avec les zéros de la transformation linéaire sur le plan perpendiculaire à cette droite.    On fait de cette propriété une proposition.   Les zéros sont perpendiculaires aux lignes de la matrice  Soit , une matrice de taille , , la ligne de la matrice et , un vecteur tel que .  Alors , c'est-à-dire que les zéros de la matrice sont perpendiculaires aux lignes de celle-ci.  La preuve est essentiellement faite dans la discussion qui précède l'exemple .   On termine avec des commandes Sage en lien avec la sous-section.   La matrice L et les solutions de base  On souhaite créer une fonction Sage qui retourne les solutions de base d'une matrice en reproduisant l'algorithme . Pour cela, on crée d'abord une fonction matL qui va retourner la matrice associée à la forme échelonnée réduite d'une matrice quelconque. Voici quelques nouvelles fonctions Sage qui seront utiles et une manière d'ajouter des composantes à un vecteur:  Les fonctions matrix_from_rows et matrix_from_columns permettent de créer une matrice à partir des lignes ou des colonnes d'une autre matrice.    Parfois, on ne sait pas quelles seront les entrées d'un vecteur, ou bien l'on veut construire un vecteur en étape, une entrée à la fois. Pour effectuer cette opération, on utilisera plutôt une liste Sage que l'on convertira en vecteur par la suite. Par exemple, si l'on dispose d'une liste l1=[1,3,4] et d'une autre liste l2=[2,4,6] et qu'on veut créer les vecteurs qui prennent ces valeurs en alternant d'une liste à l'autre, on fera     On débute avec la création de la fonction qui retourne la matrice . On se pose dans un premier temps la question suivante: est-ce que la matrice existe toujours? Dans l'algorithme, on élimine les lignes de zéros et l'on ne garde que les colonnes libres. Que faire si toutes les lignes sont nulles ou si toutes les colonnes sont pivots? Dans ces cas, il n'y a pas de matrice , mais l'interprétation est différente pour ce qui est des solutions de base. Lorsque toutes les lignes sont nulles, toutes les variables sont libres et l'ensemble solution est donc constitué de tous les vecteurs de l'espace . Si, au contraire, toutes les variables sont pivots, alors il n'y a pas de solution de base. La seule solution à est le vecteur nul. C'est dans ce deuxième cas qu'il faudra dire à notre fonction qu'il n'y a pas de solution de base.  Pour le cas où la matrice est nulle, selon l'algorithme , les solutions spéciales devraient sortir correctement et correspondre aux vecteurs de l'espace .  Pour la matrice , on a   On teste la fonction avec la matrice de l'exemple :   On va maintenant créer la fonction solbase(A) , qui, à partir d'une matrice , va retourner les solutions de base de l'équation . À l'intérieur de celle-ci, on va utiliser la fonction matL créée ci-dessus.   On teste la fonction avec la matrice de l'exemple :      L'image d'une transformation linéaire  L'équation a toujours une solution. Parfois, elle en a une infinité. Lorsqu'on remplace le vecteur nul par un vecteur quelconque, l'équation peut ne pas avoir de solution(s). Étant donnée une matrice , pour quel(s) vecteur(s) l'équation possède-t-elle au moins une solution?  Géométriquement parlant, quels sont les vecteurs qui sont atteints par la transformation linéaire , c'est-à-dire, quels sont les vecteurs qui forment l'image de cette transformation? On explore quelques cas dans l'exemple suivant.   L'image de transformations géométriques: dynamique  On considère les transformations .  On cherche à visualiser l'image de chacune de ces transformations. Pour cela, on utilise les figures interactives suivantes.   L'image de la transformation     L'image de la transformation     L'image de la transformation     L'image de la transformation    À l'exemple , on détermine algébriquement les images de ces transformations.    Pour déterminer l'image d'une transformation linéaire , on augmente la matrice avec un vecteur quelconque. En échelonnant la matrice, on obtiendra des conditions sur les entrées de pour que le système possède au moins une solution. Ceci provient du fait qu'un système compatible doit avoir des entrées nulles dans la partie augmentée s'il y a des lignes nulles dans la forme échelonnée réduite de .  On trouve les images des transformations de l'exemple .   L'image de transformations algébriques  On considère à nouveau les matrices de l'exemple . On détermine algébriquement les images de ces transformations.   On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. On débute en supposant que . .  Comme toutes les colonnes sont pivots et qu'il n'y a pas de lignes nulles, on peut conclure que peu importe la valeur du vecteur , une solution existe (ce qui n'est pas surprenant, compte tenu de la géométrie de la rotation). En plus, on obtient cette solution en fonction des entrées de .  Puisque l'on a divisé par , on doit voir ce qui se passe lorsque ce dernier vaut . Si c'est le cas, alors ou . Dans les deux cas, la matrice se réduit aussi à l'identité à l'aide d'une permutation de lignes et d'une multiplication d'une ligne par .    On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. .  La matrice est déjà sous la forme échelonnée réduite et l'on constate que la dernière ligne (de la partie non augmentée) est nulle. Pour que le système possède une solution, il faut que le terme augmenté dans la dernière ligne soit nul aussi, c'est-à-dire, il faut que . En réécrivant, on se rend compte que les vecteurs de l'image doivent satisfaire . Ce sont précisément les vecteurs sur la droite de la figure .   Voir l'exercice .   On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. .  La matrice est déjà sous la forme échelonnée réduite et l'on constate que les deux dernières lignes (de la partie non augmentée) sont nulles. Pour que le système possède une solution, il faut que les termes de la partie augmentée dans ces lignes soient nuls aussi, c'est-à-dire, il faut que et . Ceci amène un nouveau système d'équations linéaires homogène à deux équations et trois inconnues. La matrice de ce système est . On utilise la fonction solbase définie plus haut afin de trouver les solutions de base de ce système.   Les vecteurs composant l'image de la transformation linéaire se trouvent donc sur les combinaisons linéaires (donc ici, la droite) du vecteur . Ceci coïncide bien avec la droite de la figure , comme le montre l'animation suivante.   L'image de la transformation      Les vecteurs de l'image possèdent une propriété similaire à celle de l'ensemble des zéros.   L'image d'une transformation est fermée pour l'addition et la multiplication par un scalaire  Soit , la matrice d'une transformation linéaire, et , des vecteurs tels que et possèdent au moins une solution. Alors  possède au moins une solution,  possède au moins une solution.    Voir l'exercice .   On termine avec des commandes Sage en lien avec la sous-section.    L'image de transformations linéaires et Sage  Sage ne pourra pas travailler directement avec les variables comme si on ne l'aide pas un peu. Pour déterminer l'image d'une transformation avec Sage, trois ajustements seront nécessaires. Leur raison d'être est liée au fonctionnement du logiciel et dépasse le niveau du manuel. On se contente d'appliquer la solution. On constate l'ajout d'une ligne R.<b1,b2,b3>=QQ[] au code. De plus, la colonne augmentée est inscrite à même la matrice. Finalement, on note l'utilisation de la fonction echelon_form() plutôt que le standard rref() . Avec ces ajustements, on peut obtenir la forme échelonnée réduite de la matrice avec le vecteur variable.  On procède avec les matrices de l'exemple .   On trouve la condition . On reconnait ici l'équation normale d'un plan dans . On pourrait trouver l'équation vectorielle en isolant par exemple ou encore en utilisant solbase . Puisque ceci est un exemple Sage, on choisit ce bazooka pour tuer une mouche. Voir   On trouve une équation vectorielle pour ce même plan: .  On regarde maintenant l'image de la matrice .   On trouve les mêmes deux conditions et sur le vecteur que lors de l'exemple . La solution sera bien sûr encore la droite de vecteur directeur .    Le lecteur astucieux aura peut-être remarqué que les vecteurs directeurs des droites de l'image des matrices et de cette sous-section étaient un multiple d'une colonne de ces matrices. Le lecteur encore plus astucieux aura peut-être même remarqué que les vecteurs directeurs du plan de l'image de la matrice trouvés à l'exemple calculatoire sont des combinaisons linéaires de deux des colonnes de la matrice. En effet, . Pour comprendre cela, on se rappelle que le produit peut être interprété comme les combinaisons linéaires des colonnes de la matrice . L'ensemble des s'écrivant comme ces combinaisons linéaires constitue donc l'image de la transformation .  Il semble toutefois qu'il n'est pas nécessaire d'utiliser toutes les colonnes pour engendrer l'image, comme le montrent les images des matrices et . La section va donner la réponse à cette question.    La solution générale à .  Les solutions à l'équation s'écrivent toutes comme des combinaisons linéaires des vecteurs de base. Selon le nombre de vecteurs de base, ces solutions se trouvent sur une droite (un vecteur), un plan (deux vecteurs) ou plus généralement un hyperplan (trois vecteurs ou plus) passant par l'origine. Lorsque le vecteur nul est remplacé par un vecteur quelconque, les solutions ont toujours la forme de droites, plans ou hyperplans, mais ceux-ci ne passent plus nécessairement par l'origine. Il est possible d'écrire toutes les solutions à l'équation comme la translation des solutions à l'équation , un peu à l'image de la figure .  En fait, si l'on suit la démarche de la section lorsqu'il y a infinité de solutions, c'est précisément ce qui se passait lorsqu'on isolait les variables pivots en fonction des variables libres. On ne fait donc que faire le lien avec la première sous-section.   Des systèmes à quatre équations et trois inconnues, prise deux   On reprend les systèmes et de l'exemple . La solution respective à ces systèmes était et .  Pour la matrice , le vecteur devrait être celui de la solution de base et le vecteur représente la translation de la droite de vecteur directeur . On vérifie avec la fonction solbase et la matrice . Malheureusement, on doit la redéfinir puisque l'on n'est pas dans la section principale du texte.   Pour la matrice , les vecteurs et devraient être ceux des solutions de base et le vecteur représente la translation du plan engendré par les deux premiers vecteurs. On vérifie avec la fonction solbase et la matrice .     On obtient la proposition suivante, sur l'allure des solutions à l'équation .   La forme générale des solutions à l'équation  Soit , une matrice , , un vecteur de pour lequel l'équation possède au moins une solution et soit , la solution à l'équation homogène . Finalement, soit , une solution particulière à l'équation . Alors représente l'ensemble de toutes les solutions à l'équation . On dit que est la solution générale.    Dans un premier temps, on vérifie que est bel et bien une solution à . .  On montre maintenant que toute solution à l'équation peut s'écrire sous cette forme. Soit , une solution à . On remarque que .  Ainsi, est une solution à l'équation . Il existe donc tels que où les vecteurs sont les solutions de base de l'équation homogène. En laissant représenter n'importe quelle solution à et en l'isolant dans l'équation , on a .    Une manière facile de trouver une solution particulière à l'équation est de prendre celle pour laquelle les variables libres sont toutes égales à . Dans la géométrie, cela va correspondre au vecteur translatant la solution homogène.   La solution particulière à un système d'équations linéaire  On reprend les systèmes de l'exemple . De plus, on considère la matrice échelonnée réduite .   On fait la matrice et la matrice ensemble. On échelonne ces systèmes afin de voir comment lire la solution particulière.   La solution particulière pour la matrice était . Ce vecteur est celui obtenu lorsque la variable libre est nulle. On remarque qu'il se trouve dans la dernière colonne de la matrice augmentée échelonnée réduite. Les entrées importantes se trouvent sur chaque ligne où il y a un pivot. L'entrée de la partie augmentée ira dans la composante de la solution particulière correspondant à la colonne qui est le pivot de la ligne. Les autres entrées du vecteur sont nulles.  Ainsi, pour la matrice , on obtient , puisque la seule variable non libre est la première et les deux suivantes sont libres.   Selon ce qui est mentionné à la fin de la démarche pour les matrices , la solution particulière se trouve dans la partie augmentée. Les lignes un et deux contiennent des pivots. Ce sont donc les entrées et qui sont importantes. Les pivots sont aux colonnes deux et quatre. La solution particulière est donc .   On termine avec des commandes Sage en lien avec la sous-section.   La solution générale avec Sage  Dans cet exemple, on s'intéresse à créer une fonction solgen qui, étant donné une matrice et un vecteur, va retourner la solution générale à l'équation . La fonction devrait être relativement simple à créer, puisqu'on peut partir de la fonction solbase qui retourne déjà les solutions de base. Ce qu'il faut considérer est que maintenant, il se peut que l'équation ne possède pas de solution(s). Pour cela, on utilise la proposition .  Pour ce qui est de la solution particulière, il suffit de rappeler que les entrées importantes de celle-ci se trouvent dans la colonne augmentée de la matrice. Ces entrées sont dans les lignes non nulles de la forme échelonnée réduite et vont à la position du pivot de cette ligne.   On essaie maintenant la fonction solgen avec les systèmes de l'exemple .     L'importance de tester son code  Lorsqu'on code une fonction, il est important de bien la tester afin de vérifier qu'elle répond aux attentes et que des cas particuliers ne causent pas de problèmes. Par exemple, la fonction matL échelonne une matrice, enlève les lignes nulles et retourne la sous-matrice des colonnes qui ne sont pas pivots.  Est-ce qu'elle fonctionne toujours lorsque la matrice est déjà échelonnée?  Qu'arrive-t-il si toutes les variables sont pivots? Est-ce la réponse attendue?  Et si aucune des variables n'est pivot? Il faut qu'une autre fonction utilisant matL puisse se servir de la réponse « vide ».   Dans le cas de la fonction solbase , on a pensé à gérer le cas où il n'y a pas de solution. Est-ce qu'il y a d'autres potentiels problèmes? Encore une fois, si l'on utilise la fonction solbase dans une autre fonction, est-ce que notre retour à un cas comme cela pourra être utilisé adéquatement par cette autre fonction?  Même question s'il n'y a pas de solution de base?  Finalement, la fonction solgen prend deux arguments. L'ordre de ces arguments est-il important? Et si les arguments n'étaient pas du tout ce à quoi la fonction s'attend? Ce genre de problème peut être prévenu à l'aide de « gestion d'erreurs », mais on ne considère pas cela ici.         Les points importants de cette section sont:  Le fait que l'addition et la multiplication par un scalaire de solutions à l'équation restent des solutions et que deux vecteurs de l'image se combinent de manière similaire pour rester dans l'image.  La notion de solutions de base d'une matrice et la solution homogène.   La forme générale de la solution à l'équation .  .  De plus, avec Sage, on a les commandes matrix_from_rows et matrix_from_columns qui permettent d'extraire d'une matrice une sous-matrice selon les lignes ou colonnes souhaitées. Les fonctions matL , solbase(A) et solgen seront utiles plus tard. On a aussi vu comment utiliser les listes pour créer en étape un vecteur. Pour travailler de manière symbolique, on a vu l'utilisation de la commande echelon_form et l'ajout de R.<variables>.QQ[] afin de pouvoir manipuler les variables dans <variables> .      Exercices   Le produit vectoriel Dans cet exercice, on s'intéresse à trouver les vecteurs de qui sont perpendiculaires à deux vecteurs donnés. Essentiellement, on cherche à trouver le vecteur normal au plan engendré par les deux vecteurs donnés. Soit . On cherche tel que et . Écrire le système d'équations linéaires associé à ces équations et le résoudre. avec On écrit les équations obtenues en remplaçant par les vecteurs donnés et le vecteur quelconque . La matrice et le vecteur résument le système d'équations linéaires dans l'équation matricielle . C'est un système homogène. On va donc l'échelonner sans la partie augmentée. Il n'y a qu'une seule variable libre ici, la troisième ( ). Les équations restantes sont .  Si l'on pose , on obtient la solution de base . La solution homogène est donc avec . Soit . On cherche tel que et . Écrire le système d'équations linéaires associé à ces équations et le résoudre. avec On écrit les équations obtenues en remplaçant par les vecteurs donnés et le vecteur quelconque . La matrice et le vecteur résument le système d'équations linéaires dans l'équation matricielle . C'est un système homogène. On va donc l'échelonner sans la partie augmentée. Il n'y a qu'une seule variable libre ici, la troisième ( ). Les équations restantes sont .  Si l'on pose , on obtient la solution de base . La solution homogène est donc avec . Dans les deux calculs précédents, quelle est la plus petite valeur positive de la variable libre qui fait en sorte que les entrées du vecteur sont toutes entières? Quels sont ces vecteurs ?  et  et  Refaire les parties et en remplaçant le vecteur par un vecteur quelconque . Compléter les cellules Sage ci-dessous pour faire les calculs.    Sélectionner à nouveau une valeur pour qui évite les fractions.    Le code solution pour la lettre (a)   var(\"u1,u2,u3\") u=vector([u1,u2,u3]) v=vector([2,3,4]) R.<u1,u2,u3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full()) #On utilise la fonction simplify_full() pour que les fractions soient réduites    On choisit la valeur pour obtenir le vecteur ayant des valeurs entières .   Le code solution pour la lettre (b)   var(\"u1,u2,u3\") u=vector([u1,u2,u3]) v=vector([-2,1,5]) R.<u1,u2,u3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full())    On choisit la valeur pour obtenir le vecteur à valeurs entières .  Refaire la partie en remplaçant les vecteurs par un vecteur quelconque . Compléter la cellule Sage ci-dessous pour faire les calculs   Sélectionner à nouveau une valeur pour qui évite les fractions.    Le code solution   var(\"u1,u2,u3,v1,v2,v3\") u=vector([u1,u2,u3]) v=vector([v1,v2,v3]) R.<u1,u2,u3,v1,v2,v3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full())    On choisit la valeur pour obtenir le vecteur à valeurs entières .  Le vecteur est appelé le produit vectoriel de et , et est noté . On y reviendra à la section .  Ce vecteur a été obtenu en prenant la variable libre dans le système d'équations linéaires comme étant égale à pour éliminer une fraction. Il se peut toutefois que ce nombre soit nul. Dans la section , on montrera que ce n'est pas un problème.  On considère la matrice . Déterminer les solutions de base en fonction de .  Si , alors .  Si , alors .   Pour trouver les solutions, il faut échelonner la matrice. Puisqu'on cherche les solutions de base, il n'est pas nécessaire d'échelonner la matrice augmentée du système puisque cette colonne sera toujours nulle. La dernière étape n'est possible que si . Cela nous amène à séparer les solutions possibles en deux groupes, selon les valeurs de .  D'abord, si , alors, toutes les variables sont pivots et le système a une seule solution qui est le vecteur nul. On a donc .  Ensuite, si , alors la matrice échelonnée devient: et on peut ainsi lire le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .  Finalement, si , la matrice échelonnée est la même et donc la solution de base est la même.   On considère la matrice . Déterminer les solutions de base en fonction de et .  Si et , alors .  Si , et , alors .  Si , et , alors et .  Si , alors .   Pour trouver les solutions, il faut échelonner la matrice. Puisqu'on cherche les solutions de base, il n'est pas nécessaire d'échelonner la matrice augmentée du système puisque cette colonne sera toujours nulle. Les deux dernières étapes ne sont possibles que si , puis si . Cela nous amène à séparer les solutions possibles en trois groupes, selon les valeurs de .  D'abord, si et , alors, on lit le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .  Ensuite, si , alors, la matrice échelonnée devient: Cette avant-dernière étape n'est possible que si . Dans ce cas, le vecteur solution de base est , car les variables non-pivots sont forcées à être égales à . Autrement, si , alors la matrice échelonnée devient: . On a maintenant deux variables pivots et une seule non-pivot. Les vecteurs solutions de base sont donc: et . On les a obtenus en posant alternativement chaque variable libre égale à et .  Finalement, si , la matrice échelonnée devient: . On lit le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .   Un plan a comme équation . En fonction de ce plan, que représente la solution homogène à l'équation ? Donner cette solution. L'équation vectorielle de ce plan. La solution homogène est: Puisque l'équation sous forme matricielle représente la même équation, il s'agit du même plan. La solution homogène correspondra à l'équation vectorielle de ce plan passant par l'origine. Les vecteurs directeurs seront donnés par les solutions de base. La matrice échelonnée sera: . On l'interprète en posant que les variables libres et respectivement égales à puis à . Les vecteurs solutions de base sont donc: et . La solution homogène est : Le plan est donc décrit par l'équation vectorielle : .  Un plan a comme équation . En fonction de ce plan, que représente la solution générale à l'équation ? Donner cette solution. L'équation vectorielle de ce plan. La solution générale est: Puisque l'équation sous forme matricielle représente la même équation, il s'agit du même plan. La solution générale correspondra à l'équation vectorielle de ce plan passant par un point de départ qui correspond à la solution particulière. Les vecteurs directeurs seront donnés par les solutions de base. La matrice augmentée échelonnée sera: . La solution homogène, qui a déjà été trouvée à l'exercice , est : . La solution particulière est obtenue de la matrice augmentée en posant toutes les variables libres égales à . Puisque seule la première variable est pivot, c'est donc elle qui prendra la seule valeur dans la partie augmentée. La solution particulière est donc: . La solution générale est : . Le plan est donc décrit par l'équation vectorielle : .  Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve la solution de base à l'équation et la solution particulière à l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 1    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base. La partie augmentée sera déterminée par la solution particulière. On distinguera trois cas de figure.  D'abord, si le vecteur solution de base est , on sait que la solution homogène est égale au vecteur nul. La partie de gauche n'a donc pas le choix d'être la matrice identité puisque l'on a une solution unique. La partie augmentée sera simplement le vecteur de la solution particulière. On a donc .  Ensuite, si le vecteur solution de base est , on sait que la solution homogène est une droite et donc qu'il y a une variable libre. La variable libre est toujours celle pour laquelle le vecteur solution de base a une valeur de . C'est donc ici . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Ce vecteur sera toujours de la forme pour être une solution de l'équation matricielle .  Finalement, si le vecteur solution de base est de la forme , on sait que la solution homogène est une droite et donc qu'il y a une variable libre. La variable libre est toujours celle pour laquelle le vecteur solution de base a une valeur de . C'est donc ici . La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Ce sera donc toujours un vecteur de la forme .   Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve la solution de base à l'équation et un point appartenant à l'ensemble solution de l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 2    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base exactement comme à l'exercice . La partie augmentée sera déterminée par le point appartenant à l'ensemble solution. Il faudra parfois effectuer un calcul, d'autres fois lire directement la valeur. On distinguera les mêmes trois cas de figure.  D'abord, si le vecteur solution de base est , on sait que la solution homogène est égale au vecteur nul. La partie de gauche n'a donc pas le choix d'être la matrice identité puisque l'on a une solution unique. La partie augmentée sera simplement le point appartenant à l'ensemble solution. On a donc .  Ensuite, si le vecteur solution de base est , on sait que la solution homogène est une droite et donc qu'il y a une variable libre qui est dans ce cas. La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Finalement, si le vecteur solution de base est de la forme , on sait que la solution homogène est une droite et donc qu'il y a une variable libre qui est dans ce cas-ci. La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Cependant, on n'a pas cette solution particulière avec la bonne forme, on en a une quelconque donnée par qui est dans l'ensemble solution. Il faudra donc calculer la valeur en isolant dans l'équation: .   Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve un vecteur parallèle à la solution de base à l'équation et un point appartenant à l'ensemble solution de l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 3    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base exactement comme à l'exercice . La partie augmentée sera déterminée par le point appartenant à l'ensemble solution. Il faudra parfois effectuer un calcul, d'autres fois lire directement la valeur. On distinguera les mêmes trois cas de figure.  D'abord, si le vecteur donné est de la forme , on sait que le vecteur solution de base est , puisqu'il doit y avoir une variable libre qui est , la seule variable non nulle ici. Alors, on sait que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Ensuite, si le vecteur donné est de la forme , on sait que le vecteur solution de base est , puisqu'il doit y avoir une variable libre qui est , la seule variable non nulle ici. On sait alors que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre et pour laquelle vaut . La partie augmentée sera toujours un vecteur de la forme où est la première et seule composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Finalement, si le vecteur donné est de la forme , alors le vecteur solution de base est de la forme , puisqu'il doit y avoir une variable libre et que ça ne peut être sans que la composante du vecteur soit nulle. On obtient la valeur de à partir du fait que (ils sont parallèles). Par exemple, si , alors et donc . Ainsi, on sait que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Cependant, on n'a pas cette solution particulière avec la bonne forme, on en a une quelconque donnée par qui est dans l'ensemble solution. Il faudra donc calculer la valeur en isolant dans l'équation: .   Donner une transformation telle que son image est égale à ses zéros. Une suffit. On suit l'indication et l'on cherche une transformation de vers . Il n'est pas facile à priori de trouver une telle transformation sans avoir une bonne intuition géométrique de ces deux concepts. On rappelle que les zéros sont l'ensemble des solutions à l'équation homogène . Ce sont donc des vecteurs du plan qui sont tels que la transformation recherchée les amènera à zéro. C'est la solution homogène à la transformation. On indique dans la question que la transformation a des zéros. Or, on sait que si elle en a plus d'un, elle en a une infinité. On a donc des zéros de la forme où est la solution de base. Pour simplifier le problème, on suppose que . Les zéros sont donc l'ensemble des vecteurs sur l'axe des . Une transformation linéaire amenant tous les vecteurs sur l'axe des à l'origine a nécessairement comme première colonne des zéros.  On propose la matrice de transformation qui envoie le vecteur à et le vecteur à . On a présenté la raison pour laquelle la première colonne est formée seulement de zéros. Pourquoi amener la deuxième colonne à ? La réponse est parce que l'on veut que l'image de la transformation soit aussi l'ensemble des vecteurs sur l'axe des . Avec cette transformation, on a effectivement: et . Ce dernier résultat constitue l'image de et est clairement un vecteur sur l'axe des .  Les matrices ci-dessous sont des matrices , obtenues par exemple avec la fonction matL . Pour chaque matrice, donner une matrice échelonnée réduite qui possède la matrice comme sous matrice.  Soit , des transformations linéaires non nulles telles que . Que peut-on dire de l'image de par rapport aux zéros de ? On a . Donner des exemples de transformations non nulles de taille telles que et determiner les zéros de et l'image de . Vérifier la relation de l'exercice précédent. Donner des exemples de transformations non nulles de taille telles que et telles que l'image de n'est pas égale aux zéros de .   Donner, si possible, une matrice qui a comme solution(s) de base les vecteurs suivants. Dans l'impossibilité de le faire, expliquer pourquoi.  Le vecteur . S'inspirer de l'exemple et de la proposition . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit, dans la solution de base, que ou peuvent être libres. On choisit puisque c'est plus facile et l'on met dans la colonne non pivot les valeurs correspondant à l'opposé des valeurs de et de dans . On propose de créer la matrice initiale en faisant des combinaisons linéaires des lignes non-nulles de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et ensuite . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que et sont libres, car leur composante est de dans un des vecteurs de base et de dans l'autre. La variable est donc la seule non libre. Il n'y a qu'un pivot et les valeurs sous les colonnes non pivots sont les opposés des valeurs de dans les vecteurs de base respectifs. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à et (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que et sont libres, car leur composante est de dans un des vecteurs de base et de dans l'autre. La variable est donc la seule non libre. Il n'y a qu'un pivot et les valeurs sous les colonnes non pivots sont les opposés des valeurs de dans les vecteurs de base respectifs. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à et (produit scalaire égal à zéro). Les vecteurs . Impossible. On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à . Cela est impossible puisqu'un vecteur de ne peut pas être à la fois perpendiculaire à trois différents vecteurs qui ne sont pas parallèles entre eux. Le vecteur . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que est la seule variable libre. Toutes les autres étant non libres, elles doivent être pivots. On inscrit, dans la colonne non pivot, les valeurs correspondant à l'opposé des valeurs de et de dans . On propose de créer la matrice initiale en faisant des combinaisons linéaires des lignes non nulles de la matrice échelonnée. On obtient, par exemple: . On a simplement fait , ensuite , puis et finalement . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que , et sont libres, car leur composante est de dans un des vecteurs de base et de dans les autres. Les variables et sont donc non libres et doivent avoir un pivot. Les valeurs sous les colonnes non pivots sont les opposés des valeurs de et dans les vecteurs de base respectifs à ces colonnes. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait , ensuite , puis et finalement . Un calcul rapide (un peu long!) permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro).  Démontrer la proposition et la proposition . D'abord, on démontre la proposition . et . Ensuite, on démontre la proposition . Soit , une solution de et , une solution de . Alors, . Une solution à est donc le vecteur . De façon semblable, . Une solution à est donc le vecteur .  Voici un énoncé et sa « démonstration ».  Énoncé: Soit . Cette équation a une infinité de solutions.  Démonstration: On sait qu'il existe au moins une solution à l'équation. La proposition dit que tout multiple d'une solution est aussi une solution. Il y en a donc une infinité.  Trouver l'erreur dans l'argument ci-dessus. Il est vrai que l'équation a au moins une solution. En effet, par la proposition , toute équation homogène a toujours comme solution le vecteur nul . Cependant, l'argument qu'on peut obtenir une infinité de solutions à partir de cette dernière en la multipliant par un scalaire oublie le fait que lorsqu'on multiplie le vecteur nul par un scalaire, il demeure le vecteur nul. Bref, rien ne montre dans cette « démonstration » que l'équation a d'autres solutions que la solution triviale .  Pour chaque matrice ci-dessous, déterminer l'image de la transformation associée. On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. Aucune condition pour qu'on ait une solution n'est donnée par la matrice augmentée échelonnée. L'image est donc l'ensemble de l'espace . On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. Deux conditions pour qu'on ait une solution sont données par les deuxième et troisième lignes. En effet, il faut que et . On place ces deux équations dans une nouvelle matrice pour en trouver la solution. La solution à ce système est: . On reconnait l'équation d'une droite. On donne son équation de façon plus standard.  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:    Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.   Utiliser Sage pour trouver l'image des matrices de l'exercice .    "
},
{
  "id": "ex-zerosgeo",
  "level": "2",
  "url": "sec-SELgeo.html#ex-zerosgeo",
  "type": "Exemple",
  "number": "3.3.1",
  "title": "Les zéros de quelques transformations: dynamique.",
  "body": " Les zéros de quelques transformations: dynamique  Dans un premier temps, on considère les transformations de l'exemple . Puisque toutes ces transformations sont inversibles sauf la projection orthogonale, on conclut qu'il n'y a que le vecteur nul comme zéro des premières. Pour la projection orthogonale, on peut réfléchir géométriquement. On cherche . Or selon l'équation , un vecteur perpendiculaire à sera projeté sur le vecteur nul. Si , tout vecteur est un zéro de la projection orthogonale.  On regarde maintenant quelques exemples à trois dimensions. On considère les matrices .  La figure interactive suivante permet de visualiser l'image d'un vecteur par chacune des transformations. Les détails algébriques se trouvent dans les solutions ci-dessous.   Les zéros de deux transformations linéaires de l'espace      On utilise Sage pour échelonner la matrice et déterminer les solutions.   Les variables sont pivots et la variable est libre. En isolant les équations de la matrice échelonnée réduite, on trouve . Les vecteurs solutions au système sont donc ceux de la forme . On reconnait l'équation d'une droite dans passant par l'origine et de vecteur directeur .    On utilise Sage pour échelonner la matrice et déterminer les solutions.   La variable est pivot et les variables sont libres. En isolant les équations de la matrice échelonnée réduite, on trouve . Les vecteurs solutions au système sont donc ceux de la forme . On reconnait l'équation d'un plan dans passant par l'origine et de vecteurs directeurs et .   "
},
{
  "id": "prop-Ax0sev",
  "level": "2",
  "url": "sec-SELgeo.html#prop-Ax0sev",
  "type": "Proposition",
  "number": "3.3.3",
  "title": "Les zéros d’une transformation linéaire sont fermés pour l’addition et la multiplication par un scalaire.",
  "body": " Les zéros d'une transformation linéaire sont fermés pour l'addition et la multiplication par un scalaire  Soit , la matrice d'une transformation linéaire, et , des vecteurs tels que . Alors  ,  .    Voir l'exercice .  "
},
{
  "id": "def-solbase",
  "level": "2",
  "url": "sec-SELgeo.html#def-solbase",
  "type": "Définition",
  "number": "3.3.4",
  "title": "Les solutions de base à un système <span class=\"process-math\">\\(A\\vec{x}=\\vec{0}\\)<\/span>.",
  "body": " Les solutions de base à un système   Soit , une matrice quelconque telle que l'équation possède plus d'une solution. On nomme les « solutions de base » les solutions obtenues lorsqu'une seule une des variables libres est égale à et que les autres sont nulles. On verra à la section que l'expression « de base » est reliée à la notion de base d'un espace vectoriel.  Il y a autant de solutions de base que de variables libres. Si la matrice ne possède pas de variables libres, la seule solution à l'équation est le vecteur . Celui-ci n'est pas « spécial ».  L'ensemble de toutes les combinaisons linéaires des solutions de base additionnées du vecteur est appelé la solution homogène . On la note .   "
},
{
  "id": "ex-solbase1",
  "level": "2",
  "url": "sec-SELgeo.html#ex-solbase1",
  "type": "Exemple",
  "number": "3.3.5",
  "title": "Solutions de base de matrices échelonnées réduites.",
  "body": " Solutions de base de matrices échelonnées réduites   On cherche à déterminer les solutions de base pour les matrices suivantes. Les matrices ne sont pas augmentées, car les solutions de base sont toujours obtenues lorsque la partie augmentée est le vecteur nul. L'information additionnelle de la colonne augmentée n'est donc pas utile.          Il n'y a qu'une seule variable libre ici, la troisième. Les équations restantes sont .  Si l'on pose , on obtient la solution de base , la solution homogène est donc pour .   Ici, il y a deux variables libres, la deuxième et la troisième. Les équations restantes sont .  Si l'on pose et , on obtient la première solution de base . Si l'on pose et , on obtient la deuxième solution de base . La solution homogène est pour .    Dans cet exemple, les variables et sont pivots et les variables et sont libres. On écrit les équations de ce système: .  En posant , on obtient la première solution de base . En posant , on obtient la deuxième solution de base . Finalement, en posant , on obtient la troisième et dernière solution de base .  La solution homogène est avec .    Dans cet exemple, toutes les variables sont pivots. Il n'y a donc pas de solution de base. La seule solution à l'équation est le vecteur nul. Donc .   "
},
{
  "id": "ex-solbase2",
  "level": "2",
  "url": "sec-SELgeo.html#ex-solbase2",
  "type": "Exemple",
  "number": "3.3.6",
  "title": "Lecture des solutions de base à partir de la matrice.",
  "body": " Lecture des solutions de base à partir de la matrice  On considère à nouveau les matrices et de l'exemple .  On commence par la matrice . Celle-ci avait une seule variable libre, , et la solution de base trouvée était . On regarde la matrice , particulièrement dans la troisième colonne (car la variable est libre), les entrées un et deux (correspondant aux lignes non nulles).   La solution de base de la matrice   La matrice A est réécrite, avec les entrée en position 1,3 et 2,3 colorées respectivement en bleu et en rouge.    On peut y voir la valeur négative des composantes du vecteur de base .  On détaille ci-dessous la lecture des matrices et . La matrice n'est pas analysée, car il n'y a pas de solution de base.   On regarde maintenant la matrice . Cette fois-ci, on s'intéresse à la deuxième et à la troisième colonne, car celles-ci correspondent aux variables libres, plus particulièrement à la première ligne de ces colonnes, car les autres sont nulles.   La solution de base de la matrice   La matrice B est réécrite, avec les entrée en position 1,2 et 1,3 colorées respectivement en bleu et en rouge.      On regarde maintenant la matrice . Cette fois-ci, on s'intéresse aux deuxième, quatrième et cinquième colonnes, car celles-ci correspondent aux variables libres, plus particulièrement aux lignes un et deux de ces colonnes, car la troisième est nulle.   La solution de base de la matrice   La matrice C est réécrite, avec les entrée en position 1,2, 1,4 et 1,5 colorées en bleu et les entrées 2,2, 2,4 et 2,5 en rouge.     "
},
{
  "id": "ex-sousmatriceIL",
  "level": "2",
  "url": "sec-SELgeo.html#ex-sousmatriceIL",
  "type": "Exemple",
  "number": "3.3.10",
  "title": "Les sous-matrices <span class=\"process-math\">\\(I\\)<\/span> et <span class=\"process-math\">\\(L\\)<\/span>.",
  "body": " Les sous-matrices et   On considère la matrice échelonnée réduite .  Les colonnes et sont pivots et les colonnes et sont libres. En éliminant les lignes nulles et les colonnes libres, on peut observer une matrice identité:   La matrice identité dans la matrice échelonnée   La matrice R est écrite avec les trois dernières lignes rayées, ainsi que les colonnes 2,4 et 6. On voit ensuite une flèche vers la matrice identité de taille 3, correspondant aux valeurs non rayées dans R.    En éliminant à nouveau les lignes nulles, mais en éliminant cette fois-ci les colonnes pivots plutôt que les libres, on obtient une autre sous-matrice :   La matrice dans la matrice échelonnée   La matrice R est écrite avec les trois dernières lignes rayées, ainsi que les colonnes 1,3 et 5. On voit ensuite une flèche vers une matrice de taille 3, correspondant aux valeurs non rayées dans R.    On montre maintenant comment on peut se servir de la matrice pour obtenir les solutions de base. La matrice possède trois variables libres, . Il y aura donc trois solutions de base. On écrit dans trois vecteurs la « matrice identité » de taille Attention, cette matrice identité n'est pas nécessairement celle de la sous-matrice. Elle est de la taille du nombre de variables libres. , où est le rang de la matrice (le nombre de variables pivots), aux positions libres ( ). Dans ce cas-ci, : . La taille des vecteurs est si la matrice est .  Pour compléter les vecteurs , on utilise l'opposé des colonnes de la matrice , la colonne pour le vecteur et ainsi de suite: .  On vérifie à l'aide de Sage que les vecteurs ainsi trouvés sont en effet des solutions à l'équation .    "
},
{
  "id": "ex-zerosperplignes",
  "level": "2",
  "url": "sec-SELgeo.html#ex-zerosperplignes",
  "type": "Exemple",
  "number": "3.3.13",
  "title": "Les zéros sont perpendiculaires aux lignes de la matrice.",
  "body": " Les zéros sont perpendiculaires aux lignes de la matrice  On considère les matrices et ci-dessous: .  Pour chaque matrice, on cherche les solutions de base et l'on vérifie que celles-ci sont perpendiculaires aux lignes de la matrice.    On échelonne la matrice . L'opération permet d'obtenir la matrice échelonnée réduite équivalente . Il y a une variable libre et donc, une solution de base. Celle-ci est .  La figure suivante permet d'observer la perpendicularité de cette solution (ou ses multiples) et des lignes de la matrice .   Les zéros de sont perpendiculaires aux lignes        On utilise Sage et la méthode de l'exemple pour déterminer les solutions de base de la matrice .   La variable est libre. Il y a une solution de base, qui est . La figure suivante permet de visualier la perpendicularité des multiples de la solution de base avec les lignes de la matrice.      Comme la troisième ligne de la forme échelonnée réduite de est nulle, on peut dire que le troisième vecteur est dans le plan engendré par les deux premières lignes. La géométrie de l'équation semble donc composée du plan engendré par les lignes de , avec les zéros de la transformation linéaire sur le vecteur normal du plan.    On utilise Sage et la méthode de l'exemple pour déterminer les solutions de base de la matrice .   Les variables et sont libres. Il y a deux solutions de base, qui sont et . La figure suivante permet de visualiser la perpendicularité des combinaisons linéaires des solutions de base avec les lignes de la matrice.      Comme la deuxième et la troisième ligne de la forme échelonnée réduite de sont nulles, ces vecteurs sont des multiples de la première ligne. La géométrie de l'équation semble donc composée de la droite engendrée par les lignes de , avec les zéros de la transformation linéaire sur le plan perpendiculaire à cette droite.   "
},
{
  "id": "prop-zerosperplignes",
  "level": "2",
  "url": "sec-SELgeo.html#prop-zerosperplignes",
  "type": "Proposition",
  "number": "3.3.17",
  "title": "Les zéros sont perpendiculaires aux lignes de la matrice.",
  "body": " Les zéros sont perpendiculaires aux lignes de la matrice  Soit , une matrice de taille , , la ligne de la matrice et , un vecteur tel que .  Alors , c'est-à-dire que les zéros de la matrice sont perpendiculaires aux lignes de celle-ci.  La preuve est essentiellement faite dans la discussion qui précède l'exemple . "
},
{
  "id": "sageex-Ax0",
  "level": "2",
  "url": "sec-SELgeo.html#sageex-Ax0",
  "type": "Calcul",
  "number": "3.3.18",
  "title": "La matrice L et les solutions de base.",
  "body": " La matrice L et les solutions de base  On souhaite créer une fonction Sage qui retourne les solutions de base d'une matrice en reproduisant l'algorithme . Pour cela, on crée d'abord une fonction matL qui va retourner la matrice associée à la forme échelonnée réduite d'une matrice quelconque. Voici quelques nouvelles fonctions Sage qui seront utiles et une manière d'ajouter des composantes à un vecteur:  Les fonctions matrix_from_rows et matrix_from_columns permettent de créer une matrice à partir des lignes ou des colonnes d'une autre matrice.    Parfois, on ne sait pas quelles seront les entrées d'un vecteur, ou bien l'on veut construire un vecteur en étape, une entrée à la fois. Pour effectuer cette opération, on utilisera plutôt une liste Sage que l'on convertira en vecteur par la suite. Par exemple, si l'on dispose d'une liste l1=[1,3,4] et d'une autre liste l2=[2,4,6] et qu'on veut créer les vecteurs qui prennent ces valeurs en alternant d'une liste à l'autre, on fera     On débute avec la création de la fonction qui retourne la matrice . On se pose dans un premier temps la question suivante: est-ce que la matrice existe toujours? Dans l'algorithme, on élimine les lignes de zéros et l'on ne garde que les colonnes libres. Que faire si toutes les lignes sont nulles ou si toutes les colonnes sont pivots? Dans ces cas, il n'y a pas de matrice , mais l'interprétation est différente pour ce qui est des solutions de base. Lorsque toutes les lignes sont nulles, toutes les variables sont libres et l'ensemble solution est donc constitué de tous les vecteurs de l'espace . Si, au contraire, toutes les variables sont pivots, alors il n'y a pas de solution de base. La seule solution à est le vecteur nul. C'est dans ce deuxième cas qu'il faudra dire à notre fonction qu'il n'y a pas de solution de base.  Pour le cas où la matrice est nulle, selon l'algorithme , les solutions spéciales devraient sortir correctement et correspondre aux vecteurs de l'espace .  Pour la matrice , on a   On teste la fonction avec la matrice de l'exemple :   On va maintenant créer la fonction solbase(A) , qui, à partir d'une matrice , va retourner les solutions de base de l'équation . À l'intérieur de celle-ci, on va utiliser la fonction matL créée ci-dessus.   On teste la fonction avec la matrice de l'exemple :   "
},
{
  "id": "ex-imggeo",
  "level": "2",
  "url": "sec-SELgeo.html#ex-imggeo",
  "type": "Exemple",
  "number": "3.3.19",
  "title": "L’image de transformations géométriques: dynamique.",
  "body": " L'image de transformations géométriques: dynamique  On considère les transformations .  On cherche à visualiser l'image de chacune de ces transformations. Pour cela, on utilise les figures interactives suivantes.   L'image de la transformation     L'image de la transformation     L'image de la transformation     L'image de la transformation    À l'exemple , on détermine algébriquement les images de ces transformations.   "
},
{
  "id": "ex-imgalg",
  "level": "2",
  "url": "sec-SELgeo.html#ex-imgalg",
  "type": "Exemple",
  "number": "3.3.24",
  "title": "L’image de transformations algébriques.",
  "body": " L'image de transformations algébriques  On considère à nouveau les matrices de l'exemple . On détermine algébriquement les images de ces transformations.   On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. On débute en supposant que . .  Comme toutes les colonnes sont pivots et qu'il n'y a pas de lignes nulles, on peut conclure que peu importe la valeur du vecteur , une solution existe (ce qui n'est pas surprenant, compte tenu de la géométrie de la rotation). En plus, on obtient cette solution en fonction des entrées de .  Puisque l'on a divisé par , on doit voir ce qui se passe lorsque ce dernier vaut . Si c'est le cas, alors ou . Dans les deux cas, la matrice se réduit aussi à l'identité à l'aide d'une permutation de lignes et d'une multiplication d'une ligne par .    On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. .  La matrice est déjà sous la forme échelonnée réduite et l'on constate que la dernière ligne (de la partie non augmentée) est nulle. Pour que le système possède une solution, il faut que le terme augmenté dans la dernière ligne soit nul aussi, c'est-à-dire, il faut que . En réécrivant, on se rend compte que les vecteurs de l'image doivent satisfaire . Ce sont précisément les vecteurs sur la droite de la figure .   Voir l'exercice .   On pose et l'on augmente la matrice avec le vecteur , afin de procéder à l'échelonnage. .  La matrice est déjà sous la forme échelonnée réduite et l'on constate que les deux dernières lignes (de la partie non augmentée) sont nulles. Pour que le système possède une solution, il faut que les termes de la partie augmentée dans ces lignes soient nuls aussi, c'est-à-dire, il faut que et . Ceci amène un nouveau système d'équations linéaires homogène à deux équations et trois inconnues. La matrice de ce système est . On utilise la fonction solbase définie plus haut afin de trouver les solutions de base de ce système.   Les vecteurs composant l'image de la transformation linéaire se trouvent donc sur les combinaisons linéaires (donc ici, la droite) du vecteur . Ceci coïncide bien avec la droite de la figure , comme le montre l'animation suivante.   L'image de la transformation     "
},
{
  "id": "prop-imasev",
  "level": "2",
  "url": "sec-SELgeo.html#prop-imasev",
  "type": "Proposition",
  "number": "3.3.26",
  "title": "L’image d’une transformation est fermée pour l’addition et la multiplication par un scalaire.",
  "body": " L'image d'une transformation est fermée pour l'addition et la multiplication par un scalaire  Soit , la matrice d'une transformation linéaire, et , des vecteurs tels que et possèdent au moins une solution. Alors  possède au moins une solution,  possède au moins une solution.    Voir l'exercice .  "
},
{
  "id": "sageex-imgalg",
  "level": "2",
  "url": "sec-SELgeo.html#sageex-imgalg",
  "type": "Calcul",
  "number": "3.3.27",
  "title": "L’image de transformations linéaires et Sage.",
  "body": "  L'image de transformations linéaires et Sage  Sage ne pourra pas travailler directement avec les variables comme si on ne l'aide pas un peu. Pour déterminer l'image d'une transformation avec Sage, trois ajustements seront nécessaires. Leur raison d'être est liée au fonctionnement du logiciel et dépasse le niveau du manuel. On se contente d'appliquer la solution. On constate l'ajout d'une ligne R.<b1,b2,b3>=QQ[] au code. De plus, la colonne augmentée est inscrite à même la matrice. Finalement, on note l'utilisation de la fonction echelon_form() plutôt que le standard rref() . Avec ces ajustements, on peut obtenir la forme échelonnée réduite de la matrice avec le vecteur variable.  On procède avec les matrices de l'exemple .   On trouve la condition . On reconnait ici l'équation normale d'un plan dans . On pourrait trouver l'équation vectorielle en isolant par exemple ou encore en utilisant solbase . Puisque ceci est un exemple Sage, on choisit ce bazooka pour tuer une mouche. Voir   On trouve une équation vectorielle pour ce même plan: .  On regarde maintenant l'image de la matrice .   On trouve les mêmes deux conditions et sur le vecteur que lors de l'exemple . La solution sera bien sûr encore la droite de vecteur directeur .  "
},
{
  "id": "rem-spancolonne",
  "level": "2",
  "url": "sec-SELgeo.html#rem-spancolonne",
  "type": "Remarque",
  "number": "3.3.28",
  "title": "",
  "body": " Le lecteur astucieux aura peut-être remarqué que les vecteurs directeurs des droites de l'image des matrices et de cette sous-section étaient un multiple d'une colonne de ces matrices. Le lecteur encore plus astucieux aura peut-être même remarqué que les vecteurs directeurs du plan de l'image de la matrice trouvés à l'exemple calculatoire sont des combinaisons linéaires de deux des colonnes de la matrice. En effet, . Pour comprendre cela, on se rappelle que le produit peut être interprété comme les combinaisons linéaires des colonnes de la matrice . L'ensemble des s'écrivant comme ces combinaisons linéaires constitue donc l'image de la transformation .  Il semble toutefois qu'il n'est pas nécessaire d'utiliser toutes les colonnes pour engendrer l'image, comme le montrent les images des matrices et . La section va donner la réponse à cette question. "
},
{
  "id": "ex-solgen",
  "level": "2",
  "url": "sec-SELgeo.html#ex-solgen",
  "type": "Exemple",
  "number": "3.3.29",
  "title": "Des systèmes à quatre équations et trois inconnues, prise deux.",
  "body": " Des systèmes à quatre équations et trois inconnues, prise deux   On reprend les systèmes et de l'exemple . La solution respective à ces systèmes était et .  Pour la matrice , le vecteur devrait être celui de la solution de base et le vecteur représente la translation de la droite de vecteur directeur . On vérifie avec la fonction solbase et la matrice . Malheureusement, on doit la redéfinir puisque l'on n'est pas dans la section principale du texte.   Pour la matrice , les vecteurs et devraient être ceux des solutions de base et le vecteur représente la translation du plan engendré par les deux premiers vecteurs. On vérifie avec la fonction solbase et la matrice .    "
},
{
  "id": "prop-solgen",
  "level": "2",
  "url": "sec-SELgeo.html#prop-solgen",
  "type": "Proposition",
  "number": "3.3.30",
  "title": "La forme générale des solutions à l’équation <span class=\"process-math\">\\(A\\vec{x}=\\vec{b}\\)<\/span>.",
  "body": " La forme générale des solutions à l'équation  Soit , une matrice , , un vecteur de pour lequel l'équation possède au moins une solution et soit , la solution à l'équation homogène . Finalement, soit , une solution particulière à l'équation . Alors représente l'ensemble de toutes les solutions à l'équation . On dit que est la solution générale.    Dans un premier temps, on vérifie que est bel et bien une solution à . .  On montre maintenant que toute solution à l'équation peut s'écrire sous cette forme. Soit , une solution à . On remarque que .  Ainsi, est une solution à l'équation . Il existe donc tels que où les vecteurs sont les solutions de base de l'équation homogène. En laissant représenter n'importe quelle solution à et en l'isolant dans l'équation , on a .   "
},
{
  "id": "ex-solpart",
  "level": "2",
  "url": "sec-SELgeo.html#ex-solpart",
  "type": "Exemple",
  "number": "3.3.31",
  "title": "La solution particulière à un système d’équations linéaire.",
  "body": " La solution particulière à un système d'équations linéaire  On reprend les systèmes de l'exemple . De plus, on considère la matrice échelonnée réduite .   On fait la matrice et la matrice ensemble. On échelonne ces systèmes afin de voir comment lire la solution particulière.   La solution particulière pour la matrice était . Ce vecteur est celui obtenu lorsque la variable libre est nulle. On remarque qu'il se trouve dans la dernière colonne de la matrice augmentée échelonnée réduite. Les entrées importantes se trouvent sur chaque ligne où il y a un pivot. L'entrée de la partie augmentée ira dans la composante de la solution particulière correspondant à la colonne qui est le pivot de la ligne. Les autres entrées du vecteur sont nulles.  Ainsi, pour la matrice , on obtient , puisque la seule variable non libre est la première et les deux suivantes sont libres.   Selon ce qui est mentionné à la fin de la démarche pour les matrices , la solution particulière se trouve dans la partie augmentée. Les lignes un et deux contiennent des pivots. Ce sont donc les entrées et qui sont importantes. Les pivots sont aux colonnes deux et quatre. La solution particulière est donc .  "
},
{
  "id": "sageex-solstd",
  "level": "2",
  "url": "sec-SELgeo.html#sageex-solstd",
  "type": "Calcul",
  "number": "3.3.32",
  "title": "La solution générale avec Sage.",
  "body": " La solution générale avec Sage  Dans cet exemple, on s'intéresse à créer une fonction solgen qui, étant donné une matrice et un vecteur, va retourner la solution générale à l'équation . La fonction devrait être relativement simple à créer, puisqu'on peut partir de la fonction solbase qui retourne déjà les solutions de base. Ce qu'il faut considérer est que maintenant, il se peut que l'équation ne possède pas de solution(s). Pour cela, on utilise la proposition .  Pour ce qui est de la solution particulière, il suffit de rappeler que les entrées importantes de celle-ci se trouvent dans la colonne augmentée de la matrice. Ces entrées sont dans les lignes non nulles de la forme échelonnée réduite et vont à la position du pivot de cette ligne.   On essaie maintenant la fonction solgen avec les systèmes de l'exemple .   "
},
{
  "id": "insight-7",
  "level": "2",
  "url": "sec-SELgeo.html#insight-7",
  "type": "Conseil",
  "number": "3.3.33",
  "title": "L’importance de tester son code.",
  "body": " L'importance de tester son code  Lorsqu'on code une fonction, il est important de bien la tester afin de vérifier qu'elle répond aux attentes et que des cas particuliers ne causent pas de problèmes. Par exemple, la fonction matL échelonne une matrice, enlève les lignes nulles et retourne la sous-matrice des colonnes qui ne sont pas pivots.  Est-ce qu'elle fonctionne toujours lorsque la matrice est déjà échelonnée?  Qu'arrive-t-il si toutes les variables sont pivots? Est-ce la réponse attendue?  Et si aucune des variables n'est pivot? Il faut qu'une autre fonction utilisant matL puisse se servir de la réponse « vide ».   Dans le cas de la fonction solbase , on a pensé à gérer le cas où il n'y a pas de solution. Est-ce qu'il y a d'autres potentiels problèmes? Encore une fois, si l'on utilise la fonction solbase dans une autre fonction, est-ce que notre retour à un cas comme cela pourra être utilisé adéquatement par cette autre fonction?  Même question s'il n'y a pas de solution de base?  Finalement, la fonction solgen prend deux arguments. L'ordre de ces arguments est-il important? Et si les arguments n'étaient pas du tout ce à quoi la fonction s'attend? Ce genre de problème peut être prévenu à l'aide de « gestion d'erreurs », mais on ne considère pas cela ici.  "
},
{
  "id": "exo-prodvec",
  "level": "2",
  "url": "sec-SELgeo.html#exo-prodvec",
  "type": "Exercice",
  "number": "3.3.4.1",
  "title": "Le produit vectoriel.",
  "body": "Le produit vectoriel Dans cet exercice, on s'intéresse à trouver les vecteurs de qui sont perpendiculaires à deux vecteurs donnés. Essentiellement, on cherche à trouver le vecteur normal au plan engendré par les deux vecteurs donnés. Soit . On cherche tel que et . Écrire le système d'équations linéaires associé à ces équations et le résoudre. avec On écrit les équations obtenues en remplaçant par les vecteurs donnés et le vecteur quelconque . La matrice et le vecteur résument le système d'équations linéaires dans l'équation matricielle . C'est un système homogène. On va donc l'échelonner sans la partie augmentée. Il n'y a qu'une seule variable libre ici, la troisième ( ). Les équations restantes sont .  Si l'on pose , on obtient la solution de base . La solution homogène est donc avec . Soit . On cherche tel que et . Écrire le système d'équations linéaires associé à ces équations et le résoudre. avec On écrit les équations obtenues en remplaçant par les vecteurs donnés et le vecteur quelconque . La matrice et le vecteur résument le système d'équations linéaires dans l'équation matricielle . C'est un système homogène. On va donc l'échelonner sans la partie augmentée. Il n'y a qu'une seule variable libre ici, la troisième ( ). Les équations restantes sont .  Si l'on pose , on obtient la solution de base . La solution homogène est donc avec . Dans les deux calculs précédents, quelle est la plus petite valeur positive de la variable libre qui fait en sorte que les entrées du vecteur sont toutes entières? Quels sont ces vecteurs ?  et  et  Refaire les parties et en remplaçant le vecteur par un vecteur quelconque . Compléter les cellules Sage ci-dessous pour faire les calculs.    Sélectionner à nouveau une valeur pour qui évite les fractions.    Le code solution pour la lettre (a)   var(\"u1,u2,u3\") u=vector([u1,u2,u3]) v=vector([2,3,4]) R.<u1,u2,u3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full()) #On utilise la fonction simplify_full() pour que les fractions soient réduites    On choisit la valeur pour obtenir le vecteur ayant des valeurs entières .   Le code solution pour la lettre (b)   var(\"u1,u2,u3\") u=vector([u1,u2,u3]) v=vector([-2,1,5]) R.<u1,u2,u3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full())    On choisit la valeur pour obtenir le vecteur à valeurs entières .  Refaire la partie en remplaçant les vecteurs par un vecteur quelconque . Compléter la cellule Sage ci-dessous pour faire les calculs   Sélectionner à nouveau une valeur pour qui évite les fractions.    Le code solution   var(\"u1,u2,u3,v1,v2,v3\") u=vector([u1,u2,u3]) v=vector([v1,v2,v3]) R.<u1,u2,u3,v1,v2,v3>=QQ[] A=matrix([u,v]) rrefA=A.echelon_form() show(\"rref(A)=\",rrefA.simplify_full())    On choisit la valeur pour obtenir le vecteur à valeurs entières .  Le vecteur est appelé le produit vectoriel de et , et est noté . On y reviendra à la section .  Ce vecteur a été obtenu en prenant la variable libre dans le système d'équations linéaires comme étant égale à pour éliminer une fraction. Il se peut toutefois que ce nombre soit nul. Dans la section , on montrera que ce n'est pas un problème. "
},
{
  "id": "exercise-166",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-166",
  "type": "Exercice",
  "number": "3.3.4.2",
  "title": "",
  "body": "On considère la matrice . Déterminer les solutions de base en fonction de .  Si , alors .  Si , alors .   Pour trouver les solutions, il faut échelonner la matrice. Puisqu'on cherche les solutions de base, il n'est pas nécessaire d'échelonner la matrice augmentée du système puisque cette colonne sera toujours nulle. La dernière étape n'est possible que si . Cela nous amène à séparer les solutions possibles en deux groupes, selon les valeurs de .  D'abord, si , alors, toutes les variables sont pivots et le système a une seule solution qui est le vecteur nul. On a donc .  Ensuite, si , alors la matrice échelonnée devient: et on peut ainsi lire le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .  Finalement, si , la matrice échelonnée est la même et donc la solution de base est la même.  "
},
{
  "id": "exercise-167",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-167",
  "type": "Exercice",
  "number": "3.3.4.3",
  "title": "",
  "body": "On considère la matrice . Déterminer les solutions de base en fonction de et .  Si et , alors .  Si , et , alors .  Si , et , alors et .  Si , alors .   Pour trouver les solutions, il faut échelonner la matrice. Puisqu'on cherche les solutions de base, il n'est pas nécessaire d'échelonner la matrice augmentée du système puisque cette colonne sera toujours nulle. Les deux dernières étapes ne sont possibles que si , puis si . Cela nous amène à séparer les solutions possibles en trois groupes, selon les valeurs de .  D'abord, si et , alors, on lit le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .  Ensuite, si , alors, la matrice échelonnée devient: Cette avant-dernière étape n'est possible que si . Dans ce cas, le vecteur solution de base est , car les variables non-pivots sont forcées à être égales à . Autrement, si , alors la matrice échelonnée devient: . On a maintenant deux variables pivots et une seule non-pivot. Les vecteurs solutions de base sont donc: et . On les a obtenus en posant alternativement chaque variable libre égale à et .  Finalement, si , la matrice échelonnée devient: . On lit le vecteur solution de base dans la colonne pivot en changeant le signe des valeurs et en posant la variable pivot à : .  "
},
{
  "id": "exo-eqvecsolhomo",
  "level": "2",
  "url": "sec-SELgeo.html#exo-eqvecsolhomo",
  "type": "Exercice",
  "number": "3.3.4.4",
  "title": "",
  "body": "Un plan a comme équation . En fonction de ce plan, que représente la solution homogène à l'équation ? Donner cette solution. L'équation vectorielle de ce plan. La solution homogène est: Puisque l'équation sous forme matricielle représente la même équation, il s'agit du même plan. La solution homogène correspondra à l'équation vectorielle de ce plan passant par l'origine. Les vecteurs directeurs seront donnés par les solutions de base. La matrice échelonnée sera: . On l'interprète en posant que les variables libres et respectivement égales à puis à . Les vecteurs solutions de base sont donc: et . La solution homogène est : Le plan est donc décrit par l'équation vectorielle : . "
},
{
  "id": "exercise-169",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-169",
  "type": "Exercice",
  "number": "3.3.4.5",
  "title": "",
  "body": "Un plan a comme équation . En fonction de ce plan, que représente la solution générale à l'équation ? Donner cette solution. L'équation vectorielle de ce plan. La solution générale est: Puisque l'équation sous forme matricielle représente la même équation, il s'agit du même plan. La solution générale correspondra à l'équation vectorielle de ce plan passant par un point de départ qui correspond à la solution particulière. Les vecteurs directeurs seront donnés par les solutions de base. La matrice augmentée échelonnée sera: . La solution homogène, qui a déjà été trouvée à l'exercice , est : . La solution particulière est obtenue de la matrice augmentée en posant toutes les variables libres égales à . Puisque seule la première variable est pivot, c'est donc elle qui prendra la seule valeur dans la partie augmentée. La solution particulière est donc: . La solution générale est : . Le plan est donc décrit par l'équation vectorielle : . "
},
{
  "id": "exo-rrefgeo1",
  "level": "2",
  "url": "sec-SELgeo.html#exo-rrefgeo1",
  "type": "Exercice",
  "number": "3.3.4.6",
  "title": "",
  "body": "Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve la solution de base à l'équation et la solution particulière à l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 1    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base. La partie augmentée sera déterminée par la solution particulière. On distinguera trois cas de figure.  D'abord, si le vecteur solution de base est , on sait que la solution homogène est égale au vecteur nul. La partie de gauche n'a donc pas le choix d'être la matrice identité puisque l'on a une solution unique. La partie augmentée sera simplement le vecteur de la solution particulière. On a donc .  Ensuite, si le vecteur solution de base est , on sait que la solution homogène est une droite et donc qu'il y a une variable libre. La variable libre est toujours celle pour laquelle le vecteur solution de base a une valeur de . C'est donc ici . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Ce vecteur sera toujours de la forme pour être une solution de l'équation matricielle .  Finalement, si le vecteur solution de base est de la forme , on sait que la solution homogène est une droite et donc qu'il y a une variable libre. La variable libre est toujours celle pour laquelle le vecteur solution de base a une valeur de . C'est donc ici . La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Ce sera donc toujours un vecteur de la forme .  "
},
{
  "id": "exercise-171",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-171",
  "type": "Exercice",
  "number": "3.3.4.7",
  "title": "",
  "body": "Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve la solution de base à l'équation et un point appartenant à l'ensemble solution de l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 2    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base exactement comme à l'exercice . La partie augmentée sera déterminée par le point appartenant à l'ensemble solution. Il faudra parfois effectuer un calcul, d'autres fois lire directement la valeur. On distinguera les mêmes trois cas de figure.  D'abord, si le vecteur solution de base est , on sait que la solution homogène est égale au vecteur nul. La partie de gauche n'a donc pas le choix d'être la matrice identité puisque l'on a une solution unique. La partie augmentée sera simplement le point appartenant à l'ensemble solution. On a donc .  Ensuite, si le vecteur solution de base est , on sait que la solution homogène est une droite et donc qu'il y a une variable libre qui est dans ce cas. La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Finalement, si le vecteur solution de base est de la forme , on sait que la solution homogène est une droite et donc qu'il y a une variable libre qui est dans ce cas-ci. La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Cependant, on n'a pas cette solution particulière avec la bonne forme, on en a une quelconque donnée par qui est dans l'ensemble solution. Il faudra donc calculer la valeur en isolant dans l'équation: .  "
},
{
  "id": "exercise-172",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-172",
  "type": "Exercice",
  "number": "3.3.4.8",
  "title": "",
  "body": "Soit , une matrice échelonnée réduite. Dans la figure ci-dessous, on retrouve un vecteur parallèle à la solution de base à l'équation et un point appartenant à l'ensemble solution de l'équation . Entrer sur la figure les valeurs pour la matrice et le vecteur qui correspondent à cette géométrie.   La géométrie de l'équation , version 3    Attention, on invite le lecteur à essayer plusieurs fois l'exercice pour arriver à comprendre les différents cas possibles avant de lire la solution. Il est clair qu'il faut bien comprendre les deux concepts en présence. La partie de gauche de la matrice augmentée sera déterminée par la solution de base exactement comme à l'exercice . La partie augmentée sera déterminée par le point appartenant à l'ensemble solution. Il faudra parfois effectuer un calcul, d'autres fois lire directement la valeur. On distinguera les mêmes trois cas de figure.  D'abord, si le vecteur donné est de la forme , on sait que le vecteur solution de base est , puisqu'il doit y avoir une variable libre qui est , la seule variable non nulle ici. Alors, on sait que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre. La partie augmentée sera toujours un vecteur de la forme où est la deuxième composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Ensuite, si le vecteur donné est de la forme , on sait que le vecteur solution de base est , puisqu'il doit y avoir une variable libre qui est , la seule variable non nulle ici. On sait alors que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la seule matrice échelonnée réduite ayant comme variable libre et pour laquelle vaut . La partie augmentée sera toujours un vecteur de la forme où est la première et seule composante du vecteur . Puisqu'on n'a pas cette solution particulière, mais seulement un point faisant partie de l'ensemble solution, il faudra déduire sa valeur. Toute solution à l'équation aura la forme: . Ainsi, la coordonnée en du point nous donne directement la valeur voulue. Aucun calcul n'est nécessaire.  Finalement, si le vecteur donné est de la forme , alors le vecteur solution de base est de la forme , puisqu'il doit y avoir une variable libre et que ça ne peut être sans que la composante du vecteur soit nulle. On obtient la valeur de à partir du fait que (ils sont parallèles). Par exemple, si , alors et donc . Ainsi, on sait que la solution homogène est une droite de vecteur directeur . La partie de gauche sera donc la matrice , puisque c'est la matrice échelonnée réduite ayant comme variable libre et donnant comme solution de base le vecteur . La partie augmentée sera toujours le vecteur où la première composante seulement peut être non nulle. Cependant, on n'a pas cette solution particulière avec la bonne forme, on en a une quelconque donnée par qui est dans l'ensemble solution. Il faudra donc calculer la valeur en isolant dans l'équation: .  "
},
{
  "id": "exercise-173",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-173",
  "type": "Exercice",
  "number": "3.3.4.9",
  "title": "",
  "body": "Donner une transformation telle que son image est égale à ses zéros. Une suffit. On suit l'indication et l'on cherche une transformation de vers . Il n'est pas facile à priori de trouver une telle transformation sans avoir une bonne intuition géométrique de ces deux concepts. On rappelle que les zéros sont l'ensemble des solutions à l'équation homogène . Ce sont donc des vecteurs du plan qui sont tels que la transformation recherchée les amènera à zéro. C'est la solution homogène à la transformation. On indique dans la question que la transformation a des zéros. Or, on sait que si elle en a plus d'un, elle en a une infinité. On a donc des zéros de la forme où est la solution de base. Pour simplifier le problème, on suppose que . Les zéros sont donc l'ensemble des vecteurs sur l'axe des . Une transformation linéaire amenant tous les vecteurs sur l'axe des à l'origine a nécessairement comme première colonne des zéros.  On propose la matrice de transformation qui envoie le vecteur à et le vecteur à . On a présenté la raison pour laquelle la première colonne est formée seulement de zéros. Pourquoi amener la deuxième colonne à ? La réponse est parce que l'on veut que l'image de la transformation soit aussi l'ensemble des vecteurs sur l'axe des . Avec cette transformation, on a effectivement: et . Ce dernier résultat constitue l'image de et est clairement un vecteur sur l'axe des . "
},
{
  "id": "exercise-174",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-174",
  "type": "Exercice",
  "number": "3.3.4.10",
  "title": "",
  "body": "Les matrices ci-dessous sont des matrices , obtenues par exemple avec la fonction matL . Pour chaque matrice, donner une matrice échelonnée réduite qui possède la matrice comme sous matrice. "
},
{
  "id": "exercise-175",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-175",
  "type": "Exercice",
  "number": "3.3.4.11",
  "title": "",
  "body": "Soit , des transformations linéaires non nulles telles que . Que peut-on dire de l'image de par rapport aux zéros de ? On a . Donner des exemples de transformations non nulles de taille telles que et determiner les zéros de et l'image de . Vérifier la relation de l'exercice précédent. Donner des exemples de transformations non nulles de taille telles que et telles que l'image de n'est pas égale aux zéros de . "
},
{
  "id": "exercise-176",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-176",
  "type": "Exercice",
  "number": "3.3.4.12",
  "title": "",
  "body": " Donner, si possible, une matrice qui a comme solution(s) de base les vecteurs suivants. Dans l'impossibilité de le faire, expliquer pourquoi.  Le vecteur . S'inspirer de l'exemple et de la proposition . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit, dans la solution de base, que ou peuvent être libres. On choisit puisque c'est plus facile et l'on met dans la colonne non pivot les valeurs correspondant à l'opposé des valeurs de et de dans . On propose de créer la matrice initiale en faisant des combinaisons linéaires des lignes non-nulles de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et ensuite . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que et sont libres, car leur composante est de dans un des vecteurs de base et de dans l'autre. La variable est donc la seule non libre. Il n'y a qu'un pivot et les valeurs sous les colonnes non pivots sont les opposés des valeurs de dans les vecteurs de base respectifs. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à et (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que et sont libres, car leur composante est de dans un des vecteurs de base et de dans l'autre. La variable est donc la seule non libre. Il n'y a qu'un pivot et les valeurs sous les colonnes non pivots sont les opposés des valeurs de dans les vecteurs de base respectifs. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait et . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à et (produit scalaire égal à zéro). Les vecteurs . Impossible. On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à . Cela est impossible puisqu'un vecteur de ne peut pas être à la fois perpendiculaire à trois différents vecteurs qui ne sont pas parallèles entre eux. Le vecteur . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que est la seule variable libre. Toutes les autres étant non libres, elles doivent être pivots. On inscrit, dans la colonne non pivot, les valeurs correspondant à l'opposé des valeurs de et de dans . On propose de créer la matrice initiale en faisant des combinaisons linéaires des lignes non nulles de la matrice échelonnée. On obtient, par exemple: . On a simplement fait , ensuite , puis et finalement . Un calcul rapide permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro). Les vecteurs . On cherche essentiellement une matrice où toutes les lignes sont perpendiculaires à et et qui donnera la matrice suivante lorsqu'échelonnée: . On peut donner directement cette matrice échelonnée puisque l'on voit dans la solution de base que , et sont libres, car leur composante est de dans un des vecteurs de base et de dans les autres. Les variables et sont donc non libres et doivent avoir un pivot. Les valeurs sous les colonnes non pivots sont les opposés des valeurs de et dans les vecteurs de base respectifs à ces colonnes. On propose de créer la matrice initiale en faisant des combinaisons linéaires de la ligne non nulle de la matrice échelonnée. On obtient, par exemple: . On a simplement fait , ensuite , puis et finalement . Un calcul rapide (un peu long!) permet de vérifier que chaque ligne est perpendiculaire à (produit scalaire égal à zéro). "
},
{
  "id": "exo-Ax0sev",
  "level": "2",
  "url": "sec-SELgeo.html#exo-Ax0sev",
  "type": "Exercice",
  "number": "3.3.4.13",
  "title": "",
  "body": "Démontrer la proposition et la proposition . D'abord, on démontre la proposition . et . Ensuite, on démontre la proposition . Soit , une solution de et , une solution de . Alors, . Une solution à est donc le vecteur . De façon semblable, . Une solution à est donc le vecteur . "
},
{
  "id": "exercise-178",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-178",
  "type": "Exercice",
  "number": "3.3.4.14",
  "title": "",
  "body": "Voici un énoncé et sa « démonstration ».  Énoncé: Soit . Cette équation a une infinité de solutions.  Démonstration: On sait qu'il existe au moins une solution à l'équation. La proposition dit que tout multiple d'une solution est aussi une solution. Il y en a donc une infinité.  Trouver l'erreur dans l'argument ci-dessus. Il est vrai que l'équation a au moins une solution. En effet, par la proposition , toute équation homogène a toujours comme solution le vecteur nul . Cependant, l'argument qu'on peut obtenir une infinité de solutions à partir de cette dernière en la multipliant par un scalaire oublie le fait que lorsqu'on multiplie le vecteur nul par un scalaire, il demeure le vecteur nul. Bref, rien ne montre dans cette « démonstration » que l'équation a d'autres solutions que la solution triviale . "
},
{
  "id": "exo-imgalg",
  "level": "2",
  "url": "sec-SELgeo.html#exo-imgalg",
  "type": "Exercice",
  "number": "3.3.4.15",
  "title": "",
  "body": "Pour chaque matrice ci-dessous, déterminer l'image de la transformation associée. On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. Aucune condition pour qu'on ait une solution n'est donnée par la matrice augmentée échelonnée. L'image est donc l'ensemble de l'espace . On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. Deux conditions pour qu'on ait une solution sont données par les deuxième et troisième lignes. En effet, il faut que et . On place ces deux équations dans une nouvelle matrice pour en trouver la solution. La solution à ce système est: . On reconnait l'équation d'une droite. On donne son équation de façon plus standard.  On s'inspire de l'exemple pour trouver l'image de cette transformation. On doit échelonner la matrice augmentée et interpréter la partie de droite. La seule condition pour qu'on ait une solution est donnée par la dernière ligne. Il faut que , sinon il n'y aura aucune solution. On reconnait l'équation normale d'un plan dans . On isole et l'on remplace dans le vecteur pour trouver l'équation vectorielle. L'image est donc le plan d'équation:  "
},
{
  "id": "exercise-180",
  "level": "2",
  "url": "sec-SELgeo.html#exercise-180",
  "type": "Exercice",
  "number": "3.3.4.16",
  "title": "",
  "body": "Utiliser Sage pour trouver l'image des matrices de l'exercice . "
},
{
  "id": "sec-transposee",
  "level": "1",
  "url": "sec-transposee.html",
  "type": "Section",
  "number": "3.4",
  "title": "La transposée d’une matrice",
  "body": "  La transposée d'une matrice    Aller aux exercices de la section.  Dans la section , on a vu une proposition avançant que les lignes d'une matrice sont perpendiculaires aux zéros de la transformation linéaire associée à . On peut se demander si les colonnes d'une matrice sont aussi perpendiculaires à un ensemble de vecteurs spécifiques.  Dans cette section, on introduit la notion de matrice transposée. On y définit aussi les quatre (sous) espaces dits fondamentaux en lien avec une matrice, soit l'espace ligne, l'espace colonne, l'espace nul et l'espace nul gauche.     La transposée d'une matrice  Pour répondre à la question en introduction, on s'imagine que les colonnes de la matrice sont les lignes d'une autre matrice. Alors ces colonnes sont perpendiculaires aux zéros de cette nouvelle transformation linéaire. Ceci motive la définition suivante.   Soit , une matrice de taille . La transposée de la matrice , notée , est la matrice où les lignes sont devenues des colonnes et les colonnes sont devenues des lignes. On a donc .   En passant La matrice transposée est parfois aussi notée avec la lettre « t » minuscule, ou encore avec une apostrophe ʹ .  On regarde quelques exemples de matrices et de leur transposée.   La transposée de certaines matrices  Soit    .  On cherche la transposée de ces matrices.   On procède en convertissant les colonnes en lignes. Soit et . On a alors . La matrice transposée est la matrice .   Cette fois, on convertit les lignes en colonnes. Soit , et . On a alors . La matrice transposée est la matrice .  Qu'on transforme les lignes en colonnes ou les colonnes en lignes, le résultat sera le même. Tant que la correspondance est respectée, soit que la ligne devienne la colonne et vice-versa, on obtient la transposée. Pour la matrice , la transposée est .   La transposée possède les propriétés suivantes.   Les propriétés de la transposée   Soit , des matrices , , une matrice et , un scalaire. Alors  ;  ;  ;  ;  si et que est inversible, on a .     Les lignes de sont les colonnes de . Si l'on transpose à nouveau, ces lignes redeviendront des colonnes. On aura alors la matrice .    Selon la définition du produit d'une matrice par un scalaire, chaque entrée de la matrice est multipliée par . Lorsqu'on transpose, on peut mettre en évidence le nombre de chaque entrée de la matrice pour retrouver .   De manière similaire, la somme de deux matrices se fait entrée par entrée avec les entrées correspondantes. Que l'on transpose avant ou après la somme ne change pas le résultat final.  D'abord, une analyse des dimensions. Le produit est le produit d'une matrice par une matrice . Le résultat sera donc une matrice . Une fois transposée, on aura une matrice . De l'autre côté, les matrices et sont respectivement des matrices de taille et . Leur produit sera donc lui aussi de taille .  On note par les lignes de la matrice et par les colonnes de la matrice . Selon la définition du produit matriciel, la matrice s'écrit . Ainsi, l'entrée en position de la matrice est donnée par le produit scalaire des vecteurs et , c'est-à-dire .  De l'autre côté, la matrice s'écrit , car les colonnes de sont les lignes de la matrice . De plus, comme les lignes de sont les colonnes de , on sait que l'entrée en position de la matrice est égale au produit scalaire entre les vecteurs et , c'est-à-dire . Comme le produit scalaire est commutatif, l'égalité est démontrée.   D'abord, on remarque que si est la matrice identité. Puisque est inversible, on a . En transposant cette égalité, on obtient et en utilisant la propriété , on obtient que . La matrice est donc inversible et, comme l'inverse d'une matrice est unique , on a .   Il faut attendre encore un peu avant de voir l'utilité géométrique de la matrice transposée. On peut toutefois donner un aperçu de la section avec l'exemple suivant.   La projection orthogonale  À l'exercice , on avait introduit la notion de transposée, mais avec les vecteurs. En considérant par défaut un vecteur comme étant debout Bien qu'on les écrive souvent couchés, on préfère considérer les vecteurs comme des colonnes essentiellement à cause du produit matrice vecteur représentant l'image du vecteur par la transformation linéaire. , on note par la matrice qui consiste en ce vecteur couché.  En particulier, on a étudié la transformation et constaté que le rang de cette transformation était égal à . On s'intéresse au cas où et à la transformation associée à la matrice .    On pose . On a .  La dernière ligne rappelle la projection orthogonale du vecteur sur le vecteur . Il manque cependant la division par . Si, toutefois, est unitaire, alors la matrice . Dans le cas général, on ajuste la formule pour avoir . Une formule semblable à celle-ci apparaitra dans la section .   L'exemple motive la définition suivante.   La matrice d'une projection orthogonale   Soit , un vecteur quelconque et soit , un vecteur unitaire dans la même direction que . La projection orthogonale sur peut être représentée par la matrice .  On appelle la matrice de l'équation la matrice standard de la projection.   On termine avec des commandes Sage en lien avec la sous-section.   La transposée sur Sage  Évidemment, Sage possède une fonction pour obtenir la transposée d'une matrice. La commande A.transpose() permet d'obtenir la matrice . La commande s'utilise aussi sous la forme transpose(A) .   Pour utiliser la forme transposée d'un vecteur, il faut d'abord le redéfinir comme une matrice.      Quatre ensembles particuliers de vecteurs  Dans la section , on a défini les zéros et l'image d'une transformation linéaire. On a aussi remarqué que les lignes de la matrice sont toujours perpendiculaires aux zéros de la transformation linéaire. On commence cette sous-section en cherchant un ensemble de vecteurs qui seraient perpendiculaires aux colonnes d'une matrice, si un tel ensemble existe.  L'idée est de passer par la transposée. Comme les colonnes de la matrice deviennent des lignes dans la matrice , il semble que celles-ci devraient être perpendiculaires aux zéros de la transformation linéaire associée à la matrice .   La relation entre les lignes, colonnes et zéros d'une matrice   Soit , une matrice. On pose , , respectivement les lignes de la matrice , et , et , respectivement les colonnes de la matrice . On cherche tous les vecteurs qui sont perpendiculaires à la fois à et et tous les vecteurs qui sont perpendiculaires à la fois à , et .    On sait que les lignes sont perpendiculaires aux zéros de la matrice . Il suffit donc de trouver les solutions de base à l'équation et de prendre toutes les combinaisons linéaires de ceux-ci. On utilise Sage pour faire les calculs.   La première variable est pivot et les deux autres sont libres. On a donc deux solutions de base qui sont .  Tout vecteur s'écrivant sous la forme est donc perpendiculaire aux lignes de la matrice . Pour les colonnes, on regarde les solutions de base à l'équation .   La première variable est pivot et la seconde est libre. Il y a donc une solution de base qui est .  Tout vecteur s'écrivant comme un multiple de est donc perpendiculaire aux lignes de la matrice et par conséquent, aux colonnes de .    On définit maintenant quatre sous-espaces associés à la matrice . Pour l'instant, on peut interpréter le mot sous-espace comme désignant des sous-ensembles de et . Dans le chapitre , on formalisera ces notions.   Les sous-espaces fondamentaux d'une matrice   Soit , une matrice de taille . On définit   L'espace nul  L'espace nul est formé de l'ensemble de tous les vecteurs qui satisfont l'équation . Ces vecteurs sont les zéros de la transformation associée à . C'est un sous-espace de . Il est formé de toutes les combinaisons linéaires des solutions de base de la matrice et du vecteur nul. On le note .  On appelle parfois l'espace nul le noyau (en anglais, on dit « kernel »).   L'espace colonne  L'espace colonne est formé de l'ensemble des combinaisons linéaires des colonnes de la matrice . C'est un sous-espace de . On le note .    L'espace ligne  L'espace ligne est formé par les combinaisons linéaires des lignes de la matrice . Il correspond à l'espace colonne de la matrice . C'est donc l'ensemble des vecteurs dans l'image de la transformation associée à la transposée de la matrice . C'est un sous-espace de . On le note ou .   L'espace nul gauche  L'espace nul gauche est simplement l'espace nul de la transposée. On le note . C'est un sous-espace de .       Géométriquement, on a dit que l'espace nul correspond aux zéros de la transformation linéaire. L'espace colonne, lui, correspond aux vecteurs dans l'image qui sont atteints par la transformation linéaire.   L'espace colonne et l'image   Soit , une transformation linéaire et , un vecteur de . Alors si et seulement si l'équation est compatible.    On commence par supposer que est dans l'espace colonne. Si l'on écrit pour les colonnes de , cela signifie qu'il existe des coefficients tels que . Le vecteur est donc une solution à l'équation , en vertu de l'équation    Ces quatre sous-espaces sont en étroite relation. Certaines d'entre elles ont déjà été constatées. On en explore quelques-unes dans les exemples qui suivent. D'autres seront formulées au chapitre .   Les quatre espaces de certaines matrices   On considère les matrices . On cherche à déterminer les quatre sous-espaces fondamentaux de ces matrices.   Les vecteurs de l'espace nul sont les combinaisons linéaires des solutions spéciales de la matrice .   En utilisant Sage, on trouve que toutes les variables sont pivots. Il n'y a pas de solutions spéciales, l'espace nul est constitué du vecteur nul seulement. Ainsi .  L'espace colonne est composé des combinaisons linéaires des colonnes de la matrice . C'est donc l'ensemble des points dans tels que . On reconnait un plan avec comme vecteurs directeurs les colonnes de . On aurait aussi pu procéder avec un vecteur et échelonner la matrice . On utilise Sage pour effectuer ce calcul.   On trouve , ce qui fait de l'image un plan de vecteur normal . À noter que ce vecteur est bel et bien perpendiculaire aux vecteurs colonnes de la matrice. On parle donc en effet du même plan.  L'espace ligne est composé des combinaisons linéaires des lignes de la matrices. C'est donc l'ensemble des vecteurs qui s'écrivent comme . Or, ces vecteurs sont dans , un plan. Deux vecteurs devraient être suffisants pour le générer. En effet, puisque , on peut simplement dire que l'espace ligne est constitué des vecteurs . Ces vecteurs sont en fait au complet.  Finalement, l'espace nul gauche. Celui-ci est fait des solutions à l'équation . Toujours avec Sage, on obtient   une seule variable libre, la troisième. La solution de base est . On remarque que ce vecteur est le même que le vecteur normal du plan de l'espace colonne de la matrice . Cela est dû au fait que les vecteurs de l'espace nul d'une matrice sont perpendiculaires aux lignes de la matrice et que .   Dans la solution précédente, il a été nécessaire d'augmenter la matrice du vecteur et de calculer la forme échelonnée réduite des matrices et pour caractériser les quatre sous-espaces. On effectue donc ces calculs immédiatement avec Sage pour ensuite aller chercher l'information nécessaire sur les espaces.   Le rang de la matrice est deux. Il y a donc une variable libre. L'espace nul est donc composé des multiples du vecteur . L'espace colonne est généré par les colonnes de la matrice . Ce sont donc l'ensemble des vecteurs tels que . Avec la forme augmentée, on remarque que l'image correspond au plan d'équation . Comme le plan est à deux dimensions et qu'il y a trois colonnes, on comprend que l'une d'entre elles est inutile dans les combinaisons linéaires. De fait, on peut facilement constater que la troisième colonne est égale à deux fois la première. On peut alors écrire l'espace colonne sous forme paramétrique comme étant l'ensemble des combinaisons linéaires des deux premières colonnes de la matrice : .  L'espace ligne est, quant à lui, composé des combinaisons linéaires des lignes de : . L'espace nul gauche est obtenu à partir de la matrice transposée. Celle-ci, sous forme échelonnée, possède une variable libre. L'espace nul gauche est donc composé de tous les multiples du vecteur . On reconnait encore une fois le vecteur normal du plan de l'image (espace colonne).  L'espace colonne est un plan, un espace à deux dimensions et l'espace nul gauche est une droite, un espace à une dimension. Ensemble, les dimensions de ces deux espaces totalisent trois, la dimension de . L'espace ligne, quant à lui, possède trois vecteurs et l'espace nul est une droite. Si l'on additionne ces dimensions, on obtient quatre. Comme l'une des colonnes n'était pas nécessaire dans les combinaisons linéaires pour l'espace colonne, on se doute que quelque chose de similaire pourrait se produire avec les lignes. La dernière ligne de la forme échelonnée réduite de est nulle. On peut avoir une bonne idée des opérations qui ont été faites pour arriver à cette ligne en regardant la colonne augmentée en . La dernière entrée est . Il semble donc que, pour éliminer la ligne trois, on a ajouté fois la ligne un et fois la ligne deux. On aurait donc . On vérifie facilement que c'est le cas avec Sage.   Avec cette remarque, on peut voir l'espace ligne comme étant les combinaisons linéaires des deux premières lignes de la matrice : . Encore une fois, la dimension de l'espace ligne ( ) additionnée à la dimension de l'espace nul ( ) donne la dimension de .  Cette relation s'avère toujours exacte et sera démontrée plus spécifiquement à la section .    On utilise la même stratégie que pour la matrice .   Le rang de la matrice est égal à . Il y a deux variables libres, et . Les solutions spéciales sont et . L'espace nul est donc le plan de engendré par ces deux vecteurs.  Selon la forme échelonnée réduite de la matrice augmentée, il n'y a aucune restriction sur les vecteurs de l'image de la transformation associée à . L'image est donc . Comme il y a quatre colonnes dans la matrice , on se doute que deux d'entre elles sont inutiles pour les combinaisons linéaires. Pour l'instant, on se contente de remarquer que deux vecteurs non parallèles de suffisent pour engendrer le plan qu'est . L'espace colonne est donc au complet.  L'espace ligne est composé des vecteurs formés des combinaisons linéaires des lignes de la matrice : . C'est aussi un plan dans . On remarque une, fois de plus, que la somme de la dimension de l'espace nul ( )et de la dimension de l'espace ligne ( ) est égale à la dimension de l'espace . De plus, les vecteurs sont perpendiculaires aux lignes de la matrice .  Finalement, on se tourne vers la transposée pour analyser l'espace nul gauche. Comme il n'y a aucune variable libre, le seul élément de l'espace nul est le vecteur . C'est un espace de dimension (un point). Additionnée à la dimension de l'espace colonne ( ), on obtient la dimension de l'espace complet .    On énonce de manière informelle les relations entre les quatre sous-espaces. On formalisera le tout lors de l'énoncé du théorème .   Relations entre les sous-espaces fondamentaux  Soit , une matrice . Alors  Si , et si , alors .  Si la dimension de est , alors la dimension de est .  Si , et si , alors .  Si la dimension de est , alors la dimension de est .     On reporte la démonstration au théorème .  On termine avec des commandes Sage en lien avec la sous-section.   Les quatre espaces avec Sage  Il est possible avec Sage de déterminer les espaces fondamentaux d'une matrice. Dans la section , on a créé une fonction solbase qui fait essentiellement ce travail pour l'espace nul. On peut maintenant utiliser la commande A.right_kernel(basis=\"pivot\") pour effectuer cette opération. On utilise right_kernel pour le noyau de droite, car Sage a une préférence pour les lignes et son noyau est par défaut le noyau de gauche (l'espace nul gauche). L'argument basis=\"pivot\" permet d'obtenir ce qu'on a appelé les solutions de base. On reprend les trois matrices de l'exemple . On note que, pour des raisons techniques, il faut ajouter QQ dans la définition de la matrice.   Ce qu'on obtient de Sage est un peu étrange. D'abord, le terme Rowspan_Q signifie l'espace engendré par les lignes de la matrice qui vient après. On comprend que les solutions de base sont retournées dans une matrice. Si l'on préfère obtenir uniquement les solutions de base, on ajoute l'option .basis() .   Lorsque la base est vide, comme pour la matrice , il faut comprendre qu'il n'y a pas de solution de base. Il ne faut toutefois pas oublier que le vecteur nul fait toujours partie de l'espace nul.  On procède de manière similaire pour l'espace colonne. On remarquera toutefois que les vecteurs obtenus ne sont pas nécessairement les mêmes que ceux de l'exemple . Dans la section , on verra une procédure systématique pour choisir les vecteurs qui génèrent l'espace colonne. En attendant, on fait confiance à Sage.   Une commande similaire pour l'espace ligne, avec la même remarque que précédemment sur la différence entre les vecteurs obtenus lors de l'exemple et ceux obtenus par Sage.   Finalement, l'espace nul gauche.       Les éléments importants de cette section sont:  La matrice transposée et ses propriétés ;  La matrice standard d'une projection orthogonale;  La définition des quatre sous-espaces fondamentaux d'une matrice;  Les relations entre ces quatre sous-espaces.    De même, avec Sage, on a vu la commande transpose() pour obtenir la transposée d'une matrice. De plus, les commandes right_kernel(basis=\"pivot\").basis() , column_space().basis() , row_space().basis() et left_kernel(basis=\"pivot\").basis() permettent d'obtenir respectivement une base des espaces nul, colonne, ligne et nul gauche. La notion de base d'un espace sera précisée dans la section .      Exercices   Soit et . Calculer, si possible, les expressions suivantes ou expliquer pourquoi le calcul est impossible.   La matrice et la matrice . Ces matrices sont de formats compatibles pour l'addition, donc . La matrice est une matrice de taille et la matrice est aussi une matrice de taille , qui sont ainsi compatibles pour l'addition. On a alors . La matrice est une matrice de taille et la matrice est une matrice de taille . Ces formats sont compatibles pour la multiplication , on a alors . C'est impossible. La matrice est de format et la matrice est de format . Ces formats ne sont pas compatibles dans l'ordre .  La matrice est de format et la matrice est de format . Ces formats sont compatibles pour la multiplication . On a .  C'est impossible. Les formats des matrices et ne sont pas compatibles pour la multiplication.  Les matrices et sont compatibles pour la multiplication. On a alors .  Les matrices et sont compatibles pour la multiplication. On a . C'est impossible Les matrices , de format et , de format ne sont pas compatibles pour la multiplication. Une matrice est toujours compatible avec la multiplication par sa transposée. On a . Une matrice est toujours compatible avec la multiplication par sa transposée. On a . La matrice est de taille et la matrice est de taille . Elles sont compatibles pour la multiplication. Ainsi .   La matrice est de format et la matrice est de taille . Elles sont compatibles pour la multiplication. Ainsi, . Les matrices et sont compatibles pour la multiplication, donc .  La matrice est de format et la matrice est de format . Le produit est donc compatible pour la multiplication. Ainsi .   Montrer que si est une matrice quelconque de taille , alors et sont définies. Donner aussi la taille des matrices et . Puisque est de taille , sa transposée est de taille . Le produit est donc bien défini pour la multiplication et donnera une matrice de taille . À l'inverse, le produit , aussi bien défini, donnera une matrice de taille .  Soit , une matrice . On considère l'équation . Quelles doivent être les dimensions des vecteurs pour que l'équation soit bien définie? Pour la démonstration, utiliser l'exercice . Le vecteur doit être dans . Le produit est un vecteur de et donc . Démontrer l'équation . Avec les vecteurs de format approprié, on réécrit le produit scalaire comme suit: .  On considère des matrices telles que pour tous les vecteurs de taille compatible. Montrer que  Utiliser les exercices et . On réécrit l'équation pour avoir . Selon l'exercice , la matrice , car l'égalité tient pour tous les vecteurs de taille compatible. Ainsi, .   Pour chaque vecteur ci-dessous, déterminer la matrice standard de la projection orthogonale sur ce vecteur.  Le vecteur est unitaire. La matrice standard de projection orthogonale sur est . Le vecteur est unitaire. La matrice standard de projection orthogonale sur est Ici, le vecteur n'est pas unitaire, on doit commencer par calculer . La matrice standard de projection orthogonale sur est  Le vecteur est unitaire. La matrice que l'on obtiendra représente la projection orthogonale dans la direction . Elle est égale à Le vecteur est unitaire. C'est un vecteur de , mais la définition fonctionne indépendamment de la dimension des vecteurs. On a donc   Les matrices symétriques  Soit , une matrice carrée . On dit que la matrice est symétrique si .  Donner deux exemples de matrices symétriques de taille et un exemple de taille . Plusieurs réponses sont possibles. Pour que , il faut que l'entrée en position soit égale à l'entrée en position . Dans le cas , n'importe quelle matrice fera l'affaire, avec . Par exemple, sont des matrices symétriques. La même règle s'applique pour une matrice et donc, toute matrice de la forme sera symétrique. Par exemple, est une matrice symétrique. Soit , une matrice quelconque. Montrer que est une matrice symétrique. En utilisant la définition, on calcule . Ainsi, la matrice est symétrique. Une matrice carrée est antisymétrique si . Donner deux exemples de matrices antisymétriques de taille et un exemple de taille . Encore une fois ici, plusieurs réponses sont possibles. Pour que soit antisymétrique, il faut que l'entrée en position soit égale à l'entrée en position , mais avec le signe opposé.  En particulier, , ce qui fait que la diagonale doit nécessairement être nulle.  Pour les matrices , toute matrice de la forme est antisymétrique. Par exemple, les matrices sont antisymétriques.  La même règle s'applique pour une matrice , en ce sens, toute matrice de la forme sera antisymétrique. Par exemple, est une matrice antisymétrique.  Que doivent valoir les éléments sur la diagonale d'une matrice antisymétrique? Pourquoi? Les entrées doivent être nulles. car on veut que . Lorsque , on obtient , qui n'est possible que lorsque . Soit , une matrice quelconque. On pose et . Montrer que est une matrice symétrique. On applique la définition de matrice symétrique. On a . La matrice est donc symétrique. Montrer que est une matrice antisymétrique. On applique la définition de matrice symétrique. On détermine . La matrice est donc antisymétrique. Montrer que toute matrice peut s'écrire comme la somme d'une matrice symétrique et d'une matrice antisymétrique. Il suffit de remarquer que .  Soit , deux matrices symétriques. Montrer que est symétrique si et seulement si .  La preuve se fait en deux parties. Dans un premier temps, on suppose que est symétrique. On veut montrer que . On a . Ceci complète la première partie de la preuve.  On suppose maintenant qu'en plus d'être symétriques, les matrices sont telles que . On veut montrer que le produit est aussi symétrique. On a . Le produit est donc symétrique.   On s'intéresse aux matrices telles que les colonnes sont composées de vecteurs orthogonaux entre eux. Soit et , son vecteur perpendiculaire. On considère la matrice dont les colonnes sont et . Calculer . Qu'y a-t-il de particulier? La matrice et sa transposée est . Leur produit donne , une matrice diagonale. C'est aussi une matrice symétrique. Répéter la partie précédente avec . La matrice et sa transposée est . Leur produit donne , une matrice diagonale. C'est aussi une matrice symétrique. Soit , une matrice telle que ses colonnes sont orthogonales entre elles. Montrer que est une matrice dont les seules entrées non nulles se situent sur la diagonale principale. Que valent les entrées non nulles? On utilise la définition du produit matriciel. La colonne du produit est donnée par le produit matrice vecteur où représente la colonne de la matrice . Les entrées de ce produit matrice vecteur correspondent à l'entrée du produit . On les calcule en prenant le produit scalaire des lignes de avec le vecteur . Comme les lignes de sont les colonnes de , on a . Par définition, les colonnes de la matrice sont orthogonales entre elles, ce produit scalaire vaut donc , sauf, évidemment, lorsque . Dans ce cas, les seules entrées non nulles de sont sur la diagonale. Elles sont égales à .  Montrer que si est une matrice de rang de taille , alors il existe des vecteurs non nuls tels que .  On a utilisé cette propriété à l'exercice .  À quoi ressemblent les lignes d'une matrice de la forme ? On pose , la première ligne non nulle de . Par simplicité, on suppose que c'est la première ligne. Soit , les lignes de la matrice . Si la matrice est de rang , alors toutes ses lignes sont parallèles. Il existe donc tels que . On pose . On a alors   On considère les matrices de permutation définies à l'exercice . Montrer que si est une matrice de permutation , alors . Il y a deux cas à vérifier. Le premier est , la matrice identité. On vérifie facilement que . Le deuxième cas est . On sait que c'est une matrice qui est son propre inverse, on remarque aussi qu'elle est symétrique. On a donc bel et bien . Utiliser le code de l'exercice pour montrer que les matrices de permutation de taille et ont cette propriété.  On inclut une cellule vide pour recopier le code de l'exercice.   La vérification peut se faire de la manière suivante (S'assurer d'avoir copié le code de l'exercice et exécuter la cellule ci-dessus).   On veut montrer que, pour une matrice de permutation , on a . Montrer que les matrices élémentaires de type ont cette propriété. On considère une matrice élémentaire de type . Cette matrice est obtenue de l'identité en échangeant la ligne et la ligne ou, de manière équivalente, la colonne avec la colonne . Les colonnes sont orthogonales entre elles et donc, selon l'exercice , le produit , où est une matrice diagonale. Comme les colonnes sont des vecteurs dont la norme vaut , le même exercice permet de déduire que . On a donc . Utiliser l'exercice pour montrer qu'une matrice de permutation quelconque possède la propriété . Une matrice pour laquelle la transposée est son inverse est dite orthogonale. Ces matrices seront très importantes dans le chapitre . Soit , une matrice de permutation quelconque. Selon l'exercice , il existe des matrices élémentaires telles que . On a .  Soit , une matrice carrée et , un vecteur qui n'est pas une combinaison linéaire des lignes de . Montrer que l'équation ne possède pas de solutions. Puisqu'on peut interpréter une solution à l'équation comme étant , où les vecteurs sont les colonnes de la matrice , on a que, si une solution existe, alors est une combinaison linéaire des colonnes de . Or, les colonnes de sont égales aux lignes de et l'on sait que n'est pas une combinaison linéaire de ces lignes. Ainsi l'équation n'a pas de solutions.   Dans cet exercice, on veut donner un sens au mot « gauche » dans l'expression espace nul gauche.  On considère la matrice . Déterminer tous les vecteurs dans l'espace nul gauche.     L'espace nul gauche consiste en l'ensemble des vecteurs tel que . On échelonne la matrice transposée pour arriver aux solutions. . Il y a une variable pivot et deux variables libres. Les solutions spéciales sont . L'espace nul gauche est l'ensemble des combinaisons linéaires de ces vecteurs, soit le plan .  Soit . Montrer que les vecteurs de l'espace nul gauche satisfont l'équation . On commence par vérifier que les vecteurs satisfont l'équation. D'une part, on a et d'autre part, pour , on a .  Soit , un vecteur de l'espace nul gauche. Alors, il existe tels que . Ainsi, .  Soit , une matrice quelconque et une vecteur, dans l'espace nul de . Montrer que satisfait l'équation . Considérer la proposition . Selon la proposition , les solutions à l'équation formant l'espace nul gauche sont perpendiculaires aux lignes de , qui elles, sont les colonnes de . Dans le produit , on fait le produit scalaire de vecteur avec les colonnes de la matrice et donc, le résultat est le vecteur nul.  Pour chaque matrice ci-dessous, trouver tous les vecteurs qui sont perpendiculaires aux lignes et tous les vecteurs qui sont perpendiculaires aux colonnes. Pour déterminer les vecteurs perpendiculaires aux lignes, il faut, selon la proposition , résoudre l'équation . La matrice est échelonnée réduite. Il y a deux variables pivots et deux variables libres. Les solutions spéciales sont . Ainsi, tout vecteur de la forme sera perpendiculaire aux lignes.  Pour trouver les vecteurs qui sont perpendiculaires aux colonnes, on transpose la matrice afin d'utiliser à nouveau la proposition . Cette fois, il faut échelonner la matrice . On a .  On a une variable libre et deux variables pivots. La solution spéciale est . Tous les vecteurs de la forme sont perpendiculaires aux lignes de et donc, aux colonnes de .   La matrice est échelonnée. Il y a une variable libre et donc, une solution spéciale . Tout multiple de ce vecteur sera perpendiculaire aux lignes de .  Pour les colonnes, on échelonne la matrice : . On a deux variables libres et trois pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces deux solutions sera perpendiculaire aux lignes de et donc, aux colonnes de .  La matrice est échelonnée réduite. Il y a deux variables libres et deux pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces solutions est perpendiculaire aux lignes de .  Pour les colonnes, on échelonne la matrice : .  Il y a deux variables libres et deux variables pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces deux solutions sera perpendiculaire aux lignes de et donc, aux colonnes de .   Pour chaque description ci-dessous, donner une matrice qui la satisfait. La matrice est avec , elle ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs parallèles à . La manière la plus simple est de mettre le vecteur dans les colonnes d'une matrice jusqu'à ce que . Un exemple est donc . L'espace colonne étant l'ensemble des combinaisons linéaires des colonnes de la matrice, cette matrice respecte la condition que son espace colonne ne contient que les vecteurs parallèles à , puisque les colonnes sont toutes égales à . De manière générale, on aurait pu avoir n'importe quelle matrice de la forme où et . La matrice ne contient aucune entrée égale à zéro et possède comme espace nul que les vecteurs parallèles à .  En d'autres mots, on veut que la solution spéciale à l'équation soit un multiple du vecteur . Le vecteur satisfait cette contrainte. La matrice échelonnée réduite la plus simple qui correspond à cette situation serait . Pour respecter la condition de n'avoir aucune entrée égale à zéro, il suffit de prendre un multiple de la ligne un et de l'ajouter à la ligne deux. L'exemple le plus simple serait de copier la ligne un à la ligne deux . De manière générale, toute matrice de la forme ferait l'affaire.  La matrice avec ne contient aucune entrée égale à zéro et possède comme espace ligne que les vecteurs parallèles à . Il doit y avoir deux colonnes, car l'espace ligne est dans . Il y aura donc quatre lignes pour satisfaire . La manière la plus simple est de copier le vecteur aux quatre lignes de la matrice. De manière générale, toute matrice de la forme où fera l'affaire. La matrice ne contient aucune entrée égale à zéro et possède comme espace nul gauche que les vecteurs parallèles à . De manière semblable à la matrice trouvée pour que l'espace nul soit composé uniquement des multiples de , on montre que la matrice aura comme espace nul les multiples du vecteur . On ajoute à la ligne deux un multiple de la ligne un pour avoir en général . Puisque l'espace nul gauche est , si l'on prend comme matrice , son espace nul gauche va correspondre à l'espace nul de et aura les conditions requises. Toute matrice de la forme fera l'affaire. La matrice ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs parallèles à . L'idée est la même que précédemment, toute matrice de la forme fera l'affaire. La matrice est carrée, ne contient aucune entrée égale à zéro, les lignes ne sont pas parallèles entre elles et possède comme espace nul que les vecteurs parallèles à . Encore ici, on cherche une matrice dont la forme échelonnée n'aura qu'une solution de base. La matrice échelonnée réduite a pour seule solution spéciale le vecteur . Pour éliminer les zéros, on fait des opérations élémentaires sur les lignes. Par exemple, . Évidemment, d'autres choix de facteurs auraient pu être faits pour les opérations élémentaires. La matrice ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs qui sont des combinaisons linéaires des vecteurs . Le plus simple consiste à mettre les deux vecteurs comme des colonnes d'une matrice. Ainsi, fait l'affaire. La matrice carrée ne contient aucune entrée égale à zéro, aucune fraction et possède comme espace nul que les vecteurs qui sont des combinaisons linéaires des vecteurs . Les vecteurs n'ont pas la forme de solutions de base. Le fait qu'il faut deux vecteurs pour générer l'espace nul signifie qu'il doit y avoir deux variables libres. Si l'on suppose que sont les variables libres, il faudrait que les vecteurs soit de la forme pour respecter la forme des solutions de base. On cherche donc comment, à partir de , on peut obtenir ces vecteurs. On veut . Comme on ne se soucie pas de la première composante, on a que et . Pour le vecteur , on obtient de manière similaire les équations et . On peut résoudre simultanément ces systèmes en échelonnant la matrice augmentée . Le premier vecteur est et le deuxième vecteur est .  Une matrice échelonnée réduite ayant ces deux vecteurs comme solutions de base serait . Pour satisfaire les conditions d'entrées non nulles et d'absence de fractions, on peut multiplier la première ligne par trois et recopier cette ligne dans les deux autres. On a donc  La matrice carrée ne contient aucune ligne parallèle, aucune entrée égale à zéro et possède comme espace ligne que les vecteurs qui sont des combinaisons linéaires des vecteurs . La réponse la plus simple consiste à inscrire les vecteurs dans les deux premières lignes d'une matrice dont la troisième sera nulle et d'utiliser les opérations élémentaires pour éliminer les zéros. On a donc , la dernière étape étant nécessaire pour respecter la condition que les lignes ne soient pas parallèles. La matrice ne contient aucune entrée égale à zéro et possède comme espace nul gauche que les vecteurs qui sont des combinaisons linéaires des vecteurs . On cherche une matrice telle que la transposée aura deux solutions de base. On commence par construire la transposée. Les vecteurs ont la forme de solution de base si les variables sont libres. On construit donc une matrice échelonnée réduite qui aura ces vecteurs comme solution de base: . On peut ensuite appliquer des opérations élémentaires sur les lignes afin d'éliminer les zéros. On pourrait avoir, par exemple, .  Finalement, pour que la matrice ait comme espace nul gauche l'espace engendré par les vecteurs , on prend la transposée de la matrice ci-dessus : .    Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières possibles d'arriver aux réponses.   Utiliser la fonction matquelc de l'exemple calculatoire pour vérifier les égalités suivantes. Recopier le code de la fonction matquelc ci-dessous dans un premier temps et exécuter ensuite la cellule.   Une matrice de taille multipliée par sa transposée est une matrice symétrique. (La commande A.is_symmetric() permet de vérifier si la matrice est symétrique ou non.    Le code de la solution   A=matquelc(5,4,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A*(A.transpose())).is_symmetric()    Soit , une matrice . La matrice est symétrique.    Le code de la solution   A=matquelc(5,5,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A+(A.transpose())).is_symmetric()    Soit , une matrice . La matrice est antisymétrique (La commande pour antisymétrique sur Sage est A.is_skew_symmetric() .    Le code de la solution   A=matquelc(7,7,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A*(A.transpose())).is_skew_symmetric()    Vérifier les quatre premières propriétés de la proposition avec et .    Le code de la solution   A=matquelc(4,5,'a') B=matquelc(4,5,'b') C=matquelc(5,6,'c') var(\"k\") show(\"La propriété 1 est \",(A.transpose()).transpose()==A) show(\"La propriété 2 est \",(k*A).transpose()==k*(A.transpose())) show(\"La propriété 3 est \",(A+B).transpose()==A.transpose()+B.transpose()) show(\"La propriété 4 est \",(A*C).transpose()==(C.transpose())*(A.transpose()))     Refaire les cas possibles de l'exercice .    Le code de la solution   A=matrix([[1,-2],[3,1]]) B=matrix([[3,2],[1,5]]) C=matrix([[2,-2,3],[0,2,1]]) D=matrix([[7,-1],[2,4],[1,0]]) show(\"A^T=\",A.transpose()) show(\"4A-5B^T=\",4*A-5*B.transpose()) show(\"C^T=\",C.transpose()) show(\"C^T+D\",C.transpose()+D) show(\"A^TC\",A.transpose()*C) show(\"AC^T n'est pas possible\") show(\"C^TB^T=\",(C.transpose())*(B.transpose())) show(\"BD n'est pas possible\") show(\"BD^T=\",B*(D.transpose())) show(\"DB=\",D*B) show(\"D^TB n'est pas possible\") show(\"CC^T=\",C*(C.transpose())) show(\"C^TC=\",C.transpose()*C) show(\"CD=\",C*D) show(\"C^TD^T=\",C.transpose()*D.transpose()) show(\"DC=\",D*C) show(\"D^TC^T=\",D.transpose()*C.transpose())     Déterminer, à la manière de l'exemple calculatoire , les espaces fondamentaux des matrices de l'exercice   .     Le code de la solution   A1=matrix(QQ,[[1,-3,-4,0],[0,0,0,1],[0,0,0,0]]) A2=matrix(QQ,[[1,0,0,-1],[0,1,0,3],[0,0,1,-4],[0,0,0,0],[0,0,0,0]]) A3=matrix(QQ,[[1,4,0,1],[0,0,1,-2],[0,0,0,0],[0,0,0,0]]) ####Pour la matrice A1#### show(\"Pour la matrice A1\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A1.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A1.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A1.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A1.left_kernel(basis=\"pivot\").basis()) ########################################## ####Pour la matrice A1#### show(\"Pour la matrice A2\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A2.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A2.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A2.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A2.left_kernel(basis=\"pivot\").basis()) ############################################## ####Pour la matrice A1#### show(\"Pour la matrice A3\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A3.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A3.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A3.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A3.left_kernel(basis=\"pivot\").basis())sub       "
},
{
  "id": "def-transposee",
  "level": "2",
  "url": "sec-transposee.html#def-transposee",
  "type": "Définition",
  "number": "3.4.1",
  "title": "",
  "body": " Soit , une matrice de taille . La transposée de la matrice , notée , est la matrice où les lignes sont devenues des colonnes et les colonnes sont devenues des lignes. On a donc .  "
},
{
  "id": "example-73",
  "level": "2",
  "url": "sec-transposee.html#example-73",
  "type": "Exemple",
  "number": "3.4.2",
  "title": "La transposée de certaines matrices.",
  "body": " La transposée de certaines matrices  Soit    .  On cherche la transposée de ces matrices.   On procède en convertissant les colonnes en lignes. Soit et . On a alors . La matrice transposée est la matrice .   Cette fois, on convertit les lignes en colonnes. Soit , et . On a alors . La matrice transposée est la matrice .  Qu'on transforme les lignes en colonnes ou les colonnes en lignes, le résultat sera le même. Tant que la correspondance est respectée, soit que la ligne devienne la colonne et vice-versa, on obtient la transposée. Pour la matrice , la transposée est .  "
},
{
  "id": "prop-transposeeprop",
  "level": "2",
  "url": "sec-transposee.html#prop-transposeeprop",
  "type": "Proposition",
  "number": "3.4.3",
  "title": "Les propriétés de la transposée.",
  "body": " Les propriétés de la transposée   Soit , des matrices , , une matrice et , un scalaire. Alors  ;  ;  ;  ;  si et que est inversible, on a .     Les lignes de sont les colonnes de . Si l'on transpose à nouveau, ces lignes redeviendront des colonnes. On aura alors la matrice .    Selon la définition du produit d'une matrice par un scalaire, chaque entrée de la matrice est multipliée par . Lorsqu'on transpose, on peut mettre en évidence le nombre de chaque entrée de la matrice pour retrouver .   De manière similaire, la somme de deux matrices se fait entrée par entrée avec les entrées correspondantes. Que l'on transpose avant ou après la somme ne change pas le résultat final.  D'abord, une analyse des dimensions. Le produit est le produit d'une matrice par une matrice . Le résultat sera donc une matrice . Une fois transposée, on aura une matrice . De l'autre côté, les matrices et sont respectivement des matrices de taille et . Leur produit sera donc lui aussi de taille .  On note par les lignes de la matrice et par les colonnes de la matrice . Selon la définition du produit matriciel, la matrice s'écrit . Ainsi, l'entrée en position de la matrice est donnée par le produit scalaire des vecteurs et , c'est-à-dire .  De l'autre côté, la matrice s'écrit , car les colonnes de sont les lignes de la matrice . De plus, comme les lignes de sont les colonnes de , on sait que l'entrée en position de la matrice est égale au produit scalaire entre les vecteurs et , c'est-à-dire . Comme le produit scalaire est commutatif, l'égalité est démontrée.   D'abord, on remarque que si est la matrice identité. Puisque est inversible, on a . En transposant cette égalité, on obtient et en utilisant la propriété , on obtient que . La matrice est donc inversible et, comme l'inverse d'une matrice est unique , on a .  "
},
{
  "id": "ex-projorthomat",
  "level": "2",
  "url": "sec-transposee.html#ex-projorthomat",
  "type": "Exemple",
  "number": "3.4.4",
  "title": "La projection orthogonale.",
  "body": " La projection orthogonale  À l'exercice , on avait introduit la notion de transposée, mais avec les vecteurs. En considérant par défaut un vecteur comme étant debout Bien qu'on les écrive souvent couchés, on préfère considérer les vecteurs comme des colonnes essentiellement à cause du produit matrice vecteur représentant l'image du vecteur par la transformation linéaire. , on note par la matrice qui consiste en ce vecteur couché.  En particulier, on a étudié la transformation et constaté que le rang de cette transformation était égal à . On s'intéresse au cas où et à la transformation associée à la matrice .    On pose . On a .  La dernière ligne rappelle la projection orthogonale du vecteur sur le vecteur . Il manque cependant la division par . Si, toutefois, est unitaire, alors la matrice . Dans le cas général, on ajuste la formule pour avoir . Une formule semblable à celle-ci apparaitra dans la section .  "
},
{
  "id": "def-projorthomat",
  "level": "2",
  "url": "sec-transposee.html#def-projorthomat",
  "type": "Définition",
  "number": "3.4.5",
  "title": "La matrice d’une projection orthogonale.",
  "body": " La matrice d'une projection orthogonale   Soit , un vecteur quelconque et soit , un vecteur unitaire dans la même direction que . La projection orthogonale sur peut être représentée par la matrice .  On appelle la matrice de l'équation la matrice standard de la projection.  "
},
{
  "id": "computation-26",
  "level": "2",
  "url": "sec-transposee.html#computation-26",
  "type": "Calcul",
  "number": "3.4.6",
  "title": "La transposée sur Sage.",
  "body": " La transposée sur Sage  Évidemment, Sage possède une fonction pour obtenir la transposée d'une matrice. La commande A.transpose() permet d'obtenir la matrice . La commande s'utilise aussi sous la forme transpose(A) .   Pour utiliser la forme transposée d'un vecteur, il faut d'abord le redéfinir comme une matrice.   "
},
{
  "id": "example-75",
  "level": "2",
  "url": "sec-transposee.html#example-75",
  "type": "Exemple",
  "number": "3.4.7",
  "title": "La relation entre les lignes, colonnes et zéros d’une matrice.",
  "body": " La relation entre les lignes, colonnes et zéros d'une matrice   Soit , une matrice. On pose , , respectivement les lignes de la matrice , et , et , respectivement les colonnes de la matrice . On cherche tous les vecteurs qui sont perpendiculaires à la fois à et et tous les vecteurs qui sont perpendiculaires à la fois à , et .    On sait que les lignes sont perpendiculaires aux zéros de la matrice . Il suffit donc de trouver les solutions de base à l'équation et de prendre toutes les combinaisons linéaires de ceux-ci. On utilise Sage pour faire les calculs.   La première variable est pivot et les deux autres sont libres. On a donc deux solutions de base qui sont .  Tout vecteur s'écrivant sous la forme est donc perpendiculaire aux lignes de la matrice . Pour les colonnes, on regarde les solutions de base à l'équation .   La première variable est pivot et la seconde est libre. Il y a donc une solution de base qui est .  Tout vecteur s'écrivant comme un multiple de est donc perpendiculaire aux lignes de la matrice et par conséquent, aux colonnes de .   "
},
{
  "id": "def-4espaces",
  "level": "2",
  "url": "sec-transposee.html#def-4espaces",
  "type": "Définition",
  "number": "3.4.8",
  "title": "Les sous-espaces fondamentaux d’une matrice.",
  "body": " Les sous-espaces fondamentaux d'une matrice   Soit , une matrice de taille . On définit   L'espace nul  L'espace nul est formé de l'ensemble de tous les vecteurs qui satisfont l'équation . Ces vecteurs sont les zéros de la transformation associée à . C'est un sous-espace de . Il est formé de toutes les combinaisons linéaires des solutions de base de la matrice et du vecteur nul. On le note .  On appelle parfois l'espace nul le noyau (en anglais, on dit « kernel »).   L'espace colonne  L'espace colonne est formé de l'ensemble des combinaisons linéaires des colonnes de la matrice . C'est un sous-espace de . On le note .    L'espace ligne  L'espace ligne est formé par les combinaisons linéaires des lignes de la matrice . Il correspond à l'espace colonne de la matrice . C'est donc l'ensemble des vecteurs dans l'image de la transformation associée à la transposée de la matrice . C'est un sous-espace de . On le note ou .   L'espace nul gauche  L'espace nul gauche est simplement l'espace nul de la transposée. On le note . C'est un sous-espace de .      "
},
{
  "id": "prop-espcolimg",
  "level": "2",
  "url": "sec-transposee.html#prop-espcolimg",
  "type": "Proposition",
  "number": "3.4.9",
  "title": "L’espace colonne et l’image.",
  "body": " L'espace colonne et l'image   Soit , une transformation linéaire et , un vecteur de . Alors si et seulement si l'équation est compatible.    On commence par supposer que est dans l'espace colonne. Si l'on écrit pour les colonnes de , cela signifie qu'il existe des coefficients tels que . Le vecteur est donc une solution à l'équation , en vertu de l'équation   "
},
{
  "id": "ex-4esp1",
  "level": "2",
  "url": "sec-transposee.html#ex-4esp1",
  "type": "Exemple",
  "number": "3.4.10",
  "title": "Les quatre espaces de certaines matrices.",
  "body": " Les quatre espaces de certaines matrices   On considère les matrices . On cherche à déterminer les quatre sous-espaces fondamentaux de ces matrices.   Les vecteurs de l'espace nul sont les combinaisons linéaires des solutions spéciales de la matrice .   En utilisant Sage, on trouve que toutes les variables sont pivots. Il n'y a pas de solutions spéciales, l'espace nul est constitué du vecteur nul seulement. Ainsi .  L'espace colonne est composé des combinaisons linéaires des colonnes de la matrice . C'est donc l'ensemble des points dans tels que . On reconnait un plan avec comme vecteurs directeurs les colonnes de . On aurait aussi pu procéder avec un vecteur et échelonner la matrice . On utilise Sage pour effectuer ce calcul.   On trouve , ce qui fait de l'image un plan de vecteur normal . À noter que ce vecteur est bel et bien perpendiculaire aux vecteurs colonnes de la matrice. On parle donc en effet du même plan.  L'espace ligne est composé des combinaisons linéaires des lignes de la matrices. C'est donc l'ensemble des vecteurs qui s'écrivent comme . Or, ces vecteurs sont dans , un plan. Deux vecteurs devraient être suffisants pour le générer. En effet, puisque , on peut simplement dire que l'espace ligne est constitué des vecteurs . Ces vecteurs sont en fait au complet.  Finalement, l'espace nul gauche. Celui-ci est fait des solutions à l'équation . Toujours avec Sage, on obtient   une seule variable libre, la troisième. La solution de base est . On remarque que ce vecteur est le même que le vecteur normal du plan de l'espace colonne de la matrice . Cela est dû au fait que les vecteurs de l'espace nul d'une matrice sont perpendiculaires aux lignes de la matrice et que .   Dans la solution précédente, il a été nécessaire d'augmenter la matrice du vecteur et de calculer la forme échelonnée réduite des matrices et pour caractériser les quatre sous-espaces. On effectue donc ces calculs immédiatement avec Sage pour ensuite aller chercher l'information nécessaire sur les espaces.   Le rang de la matrice est deux. Il y a donc une variable libre. L'espace nul est donc composé des multiples du vecteur . L'espace colonne est généré par les colonnes de la matrice . Ce sont donc l'ensemble des vecteurs tels que . Avec la forme augmentée, on remarque que l'image correspond au plan d'équation . Comme le plan est à deux dimensions et qu'il y a trois colonnes, on comprend que l'une d'entre elles est inutile dans les combinaisons linéaires. De fait, on peut facilement constater que la troisième colonne est égale à deux fois la première. On peut alors écrire l'espace colonne sous forme paramétrique comme étant l'ensemble des combinaisons linéaires des deux premières colonnes de la matrice : .  L'espace ligne est, quant à lui, composé des combinaisons linéaires des lignes de : . L'espace nul gauche est obtenu à partir de la matrice transposée. Celle-ci, sous forme échelonnée, possède une variable libre. L'espace nul gauche est donc composé de tous les multiples du vecteur . On reconnait encore une fois le vecteur normal du plan de l'image (espace colonne).  L'espace colonne est un plan, un espace à deux dimensions et l'espace nul gauche est une droite, un espace à une dimension. Ensemble, les dimensions de ces deux espaces totalisent trois, la dimension de . L'espace ligne, quant à lui, possède trois vecteurs et l'espace nul est une droite. Si l'on additionne ces dimensions, on obtient quatre. Comme l'une des colonnes n'était pas nécessaire dans les combinaisons linéaires pour l'espace colonne, on se doute que quelque chose de similaire pourrait se produire avec les lignes. La dernière ligne de la forme échelonnée réduite de est nulle. On peut avoir une bonne idée des opérations qui ont été faites pour arriver à cette ligne en regardant la colonne augmentée en . La dernière entrée est . Il semble donc que, pour éliminer la ligne trois, on a ajouté fois la ligne un et fois la ligne deux. On aurait donc . On vérifie facilement que c'est le cas avec Sage.   Avec cette remarque, on peut voir l'espace ligne comme étant les combinaisons linéaires des deux premières lignes de la matrice : . Encore une fois, la dimension de l'espace ligne ( ) additionnée à la dimension de l'espace nul ( ) donne la dimension de .  Cette relation s'avère toujours exacte et sera démontrée plus spécifiquement à la section .    On utilise la même stratégie que pour la matrice .   Le rang de la matrice est égal à . Il y a deux variables libres, et . Les solutions spéciales sont et . L'espace nul est donc le plan de engendré par ces deux vecteurs.  Selon la forme échelonnée réduite de la matrice augmentée, il n'y a aucune restriction sur les vecteurs de l'image de la transformation associée à . L'image est donc . Comme il y a quatre colonnes dans la matrice , on se doute que deux d'entre elles sont inutiles pour les combinaisons linéaires. Pour l'instant, on se contente de remarquer que deux vecteurs non parallèles de suffisent pour engendrer le plan qu'est . L'espace colonne est donc au complet.  L'espace ligne est composé des vecteurs formés des combinaisons linéaires des lignes de la matrice : . C'est aussi un plan dans . On remarque une, fois de plus, que la somme de la dimension de l'espace nul ( )et de la dimension de l'espace ligne ( ) est égale à la dimension de l'espace . De plus, les vecteurs sont perpendiculaires aux lignes de la matrice .  Finalement, on se tourne vers la transposée pour analyser l'espace nul gauche. Comme il n'y a aucune variable libre, le seul élément de l'espace nul est le vecteur . C'est un espace de dimension (un point). Additionnée à la dimension de l'espace colonne ( ), on obtient la dimension de l'espace complet .   "
},
{
  "id": "prop-fondlinalg",
  "level": "2",
  "url": "sec-transposee.html#prop-fondlinalg",
  "type": "Proposition",
  "number": "3.4.11",
  "title": "Relations entre les sous-espaces fondamentaux.",
  "body": " Relations entre les sous-espaces fondamentaux  Soit , une matrice . Alors  Si , et si , alors .  Si la dimension de est , alors la dimension de est .  Si , et si , alors .  Si la dimension de est , alors la dimension de est .    "
},
{
  "id": "proof-44",
  "level": "2",
  "url": "sec-transposee.html#proof-44",
  "type": "Démonstration",
  "number": "3.4.2.1",
  "title": "",
  "body": "On reporte la démonstration au théorème . "
},
{
  "id": "sageex-espfond",
  "level": "2",
  "url": "sec-transposee.html#sageex-espfond",
  "type": "Calcul",
  "number": "3.4.12",
  "title": "Les quatre espaces avec Sage.",
  "body": " Les quatre espaces avec Sage  Il est possible avec Sage de déterminer les espaces fondamentaux d'une matrice. Dans la section , on a créé une fonction solbase qui fait essentiellement ce travail pour l'espace nul. On peut maintenant utiliser la commande A.right_kernel(basis=\"pivot\") pour effectuer cette opération. On utilise right_kernel pour le noyau de droite, car Sage a une préférence pour les lignes et son noyau est par défaut le noyau de gauche (l'espace nul gauche). L'argument basis=\"pivot\" permet d'obtenir ce qu'on a appelé les solutions de base. On reprend les trois matrices de l'exemple . On note que, pour des raisons techniques, il faut ajouter QQ dans la définition de la matrice.   Ce qu'on obtient de Sage est un peu étrange. D'abord, le terme Rowspan_Q signifie l'espace engendré par les lignes de la matrice qui vient après. On comprend que les solutions de base sont retournées dans une matrice. Si l'on préfère obtenir uniquement les solutions de base, on ajoute l'option .basis() .   Lorsque la base est vide, comme pour la matrice , il faut comprendre qu'il n'y a pas de solution de base. Il ne faut toutefois pas oublier que le vecteur nul fait toujours partie de l'espace nul.  On procède de manière similaire pour l'espace colonne. On remarquera toutefois que les vecteurs obtenus ne sont pas nécessairement les mêmes que ceux de l'exemple . Dans la section , on verra une procédure systématique pour choisir les vecteurs qui génèrent l'espace colonne. En attendant, on fait confiance à Sage.   Une commande similaire pour l'espace ligne, avec la même remarque que précédemment sur la différence entre les vecteurs obtenus lors de l'exemple et ceux obtenus par Sage.   Finalement, l'espace nul gauche.   "
},
{
  "id": "exo-transpose",
  "level": "2",
  "url": "sec-transposee.html#exo-transpose",
  "type": "Exercice",
  "number": "3.4.3.1",
  "title": "",
  "body": "Soit et . Calculer, si possible, les expressions suivantes ou expliquer pourquoi le calcul est impossible.   La matrice et la matrice . Ces matrices sont de formats compatibles pour l'addition, donc . La matrice est une matrice de taille et la matrice est aussi une matrice de taille , qui sont ainsi compatibles pour l'addition. On a alors . La matrice est une matrice de taille et la matrice est une matrice de taille . Ces formats sont compatibles pour la multiplication , on a alors . C'est impossible. La matrice est de format et la matrice est de format . Ces formats ne sont pas compatibles dans l'ordre .  La matrice est de format et la matrice est de format . Ces formats sont compatibles pour la multiplication . On a .  C'est impossible. Les formats des matrices et ne sont pas compatibles pour la multiplication.  Les matrices et sont compatibles pour la multiplication. On a alors .  Les matrices et sont compatibles pour la multiplication. On a . C'est impossible Les matrices , de format et , de format ne sont pas compatibles pour la multiplication. Une matrice est toujours compatible avec la multiplication par sa transposée. On a . Une matrice est toujours compatible avec la multiplication par sa transposée. On a . La matrice est de taille et la matrice est de taille . Elles sont compatibles pour la multiplication. Ainsi .   La matrice est de format et la matrice est de taille . Elles sont compatibles pour la multiplication. Ainsi, . Les matrices et sont compatibles pour la multiplication, donc .  La matrice est de format et la matrice est de format . Le produit est donc compatible pour la multiplication. Ainsi .  "
},
{
  "id": "exercise-182",
  "level": "2",
  "url": "sec-transposee.html#exercise-182",
  "type": "Exercice",
  "number": "3.4.3.2",
  "title": "",
  "body": "Montrer que si est une matrice quelconque de taille , alors et sont définies. Donner aussi la taille des matrices et . Puisque est de taille , sa transposée est de taille . Le produit est donc bien défini pour la multiplication et donnera une matrice de taille . À l'inverse, le produit , aussi bien défini, donnera une matrice de taille . "
},
{
  "id": "exo-prodscaltransposee",
  "level": "2",
  "url": "sec-transposee.html#exo-prodscaltransposee",
  "type": "Exercice",
  "number": "3.4.3.3",
  "title": "",
  "body": "Soit , une matrice . On considère l'équation . Quelles doivent être les dimensions des vecteurs pour que l'équation soit bien définie? Pour la démonstration, utiliser l'exercice . Le vecteur doit être dans . Le produit est un vecteur de et donc . Démontrer l'équation . Avec les vecteurs de format approprié, on réécrit le produit scalaire comme suit: . "
},
{
  "id": "exercise-184",
  "level": "2",
  "url": "sec-transposee.html#exercise-184",
  "type": "Exercice",
  "number": "3.4.3.4",
  "title": "",
  "body": "On considère des matrices telles que pour tous les vecteurs de taille compatible. Montrer que  Utiliser les exercices et . On réécrit l'équation pour avoir . Selon l'exercice , la matrice , car l'égalité tient pour tous les vecteurs de taille compatible. Ainsi, . "
},
{
  "id": "exercise-185",
  "level": "2",
  "url": "sec-transposee.html#exercise-185",
  "type": "Exercice",
  "number": "3.4.3.5",
  "title": "",
  "body": " Pour chaque vecteur ci-dessous, déterminer la matrice standard de la projection orthogonale sur ce vecteur.  Le vecteur est unitaire. La matrice standard de projection orthogonale sur est . Le vecteur est unitaire. La matrice standard de projection orthogonale sur est Ici, le vecteur n'est pas unitaire, on doit commencer par calculer . La matrice standard de projection orthogonale sur est  Le vecteur est unitaire. La matrice que l'on obtiendra représente la projection orthogonale dans la direction . Elle est égale à Le vecteur est unitaire. C'est un vecteur de , mais la définition fonctionne indépendamment de la dimension des vecteurs. On a donc  "
},
{
  "id": "exo-matsym",
  "level": "2",
  "url": "sec-transposee.html#exo-matsym",
  "type": "Exercice",
  "number": "3.4.3.6",
  "title": "Les matrices symétriques.",
  "body": "Les matrices symétriques  Soit , une matrice carrée . On dit que la matrice est symétrique si .  Donner deux exemples de matrices symétriques de taille et un exemple de taille . Plusieurs réponses sont possibles. Pour que , il faut que l'entrée en position soit égale à l'entrée en position . Dans le cas , n'importe quelle matrice fera l'affaire, avec . Par exemple, sont des matrices symétriques. La même règle s'applique pour une matrice et donc, toute matrice de la forme sera symétrique. Par exemple, est une matrice symétrique. Soit , une matrice quelconque. Montrer que est une matrice symétrique. En utilisant la définition, on calcule . Ainsi, la matrice est symétrique. Une matrice carrée est antisymétrique si . Donner deux exemples de matrices antisymétriques de taille et un exemple de taille . Encore une fois ici, plusieurs réponses sont possibles. Pour que soit antisymétrique, il faut que l'entrée en position soit égale à l'entrée en position , mais avec le signe opposé.  En particulier, , ce qui fait que la diagonale doit nécessairement être nulle.  Pour les matrices , toute matrice de la forme est antisymétrique. Par exemple, les matrices sont antisymétriques.  La même règle s'applique pour une matrice , en ce sens, toute matrice de la forme sera antisymétrique. Par exemple, est une matrice antisymétrique.  Que doivent valoir les éléments sur la diagonale d'une matrice antisymétrique? Pourquoi? Les entrées doivent être nulles. car on veut que . Lorsque , on obtient , qui n'est possible que lorsque . Soit , une matrice quelconque. On pose et . Montrer que est une matrice symétrique. On applique la définition de matrice symétrique. On a . La matrice est donc symétrique. Montrer que est une matrice antisymétrique. On applique la définition de matrice symétrique. On détermine . La matrice est donc antisymétrique. Montrer que toute matrice peut s'écrire comme la somme d'une matrice symétrique et d'une matrice antisymétrique. Il suffit de remarquer que . "
},
{
  "id": "exercise-187",
  "level": "2",
  "url": "sec-transposee.html#exercise-187",
  "type": "Exercice",
  "number": "3.4.3.7",
  "title": "",
  "body": "Soit , deux matrices symétriques. Montrer que est symétrique si et seulement si .  La preuve se fait en deux parties. Dans un premier temps, on suppose que est symétrique. On veut montrer que . On a . Ceci complète la première partie de la preuve.  On suppose maintenant qu'en plus d'être symétriques, les matrices sont telles que . On veut montrer que le produit est aussi symétrique. On a . Le produit est donc symétrique.  "
},
{
  "id": "exercise-188",
  "level": "2",
  "url": "sec-transposee.html#exercise-188",
  "type": "Exercice",
  "number": "3.4.3.8",
  "title": "",
  "body": "On s'intéresse aux matrices telles que les colonnes sont composées de vecteurs orthogonaux entre eux. Soit et , son vecteur perpendiculaire. On considère la matrice dont les colonnes sont et . Calculer . Qu'y a-t-il de particulier? La matrice et sa transposée est . Leur produit donne , une matrice diagonale. C'est aussi une matrice symétrique. Répéter la partie précédente avec . La matrice et sa transposée est . Leur produit donne , une matrice diagonale. C'est aussi une matrice symétrique. Soit , une matrice telle que ses colonnes sont orthogonales entre elles. Montrer que est une matrice dont les seules entrées non nulles se situent sur la diagonale principale. Que valent les entrées non nulles? On utilise la définition du produit matriciel. La colonne du produit est donnée par le produit matrice vecteur où représente la colonne de la matrice . Les entrées de ce produit matrice vecteur correspondent à l'entrée du produit . On les calcule en prenant le produit scalaire des lignes de avec le vecteur . Comme les lignes de sont les colonnes de , on a . Par définition, les colonnes de la matrice sont orthogonales entre elles, ce produit scalaire vaut donc , sauf, évidemment, lorsque . Dans ce cas, les seules entrées non nulles de sont sur la diagonale. Elles sont égales à . "
},
{
  "id": "exo-rang1decomp",
  "level": "2",
  "url": "sec-transposee.html#exo-rang1decomp",
  "type": "Exercice",
  "number": "3.4.3.9",
  "title": "",
  "body": "Montrer que si est une matrice de rang de taille , alors il existe des vecteurs non nuls tels que .  On a utilisé cette propriété à l'exercice .  À quoi ressemblent les lignes d'une matrice de la forme ? On pose , la première ligne non nulle de . Par simplicité, on suppose que c'est la première ligne. Soit , les lignes de la matrice . Si la matrice est de rang , alors toutes ses lignes sont parallèles. Il existe donc tels que . On pose . On a alors  "
},
{
  "id": "exercise-190",
  "level": "2",
  "url": "sec-transposee.html#exercise-190",
  "type": "Exercice",
  "number": "3.4.3.10",
  "title": "",
  "body": "On considère les matrices de permutation définies à l'exercice . Montrer que si est une matrice de permutation , alors . Il y a deux cas à vérifier. Le premier est , la matrice identité. On vérifie facilement que . Le deuxième cas est . On sait que c'est une matrice qui est son propre inverse, on remarque aussi qu'elle est symétrique. On a donc bel et bien . Utiliser le code de l'exercice pour montrer que les matrices de permutation de taille et ont cette propriété.  On inclut une cellule vide pour recopier le code de l'exercice.   La vérification peut se faire de la manière suivante (S'assurer d'avoir copié le code de l'exercice et exécuter la cellule ci-dessus).   On veut montrer que, pour une matrice de permutation , on a . Montrer que les matrices élémentaires de type ont cette propriété. On considère une matrice élémentaire de type . Cette matrice est obtenue de l'identité en échangeant la ligne et la ligne ou, de manière équivalente, la colonne avec la colonne . Les colonnes sont orthogonales entre elles et donc, selon l'exercice , le produit , où est une matrice diagonale. Comme les colonnes sont des vecteurs dont la norme vaut , le même exercice permet de déduire que . On a donc . Utiliser l'exercice pour montrer qu'une matrice de permutation quelconque possède la propriété . Une matrice pour laquelle la transposée est son inverse est dite orthogonale. Ces matrices seront très importantes dans le chapitre . Soit , une matrice de permutation quelconque. Selon l'exercice , il existe des matrices élémentaires telles que . On a . "
},
{
  "id": "exo-detcomblinettransposee",
  "level": "2",
  "url": "sec-transposee.html#exo-detcomblinettransposee",
  "type": "Exercice",
  "number": "3.4.3.11",
  "title": "",
  "body": "Soit , une matrice carrée et , un vecteur qui n'est pas une combinaison linéaire des lignes de . Montrer que l'équation ne possède pas de solutions. Puisqu'on peut interpréter une solution à l'équation comme étant , où les vecteurs sont les colonnes de la matrice , on a que, si une solution existe, alors est une combinaison linéaire des colonnes de . Or, les colonnes de sont égales aux lignes de et l'on sait que n'est pas une combinaison linéaire de ces lignes. Ainsi l'équation n'a pas de solutions. "
},
{
  "id": "exercise-192",
  "level": "2",
  "url": "sec-transposee.html#exercise-192",
  "type": "Exercice",
  "number": "3.4.3.12",
  "title": "",
  "body": "Dans cet exercice, on veut donner un sens au mot « gauche » dans l'expression espace nul gauche.  On considère la matrice . Déterminer tous les vecteurs dans l'espace nul gauche.     L'espace nul gauche consiste en l'ensemble des vecteurs tel que . On échelonne la matrice transposée pour arriver aux solutions. . Il y a une variable pivot et deux variables libres. Les solutions spéciales sont . L'espace nul gauche est l'ensemble des combinaisons linéaires de ces vecteurs, soit le plan .  Soit . Montrer que les vecteurs de l'espace nul gauche satisfont l'équation . On commence par vérifier que les vecteurs satisfont l'équation. D'une part, on a et d'autre part, pour , on a .  Soit , un vecteur de l'espace nul gauche. Alors, il existe tels que . Ainsi, .  Soit , une matrice quelconque et une vecteur, dans l'espace nul de . Montrer que satisfait l'équation . Considérer la proposition . Selon la proposition , les solutions à l'équation formant l'espace nul gauche sont perpendiculaires aux lignes de , qui elles, sont les colonnes de . Dans le produit , on fait le produit scalaire de vecteur avec les colonnes de la matrice et donc, le résultat est le vecteur nul. "
},
{
  "id": "exo-noyaux",
  "level": "2",
  "url": "sec-transposee.html#exo-noyaux",
  "type": "Exercice",
  "number": "3.4.3.13",
  "title": "",
  "body": "Pour chaque matrice ci-dessous, trouver tous les vecteurs qui sont perpendiculaires aux lignes et tous les vecteurs qui sont perpendiculaires aux colonnes. Pour déterminer les vecteurs perpendiculaires aux lignes, il faut, selon la proposition , résoudre l'équation . La matrice est échelonnée réduite. Il y a deux variables pivots et deux variables libres. Les solutions spéciales sont . Ainsi, tout vecteur de la forme sera perpendiculaire aux lignes.  Pour trouver les vecteurs qui sont perpendiculaires aux colonnes, on transpose la matrice afin d'utiliser à nouveau la proposition . Cette fois, il faut échelonner la matrice . On a .  On a une variable libre et deux variables pivots. La solution spéciale est . Tous les vecteurs de la forme sont perpendiculaires aux lignes de et donc, aux colonnes de .   La matrice est échelonnée. Il y a une variable libre et donc, une solution spéciale . Tout multiple de ce vecteur sera perpendiculaire aux lignes de .  Pour les colonnes, on échelonne la matrice : . On a deux variables libres et trois pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces deux solutions sera perpendiculaire aux lignes de et donc, aux colonnes de .  La matrice est échelonnée réduite. Il y a deux variables libres et deux pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces solutions est perpendiculaire aux lignes de .  Pour les colonnes, on échelonne la matrice : .  Il y a deux variables libres et deux variables pivots. Les solutions spéciales sont . Tout vecteur s'écrivant comme une combinaison linéaire de ces deux solutions sera perpendiculaire aux lignes de et donc, aux colonnes de .  "
},
{
  "id": "exercise-194",
  "level": "2",
  "url": "sec-transposee.html#exercise-194",
  "type": "Exercice",
  "number": "3.4.3.14",
  "title": "",
  "body": "Pour chaque description ci-dessous, donner une matrice qui la satisfait. La matrice est avec , elle ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs parallèles à . La manière la plus simple est de mettre le vecteur dans les colonnes d'une matrice jusqu'à ce que . Un exemple est donc . L'espace colonne étant l'ensemble des combinaisons linéaires des colonnes de la matrice, cette matrice respecte la condition que son espace colonne ne contient que les vecteurs parallèles à , puisque les colonnes sont toutes égales à . De manière générale, on aurait pu avoir n'importe quelle matrice de la forme où et . La matrice ne contient aucune entrée égale à zéro et possède comme espace nul que les vecteurs parallèles à .  En d'autres mots, on veut que la solution spéciale à l'équation soit un multiple du vecteur . Le vecteur satisfait cette contrainte. La matrice échelonnée réduite la plus simple qui correspond à cette situation serait . Pour respecter la condition de n'avoir aucune entrée égale à zéro, il suffit de prendre un multiple de la ligne un et de l'ajouter à la ligne deux. L'exemple le plus simple serait de copier la ligne un à la ligne deux . De manière générale, toute matrice de la forme ferait l'affaire.  La matrice avec ne contient aucune entrée égale à zéro et possède comme espace ligne que les vecteurs parallèles à . Il doit y avoir deux colonnes, car l'espace ligne est dans . Il y aura donc quatre lignes pour satisfaire . La manière la plus simple est de copier le vecteur aux quatre lignes de la matrice. De manière générale, toute matrice de la forme où fera l'affaire. La matrice ne contient aucune entrée égale à zéro et possède comme espace nul gauche que les vecteurs parallèles à . De manière semblable à la matrice trouvée pour que l'espace nul soit composé uniquement des multiples de , on montre que la matrice aura comme espace nul les multiples du vecteur . On ajoute à la ligne deux un multiple de la ligne un pour avoir en général . Puisque l'espace nul gauche est , si l'on prend comme matrice , son espace nul gauche va correspondre à l'espace nul de et aura les conditions requises. Toute matrice de la forme fera l'affaire. La matrice ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs parallèles à . L'idée est la même que précédemment, toute matrice de la forme fera l'affaire. La matrice est carrée, ne contient aucune entrée égale à zéro, les lignes ne sont pas parallèles entre elles et possède comme espace nul que les vecteurs parallèles à . Encore ici, on cherche une matrice dont la forme échelonnée n'aura qu'une solution de base. La matrice échelonnée réduite a pour seule solution spéciale le vecteur . Pour éliminer les zéros, on fait des opérations élémentaires sur les lignes. Par exemple, . Évidemment, d'autres choix de facteurs auraient pu être faits pour les opérations élémentaires. La matrice ne contient aucune entrée égale à zéro et possède comme espace colonne que les vecteurs qui sont des combinaisons linéaires des vecteurs . Le plus simple consiste à mettre les deux vecteurs comme des colonnes d'une matrice. Ainsi, fait l'affaire. La matrice carrée ne contient aucune entrée égale à zéro, aucune fraction et possède comme espace nul que les vecteurs qui sont des combinaisons linéaires des vecteurs . Les vecteurs n'ont pas la forme de solutions de base. Le fait qu'il faut deux vecteurs pour générer l'espace nul signifie qu'il doit y avoir deux variables libres. Si l'on suppose que sont les variables libres, il faudrait que les vecteurs soit de la forme pour respecter la forme des solutions de base. On cherche donc comment, à partir de , on peut obtenir ces vecteurs. On veut . Comme on ne se soucie pas de la première composante, on a que et . Pour le vecteur , on obtient de manière similaire les équations et . On peut résoudre simultanément ces systèmes en échelonnant la matrice augmentée . Le premier vecteur est et le deuxième vecteur est .  Une matrice échelonnée réduite ayant ces deux vecteurs comme solutions de base serait . Pour satisfaire les conditions d'entrées non nulles et d'absence de fractions, on peut multiplier la première ligne par trois et recopier cette ligne dans les deux autres. On a donc  La matrice carrée ne contient aucune ligne parallèle, aucune entrée égale à zéro et possède comme espace ligne que les vecteurs qui sont des combinaisons linéaires des vecteurs . La réponse la plus simple consiste à inscrire les vecteurs dans les deux premières lignes d'une matrice dont la troisième sera nulle et d'utiliser les opérations élémentaires pour éliminer les zéros. On a donc , la dernière étape étant nécessaire pour respecter la condition que les lignes ne soient pas parallèles. La matrice ne contient aucune entrée égale à zéro et possède comme espace nul gauche que les vecteurs qui sont des combinaisons linéaires des vecteurs . On cherche une matrice telle que la transposée aura deux solutions de base. On commence par construire la transposée. Les vecteurs ont la forme de solution de base si les variables sont libres. On construit donc une matrice échelonnée réduite qui aura ces vecteurs comme solution de base: . On peut ensuite appliquer des opérations élémentaires sur les lignes afin d'éliminer les zéros. On pourrait avoir, par exemple, .  Finalement, pour que la matrice ait comme espace nul gauche l'espace engendré par les vecteurs , on prend la transposée de la matrice ci-dessus : . "
},
{
  "id": "exercise-195",
  "level": "2",
  "url": "sec-transposee.html#exercise-195",
  "type": "Exercice",
  "number": "3.4.3.15",
  "title": "",
  "body": " Utiliser la fonction matquelc de l'exemple calculatoire pour vérifier les égalités suivantes. Recopier le code de la fonction matquelc ci-dessous dans un premier temps et exécuter ensuite la cellule.   Une matrice de taille multipliée par sa transposée est une matrice symétrique. (La commande A.is_symmetric() permet de vérifier si la matrice est symétrique ou non.    Le code de la solution   A=matquelc(5,4,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A*(A.transpose())).is_symmetric()    Soit , une matrice . La matrice est symétrique.    Le code de la solution   A=matquelc(5,5,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A+(A.transpose())).is_symmetric()    Soit , une matrice . La matrice est antisymétrique (La commande pour antisymétrique sur Sage est A.is_skew_symmetric() .    Le code de la solution   A=matquelc(7,7,'a') show(\"A=\",A) show(\"A^T=\",A.transpose()) (A*(A.transpose())).is_skew_symmetric()    Vérifier les quatre premières propriétés de la proposition avec et .    Le code de la solution   A=matquelc(4,5,'a') B=matquelc(4,5,'b') C=matquelc(5,6,'c') var(\"k\") show(\"La propriété 1 est \",(A.transpose()).transpose()==A) show(\"La propriété 2 est \",(k*A).transpose()==k*(A.transpose())) show(\"La propriété 3 est \",(A+B).transpose()==A.transpose()+B.transpose()) show(\"La propriété 4 est \",(A*C).transpose()==(C.transpose())*(A.transpose()))    "
},
{
  "id": "exercise-196",
  "level": "2",
  "url": "sec-transposee.html#exercise-196",
  "type": "Exercice",
  "number": "3.4.3.16",
  "title": "",
  "body": "Refaire les cas possibles de l'exercice .    Le code de la solution   A=matrix([[1,-2],[3,1]]) B=matrix([[3,2],[1,5]]) C=matrix([[2,-2,3],[0,2,1]]) D=matrix([[7,-1],[2,4],[1,0]]) show(\"A^T=\",A.transpose()) show(\"4A-5B^T=\",4*A-5*B.transpose()) show(\"C^T=\",C.transpose()) show(\"C^T+D\",C.transpose()+D) show(\"A^TC\",A.transpose()*C) show(\"AC^T n'est pas possible\") show(\"C^TB^T=\",(C.transpose())*(B.transpose())) show(\"BD n'est pas possible\") show(\"BD^T=\",B*(D.transpose())) show(\"DB=\",D*B) show(\"D^TB n'est pas possible\") show(\"CC^T=\",C*(C.transpose())) show(\"C^TC=\",C.transpose()*C) show(\"CD=\",C*D) show(\"C^TD^T=\",C.transpose()*D.transpose()) show(\"DC=\",D*C) show(\"D^TC^T=\",D.transpose()*C.transpose())    "
},
{
  "id": "exercise-197",
  "level": "2",
  "url": "sec-transposee.html#exercise-197",
  "type": "Exercice",
  "number": "3.4.3.17",
  "title": "",
  "body": "Déterminer, à la manière de l'exemple calculatoire , les espaces fondamentaux des matrices de l'exercice   .     Le code de la solution   A1=matrix(QQ,[[1,-3,-4,0],[0,0,0,1],[0,0,0,0]]) A2=matrix(QQ,[[1,0,0,-1],[0,1,0,3],[0,0,1,-4],[0,0,0,0],[0,0,0,0]]) A3=matrix(QQ,[[1,4,0,1],[0,0,1,-2],[0,0,0,0],[0,0,0,0]]) ####Pour la matrice A1#### show(\"Pour la matrice A1\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A1.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A1.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A1.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A1.left_kernel(basis=\"pivot\").basis()) ########################################## ####Pour la matrice A1#### show(\"Pour la matrice A2\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A2.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A2.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A2.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A2.left_kernel(basis=\"pivot\").basis()) ############################################## ####Pour la matrice A1#### show(\"Pour la matrice A3\") ###Pour son espace nul show(\"Une base de l'espace nul est\") show(A3.right_kernel(basis=\"pivot\").basis()) ###Pour son espace ligne show(\"Une base de l'espace ligne est\") show(A3.row_space().basis()) ###Pour son espace colonne show(\"Une base de l'espace colonne est\") show(A3.column_space().basis()) ###Pour son espace nul gauche show(\"Une base de l'espace nul gauche est\") show(A3.left_kernel(basis=\"pivot\").basis())sub    "
},
{
  "id": "sec-SELlabos",
  "level": "1",
  "url": "sec-SELlabos.html",
  "type": "Section",
  "number": "3.5",
  "title": "Activités et laboratoires",
  "body": "  Activités et laboratoires    Dans cette section, on regarde des activités et des laboratoires en lien avec des concepts présentés dans le chapitre.    Des matrices magiques   On considère la matrice . Dans cette matrice, on peut remarquer que la somme de chaque ligne et de chaque colonne vaut . De plus, la somme des deux diagonales vaut aussi . La matrice est un exemple de ce qu'on appelle un carré magique. Dans la matrice , on constate que les neuf entrées sont exactement les valeurs , mais ce n'est pas une condition essentielle d'un carré magique. Un tel exemple sera dit carré magique classique.  Soit , une matrice . Si toutes les lignes et toutes les colonnes de la matrice somment à la même valeur, on dit que est semi-magique. Si, en plus, les deux diagonales somment à cette même valeur, on dit alors que est magique.  Dans cette activité, on s'intéresse à la construction de carrés magiques.   Le cas   On commence avec une méthode qui permettra d'obtenir la matrice de l'introduction. On considère une matrice quelconque de taille  .  Dans l'exemple en introduction, la somme magique est . On peut écrire un système à 8 équations et 9 inconnues pour que la matrice quelconque soit magique et que sa somme soit : . Utiliser Sage pour résoudre ce système d'équations. Il devrait y avoir deux variables libres dans la forme échelonnée réduite. Quelles sont-elles et quelles doivent être les valeurs de ces variables libres pour que la solution soit égale à la matrice de l'introduction?  Il est possible, mais facultatif, d'utiliser les fonctions solbase et solgen des exemples calculatoires et .   Déterminer le carré magique où votre date de fête, sous le format (jj\/mm), apparait aux variables libres, toujours avec une somme de . Donner d'autres exemples de carrés magiques dont la somme vaut , en changeant la valeur des variables libres. Qu'y a-t-il de commun entre chacun des carrés magiques? Donner le carré magique dont la somme est égale aux trois derniers chiffres de votre numéro de DA, toujours avec les variables libres égales à votre date de fête. Vérifier à nouveau l'hypothèse de la partie pour les carrés magiques de somme le numéro de DA.    "
},
{
  "id": "project-4",
  "level": "2",
  "url": "sec-SELlabos.html#project-4",
  "type": "Projet",
  "number": "3.5.1",
  "title": "Des matrices magiques.",
  "body": " Des matrices magiques   On considère la matrice . Dans cette matrice, on peut remarquer que la somme de chaque ligne et de chaque colonne vaut . De plus, la somme des deux diagonales vaut aussi . La matrice est un exemple de ce qu'on appelle un carré magique. Dans la matrice , on constate que les neuf entrées sont exactement les valeurs , mais ce n'est pas une condition essentielle d'un carré magique. Un tel exemple sera dit carré magique classique.  Soit , une matrice . Si toutes les lignes et toutes les colonnes de la matrice somment à la même valeur, on dit que est semi-magique. Si, en plus, les deux diagonales somment à cette même valeur, on dit alors que est magique.  Dans cette activité, on s'intéresse à la construction de carrés magiques.   Le cas   On commence avec une méthode qui permettra d'obtenir la matrice de l'introduction. On considère une matrice quelconque de taille  .  Dans l'exemple en introduction, la somme magique est . On peut écrire un système à 8 équations et 9 inconnues pour que la matrice quelconque soit magique et que sa somme soit : . Utiliser Sage pour résoudre ce système d'équations. Il devrait y avoir deux variables libres dans la forme échelonnée réduite. Quelles sont-elles et quelles doivent être les valeurs de ces variables libres pour que la solution soit égale à la matrice de l'introduction?  Il est possible, mais facultatif, d'utiliser les fonctions solbase et solgen des exemples calculatoires et .   Déterminer le carré magique où votre date de fête, sous le format (jj\/mm), apparait aux variables libres, toujours avec une somme de . Donner d'autres exemples de carrés magiques dont la somme vaut , en changeant la valeur des variables libres. Qu'y a-t-il de commun entre chacun des carrés magiques? Donner le carré magique dont la somme est égale aux trois derniers chiffres de votre numéro de DA, toujours avec les variables libres égales à votre date de fête. Vérifier à nouveau l'hypothèse de la partie pour les carrés magiques de somme le numéro de DA.   "
},
{
  "id": "sec-det2x2",
  "level": "1",
  "url": "sec-det2x2.html",
  "type": "Section",
  "number": "4.1",
  "title": "Le déterminant <span class=\"process-math\">\\(2\\times 2\\)<\/span>",
  "body": "  Le déterminant     Aller aux exercices de la section.  Dans un premier temps, on examine les transformations linéaires dans le plan . Si l'on considère le carré unité formé des vecteurs et , celui-ci est transformé en un parallélogramme (qui peut être comprimé en une ligne ou un point à l'origine) engendré par les vecteurs et . Comment est l'aire de ce parallélogramme par rapport au carré unité?  Dans cette section, on définit le déterminant d'une transformation de . On calcule des déterminants pour des transformations connues et l'on étudie les propriétés du déterminant. On regarde la notion d'orientation d'un repère et l'on donne la formule pour le calcul du déterminant d'une matrice .    Le facteur de changement d'aire  On commence cette sous-section en regardant différentes transformations du plan et en analysant l'effet sur l'aire du carré unité transformé.   Le déterminant de transformations géométriques  On s'intéresse aux quatre transformations suivantes du plan: .  La première transformation représente un étirement horizontal de facteur , la seconde est un cisaillement horizontal de facteur , la troisième représente une projection sur le vecteur et, finalement, la dernière est une transformation quelconque.  On cherche à évaluer l'impact de ces transformations sur l'aire des figures transformées. La figure interactive permet de manipuler les transformations.   Le facteur de changement d'aire pour quatre transformations    On constate que, pour un étirement de facteur , l'aire est aussi multipliée par un facteur . Dans le cas du cisaillement, le facteur ne semble pas avoir d'impact sur l'aire de la figure transformée, qui reste égale à l'aire de la figure originale.  Dans le cas de la projection, il n'y a plus d'aire. La figure est envoyée complètement sur la droite . Finalement, l'aire de la figure transformée par la matrice semble être fois l'aire de la figure originale.  On pourra bientôt comprendre d'où vient ce facteur .   Soit , une transformation linéaire. Si , l'image des vecteurs et est un parallélogramme, comme illustré ci-dessous.   L'aire d'un parallélogramme      L'aire de ce parallélogramme peut se calculer ainsi:  On prend l'aire du grand rectangle de côtés et , ce qui donne .  On soustrait l'aire des rectangles de côtés , en jaune sur la figure . Comme il y en a deux, on soustrait .  On soustrait ensuite l'aire des triangles rectangles de côtés , en vert sur la figure . Comme il y en a deux, on soustrait .  Finalement, on soustrait l'aire des triangles rectangles de côtés , en rouge sur la figure . Comme il y en a deux, on soustrait .    L'aire du parallélogramme est donc . Ce terme devrait être familier. C'est le même terme que l'on a vu dans la section pour qu'une matrice soit inversible. En y réfléchissant, on peut se convaincre du lien entre l'apparition de ce terme dans le calcul de l'aire du parallélogramme et la nécessité de sa présence pour qu'une matrice soit inversible, sachant que si , alors l'aire du parallélogramme est nulle et que l'on a plutôt une droite ou un point. La solution à « l'inverse » de la projection orthogonale, à l'exemple , fournit une explication à l'impossibilité d'avoir un inverse si l'image de la transformation dans est une droite.   D'autres déterminants de taille  On considère les quatre matrices suivantes. On cherche le déterminant de ces quatre matrices.   La matrice identité est la transformation qui ne change rien. Intuitivement, on devrait avoir un déterminant égal à un puisqu'il n'y a pas de changement d'aire. Puisque et , on a bel et bien . Évidemment, géométriquement, l'aire du parallélogramme correspond simplement à l'aire du carré unité.    L'effet de la transformation sur les vecteurs et est illustré à la figure ci-dessous.   L'effet de la transformation      Puisque le carré unité est transformé en une droite, on s'attend à ce que le déterminant soit . On a en effet .    Les transformations et envoient le carré unité sur le même parallélogramme, soit celui qui est engendré par les vecteurs et . Dans le cas de la transformation , c'est le vecteur qui est envoyé sur et est, quant à lui, envoyé sur , alors que dans le cas de la transformation , c'est le contraire qui se produit.  D'un point de vue géométrique, on s'attend donc à ce que le déterminant de ces deux matrices soit le même. Pourtant, d'un point de vue algébrique, on a pour que et pour , on a que . L'argument de l'aire fait avec la figure contient certainement une lacune, que l'on considère à l'instant.    L'exemple précédent a montré que la formule pour le calcul de l'aire du parallélogramme peut donner un résultat négatif. Heureusement, l'exercice montre que dans ce cas, l'aire est . À ce stade-ci, on peut donc modifier la formule, dire que l'aire est et en rester là ou tenter de donner un sens au signe négatif. On choisit cette dernière option.  On imagine le carré unité formé des points et . On peut remarquer que ces points apparaissent dans l'ordre lorsqu'on parcourt le carré dans le sens antihoraire.   Le carré unité      En utilisant la figure interactive , regarder comment la position relative des vecteurs peut changer l'orientation des quatre points et .   L'aire d'un parallélogramme, revisité      Définition du déterminant  Lorsqu'on parle du vecteur dans le plan, il est sous-entendu que ce vecteur est . La décomposition du vecteur selon les vecteurs dépend du vecteur choisi pour être le « premier » et du vecteur choisi pour être le « second ». Par convention, on aurait pu ordonner les vecteurs selon l'ordre . Ainsi, le vecteur aurait été , toujours selon cette convention.  Ces subtilités reviendront dans la section , mais pour le moment, on se contente de définir l'orientation de deux vecteurs non parallèles dans .   L'orientation dans  Soit , deux vecteurs non parallèles de . On note , le repère formé dans l'ordre des vecteurs et . On dit que est orienté positivement si la rotation antihoraire qui amène sur a un angle . Sinon, le repère est orienté négativement.    Voici quelques exemples de repères et leur orientation.     Un repère et son orientation       Un repère et son orientation         Un repère et son orientation       Un repère et son orientation        On va associer au signe du déterminant l'orientation (positive ou négative) du repère formé des vecteurs et . On verra à la proposition que le signe du déterminant concorde avec le signe de l'orientation.  Pour le moment, on cherche à donner une définition axiomatique du déterminant. Cette définition sera utile à la section lorsque la géométrie sera plus difficile à interpréter. Avec les observations que l'on a jusqu'à maintenant, il semble plausible de dire que le déterminant d'une matrice devrait satisfaire les propriétés suivantes:  Le déterminant de l'identité est égal à , car la transformation ne change pas l'aire des régions.  Le déterminant d'un étirement de facteur horizontal ou vertical est égal à , car le carré unité devient un rectangle ou .  Si et , alors les déterminants de et de devraient être de signes opposés, mais égaux en valeur absolue, car il n'y a que l'orientation des vecteurs qui change.    Il se trouve toutefois que ces trois propriétés ne sont pas suffisantes pour caractériser uniquement ce qu'on cherche. Plusieurs options pourraient être utilisées afin d'arriver à une définition complète du déterminant. La propriété manquante trouve son inspiration de l'exemple et de la matrice de cisaillement. On peut voir cette matrice comme étant . La géométrie du cisaillement montre que le déterminant est , car l'aire d'un parallélogramme est aussi la longueur de la base multipliée par la hauteur. La figure permet d'observer que la hauteur et la base ne changent pas pour le parallélogramme ainsi obtenu. On peut maintenant définir la notion de déterminant d'une matrice.   Le déterminant d'une matrice  Soit , une matrice . On note et . Le déterminant de la matrice est un scalaire, noté , qui satisfait les quatre propriétés suivantes:   Propriétés à satisfaire   Si , alors ;  ;  ;  .      On fait maintenant quelques remarques sur la définition du déterminant.   Précisions sur le déterminant  La définition du déterminant utilise plusieurs notations. On utilisera principalement la forme . Si le nombre en tant que tel est important, on privilégiera , alors que s'il est pratique de voir les entrées de la matrice ou si l'on fait un calcul, on utilisera . La notation sera surtout utile dans les démonstrations des propriétés du déterminant.  Les trois propriétés autres que le déterminant de l'identité rappellent d'une certaine façon les opérations élémentaires, bien que les propriétés définissant le déterminant s'appliquent sur les colonnes. On verra avec la proposition qu'il y a équivalence entre les lignes et les colonnes pour le déterminant et que cette observation est justifiée.   On va maintenant réconcilier la définition avec le facteur de changement d'aire de la section . Pour cela, on aura besoin d'une propriété additionnelle des déterminants qui se déduit de la définition.   Le déterminant et le vecteur nul  Soit , un vecteur quelconque. Alors .  Il suffit de remarquer que . On a évidemment aussi .   Et maintenant, pour relier déterminant et facteur de changement d'aire, on a la proposition suivante.   Le déterminant et le facteur de changement d'aire   Soit , une matrice . L'aire du parallélogramme engendré par les colonnes de la matrice est donnée par . De plus, si , le signe de détermine l'orientation du repère .    La démonstration se fait en deux parties. D'une part, si l'on arrive à montrer, à partir des propriétés, que , alors on saura que l'aire est donnée par la valeur absolue du déterminant. D'autre part, si l'on montre que le signe du déterminant est positif lorsque le repère est orienté positivement et négatif si le repère est orienté négativement, on complètera la preuve.  Soit . On suppose d'abord que . On a alors .  Si , alors on a une colonne nulle et donc, en vertu de la propriété . De plus, implique que l'aire du parallélogramme est nulle. Dans ce cas, le déterminant et l'aire coïncident . Toutefois, si , alors on peut soustraire à la colonne le multiple de la colonne pour obtenir .  Dans ce cas, on a bel et bien égale à l'aire du parallélogramme. Il reste donc le cas . On a alors . Encore une fois, si , on a une colonne nulle et l'argument ci-haut implique que le déterminant et sont nuls. Toutefois, si n'est pas nul, on peut soustraire à la colonne le multiple pour avoir .  On a donc aussi que est égal à l'aire du parallélogramme. Ceci complète la première partie de la démonstration.  On va maintenant montrer que le signe du déterminant et l'orientation du repère vont ensemble.  Si , alors on est dans la situation de la figure . L'orientation est positive. Si inversement le repère est orienté positivement, alors il existe tel que est parallèle à . En fait, en travaillant avec des vecteurs unitaires , on a . On calcule le déterminant des vecteurs . . Comme le signe du déterminant est entièrement déterminé par le signe de (les normes étant positives) et que celui-ci est positif lorsque , on conclut que le déterminant est aussi positif.  Un argument similaire montre que l'orientation négative du repère coïncide avec le signe négatif du déterminant.    On regarde maintenant quelques exemples de calculs et d'applications des déterminants.   L'aire d'un triangle  Soit et , trois points définissant un triangle dans . On cherche l'aire du triangle .  La stratégie usuelle pour trouver l'aire d'un triangle est de faire le produit de la base par la hauteur et de diviser par deux. On peut faire plus efficacement avec un déterminant.    On considère le parallélogramme engendré par les vecteurs et . L'aire du triangle correspond à exactement la moitié de l'aire du parallélogramme. Ainsi, .    On revient sur un concept introduit à l'exercice . On y reviendra à nouveau dans la prochaine section.   Le produit vectoriel  À l'exercice , on a introduit le produit vectoriel de deux vecteurs comme étant un vecteur qui est à la fois perpendiculaire à et à . Géométriquement, ce vecteur est un vecteur normal du plan engendré par les vecteurs et . On montre que le produit vectoriel, tel que défini à l'exercice , peut s'écrire comme   Il suffit de développer chaque déterminant et de comparer avec le vecteur de l'exercice . On a .  On a bel et bien l'égalité. Cet exemple propose un moyen simple de trouver un vecteur perpendiculaire à deux autres vecteurs dans , qui requiert le calcul de trois déterminants. En regardant composante par composante le vecteur produit vectoriel de l'équation , on peut s'imaginer une matrice contenant les vecteurs  . Pour obtenir la composante du produit vectoriel ( , on calcule le déterminant de la matrice obtenue de en éliminant la ligne . On doit se rappeler qu’il faut changer le signe de la seconde composante. On aura une explication plus détaillée dans la prochaine section.    On termine avec des commandes Sage en lien avec la sous-section.   Les déterminants et Sage  Avec Sage, pour calculer le déterminant d'une matrice carrée , il suffit d'utiliser la commande A.determinant() .   On peut aussi calculer le produit vectoriel de deux vecteurs avec la commande u.cross_product(v) .      Propriétés du déterminant  Dans cette sous-section, on énonce quelques propriétés des déterminants. On énoncera à nouveau et l'on démontrera ces résultats pour les déterminants de matrices dans la section suivante. Pour l'instant, on donne des arguments géométriques justifiant le cas .  On débute avec une propriété simple, soit lorsque la matrice contient deux colonnes parallèles. Dans ce cas, le déterminant vaut zéro, car le parallélogramme engendré par les colonnes est en fait un segment de droite. En équation de déterminant, cela se traduit par . Une autre propriété, plus surprenante est que . Les figures et permettent de visualiser cette propriété.   Les déterminants lorsqu'une colonne contient une addition, première version     Les déterminants lorsqu'une colonne contient une addition, deuxième version    La prochaine propriété est peut-être surprenante du point de vue algébrique, mais, vue sous l'œil des transformations linéaires, elle devient presque évidente. Elle stipule que le déterminant d'un produit est égal au produit des déterminants, à savoir . Puisqu'on sait que le produit de deux transformations linéaires correspond à la composition des transformations, on comprend que le facteur de changement d'aire de la composition, qui applique et ensuite , va d'abord changer l'aire des régions transformées d'un facteur et ensuite d'un facteur .  La prochaine proposition, quant à elle, se justifie difficilement géométriquement, mais elle est simple à démontrer algébriquement. Elle fait référence à la transposée d'une matrice et aura des implications importantes. On en fait une proposition formelle.   Le déterminant de la transposée d'une matrice  Soit , une matrice et , sa transposée . Alors .  Voir l'exercice .   Cette proposition a pour conséquence que les propriétés des déterminants, énoncées en fonction des colonnes de la matrice, sont aussi valides si l'on considère plutôt les lignes de la matrice. Par exemple, les propriétés de la définition du déterminant sont valides si l'on remplace par et par . En particulier, les trois dernières peuvent être vues comme l'effet des opérations élémentaires sur le déterminant. Cet effet sera utilisé lors du calcul du déterminant pour une matrice générale à la section .  Finalement, une propriété en lien avec l'inverse, qui, dans la section , donnera la prochaine version du théorème de la matrice inverse .   Le déterminant et l'inversibilité d'une matrice   Soit , une matrice . Alors est inversible si et seulement si . De plus, si est inversible, on a .  Après l'exemple , on avait déjà établi que la condition pour qu'une matrice soit inversible était que . Puisque cela coïncide avec le déterminant, la première partie de la proposition est immédiate. L'équation donne la formule pour l'inverse d'une matrice de vers , on peut alors calculer directement son résultat. En utilisant le résultat de l'exercice , on obtient .   Pour terminer, on résume les propriétés du déterminant , incluant celles de la définition.   Les propriétés du déterminant   Si , alors ;  ;  ;  ;  ;  ;  et .  ;   ;  Si est inversible, et est inversible si et seulement si ;  .        Les points importants de cette section sont:  La notion d'orientation dans ;  La définition du déterminant pour une matrice ;  L'équivalence entre le déterminant et le facteur de changement d'aire ainsi que l'interprétation du signe du déterminant, données à la proposition ;  Le produit vectoriel et son calcul par les déterminants ;        Exercices   Évaluer le déterminant dans chacune des situations suivantes.   Le déterminant        Il y a plusieurs façons de procéder et il est toujours possible de se servir des propriétés des déterminants pour calculer et pour vérifier notre réponse. On choisit de procéder d'abord avec la formule où et .  On peut lire sur le graphique que et . Il est logique que cette valeur soit positive puisque le repère est orienté positivement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit positive puisque le repère est orienté positivement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit négative puisque le repère est orienté négativement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit nulle selon la propriété . L'interprétation en ce qui concerne l'aire du parallélogramme est aussi logique puisqu'elle sera nulle, les deux vecteurs étant sur une même droite.    En utilisant l'application ci-dessous, déterminer l'orientation du repère .   L'orientation dans    On conseille au lecteur de répéter l'exercice plusieurs fois avant de lire la solution pour arriver lui-même à bien discerner la différence entre un repère positif et un repère négatif. On peut s'aider de la définition et des exemples qui suivent.  Il faut essentiellement regarder le vecteur en bleu et se demander dans quel sens on doit le faire tourner pour l'amener sur le vecteur en rouge en parcourant le plus petit angle entre les deux vecteurs. Si l'on tourne dans le sens antihoraire, l'orientation sera positive et, si l'on tourne dans le sens horaire, l'orientation sera négative.  Montrer que si l'orientation des vecteurs est renversée dans la figure , alors l'aire du parallélogramme est .   L'aire d'un parallélogramme      On utilise la figure de l'indice pour illustrer les calculs. On fait la démarche de la même façon que dans les notes.  L'aire de ce parallélogramme peut se calculer ainsi:  On prend l'aire du grand rectangle de côtés et , ce qui donne .  On soustrait à cela l'aire des rectangles de côtés , en jaune sur la figure . Comme il y en a deux, on soustrait .  On soustrait ensuite l'aire des triangles rectangles de côtés , en vert sur la figure . Comme il y en a deux, on soustrait .  Finalement, on soustrait l'aire des triangles rectangles de côtés , en rouge sur la figure . Comme il y en a deux, on soustrait .    L'aire du parallélogramme est donc .   Pour chacune des transformations de l'exemple , calculer le déterminant. Calculer également le déterminant du cisaillement, défini à l'exercice . Interpréter la réponse dans chacun des cas en lien avec la géométrie de la transformation.    La transformation identité laisse tout en place. Le facteur de changement d'aire est donc égal à puisque rien ne change.    Dans une réflexion par rapport à l'axe des abscisses, l'aire de la figure transformée ne changera pas. Cependant, puisque son orientation sera inversée, il est logique que le facteur de changement d'aire soit de , mais négatif.    Pour une rotation de dans le sens antihoraire, il n'y a aucun changement à la figure transformée pour l'aire ou l'orientation. On ne fait que tourner la figure de .    Un étirement horizontal de facteur est une transformation linéaire qui étire horizontalement une figure. Le facteur d'étirement détermine la manière dont la figure sera étirée. S'il est plus grand que , comme , par exemple, la figure sera deux fois plus large. Son aire va donc doubler. S'il est plus petit que , comme , par exemple, la figure sera moins large de la moitié. Son aire diminuera de moitié. Dans tous les cas, le facteur de changement d'aire est donné par le facteur de l'étirement .  De même, un étirement vertical de facteur devrait donner un facteur de changement d'aire égal à suivant la même logique. Effectivement, . La figure illustre de quelle manière un étirement transforme l'aire d'un carré.    L'homothétie de facteur est une transformation représentant simultanément un étirement horizontal et un étirement vertical. L'étirement horizontal occasionne un changement d'aire de facteur et l'étirement vertical du même facteur . Si l'on voit l'homothétie comme la composition de ces deux transformations, il est logique que le facteur de changement d'aire global soit de .    La permutation est une transformation linéaire qui change l'ordre des composantes d'un vecteur. Il est logique que l'orientation soit inversée si l'on interchange les et les dans une figure, puisqu'on l'obtiendra à l'envers. Cette transformation est en fait une réflexion selon l'axe et l'on a déjà constaté que les réflexions ont une facteur de . C'est également une application directe de la propriété sur calculé plus tôt.    La projection orthogonale sur un vecteur non nul est une transformation linéaire qui transforme une figure ou des vecteurs en les amenant sur une même droite. L'aire de la figure résultante sera donc toujours nulle.  Remarquons qu'il aurait été possible d'utiliser la propriété puisque les colonnes de la matrice de projection sont multiples l'une de l'autre.  La figure illustre une projection orthogonale, qui produit une figure d'aire nulle.   et Un cisaillement vertical ou horizontal ne change pas l'aire de la figure, tel qu'illustré dans la figure . Cela correspond également à une des propriétés de la définition du cisaillement.   En tenant pour acquis qu'une rotation ne change pas l'aire d'une figure géométrique et que l'aire d'un parallélogramme est , donner une preuve alternative que l'aire d'un parallélogramme est (lorsque les vecteurs sont orientés positivement) en ramenant le vecteur sur l'axe des . Soit deux vecteurs et . On veut démontrer que l'aire du parallélogramme engendré par et est . Si l'on voit le vecteur comme étant la base du parallélogramme, on peut faire une rotation de pour que cette base soit sur l'axe des . Pour ce faire, on a besoin de la matrice de rotation : . On a utilisé les identités et . La longueur de est: . Puisqu'on a besoin du sinus et du cosinus de l'angle , on les obtient des rapports trigonométriques du triangle rectangle où est le côté adjacent, le côté opposé et l'hypoténuse. Ainsi, et . La matrice devient donc: . On multiplie le vecteur par cette matrice pour obtenir le deuxième côté du parallélogramme, une fois celuit-ci transformé avec la rotation. La hauteur du parallélogramme sera donnée par la composante en de ce vecteur et la base par la longueur du vecteur . Ainsi, .  Démontrer géométriquement l'équation pour calculer l'aire d'un parallélogramme. On utilise le fait que l'aire d'un parallélogramme est donnée par . Ici, la base est la longueur du vecteur . La hauteur est le côté opposé à l'angle d'un triangle formé par les deux vecteurs d'hypoténuse et de côté adjacent . Ainsi, puisque , on a et finalement .   Soit , deux vecteurs de . Montrer que:   ;  On procède algébriquement à l'aide de la formule en posant les vecteurs et . On effectue d'abord le calcul à partir du membre de droite.  ;  On procède algébriquement à l'aide de la formule en posant les vecteurs et . On effectue d'abord le calcul à partir du membre de droite.  Comment savoir si deux vecteurs sont parallèles, à l'aide d'un déterminant? Puisque le déterminant calcule l'aire du parallélogramme engendré par les vecteurs et , il est clair que si le déterminant est nul, alors le parallélogramme est entièrement sur une ligne et les vecteurs sont donc parallèles. Autrement dit, si  Trois points de sont donnés. Quel serait un critère utilisant un déterminant pour savoir si les points sont alignés? On considère les vecteurs et qui génèrent un parallélogramme de la même façon que les vecteurs et de la définition du déterminant. Si les trois points sont alignés, alors le parallélogramme engendré par les vecteurs et sera d'aire nulle.  Bref, le critère détermine que les points sont alignés si le déterminant des vecteurs est nul. Autrement dit, si .  Dans cet exercice, on s'intéresse au produit vectoriel, donné par l'équation . On fixe . Montrer que la transformation est linéaire et donner sa matrice. On commence par montrer que la transformation est linéaire, on calcule ensuite sa matrice. On remarque que, si l'on obtient sa matrice de transformation et qu'elle correspond effectivement à la transformation en termes de l'effet sur , alors on n'a pas besoin de démontrer que la transformation est linéaire en vertu de la proposition . On le fait quand même pour le lecteur ou la lectrice qui n'y aurait pas pensé. On doit montrer que est linéaire en montrant que pour des vecteurs et un scalaire quelconques, on a les deux propriétés de la définition . Noter qu'on a décidé d'utiliser au lieu de puisque ce dernier vecteur est déjà utilisé dans la transformation.  On a démontré que la transformation est linéaire. Pour trouver sa matrice, il suffit de trouver l'effet de sur les vecteurs de base.   On les met dans les colonnes de la matrice et l'on obtient . Refaire avec un vecteur quelconque. Attention, c'est exactement la même démarche que précédemment, mais avec des valeurs quelconques pour . On commence par montrer que la transformation est linéaire et l'on calcule ensuite sa matrice. On doit montrer que est linéaire en montrant que, pour des vecteurs et un scalaire quelconques, on a les deux propriétés de la définition . Noter qu'on a décidé d'utiliser au lieu de puisque ce dernier vecteur est déjà utilisé dans la transformation.  On a démontré que la transformation est linéaire. Pour trouver sa matrice, il suffit de trouver l'effet de sur les vecteurs de base.   On les met dans les colonnes de la matrice et l'on obtient .   Montrer que pour une matrice , donnant ainsi une preuve à la proposition .  Soit , une matrice quelconque. On montre l'énoncé en faisant le calcul du déterminant.  Si est une matrice , utiliser les propriétés des déterminants pour calculer . On veut utiliser la propriété qui permet de mettre en évidence une constante d'un déterminant, mais une colonne à la fois. On utilise donc le déterminant de la matrice définit comme où .   Soit , une matrice inversible. Utiliser la propriété pour montrer que , donnant par le fait même une preuve alternative à la proposition .  On sait que est inversible, ce qui signifie qu'il existe une matrice telle que . On utilise le fait que l'on connait le déterminant de l'identité et que le déterminant d'un produit se factorise pour obtenir On peut faire la dernière étape, car on sait que puisque est inversible (exemple ).  Montrer algébriquement que le déterminant d'une réflexion est égal à . Toutes les matrices de réflexion sont de la forme donnée par l'équation . On en calcule le déterminant.   Le triangle ci-dessous a pour aire . Calculer les déterminants suivants.   Un triangle       ;  On sait que le déterminant donne l'aire du parallélogramme engendré par les deux vecteurs utilisés. Pour un triangle, l'aire sera donnée par la moitié de la valeur du déterminant. Il faut également tenir compte de l'orientation, que l'on peut considérer séparément à la toute fin ou inclure dans le calcul, ce que l'on choisit de faire. Dans ce cas-ci, on sait, par exemple, que .   ;   On constate que cela donne la même valeur et qu'elle est encore une fois positive. On peut remarquer que l'orientation des vecteurs est positive si on les ramène au même point de départ et parce qu'ils forment deux côtés différents du triangle, il est logique que leur déterminant donne deux fois l'aire du triangle. On aurait donc pu donner la réponse directement.  ;   L'orientation des vecteurs est effectivement négative lorsqu'on les ramène au même point de départ.  .   L'orientation des vecteurs est effectivement négative lorsqu'on les ramène au même point de départ.  On s'intéresse au lieu des points de qui satisfont une certaine propriété en lien avec les déterminants.  Soit .   Décrire le lieu des points tels que . Puisque les déterminants sont définis en termes vectoriels, on peut voir un point de ce lieu géométrique comme le vecteur . Si le déterminant est nul, c'est que les vecteurs et sont parallèles, par la propriété . Ainsi, le lieu est l'ensemble des points sur la droite passant par l'origine parallèle à . Autrement dit, l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  Ce lieu sera le même que le précédent puisque les deux vecteurs doivent encore être parallèles. Autrement dit, c'est l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  Ce lieu est plus difficile à définir. On calcule le déterminant pour s'aider à comprendre ce que cette équation signifie. On reconnait tout de suite l'équation normale d'une droite. En réalité, les deux questions précédentes donneraient la même équation, mais égale à zéro (passant par l'origine). Bref, on peut penser que ce déterminant représente la même droite, mais passant par un point de départ, donc translatée. On choisit le point qui correspond à des valeurs entières simples de qui constituent une solution de l'équation normale. Ce lieu est donc l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  On calcule le déterminant pour s'aider à comprendre ce que cette équation signifie. On reconnait tout de suite l'équation normale d'une droite. Elle est presque identique à la précédente, mais le vecteur normal est de signe opposé. Cela ne change pas la direction de la droite, qui peut donc garder le même vecteur directeur. Par contre, le point de départ sera différent. On choisit le point qui correspond à des valeurs entières simples de qui constituent solution de l'équation normale. Ce lieu est donc l'ensemble des points sur la droite: Soit , un vecteur quelconque et . Décrire le lieu des points tels que . On utilise ce qu'on a appris dans les dernières questions pour obtenir l'équation de ce lieu géométrique qui est, sans aucun doute, une droite. On sait que la droite est parallèle au vecteur et ce sera donc son vecteur directeur. Elle passe par toutes sortes de points de départ. Il suffit d'en trouver un qui satisfait l'équation normale donnée par la déterminant: . Par exemple, on peut prendre le point . Ce lieu est donc l'ensemble des points sur la droite:   Soit , les points d'un triangle quelconque et , le barycentre des sommets du triangle. Montrer que les triangles et ont la même aire.   Trois aires égales    Définir les aires des triangles comme des déterminants de vecteurs partant tous du point . Comme suggéré dans l'indice, on écrit chaque aire comme un déterminant en fonction des vecteurs .   On a choisi l'ordre des vecteurs pour que les déterminants soient tous positifs. On remarque que, puisque le facteur est présent chaque fois, on n'a qu'à montrer que ces trois déterminants sont égaux. On utilisera l'équation du barycentre sous cette forme:  On peut faire la preuve que ce dernier déterminant est égal à en suivant exactement les mêmes étapes.     Soit et .  Montrer que .    Le code solution pour l'exercice   A=matrix([[-4,12],[-8,4]]) B=matrix([[2,1],[2,-2]]) AB=A*B moinsBA=-B*A show(AB) show(moinsBA) show(AB==moinsBA)   Calculer le déterminant des matrices et ci-dessus.  Le code solution pour l'exercice   A=matrix([[-4,12],[-8,4]]) B=matrix([[2,1],[2,-2]]) show(det(A)) show(det(B))    On aurait aussi pu les calculer à la main rapidement. Trouver l'erreur dans le raisonnement suivant.  Soit , deux matrices telles que . En prenant les déterminants de chaque côté, on a . L'erreur se trouve entre la première et la deuxième ligne. Il est vrai que les deux déterminants initiaux doivent être égaux, puisque les matrices sont égales. Cependant, à la deuxième ligne, dans le membre de droite de l'équation, on a effectué une opération que l'on ne peut pas faire. On a sorti le moins du déterminant. Cela ne peut pas être fait, car ce n'est pas une application de la propriété puisqu'on sortirait une constante de toutes les colonnes en même temps. On a considéré cette question à l'exercice , on avait alors déterminé que . Ainsi, et l'argument ne fonctionne plus.  Les opérations élémentaires du type et ne changent pas le déterminant selon la propriété . Pourtant, à partir d'une matrice , on a . L'égalité n'est alors vraie que si et , ce qui est impossible. Alors, où peut être le problème? L'erreur se situe à la deuxième ligne de la preuve. Tout ce qui est dit est vrai, mais on fait une erreur dans l'application de la propriété lorsqu'on l'applique essentiellement aux deux lignes en même temps. En effet, on effectue l'opération , ce qui donne la ligne . Ensuite, on effectue l'opération , ce qui devrait donner la ligne et non ce qu'on a obtenu. On refait le calcul du déterminant correctement en faisant ces deux opérations successivement plutôt que simultanément.   Soit , une matrice telle qu'il existe une matrice diagonale et , une matrice inversible avec .  Calculer .     On considère la matrice . Pour quelle(s) valeurs de le déterminant de la matrice est-il nul?  Comparer avec les valeurs de obtenues à l'exercice . Que conclure de cette comparaison?  et  Le déterminant est donc nul si ou si .  En comparant avec l'exercice , on remarque que ce sont les mêmes valeurs. Il semble donc que, pour cette matrice, avoir un déterminant nul correspond à avoir un seul pivot.  On considère le système d'équations linéaires où est une matrice . Si le système possède au moins une solution, quel est, en fonction du déterminant de , ce qui caractérise le nombre de solutions? On affirme qu'il y a au moins une solution. Ainsi, les possibilités sont qu'il y en a une seule ou bien une infinité. D'abord, si la matrice est inversible, on a , ce qui implique que la solution unique est obtenue par ce calcul. Cela se produit lorsque le déterminant de la matrice est non nul. Autrement, si le déterminant est nul et que ce calcul est impossible ( non inversible), alors il y aura une infinité de solutions. Bref,   Dans cet exercice, on revient sur l'équation normale d'un plan. Plus particulièrement, on a une manière simple de trouver un vecteur normal, en utilisant le produit vectoriel.  Déterminer une équation normale des plans suivants.    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. Afin de simplifier l'équation normale, on choisit un vecteur normal parallèle au résultat, mais plus simple: . L'équation est donc: On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. Afin de simplifier l'équation normale, on choisit un vecteur normal parallèle au résultat, mais plus simple: . L'équation est donc: On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. On a un vecteur simple . L'équation est donc . On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,   La méthode de Cramer  On considère un système d'équations linéaires où sont connus et tels que . Le système possède donc une solution unique.   Soit . la matrice du système d'équations linéaires. On considère la matrice identité avec la première colonne remplacée par : .   Calculer .   Soit . Montrer que  D'abord, on montre que . En effet, . Ensuite, il faut montrer que . Il suffit de multiplier par et de remarquer qu'on obtient les membres de gauche des équations initiales.   Répéter la partie précédente avec la matrice afin de montrer que   D'abord, on montre que . En effet, . Ensuite, il faut montrer que . Il suffit de multiplier par et de remarquer qu'on obtient les membres de gauche des équations initiales.   Utiliser la méthode de Cramer pour trouver les solutions au système suivant: . On donne d'abord toutes les matrices associées au système:  Alors, et .   Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.    Dans cet exercice, on donne un avant-gout du chapitre . On s'intéresse aux solutions à l'équation .   On considère la matrice .  On commence avec . Résoudre l'équation en fonction de .    Voici une manière de résoudre le problème   Le code solution pour l'exercice   a=1 b=-1 A=column_matrix([[3*a\/5+2*b\/5,-3*a\/5+3*b\/5],[-2*a\/5+2*b\/5,2*a\/5+3*b\/5]]) Id=identity_matrix(2) var(\"k\") show(det(A-k*Id)) show(solve(det(A-k*Id),k))    Pour chaque valeur de trouvée, déterminer une solution au système d'équations linéaires .  Ces vecteurs sont aussi une solution de l'équation . Trouver une solution spéciale à cette équation.  Voici une manière de résoudre le problème   Le code solution pour l'exercice   ######Pour k=-1 ##### k=-1 show((A-k*Id).rref()) ######Pour k=1 ###### k=1 show((A-k*Id).rref())    On a donc, lorsque , le vecteur et, lorsque , le vecteur .  Calculer et où sont les solutions trouvées ci-dessus.   Voici une manière de résoudre le problème   Le code solution pour l'exercice   #####Pour v1 ##### v1=vector([2\/3,1]) show(\"Av_1=\",A*v1) #####Pour v2 ##### v2=vector([-1,1]) show(\"Av_2=\",A*v2)    On remarque que et que .  Refaire la partie avec quelconques.    Voici une manière de résoudre le problème   Le code solution pour l'exercice   var(\"a,b,k\") A=column_matrix([[3*a\/5+2*b\/5,-3*a\/5+3*b\/5],[-2*a\/5+2*b\/5,2*a\/5+3*b\/5]]) Id=identity_matrix(2) show(det(A-k*Id)) show(solve(det(A-k*Id),k)) ######Pour k=-1 ##### k=a show((A-k*Id).rref()) ######Pour k=1 ###### k=b show((A-k*Id).rref()) #####Pour v1 ##### v1=vector([2\/3,1]) show(\"Av_1=\",A*v1) #####Pour v2 ##### v2=vector([-1,1]) show(\"Av_2=\",A*v2)    On remarque, encore une fois, que les valeurs de qui satisfont l'équation sont et . Quant aux vecteurs , on retrouve les mêmes vecteurs qu'avec . Toutefois, on se rend compte que les produits matrice vecteur sont respectivement multipliés par . Les valeurs s'appellent les valeurs propres de la matrice et les vecteurs sont des vecteurs propres. Ces valeurs et vecteurs propres seront étudiés au chapitre .     "
},
{
  "id": "ex-dettransfogeo",
  "level": "2",
  "url": "sec-det2x2.html#ex-dettransfogeo",
  "type": "Exemple",
  "number": "4.1.1",
  "title": "Le déterminant de transformations géométriques.",
  "body": " Le déterminant de transformations géométriques  On s'intéresse aux quatre transformations suivantes du plan: .  La première transformation représente un étirement horizontal de facteur , la seconde est un cisaillement horizontal de facteur , la troisième représente une projection sur le vecteur et, finalement, la dernière est une transformation quelconque.  On cherche à évaluer l'impact de ces transformations sur l'aire des figures transformées. La figure interactive permet de manipuler les transformations.   Le facteur de changement d'aire pour quatre transformations    On constate que, pour un étirement de facteur , l'aire est aussi multipliée par un facteur . Dans le cas du cisaillement, le facteur ne semble pas avoir d'impact sur l'aire de la figure transformée, qui reste égale à l'aire de la figure originale.  Dans le cas de la projection, il n'y a plus d'aire. La figure est envoyée complètement sur la droite . Finalement, l'aire de la figure transformée par la matrice semble être fois l'aire de la figure originale.  On pourra bientôt comprendre d'où vient ce facteur .  "
},
{
  "id": "fig-airepara",
  "level": "2",
  "url": "sec-det2x2.html#fig-airepara",
  "type": "Figure",
  "number": "4.1.3",
  "title": "",
  "body": " L'aire d'un parallélogramme     "
},
{
  "id": "example-78",
  "level": "2",
  "url": "sec-det2x2.html#example-78",
  "type": "Exemple",
  "number": "4.1.4",
  "title": "D’autres déterminants de taille <span class=\"process-math\">\\(2\\times 2\\)<\/span>.",
  "body": " D'autres déterminants de taille  On considère les quatre matrices suivantes. On cherche le déterminant de ces quatre matrices.   La matrice identité est la transformation qui ne change rien. Intuitivement, on devrait avoir un déterminant égal à un puisqu'il n'y a pas de changement d'aire. Puisque et , on a bel et bien . Évidemment, géométriquement, l'aire du parallélogramme correspond simplement à l'aire du carré unité.    L'effet de la transformation sur les vecteurs et est illustré à la figure ci-dessous.   L'effet de la transformation      Puisque le carré unité est transformé en une droite, on s'attend à ce que le déterminant soit . On a en effet .    Les transformations et envoient le carré unité sur le même parallélogramme, soit celui qui est engendré par les vecteurs et . Dans le cas de la transformation , c'est le vecteur qui est envoyé sur et est, quant à lui, envoyé sur , alors que dans le cas de la transformation , c'est le contraire qui se produit.  D'un point de vue géométrique, on s'attend donc à ce que le déterminant de ces deux matrices soit le même. Pourtant, d'un point de vue algébrique, on a pour que et pour , on a que . L'argument de l'aire fait avec la figure contient certainement une lacune, que l'on considère à l'instant.   "
},
{
  "id": "figure-114",
  "level": "2",
  "url": "sec-det2x2.html#figure-114",
  "type": "Figure",
  "number": "4.1.6",
  "title": "",
  "body": " Le carré unité     "
},
{
  "id": "fig-aireparainter",
  "level": "2",
  "url": "sec-det2x2.html#fig-aireparainter",
  "type": "Figure",
  "number": "4.1.7",
  "title": "",
  "body": " L'aire d'un parallélogramme, revisité   "
},
{
  "id": "def-orientationR2",
  "level": "2",
  "url": "sec-det2x2.html#def-orientationR2",
  "type": "Définition",
  "number": "4.1.8",
  "title": "L’orientation dans <span class=\"process-math\">\\(\\R^2\\)<\/span>.",
  "body": " L'orientation dans  Soit , deux vecteurs non parallèles de . On note , le repère formé dans l'ordre des vecteurs et . On dit que est orienté positivement si la rotation antihoraire qui amène sur a un angle . Sinon, le repère est orienté négativement.   "
},
{
  "id": "figure-116",
  "level": "2",
  "url": "sec-det2x2.html#figure-116",
  "type": "Figure",
  "number": "4.1.9",
  "title": "",
  "body": " Un repère et son orientation     "
},
{
  "id": "figure-117",
  "level": "2",
  "url": "sec-det2x2.html#figure-117",
  "type": "Figure",
  "number": "4.1.10",
  "title": "",
  "body": " Un repère et son orientation     "
},
{
  "id": "figure-118",
  "level": "2",
  "url": "sec-det2x2.html#figure-118",
  "type": "Figure",
  "number": "4.1.11",
  "title": "",
  "body": " Un repère et son orientation     "
},
{
  "id": "figure-119",
  "level": "2",
  "url": "sec-det2x2.html#figure-119",
  "type": "Figure",
  "number": "4.1.12",
  "title": "",
  "body": " Un repère et son orientation     "
},
{
  "id": "def-determinant2x2",
  "level": "2",
  "url": "sec-det2x2.html#def-determinant2x2",
  "type": "Définition",
  "number": "4.1.13",
  "title": "Le déterminant d’une matrice.",
  "body": " Le déterminant d'une matrice  Soit , une matrice . On note et . Le déterminant de la matrice est un scalaire, noté , qui satisfait les quatre propriétés suivantes:   Propriétés à satisfaire   Si , alors ;  ;  ;  .     "
},
{
  "id": "remark-15",
  "level": "2",
  "url": "sec-det2x2.html#remark-15",
  "type": "Remarque",
  "number": "4.1.15",
  "title": "Précisions sur le déterminant.",
  "body": " Précisions sur le déterminant  La définition du déterminant utilise plusieurs notations. On utilisera principalement la forme . Si le nombre en tant que tel est important, on privilégiera , alors que s'il est pratique de voir les entrées de la matrice ou si l'on fait un calcul, on utilisera . La notation sera surtout utile dans les démonstrations des propriétés du déterminant.  Les trois propriétés autres que le déterminant de l'identité rappellent d'une certaine façon les opérations élémentaires, bien que les propriétés définissant le déterminant s'appliquent sur les colonnes. On verra avec la proposition qu'il y a équivalence entre les lignes et les colonnes pour le déterminant et que cette observation est justifiée.  "
},
{
  "id": "prop-detcolnulle2x2",
  "level": "2",
  "url": "sec-det2x2.html#prop-detcolnulle2x2",
  "type": "Proposition",
  "number": "4.1.16",
  "title": "Le déterminant et le vecteur nul.",
  "body": " Le déterminant et le vecteur nul  Soit , un vecteur quelconque. Alors .  Il suffit de remarquer que . On a évidemment aussi .  "
},
{
  "id": "prop-detestfact",
  "level": "2",
  "url": "sec-det2x2.html#prop-detestfact",
  "type": "Proposition",
  "number": "4.1.17",
  "title": "Le déterminant et le facteur de changement d’aire.",
  "body": " Le déterminant et le facteur de changement d'aire   Soit , une matrice . L'aire du parallélogramme engendré par les colonnes de la matrice est donnée par . De plus, si , le signe de détermine l'orientation du repère .    La démonstration se fait en deux parties. D'une part, si l'on arrive à montrer, à partir des propriétés, que , alors on saura que l'aire est donnée par la valeur absolue du déterminant. D'autre part, si l'on montre que le signe du déterminant est positif lorsque le repère est orienté positivement et négatif si le repère est orienté négativement, on complètera la preuve.  Soit . On suppose d'abord que . On a alors .  Si , alors on a une colonne nulle et donc, en vertu de la propriété . De plus, implique que l'aire du parallélogramme est nulle. Dans ce cas, le déterminant et l'aire coïncident . Toutefois, si , alors on peut soustraire à la colonne le multiple de la colonne pour obtenir .  Dans ce cas, on a bel et bien égale à l'aire du parallélogramme. Il reste donc le cas . On a alors . Encore une fois, si , on a une colonne nulle et l'argument ci-haut implique que le déterminant et sont nuls. Toutefois, si n'est pas nul, on peut soustraire à la colonne le multiple pour avoir .  On a donc aussi que est égal à l'aire du parallélogramme. Ceci complète la première partie de la démonstration.  On va maintenant montrer que le signe du déterminant et l'orientation du repère vont ensemble.  Si , alors on est dans la situation de la figure . L'orientation est positive. Si inversement le repère est orienté positivement, alors il existe tel que est parallèle à . En fait, en travaillant avec des vecteurs unitaires , on a . On calcule le déterminant des vecteurs . . Comme le signe du déterminant est entièrement déterminé par le signe de (les normes étant positives) et que celui-ci est positif lorsque , on conclut que le déterminant est aussi positif.  Un argument similaire montre que l'orientation négative du repère coïncide avec le signe négatif du déterminant.   "
},
{
  "id": "example-79",
  "level": "2",
  "url": "sec-det2x2.html#example-79",
  "type": "Exemple",
  "number": "4.1.18",
  "title": "L’aire d’un triangle.",
  "body": " L'aire d'un triangle  Soit et , trois points définissant un triangle dans . On cherche l'aire du triangle .  La stratégie usuelle pour trouver l'aire d'un triangle est de faire le produit de la base par la hauteur et de diviser par deux. On peut faire plus efficacement avec un déterminant.    On considère le parallélogramme engendré par les vecteurs et . L'aire du triangle correspond à exactement la moitié de l'aire du parallélogramme. Ainsi, .   "
},
{
  "id": "ex-prodvecdet2x2",
  "level": "2",
  "url": "sec-det2x2.html#ex-prodvecdet2x2",
  "type": "Exemple",
  "number": "4.1.19",
  "title": "Le produit vectoriel.",
  "body": " Le produit vectoriel  À l'exercice , on a introduit le produit vectoriel de deux vecteurs comme étant un vecteur qui est à la fois perpendiculaire à et à . Géométriquement, ce vecteur est un vecteur normal du plan engendré par les vecteurs et . On montre que le produit vectoriel, tel que défini à l'exercice , peut s'écrire comme   Il suffit de développer chaque déterminant et de comparer avec le vecteur de l'exercice . On a .  On a bel et bien l'égalité. Cet exemple propose un moyen simple de trouver un vecteur perpendiculaire à deux autres vecteurs dans , qui requiert le calcul de trois déterminants. En regardant composante par composante le vecteur produit vectoriel de l'équation , on peut s'imaginer une matrice contenant les vecteurs  . Pour obtenir la composante du produit vectoriel ( , on calcule le déterminant de la matrice obtenue de en éliminant la ligne . On doit se rappeler qu’il faut changer le signe de la seconde composante. On aura une explication plus détaillée dans la prochaine section.   "
},
{
  "id": "sageex-det2x2",
  "level": "2",
  "url": "sec-det2x2.html#sageex-det2x2",
  "type": "Calcul",
  "number": "4.1.20",
  "title": "Les déterminants et Sage.",
  "body": " Les déterminants et Sage  Avec Sage, pour calculer le déterminant d'une matrice carrée , il suffit d'utiliser la commande A.determinant() .   On peut aussi calculer le produit vectoriel de deux vecteurs avec la commande u.cross_product(v) .   "
},
{
  "id": "fig-det2x2sommememesigne",
  "level": "2",
  "url": "sec-det2x2.html#fig-det2x2sommememesigne",
  "type": "Figure",
  "number": "4.1.21",
  "title": "",
  "body": " Les déterminants lorsqu'une colonne contient une addition, première version   "
},
{
  "id": "fig-det2x2sommesigneopp",
  "level": "2",
  "url": "sec-det2x2.html#fig-det2x2sommesigneopp",
  "type": "Figure",
  "number": "4.1.22",
  "title": "",
  "body": " Les déterminants lorsqu'une colonne contient une addition, deuxième version   "
},
{
  "id": "prop-dettranspo2x2",
  "level": "2",
  "url": "sec-det2x2.html#prop-dettranspo2x2",
  "type": "Proposition",
  "number": "4.1.23",
  "title": "Le déterminant de la transposée d’une matrice <span class=\"process-math\">\\(2\\times 2\\)<\/span>.",
  "body": " Le déterminant de la transposée d'une matrice  Soit , une matrice et , sa transposée . Alors .  Voir l'exercice .  "
},
{
  "id": "prop-detinv2x2",
  "level": "2",
  "url": "sec-det2x2.html#prop-detinv2x2",
  "type": "Proposition",
  "number": "4.1.24",
  "title": "Le déterminant et l’inversibilité d’une matrice <span class=\"process-math\">\\(2\\times 2\\)<\/span>.",
  "body": " Le déterminant et l'inversibilité d'une matrice   Soit , une matrice . Alors est inversible si et seulement si . De plus, si est inversible, on a .  Après l'exemple , on avait déjà établi que la condition pour qu'une matrice soit inversible était que . Puisque cela coïncide avec le déterminant, la première partie de la proposition est immédiate. L'équation donne la formule pour l'inverse d'une matrice de vers , on peut alors calculer directement son résultat. En utilisant le résultat de l'exercice , on obtient .  "
},
{
  "id": "li-det2x2prop",
  "level": "2",
  "url": "sec-det2x2.html#li-det2x2prop",
  "type": "Liste",
  "number": "4.1.25",
  "title": "Les propriétés du déterminant",
  "body": " Les propriétés du déterminant   Si , alors ;  ;  ;  ;  ;  ;  et .  ;   ;  Si est inversible, et est inversible si et seulement si ;  .   "
},
{
  "id": "exercise-198",
  "level": "2",
  "url": "sec-det2x2.html#exercise-198",
  "type": "Exercice",
  "number": "4.1.4.1",
  "title": "",
  "body": "Évaluer le déterminant dans chacune des situations suivantes.   Le déterminant        Il y a plusieurs façons de procéder et il est toujours possible de se servir des propriétés des déterminants pour calculer et pour vérifier notre réponse. On choisit de procéder d'abord avec la formule où et .  On peut lire sur le graphique que et . Il est logique que cette valeur soit positive puisque le repère est orienté positivement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit positive puisque le repère est orienté positivement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit négative puisque le repère est orienté négativement selon la définition .    Le déterminant         On peut lire sur le graphique que et . Il est logique que cette valeur soit nulle selon la propriété . L'interprétation en ce qui concerne l'aire du parallélogramme est aussi logique puisqu'elle sera nulle, les deux vecteurs étant sur une même droite.  "
},
{
  "id": "exercise-199",
  "level": "2",
  "url": "sec-det2x2.html#exercise-199",
  "type": "Exercice",
  "number": "4.1.4.2",
  "title": "",
  "body": " En utilisant l'application ci-dessous, déterminer l'orientation du repère .   L'orientation dans    On conseille au lecteur de répéter l'exercice plusieurs fois avant de lire la solution pour arriver lui-même à bien discerner la différence entre un repère positif et un repère négatif. On peut s'aider de la définition et des exemples qui suivent.  Il faut essentiellement regarder le vecteur en bleu et se demander dans quel sens on doit le faire tourner pour l'amener sur le vecteur en rouge en parcourant le plus petit angle entre les deux vecteurs. Si l'on tourne dans le sens antihoraire, l'orientation sera positive et, si l'on tourne dans le sens horaire, l'orientation sera négative. "
},
{
  "id": "exo-aireparabc-ad",
  "level": "2",
  "url": "sec-det2x2.html#exo-aireparabc-ad",
  "type": "Exercice",
  "number": "4.1.4.3",
  "title": "",
  "body": "Montrer que si l'orientation des vecteurs est renversée dans la figure , alors l'aire du parallélogramme est .   L'aire d'un parallélogramme      On utilise la figure de l'indice pour illustrer les calculs. On fait la démarche de la même façon que dans les notes.  L'aire de ce parallélogramme peut se calculer ainsi:  On prend l'aire du grand rectangle de côtés et , ce qui donne .  On soustrait à cela l'aire des rectangles de côtés , en jaune sur la figure . Comme il y en a deux, on soustrait .  On soustrait ensuite l'aire des triangles rectangles de côtés , en vert sur la figure . Comme il y en a deux, on soustrait .  Finalement, on soustrait l'aire des triangles rectangles de côtés , en rouge sur la figure . Comme il y en a deux, on soustrait .    L'aire du parallélogramme est donc . "
},
{
  "id": "exercise-201",
  "level": "2",
  "url": "sec-det2x2.html#exercise-201",
  "type": "Exercice",
  "number": "4.1.4.4",
  "title": "",
  "body": " Pour chacune des transformations de l'exemple , calculer le déterminant. Calculer également le déterminant du cisaillement, défini à l'exercice . Interpréter la réponse dans chacun des cas en lien avec la géométrie de la transformation.    La transformation identité laisse tout en place. Le facteur de changement d'aire est donc égal à puisque rien ne change.    Dans une réflexion par rapport à l'axe des abscisses, l'aire de la figure transformée ne changera pas. Cependant, puisque son orientation sera inversée, il est logique que le facteur de changement d'aire soit de , mais négatif.    Pour une rotation de dans le sens antihoraire, il n'y a aucun changement à la figure transformée pour l'aire ou l'orientation. On ne fait que tourner la figure de .    Un étirement horizontal de facteur est une transformation linéaire qui étire horizontalement une figure. Le facteur d'étirement détermine la manière dont la figure sera étirée. S'il est plus grand que , comme , par exemple, la figure sera deux fois plus large. Son aire va donc doubler. S'il est plus petit que , comme , par exemple, la figure sera moins large de la moitié. Son aire diminuera de moitié. Dans tous les cas, le facteur de changement d'aire est donné par le facteur de l'étirement .  De même, un étirement vertical de facteur devrait donner un facteur de changement d'aire égal à suivant la même logique. Effectivement, . La figure illustre de quelle manière un étirement transforme l'aire d'un carré.    L'homothétie de facteur est une transformation représentant simultanément un étirement horizontal et un étirement vertical. L'étirement horizontal occasionne un changement d'aire de facteur et l'étirement vertical du même facteur . Si l'on voit l'homothétie comme la composition de ces deux transformations, il est logique que le facteur de changement d'aire global soit de .    La permutation est une transformation linéaire qui change l'ordre des composantes d'un vecteur. Il est logique que l'orientation soit inversée si l'on interchange les et les dans une figure, puisqu'on l'obtiendra à l'envers. Cette transformation est en fait une réflexion selon l'axe et l'on a déjà constaté que les réflexions ont une facteur de . C'est également une application directe de la propriété sur calculé plus tôt.    La projection orthogonale sur un vecteur non nul est une transformation linéaire qui transforme une figure ou des vecteurs en les amenant sur une même droite. L'aire de la figure résultante sera donc toujours nulle.  Remarquons qu'il aurait été possible d'utiliser la propriété puisque les colonnes de la matrice de projection sont multiples l'une de l'autre.  La figure illustre une projection orthogonale, qui produit une figure d'aire nulle.   et Un cisaillement vertical ou horizontal ne change pas l'aire de la figure, tel qu'illustré dans la figure . Cela correspond également à une des propriétés de la définition du cisaillement. "
},
{
  "id": "exercise-202",
  "level": "2",
  "url": "sec-det2x2.html#exercise-202",
  "type": "Exercice",
  "number": "4.1.4.5",
  "title": "",
  "body": " En tenant pour acquis qu'une rotation ne change pas l'aire d'une figure géométrique et que l'aire d'un parallélogramme est , donner une preuve alternative que l'aire d'un parallélogramme est (lorsque les vecteurs sont orientés positivement) en ramenant le vecteur sur l'axe des . Soit deux vecteurs et . On veut démontrer que l'aire du parallélogramme engendré par et est . Si l'on voit le vecteur comme étant la base du parallélogramme, on peut faire une rotation de pour que cette base soit sur l'axe des . Pour ce faire, on a besoin de la matrice de rotation : . On a utilisé les identités et . La longueur de est: . Puisqu'on a besoin du sinus et du cosinus de l'angle , on les obtient des rapports trigonométriques du triangle rectangle où est le côté adjacent, le côté opposé et l'hypoténuse. Ainsi, et . La matrice devient donc: . On multiplie le vecteur par cette matrice pour obtenir le deuxième côté du parallélogramme, une fois celuit-ci transformé avec la rotation. La hauteur du parallélogramme sera donnée par la composante en de ce vecteur et la base par la longueur du vecteur . Ainsi, . "
},
{
  "id": "exercise-203",
  "level": "2",
  "url": "sec-det2x2.html#exercise-203",
  "type": "Exercice",
  "number": "4.1.4.6",
  "title": "",
  "body": "Démontrer géométriquement l'équation pour calculer l'aire d'un parallélogramme. On utilise le fait que l'aire d'un parallélogramme est donnée par . Ici, la base est la longueur du vecteur . La hauteur est le côté opposé à l'angle d'un triangle formé par les deux vecteurs d'hypoténuse et de côté adjacent . Ainsi, puisque , on a et finalement . "
},
{
  "id": "exercise-204",
  "level": "2",
  "url": "sec-det2x2.html#exercise-204",
  "type": "Exercice",
  "number": "4.1.4.7",
  "title": "",
  "body": " Soit , deux vecteurs de . Montrer que:   ;  On procède algébriquement à l'aide de la formule en posant les vecteurs et . On effectue d'abord le calcul à partir du membre de droite.  ;  On procède algébriquement à l'aide de la formule en posant les vecteurs et . On effectue d'abord le calcul à partir du membre de droite. "
},
{
  "id": "exercise-205",
  "level": "2",
  "url": "sec-det2x2.html#exercise-205",
  "type": "Exercice",
  "number": "4.1.4.8",
  "title": "",
  "body": "Comment savoir si deux vecteurs sont parallèles, à l'aide d'un déterminant? Puisque le déterminant calcule l'aire du parallélogramme engendré par les vecteurs et , il est clair que si le déterminant est nul, alors le parallélogramme est entièrement sur une ligne et les vecteurs sont donc parallèles. Autrement dit, si "
},
{
  "id": "exo-vecparadet",
  "level": "2",
  "url": "sec-det2x2.html#exo-vecparadet",
  "type": "Exercice",
  "number": "4.1.4.9",
  "title": "",
  "body": "Trois points de sont donnés. Quel serait un critère utilisant un déterminant pour savoir si les points sont alignés? On considère les vecteurs et qui génèrent un parallélogramme de la même façon que les vecteurs et de la définition du déterminant. Si les trois points sont alignés, alors le parallélogramme engendré par les vecteurs et sera d'aire nulle.  Bref, le critère détermine que les points sont alignés si le déterminant des vecteurs est nul. Autrement dit, si . "
},
{
  "id": "exercise-207",
  "level": "2",
  "url": "sec-det2x2.html#exercise-207",
  "type": "Exercice",
  "number": "4.1.4.10",
  "title": "",
  "body": "Dans cet exercice, on s'intéresse au produit vectoriel, donné par l'équation . On fixe . Montrer que la transformation est linéaire et donner sa matrice. On commence par montrer que la transformation est linéaire, on calcule ensuite sa matrice. On remarque que, si l'on obtient sa matrice de transformation et qu'elle correspond effectivement à la transformation en termes de l'effet sur , alors on n'a pas besoin de démontrer que la transformation est linéaire en vertu de la proposition . On le fait quand même pour le lecteur ou la lectrice qui n'y aurait pas pensé. On doit montrer que est linéaire en montrant que pour des vecteurs et un scalaire quelconques, on a les deux propriétés de la définition . Noter qu'on a décidé d'utiliser au lieu de puisque ce dernier vecteur est déjà utilisé dans la transformation.  On a démontré que la transformation est linéaire. Pour trouver sa matrice, il suffit de trouver l'effet de sur les vecteurs de base.   On les met dans les colonnes de la matrice et l'on obtient . Refaire avec un vecteur quelconque. Attention, c'est exactement la même démarche que précédemment, mais avec des valeurs quelconques pour . On commence par montrer que la transformation est linéaire et l'on calcule ensuite sa matrice. On doit montrer que est linéaire en montrant que, pour des vecteurs et un scalaire quelconques, on a les deux propriétés de la définition . Noter qu'on a décidé d'utiliser au lieu de puisque ce dernier vecteur est déjà utilisé dans la transformation.  On a démontré que la transformation est linéaire. Pour trouver sa matrice, il suffit de trouver l'effet de sur les vecteurs de base.   On les met dans les colonnes de la matrice et l'on obtient . "
},
{
  "id": "exo-dettranspo2x2",
  "level": "2",
  "url": "sec-det2x2.html#exo-dettranspo2x2",
  "type": "Exercice",
  "number": "4.1.4.11",
  "title": "",
  "body": " Montrer que pour une matrice , donnant ainsi une preuve à la proposition .  Soit , une matrice quelconque. On montre l'énoncé en faisant le calcul du déterminant. "
},
{
  "id": "exo-detkA2x2",
  "level": "2",
  "url": "sec-det2x2.html#exo-detkA2x2",
  "type": "Exercice",
  "number": "4.1.4.12",
  "title": "",
  "body": "Si est une matrice , utiliser les propriétés des déterminants pour calculer . On veut utiliser la propriété qui permet de mettre en évidence une constante d'un déterminant, mais une colonne à la fois. On utilise donc le déterminant de la matrice définit comme où . "
},
{
  "id": "exercise-210",
  "level": "2",
  "url": "sec-det2x2.html#exercise-210",
  "type": "Exercice",
  "number": "4.1.4.13",
  "title": "",
  "body": " Soit , une matrice inversible. Utiliser la propriété pour montrer que , donnant par le fait même une preuve alternative à la proposition .  On sait que est inversible, ce qui signifie qu'il existe une matrice telle que . On utilise le fait que l'on connait le déterminant de l'identité et que le déterminant d'un produit se factorise pour obtenir On peut faire la dernière étape, car on sait que puisque est inversible (exemple ). "
},
{
  "id": "exo-detref2x2",
  "level": "2",
  "url": "sec-det2x2.html#exo-detref2x2",
  "type": "Exercice",
  "number": "4.1.4.14",
  "title": "",
  "body": "Montrer algébriquement que le déterminant d'une réflexion est égal à . Toutes les matrices de réflexion sont de la forme donnée par l'équation . On en calcule le déterminant.  "
},
{
  "id": "exercise-212",
  "level": "2",
  "url": "sec-det2x2.html#exercise-212",
  "type": "Exercice",
  "number": "4.1.4.15",
  "title": "",
  "body": "Le triangle ci-dessous a pour aire . Calculer les déterminants suivants.   Un triangle       ;  On sait que le déterminant donne l'aire du parallélogramme engendré par les deux vecteurs utilisés. Pour un triangle, l'aire sera donnée par la moitié de la valeur du déterminant. Il faut également tenir compte de l'orientation, que l'on peut considérer séparément à la toute fin ou inclure dans le calcul, ce que l'on choisit de faire. Dans ce cas-ci, on sait, par exemple, que .   ;   On constate que cela donne la même valeur et qu'elle est encore une fois positive. On peut remarquer que l'orientation des vecteurs est positive si on les ramène au même point de départ et parce qu'ils forment deux côtés différents du triangle, il est logique que leur déterminant donne deux fois l'aire du triangle. On aurait donc pu donner la réponse directement.  ;   L'orientation des vecteurs est effectivement négative lorsqu'on les ramène au même point de départ.  .   L'orientation des vecteurs est effectivement négative lorsqu'on les ramène au même point de départ. "
},
{
  "id": "exercise-213",
  "level": "2",
  "url": "sec-det2x2.html#exercise-213",
  "type": "Exercice",
  "number": "4.1.4.16",
  "title": "",
  "body": "On s'intéresse au lieu des points de qui satisfont une certaine propriété en lien avec les déterminants.  Soit .   Décrire le lieu des points tels que . Puisque les déterminants sont définis en termes vectoriels, on peut voir un point de ce lieu géométrique comme le vecteur . Si le déterminant est nul, c'est que les vecteurs et sont parallèles, par la propriété . Ainsi, le lieu est l'ensemble des points sur la droite passant par l'origine parallèle à . Autrement dit, l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  Ce lieu sera le même que le précédent puisque les deux vecteurs doivent encore être parallèles. Autrement dit, c'est l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  Ce lieu est plus difficile à définir. On calcule le déterminant pour s'aider à comprendre ce que cette équation signifie. On reconnait tout de suite l'équation normale d'une droite. En réalité, les deux questions précédentes donneraient la même équation, mais égale à zéro (passant par l'origine). Bref, on peut penser que ce déterminant représente la même droite, mais passant par un point de départ, donc translatée. On choisit le point qui correspond à des valeurs entières simples de qui constituent une solution de l'équation normale. Ce lieu est donc l'ensemble des points sur la droite:  Décrire le lieu des points tels que .  On calcule le déterminant pour s'aider à comprendre ce que cette équation signifie. On reconnait tout de suite l'équation normale d'une droite. Elle est presque identique à la précédente, mais le vecteur normal est de signe opposé. Cela ne change pas la direction de la droite, qui peut donc garder le même vecteur directeur. Par contre, le point de départ sera différent. On choisit le point qui correspond à des valeurs entières simples de qui constituent solution de l'équation normale. Ce lieu est donc l'ensemble des points sur la droite: Soit , un vecteur quelconque et . Décrire le lieu des points tels que . On utilise ce qu'on a appris dans les dernières questions pour obtenir l'équation de ce lieu géométrique qui est, sans aucun doute, une droite. On sait que la droite est parallèle au vecteur et ce sera donc son vecteur directeur. Elle passe par toutes sortes de points de départ. Il suffit d'en trouver un qui satisfait l'équation normale donnée par la déterminant: . Par exemple, on peut prendre le point . Ce lieu est donc l'ensemble des points sur la droite: "
},
{
  "id": "exercise-214",
  "level": "2",
  "url": "sec-det2x2.html#exercise-214",
  "type": "Exercice",
  "number": "4.1.4.17",
  "title": "",
  "body": " Soit , les points d'un triangle quelconque et , le barycentre des sommets du triangle. Montrer que les triangles et ont la même aire.   Trois aires égales    Définir les aires des triangles comme des déterminants de vecteurs partant tous du point . Comme suggéré dans l'indice, on écrit chaque aire comme un déterminant en fonction des vecteurs .   On a choisi l'ordre des vecteurs pour que les déterminants soient tous positifs. On remarque que, puisque le facteur est présent chaque fois, on n'a qu'à montrer que ces trois déterminants sont égaux. On utilisera l'équation du barycentre sous cette forme:  On peut faire la preuve que ce dernier déterminant est égal à en suivant exactement les mêmes étapes. "
},
{
  "id": "exercise-215",
  "level": "2",
  "url": "sec-det2x2.html#exercise-215",
  "type": "Exercice",
  "number": "4.1.4.18",
  "title": "",
  "body": " Soit et .  Montrer que .    Le code solution pour l'exercice   A=matrix([[-4,12],[-8,4]]) B=matrix([[2,1],[2,-2]]) AB=A*B moinsBA=-B*A show(AB) show(moinsBA) show(AB==moinsBA)   Calculer le déterminant des matrices et ci-dessus.  Le code solution pour l'exercice   A=matrix([[-4,12],[-8,4]]) B=matrix([[2,1],[2,-2]]) show(det(A)) show(det(B))    On aurait aussi pu les calculer à la main rapidement. Trouver l'erreur dans le raisonnement suivant.  Soit , deux matrices telles que . En prenant les déterminants de chaque côté, on a . L'erreur se trouve entre la première et la deuxième ligne. Il est vrai que les deux déterminants initiaux doivent être égaux, puisque les matrices sont égales. Cependant, à la deuxième ligne, dans le membre de droite de l'équation, on a effectué une opération que l'on ne peut pas faire. On a sorti le moins du déterminant. Cela ne peut pas être fait, car ce n'est pas une application de la propriété puisqu'on sortirait une constante de toutes les colonnes en même temps. On a considéré cette question à l'exercice , on avait alors déterminé que . Ainsi, et l'argument ne fonctionne plus. "
},
{
  "id": "exercise-216",
  "level": "2",
  "url": "sec-det2x2.html#exercise-216",
  "type": "Exercice",
  "number": "4.1.4.19",
  "title": "",
  "body": "Les opérations élémentaires du type et ne changent pas le déterminant selon la propriété . Pourtant, à partir d'une matrice , on a . L'égalité n'est alors vraie que si et , ce qui est impossible. Alors, où peut être le problème? L'erreur se situe à la deuxième ligne de la preuve. Tout ce qui est dit est vrai, mais on fait une erreur dans l'application de la propriété lorsqu'on l'applique essentiellement aux deux lignes en même temps. En effet, on effectue l'opération , ce qui donne la ligne . Ensuite, on effectue l'opération , ce qui devrait donner la ligne et non ce qu'on a obtenu. On refait le calcul du déterminant correctement en faisant ces deux opérations successivement plutôt que simultanément.  "
},
{
  "id": "exercise-217",
  "level": "2",
  "url": "sec-det2x2.html#exercise-217",
  "type": "Exercice",
  "number": "4.1.4.20",
  "title": "",
  "body": "Soit , une matrice telle qu'il existe une matrice diagonale et , une matrice inversible avec .  Calculer .   "
},
{
  "id": "exo-det2x2unpivot",
  "level": "2",
  "url": "sec-det2x2.html#exo-det2x2unpivot",
  "type": "Exercice",
  "number": "4.1.4.21",
  "title": "",
  "body": " On considère la matrice . Pour quelle(s) valeurs de le déterminant de la matrice est-il nul?  Comparer avec les valeurs de obtenues à l'exercice . Que conclure de cette comparaison?  et  Le déterminant est donc nul si ou si .  En comparant avec l'exercice , on remarque que ce sont les mêmes valeurs. Il semble donc que, pour cette matrice, avoir un déterminant nul correspond à avoir un seul pivot. "
},
{
  "id": "exercise-219",
  "level": "2",
  "url": "sec-det2x2.html#exercise-219",
  "type": "Exercice",
  "number": "4.1.4.22",
  "title": "",
  "body": "On considère le système d'équations linéaires où est une matrice . Si le système possède au moins une solution, quel est, en fonction du déterminant de , ce qui caractérise le nombre de solutions? On affirme qu'il y a au moins une solution. Ainsi, les possibilités sont qu'il y en a une seule ou bien une infinité. D'abord, si la matrice est inversible, on a , ce qui implique que la solution unique est obtenue par ce calcul. Cela se produit lorsque le déterminant de la matrice est non nul. Autrement, si le déterminant est nul et que ce calcul est impossible ( non inversible), alors il y aura une infinité de solutions. Bref, "
},
{
  "id": "exercise-220",
  "level": "2",
  "url": "sec-det2x2.html#exercise-220",
  "type": "Exercice",
  "number": "4.1.4.23",
  "title": "",
  "body": " Dans cet exercice, on revient sur l'équation normale d'un plan. Plus particulièrement, on a une manière simple de trouver un vecteur normal, en utilisant le produit vectoriel.  Déterminer une équation normale des plans suivants.    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. Afin de simplifier l'équation normale, on choisit un vecteur normal parallèle au résultat, mais plus simple: . L'équation est donc: On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. Afin de simplifier l'équation normale, on choisit un vecteur normal parallèle au résultat, mais plus simple: . L'équation est donc: On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,    On calcule d'abord le vecteur normal avec l' équation du produit vectoriel. En effet, puisque l'on veut un vecteur normal au plan, on obtiendra un tel vecteur en faisant le produit vectoriel des vecteurs directeurs. On a un vecteur simple . L'équation est donc . On obtient en remplaçant les valeurs des variables par le point connu du plan : . Et donc,  "
},
{
  "id": "exo-cramer2x2",
  "level": "2",
  "url": "sec-det2x2.html#exo-cramer2x2",
  "type": "Exercice",
  "number": "4.1.4.24",
  "title": "La méthode de Cramer <span class=\"process-math\">\\(2\\times 2\\)<\/span>.",
  "body": "La méthode de Cramer  On considère un système d'équations linéaires où sont connus et tels que . Le système possède donc une solution unique.   Soit . la matrice du système d'équations linéaires. On considère la matrice identité avec la première colonne remplacée par : .   Calculer .   Soit . Montrer que  D'abord, on montre que . En effet, . Ensuite, il faut montrer que . Il suffit de multiplier par et de remarquer qu'on obtient les membres de gauche des équations initiales.   Répéter la partie précédente avec la matrice afin de montrer que   D'abord, on montre que . En effet, . Ensuite, il faut montrer que . Il suffit de multiplier par et de remarquer qu'on obtient les membres de gauche des équations initiales.   Utiliser la méthode de Cramer pour trouver les solutions au système suivant: . On donne d'abord toutes les matrices associées au système:  Alors, et . "
},
{
  "id": "exercise-222",
  "level": "2",
  "url": "sec-det2x2.html#exercise-222",
  "type": "Exercice",
  "number": "4.1.4.25",
  "title": "",
  "body": " Dans cet exercice, on donne un avant-gout du chapitre . On s'intéresse aux solutions à l'équation .   On considère la matrice .  On commence avec . Résoudre l'équation en fonction de .    Voici une manière de résoudre le problème   Le code solution pour l'exercice   a=1 b=-1 A=column_matrix([[3*a\/5+2*b\/5,-3*a\/5+3*b\/5],[-2*a\/5+2*b\/5,2*a\/5+3*b\/5]]) Id=identity_matrix(2) var(\"k\") show(det(A-k*Id)) show(solve(det(A-k*Id),k))    Pour chaque valeur de trouvée, déterminer une solution au système d'équations linéaires .  Ces vecteurs sont aussi une solution de l'équation . Trouver une solution spéciale à cette équation.  Voici une manière de résoudre le problème   Le code solution pour l'exercice   ######Pour k=-1 ##### k=-1 show((A-k*Id).rref()) ######Pour k=1 ###### k=1 show((A-k*Id).rref())    On a donc, lorsque , le vecteur et, lorsque , le vecteur .  Calculer et où sont les solutions trouvées ci-dessus.   Voici une manière de résoudre le problème   Le code solution pour l'exercice   #####Pour v1 ##### v1=vector([2\/3,1]) show(\"Av_1=\",A*v1) #####Pour v2 ##### v2=vector([-1,1]) show(\"Av_2=\",A*v2)    On remarque que et que .  Refaire la partie avec quelconques.    Voici une manière de résoudre le problème   Le code solution pour l'exercice   var(\"a,b,k\") A=column_matrix([[3*a\/5+2*b\/5,-3*a\/5+3*b\/5],[-2*a\/5+2*b\/5,2*a\/5+3*b\/5]]) Id=identity_matrix(2) show(det(A-k*Id)) show(solve(det(A-k*Id),k)) ######Pour k=-1 ##### k=a show((A-k*Id).rref()) ######Pour k=1 ###### k=b show((A-k*Id).rref()) #####Pour v1 ##### v1=vector([2\/3,1]) show(\"Av_1=\",A*v1) #####Pour v2 ##### v2=vector([-1,1]) show(\"Av_2=\",A*v2)    On remarque, encore une fois, que les valeurs de qui satisfont l'équation sont et . Quant aux vecteurs , on retrouve les mêmes vecteurs qu'avec . Toutefois, on se rend compte que les produits matrice vecteur sont respectivement multipliés par . Les valeurs s'appellent les valeurs propres de la matrice et les vecteurs sont des vecteurs propres. Ces valeurs et vecteurs propres seront étudiés au chapitre .  "
},
{
  "id": "sec-detgen",
  "level": "1",
  "url": "sec-detgen.html",
  "type": "Section",
  "number": "4.2",
  "title": "Le déterminant d’une matrice <span class=\"process-math\">\\(n\\times n\\)<\/span>",
  "body": "  Le déterminant d'une matrice     Aller aux exercices de la section.  Dans , on peut s'intéresser au facteur de changement de volume et ensuite tenter de généraliser la notion de déterminant. Dans , la géométrie est plus difficile à imaginer. Pour ce qui est du signe du déterminant, on peut donner un sens à l'orientation dans , comme on le verra, mais c'est aussi plus difficile dans . On utilise donc les propriétés de la section précédente pour définir la notion de déterminant pour les espaces plus généraux.  Dans cette section, on généralise les idées de la section précédente, d'abord en considérant la géométrie dans , puis en donnant les résultats plus généraux pour une matrice . On introduit la notion de déterminant d'une matrice et ses propriétés.    L'espace à trois dimensions  Dans l'espace , une transformation linéaire envoie le cube unité vers l'équivalent tridimensionnel du parallélogramme, appelé le parallélépipède. En passant On écrit parfois aussi parallélipipède, pour désigner ce solide dont les six faces sont des parallélogrammes. Tout comme dans , il arrive que le solide transformé ne soit en fait plus un solide, mais un plan ou aussi une droite. Dans ces cas-là, on dira que le volume est nul.  On regarde le facteur de changement de volume de certaines transformations connues de .   Le facteur de changement de volume: dynamique  On considère les transformations suivantes dans et l'on cherche à calculer le facteur de changement de volume.   On peut visualiser l'effet des trois transformations à l'aide de la figure interactive suivante.   Le facteur de changement de volume     La matrice est celle de l'exemple et représente un étirement simultané dans les directions et de facteur et , respectivement. Géométriquement, le cube unité voit l'une de ses longueurs multipliée par , l'autre par et la dernière par . Il semble donc logique que le volume du parallélépipède obtenu sera de unités cubiques. De plus, l'intuition de la section laisse entrevoir que le facteur entrainera probablement un changement dans l'orientation, ce qui devrait faire du déterminant de cette matrice . La seconde matrice est une matrice de rotation, dont le mouvement s'effectue plus précisément autour de l'axe des , telle qu'elle est définie à l'exemple . Puisqu'une rotation ne change pas le volume, le facteur de changement de volume ici est de .  La matrice est une matrice de réflexion autour du plan , définie à l'exemple . Une réflexion ne changeant pas le volume, le facteur de changement de volume est . L'exercice laisse toutefois présager un possible changement d'orientation, si la situation dans se répète aussi dans .   On ajoute qu'à partir du facteur de changement de volume, correspondant au volume du parallélépipède, on peut aussi calculer le volume de certains solides dans l'espace. La figure interactive illustre les situations ci-dessous.  Un prisme à base triangulaire peut être vu comme la moitié d'un parallélépipède. Ainsi, son volume sera la moitié du facteur de changement de volume associé au parallélépipède.  À partir d'un tel prisme, on peut déconstruire en coupant selon un plan pour obtenir un tétraèdre et une pyramide avec comme base un parallélogramme. Cette pyramide se décompose à son tour en deux tétraèdres dont le volume est égal au premier trouvé. On constate alors que le volume de la pyramide est égal au du prisme, soit le du parallélépipède.  Les tétraèdres, quant à eux, valent le du prisme, leur volume est donc égal à de celui du parallélépipède.      Décomposition d'un parallélogramme    On regarde finalement ce que la notion d'orientation signifie dans . On pourra alors donner la définition dans du déterminant.   L'orientation dans  Soit , des vecteurs non nuls, non parallèles et qui ne sont pas tous dans le même plan. On note , le repère formé dans l'ordre des vecteurs et . On dit que est orienté positivement si le repère satisfait à la règle de la main droite:  On se place dans le plan engendré par les vecteurs et , de sorte que ceux-ci soient orientés positivement si l'on les voit comme des vecteurs de .  On place sa main droite sur le vecteur de sorte que la paume soit orientée vers le vecteur et que les doigts pointent vers .  Si le vecteur et le pouce «pointent» vers la même direction, alors l'orientation est positive. Sinon, elle est négative.  L'orientation d'un repère peut être visualisée dans la figure interactive .   L'orientation et la règle de la main droite      On regarde quelques exemples d'orientation. L'orientation combinée au facteur de changement de volume donnera le déterminant. On préfèrera toutefois la définition axiomatique de la prochaine sous-section, puisque pour , on va définir l'orientation selon le signe du déterminant.   L'orientation de certains repères : dynamique   On considère les vecteurs des figures . On veut déterminer l'orientation des repères  ;  ;  .     Premier ensemble de vecteurs     Deuxième ensemble de vecteurs     Troisième ensemble de vecteurs      Pour les vecteurs de la figure , on constate que est orienté positivement. Intuitivement, si l'on renverse l'ordre de et , on s'attend à ce que l'orientation change de signe si l'on se fie aux observations faites dans la section . C'est en effet ce que l'on remarque si l'on manipule la figure pour voir le plan engendré par avec le repère orienté positivement. On voit alors le vecteur rentrer « dans» l'écran.  Pour le repère , on peut essayer de visualiser le plan engendré par les vecteurs dans la bonne orientation. On constate alors que est orienté positivement. On pourrait aussi partir de et voir que, pour avoir , on a échangé la position des vecteurs et dans le repère. Selon ce que l'on connait de l'orientation, celle de et celle devraient être différentes. Cette intuition est bien entendu vérifiée avec la méthode décrite précédemment.    Pour les vecteurs de la figure , on constate que, cette fois, le repère est orienté négativement. Selon les mêmes arguments que pour la première figure, on s'attend à ce que l'orientation de soit positive et celle de soit négative. Ceci est vérifié en regardant dans la bonne perspective la figure .    Pour les vecteurs de la figure , on constate que le repère est aussi orienté négativement. Selon les mêmes arguments que pour la première figure, on s'attend à ce que l'orientation de soit positive et celle de soit négative. Ceci est vérifié en regardant dans la bonne perspective la figure .    On pourrait donner une définition du déterminant dans cette sous-section, mais elle serait identique à celle de la sous-section suivante, tout comme les propriétés. On préfère donc passer à la sous-section suivante. On fera la majorité des exemples de la sous-section avec des matrices .    Le déterminant  On passe maintenant à la définition axiomatique du déterminant pour une matrice . Cette définition généralise la définition pour le déterminant .   Le déterminant d'une matrice   Soit , une matrice de taille et , ses lignes. Le déterminant de est l'unique scalaire, noté , qui satisfait les quatre propriétés suivantes:   Propriétés à satisfaire   Si , alors ;  Multiplier une ligne par multiplie la valeur du déterminant par ce même , c'est-à-dire ;  Échanger la position de deux lignes change le signe du déterminant : ;  Ajouter à une ligne un multiple d'une autre ligne ne change pas le déterminant : .    Bien que dans la section on ait défini ces propriétés selon les colonnes afin de se coller aux transformations linéaires, on fait le choix ici plus standard de prendre la définition en fonction des lignes de la matrice. L'équivalence entre les deux sera montrée à la proposition . L'approche par les lignes permettra d'utiliser les opérations élémentaires sur les lignes plutôt que d'avoir à définir des opérations sur les colonnes.    Le reste de cette section va servir à trouver une manière efficace de calculer le déterminant et de démontrer ses propriétés, les mêmes que celles de la section précédente, mais généralisées. Toutefois, on fait une remarque avant de continuer.   L'existence et l'unicité du déterminant  À priori, rien n'indique que le déterminant existe, encore moins qu'il n'y en a qu'un seul pour une matrice donnée. On peut toutefois le démontrer, entre autres, grâce à Gauss-Jordan. Les détails de cette démonstration sont faits dans la section .  On commence avec un exemple de calcul de déterminant qui n'utilise que les propriétés . On voit que ces propriétés ne sont essentiellement que l'effet sur le déterminant des opérations élémentaires sur les lignes.   Un premier calcul de déterminant   On considère la matrice , que l'on a échelonnée à l'exemple . On cherche son déterminant.    On reproduit ici la démarche de l'exemple , mais cette fois en regardant l'effet sur le déterminant. .  Le déterminant de la matrice initiale vaut donc fois celui de la matrice identité, qui est . Ainsi . À noter que, lorsqu'on multiplie une ligne par , le déterminant est multiplié par . Si l'on ne veut rien changer au déterminant initial que l'on essaie de calculer, on doit diviser par . C'est pourquoi l'opération , par exemple, donne un facteur devant le déterminant et non pas .    L'algorithme de Gauss-Jordan fournit donc une manière de calculer un déterminant, mais il faut bien noter l'effet des opérations élémentaires sur le déterminant. Dans le dernier exemple, on n'a pas utilisé la propriété . On regarde un autre exemple dans lequel on utilise cette propriété.   Un autre calcul de déterminant  On reprend la matrice de l'exemple et l'on calcule son déterminant.  Cette fois, on ne reproduit pas les étapes de l'algorithme de Gauss-Jordan. On se contente de relire la solution à l'exemple et de noter l'effet de chaque opération sur le déterminant.  La première opération permute les lignes un et deux. On obtient donc un changement de signe. On note cet effet sur le déterminant par  On divise ensuite la nouvelle ligne un par pour avoir le pivot égal à . Pour ne rien changer au déterminant, il faudra multiplier par .  L'opération suivante est une opération de combinaison linéaire. Elle n'a aucun effet sur le déterminant. On pourrait dire .  La prochaine opération consiste à échanger les lignes deux et trois. Ceci apporte un nouveau changement de signe, .  S'ensuit alors une autre combinaison linéaire, qui ne change pas le déterminant: .  On divise la ligne trois par afin de rendre le pivot égal à . Pour ne pas changer le déterminant, il faut multiplier par .  Toutes les autres opérations sont des opérations de combinaisons linéaires et ne changent pas le déterminant.    La matrice obtenue à la fin est la matrice identité. Le déterminant de est donc .   Dans les derniers exemples, la matrice échelonnée réduite était toujours l'identité. Qu'arrive-t-il au déterminant si ce n'est pas le cas? Si, par exemple, on veut le déterminant de la matrice échelonnée réduite , aucune des propriétés ne permet de le faire directement. En s'inspirant des résultats de la section , il est toutefois plausible de penser que ce déterminant vaudra zéro. En effet, on voit dans la matrice la présence d'une ligne nulle, ce qui fait penser à la propriété . On sait aussi qu'une matrice carrée qui ne s'échelonne pas à l'identité ne peut pas être inversible, rappelant ainsi la propriété . On poursuit cette section dans le but de montrer les propriétés équivalentes à celles démontrées dans le cas d'un déterminant . Comme on n'a pas de formule générale comme c'était le cas précédemment, il faudra quelques résultats supplémentaires.  Ces résultats portent sur le déterminant des matrices élémentaires et sur le déterminant du produit d'une matrice élémentaire et d'une matrice quelconque.   Les matrices élémentaires et le déterminant   Soit , une matrice carrée de taille et soit et . Alors  ;  ;   si est n'importe quelle matrice élémentaire, alors .     On démontre facilement les trois premières propriétés, car celles-ci correspondent à l'application des propriétés , et des déterminants sur la matrice identité. Pour la propriété du produit, on note que l'effet de la multiplication à gauche par une matrice élémentaire sur la matrice revient à faire l'opération élémentaire sur la matrice. Comme les opérations élémentaires sont les mêmes que les propriétés , et , le résultat suit.   Avec ces résultats sur le déterminant des matrices élémentaires, on est maintenant en mesure de démontrer les propriétés des déterminants plus généralement. On en fait le résultat du théorème suivant.   Les propriétés du déterminant  Soit , une matrice carrée et , son déterminant. On note par les lignes de la matrice . Alors   Les propriétés du déterminant   Les premières propriétés font état du lien entre les lignes de la matrice. On les décline en trois variantes.  Si deux lignes sont égales, soit pour certaines valeurs de , alors .  Si deux lignes sont parallèles, soit pour certaines valeurs de et , alors .  Si une ligne est une combinaison linéaire des autres, soit , alors .  Si une ligne est nulle, soit pour une certaine valeur de , alors .  La matrice est inversible si et seulement si et .  Le déterminant d'un produit est égal au produit des déterminants, c'est-à-dire si est une autre matrice , alors .  Si une ligne est écrite comme la somme de deux vecteurs, alors .  Le déterminant de la transposée est égal au déterminant de la matrice originale, c'est-à-dire .     On démontre les deux premières propriétés regroupées. La troisième est laissée à l'exercice .  Si deux lignes sont identiques, on applique la propriété sur ces lignes. Puisque cette opération ne change pas la matrice, les lignes étant identiques, on a . Ceci entraine que et que le déterminant est nul.  Si une ligne est un multiple d'une autre, alors on applique d'abord pour mettre en évidence le scalaire. On a alors selon la propriété précédente.   On veut maintenant démontrer que si une ligne est nulle, alors le déterminant est nul. Pour cela, il suffit de « mettre en évidence » un zéro de la ligne nulle pour utiliser la propriété pour avoir .   Si est inversible, alors se réduit à la matrice identité par une chaine de matrices élémentaires, soit . On applique à répétition le fait que le déterminant d'une matrice élémentaire est non nul et le déterminant du produit d'une matrice élémentaire avec une matrice , établi à la proposition pour conclure que .  Pour montrer que , on utilise la prochaine propriété. Bien qu'elle ne soit pas encore démontrée, sa preuve n'utilise pas la valeur explicite du déterminant de et l'argument n'est donc pas circulaire. De plus, puisque , on a selon que et ainsi, .   On suppose que n'est pas inversible. Alors, selon la proposition , le produit n'est pas inversible non plus. Dans ce cas, ce qui implique à son tour que .  Si est inversible et puisque , on peut écrire . On applique la propriété à répétition pour conclure que . De l'autre côté, et par le même argument, .   Cette propriété demande un peu plus de travail et de réflexion. Dans un premier temps, on suppose que est une combinaison linéaire des vecteurs , c'est-à-dire qu'il existe tel que . On a alors .  On passe maintenant au cas où n'est pas une combinaison linéaire des lignes de la matrice. Ceci signifie que l'équation ne possède pas de solutions (voir exercice ). Ainsi, selon le théorème , la matrice n'est pas inversible et non plus. On conclut avec la propriété que .  Deux choses sont maintenant possibles. Le vecteur peut être une combinaison linéaire des vecteurs , dans ce cas selon le théorème , on a et, en utilisant à répétition la propriété pour éliminer le terme , on a . Si n'est toutefois pas une combinaison linéaire des autres lignes. On remarque d'abord que n'est pas non plus une combinaison linéaire des autres lignes et de . Si c'était le cas, on pourrait isoler dans la combinaison linéaire et l'écrire en fonction des lignes de la matrice. On considère les trois équations , où est la matrice avec la ligne remplacée par le vecteur et est la matrice avec la ligne remplacée par . Ces trois équations n'ayant pas de solutions, on conclut par le théorème que ne sont pas inversibles et donc selon . En effet, si une solution à ces équations existait, on pourrait écrire les vecteurs respectifs comme une combinaison linéaire des colonnes des matrices transposées, et donc, des lignes de ou (voir exercice ). Puisque tous les déterminants sont nuls, la propriété est vraie, car .   Voir l'exercice   La propriété et sa preuve permettent d'obtenir une nouvelle version du théorème de la matrice inverse .   Théorème de la matrice inverse, quatrième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .  Le rang de la matrice est égal à .  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité.  Aucune ligne n'est une combinaison linéaire des autres lignes.  Aucune colonne n'est une combinaison linéaire des autres colonnes.  Le déterminant de la matrice est non nul.     Les exemples et montrent que, pour calculer un déterminant, on peut faire la réduction à la forme échelonnée réduite en gardant une trace des opérations effectuées. Ces traces sont en fait les déterminants des matrices élémentaires. On peut toutefois éviter de faire l'échelonnage jusqu'au bout, avec un autre résultat. Mais avant, une définition d'un type particulier de matrices.   Les matrices triangulaires  Une matrice carrée est triangulaire inférieure si toutes les entrées au-dessus de la diagonale principale sont nulles. Similairement, une matrice carrée est triangulaire supérieure si toutes les entrées sous la diagonale principale sont nulles. On note souvent ces matrices par les lettres et , de l'anglais « lower, upper». Ci-dessous se retrouvent des exemples de matrices triangulaires de taille . Les entrées identifiées par peuvent prendre n'importe quelle valeur.    Le déterminant d'une matrice triangulaire est particulièrement facile à calculer. En particulier, si l'on rend une matrice quelconque équivalente à une matrice triangulaire supérieure , on pourra calculer le déterminant plus rapidement qu'en faisant l'algorithme de Gauss-Jordan au complet.   Le déterminant d'une matrice triangulaire   Soit , une matrice triangulaire inférieure ou supérieure. Alors le déterminant de est égal au produit des entrées sur la diagonale.   On suppose que est une matrice triangulaire supérieure. Puisque est une matrice triangulaire inférieure et que selon la propriété , il suffit de le montrer pour un des deux types.  Si l'une des entrées sur la diagonale est nulle, alors, en poursuivant les opérations élémentaires pour réduire , on aura éventuellement une ligne de zéros. Selon la propriété , le déterminant est égal à zéro. Cela correspond aussi au produit de la diagonale puisqu'un produit contenant un zéro est nul.  On suppose donc qu'aucune entrée sur la diagonale est nulle. La matrice est une matrice triangulaire supérieure qui ne contient que des sur sa diagonale. On peut poursuivre l'algorithme de Gauss-Jordan pour réduire à l'identité en n'utilisant que l'opération , qui ne change pas le déterminant. On a donc . Puisque , on isole dans l'équation .    On propose un exemple où l'on échelonne jusqu'à la forme triangulaire supérieure pour calculer le déterminant, sans nécessairement faire en sorte que les pivots soient égaux à . Bien entendu, il faut quand même garder une trace des opérations faites pour s'y rendre.   Le calcul d'un déterminant par la méthode triangulaire supérieure   Soit . On cherche le déterminant de .    On réduit la matrice jusqu'à l'apparition d'une forme triangulaire supérieure, sans forcer pour que la valeur des pivots soit . On a . Le produit de la diagonale de la dernière matrice est . Puisqu'on a effectué l'opération , ce déterminant est deux fois plus grand que celui de . On a donc .    On termine avec des commandes Sage en lien avec la sous-section.   Les déterminants et Sage  La même commande .determinant() sert à calculer le déterminant d'une matrice .        Les points importants de cette section sont:  La notion d'orientation dans et la règle de la main droite;  La définition du déterminant ;  Le déterminant des matrices élémentaires;  Les propriétés du déterminant et la quatrième version du théorème de la matrice inverse;  La notion de matrice triangulaire et le calcul de son déterminant .    De plus avec Sage, la commande .determinant() permet de calculer le déterminant d'une matrice de taille .      Exercices   Étant donné le volume des figures suivantes, déterminer la valeur des déterminants demandés.  Le parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un parallélépipède     Que vaut ?  Puisque le volume du parallélépipède engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le volume du parallélépipède. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le volume du parallélépipède. On a donc .  Le prisme obtenu du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un prisme     Que vaut ?  Puisque le volume du prisme engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume du prisme est égal à la moitié du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. On a donc .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le double du volume du prisme. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le double du volume du prisme. On a donc .  La pyramide obtenue du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Une pyramide     Que vaut ?  Puisque le volume de la pyramide engendrée par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume de la pyramide est égal au tiers du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a ainsi .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le triple du volume de la pyramide. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le triple du volume de la pyramide. On a donc .  Le tétraèdre obtenu du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un tétraèdre     Que vaut ?  Puisque le volume du tétraèdre engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume du tétraèdre est égal au sixième du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a ainsi .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est de six fois le volume du tétraèdre. On a ainsi .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est de six fois le volume du tétraèdre. On a ainsi .   Utiliser la figure interactive suivante pour déterminer l'orientation du repère dans de manière géométrique.   L'orientation de trois vecteurs    Il suffit d'appliquer la règle de la main droite en dirigeant nos doigts vers , notre paume vers et en déterminant si notre pouce pointe vers ou non. Si c'est le cas, le repère est d'orientation positive, il est d'orientation négative autrement. En affichant le plan engendré par et , si notre vue est au-dessus du plan, que est plus vers la droite et vers la gauche, il sera facile de déterminer si pointe vers le pouce puisqu'il sera en pointillé s'il pointe dans une autre direction (sous le plan).  Dans cet exercice, on s'intéresse à l'orientation d'un repère et à l'angle entre et , le produit vectoriel de et    On considère , et .  Déterminer l'orientation du repère . L'orientation du repère est positive. Il y a plus d'une façon de procéder, mais on considère que de calculer le déterminant et de regarder son signe est la meilleure approche. Pour calculer un déterminant, on peut procéder comme dans les exemples et , mais on préfère l'approche plus rapide de l'exemple . On échelonne donc la matrice obtenue en plaçant les vecteurs en lignes et l'on calcule sa trace. On remarque que l'on aurait aussi pu la construire en colonnes, par . Le produit de la diagonale de la dernière matrice est . Puisqu'on n'a effectué que des opérations du type , ce déterminant est le même que celui de . On a donc . Puisqu'il est positif, l'orientation du repère est aussi positive.  Calculer .     Calculer l'angle entre et .    Répéter l'étape avec les vecteurs et L'orientation du repère est négative.   Il y a plus d'une façon de procéder, mais on considère que de calculer le déterminant et de regarder son signe est la meilleure approche. Pour calculer un déterminant, on peut procéder comme dans les exemples et , mais on préfère l'approche plus rapide de l'exemple . On échelonne donc la matrice obtenue en plaçant les vecteurs en lignes et l'on calcule sa trace. On remarque que l'on aurait aussi pu la construire en colonnes, par . Le produit de la diagonale de la dernière matrice est . Puisqu'on n'a effectué que des opérations du type , ce déterminant est le même que celui de . On a donc . Puisqu'il est négatif, l'orientation du repère est aussi négative.  Pour le produit vectoriel, on a .  Et finalement pour l'angle, .  Formuler une hypothèse entre la relation du troisième vecteur d'un repère et le produit vectoriel des deux premiers vecteurs de ce repère. Notre hypothèse est que si l'orientation du repère de ces trois vecteurs est positive, alors l'angle entre le produit vectoriel des deux premiers vecteurs et le troisième vecteur sera un angle aigu .  À l'inverse, si l'orientation du repère de ces trois vecteurs est négative, alors l'angle entre le produit vectoriel des deux premiers vecteurs et le troisième vecteur sera un angle obtus .  Dans le cas où cet angle serait exactement égal à , le vecteur se situe dans le plan engendré par et , le déterminant est égal à zéro et l'orientation du repère n'est pas définie.    Montrer que la propriété peut être déduite à partir des propriétés et .  Voir l'exercice . Suivant l'indice, on utilise les mêmes étapes que dans l'exercice .    Démontrer la propriété .  On applique la propriété à répétition.    Dans cet exercice, on veut montrer que , donnant ainsi une preuve à la propriété .   Montrer que si est une matrice élémentaire, alors le résultat est valide.  Les opérations élémentaires sont les suivantes:  Interchanger la position de deux lignes;  Multiplier une ligne par une constante non nulle;  Ajouter à une ligne un multiple d'une autre.  Les matrices élémentaires sont donc dans ces trois catégories.  Une matrice élémentaire obtenue de la matrice identité en interchangeant deux lignes a comme déterminant par la propriété . Lorsqu'on la transpose, on obtient la même matrice. En effet, si les lignes et de la matrice identité sont interchangées, on obtient exactement la matrice où les colonnes et sont interchangées. Bref, elles ont le même déterminant.  Une matrice élémentaire obtenue de la matrice identité en multipliant une ligne par une constante non nulle a comme déterminant la valeur de cette constante, par la propriété . Cette matrice étant une matrice diagonale, elle est égale à sa transposée qui aura donc le même déterminant.  Une matrice élémentaire obtenue de la matrice identité en ajoutant à une ligne un multiple d'une autre ligne a comme déterminant par la propriété . La transposée est différente, mais peut être obtenue avec le même type d'opération, en inversant les deux lignes impliquées. Elle a donc le même déterminant, soit .    Démontrer maintenant la propriété .  Distinguer le cas inversible du cas non inversible et passer à une décomposition en produit de matrices élémentaires pour le premier cas. D'abord, si est inversible alors, par les conclusions de l'exercice , on peut écrire pour des matrices élémentaires inversibles . Ensuite, si est non inversible alors, par le théorème , on sait que la matrice n'est pas de rang maximal et que sa forme échelonnée réduite n'est pas la matrice identité. Elle a donc nécessairement une ligne de zéros et son déterminant est nul. Le déterminant de la matrice est donc aussi nul. La transposée de sera également de rang non maximal et son déterminant sera également nul.  Il s'ensuit que .   Soit , une matrice telle que sa première ligne et sa première colonne sont nulles, sauf pour l'entrée et soit , la matrice obtenue à partir de en enlevant sa première ligne et sa première colonne : .  Montrer que .  Si est la forme échelonnée réduite de , à quoi ressemble la forme échelonnée réduite de ? Comme suggéré dans l'indication, on s'attarde aux formes échelonnées réduites de et de . Rappelons que l'on peut calculer le déterminant d'une matrice à partir de sa forme échelonnée réduite comme dans l'exemple . Soit , la forme échelonnée réduite de . Deux options sont possibles.  D'abord, si n'est pas la matrice identité, alors elle contient une ligne de zéros et son déterminant est nul par la propriété . Le déterminant de est donc aussi nul, puisqu'on multiplie par des constantes pour le calculer. La forme échelonnée réduite de sera la matrice augmentée des lignes et colonnes retranchées précédemment, puisque l'on referait l'échelonnage à partir de la deuxième colonne de , la première étant déjà pivot. Il en résulte que la forme échelonnée réduite de possèdera aussi une ligne de zéros et son déterminant sera aussi nul.  Ensuite, si est la matrice identité, alors est obtenu en multipliant toutes les constantes obtenues des opérations élémentaires de l'échelonnage. L'échelonnage de la matrice n'ajoutant aucune opération élémentaire, puisque la première colonne est déjà pivot, on obtient que son déterminant sera égal à sa forme échelonnée réduite étant également l'identité. Il s'ensuit que .   Dans la section , on démontre que le produit  est inversible si et seulement si les matrices sont inversibles. Donner une preuve alternative de ce résultat en utilisant les déterminants.  On se sert des propriétés et . On a fait ce calcul pour démontrer que l'inverse de existe si et seulement si les inverses de et de existent. En effet, par le théorème , on sait qu'une matrice est inversible si et seulement si son déterminant est non nul. Le calcul précédent exige que si et seulement si et , étant donné que ce sont les conditions pour que l'égalité fonctionne.   Dans l'exercice , on utilise le déterminant pour savoir si trois points sont alignés ou si deux vecteurs sont parallèles. On s'intéresse ici à l'équivalent dans .  Dans quelle(s) circonstance(s) géométrique(s) est-ce qu'un déterminant est nul? Si les vecteurs sont sur une même droite ou un même plan.  On vérifie que trois points sont alignés (colinéaires) dans en calculant un déterminant. Ce déterminant vaut zéro si les points sont alignés. Pour faire l'équivalent à trois dimensions, on considère quatre points. Que signifie le déterminant nul obtenu à partir de ces quatre points?  Il signifie que les quatre points sont sur un même plan dans . On peut affirmer que ces points sont coplanaires.  Formuler l'énoncé précédent en termes de vecteurs.  Trois vecteurs se situent dans un même plan si leur déterminant est nul, c'est-à-dire si . On peut affirmer que ces vecteurs sont coplanaires.   Donner un argument géométrique au fait que le déterminant n'est défini que pour des matrices carrées.  Plusieurs réponses sont possibles. On utilise l'argument de l'interprétation géométrique du déterminant comme un facteur de changement (d'aire, de volume, etc.). Si le déterminant représente une constante associée à une transformation linéaire permettant de mesurer l'effet de la transformation linéaire en fonction d'un facteur de changement sur l'aire, le volume ou l'hypervolume, alors il faut absolument que la transformation soit d'un espace vers ce même espace. En effet, comment pourrait-on parler de facteur de changement d'aire si l'on passe de vers , par exemple pour une transformation linéaire représentée par une matrice ? Cela n'a pas de sens. Il faut donc absolument avoir une matrice pour pouvoir parler d'un déterminant.   Soit et , les coordonnées d'un triangle dans . On sait que l'on peut calculer l'aire du triangle avec un déterminant par exemple en le divisant par deux.  Montrer que l'aire du triangle peut aussi être obtenue à l'aide du déterminant .  On peut faire une preuve algébrique ou une preuve géométrique qui seraient toutes les deux valables. On choisit ici de faire les deux pour satisfaire les préférences de tous et toutes.  Géométriquement, il faut réfléchir à ce que représente le déterminant . Les vecteurs colonnes de ce déterminant ont tous en commun une composante en égale à . Si l'on se positionne pour que l'axe des pointe vers nous, ce que l'on observe, c'est un triangle parallèle au plan formés par les points et positionnés de la même façon qu'ils l'étaient dans . Le prisme droit de hauteur a comme volume la même valeur que l'aire du triangle puisqu'on le calcule en multipliant l'aire de la base par sa hauteur, qui est . On a démontré, à la figure , que le volume d'une pyramide triangulaire vaut les deux tiers du volume du prisme dans lequel elle est encastrée. Puisqu'on calcule le volume de la pyramide en divisant le déterminant par trois, on a donc la chaine d'égalités suivantes:  .  Algébriquement, on peut simplement développer les deux expressions en présence et observer qu'elles sont égales. Pour développer , il faut échelonner la matrice pour avoir une matrice triangulaire supérieure. Puisque les opérations élémentaires effectuées étaient toutes du type , on obtient le déterminant en multipliant les éléments de la diagonale. Noter que l'on aurait pu arrêter les deux calculs deux lignes plus tôt puisqu'on avait déjà obtenu la même expression.   Montrer que Rendre la matrice triangulaire. On suit l'indice et l'on calcule le déterminant en échelonnant pour avoir une matrice triangulaire supérieure. Puisque les opérations élémentaires effectuées étaient toutes du type , on obtient le déterminant en multipliant les éléments de la diagonale.   Une matrice est dite orthogonale si , c'est-à-dire que son inverse est égal à sa transposée. Montrer que les matrices de rotation et de réflexion dans sont orthogonales. On connait ces matrices. Il suffit de faire le calcul. On commence par la matrice de rotation . On poursuit avec la matrice de réflexion .  Quelles sont les valeurs possibles pour le déterminant d'une matrice orthogonale? Il peut valoir ou . On utilise la définition précédente. Soit , une matrice orthogonale. Alors, on sait que . On calcule son déterminant. Si , alors il n'y a que deux options, soit ou .    Une matrice antisymétrique est une matrice telle que . Si est une matrice antisymétrique de taille où est impair, montrer que . Pourquoi est-ce impossible dans le cas où est pair?  Soit , une matrice antisymétrique. On utilise les propriétés des déterminants pour calculer le déterminant de . Et donc, si , alors . On remarque que l'on a utilisé la propriété à la deuxième ligne fois, une fois pour chaque ligne.  Il est clair que si est pair, tout ce que l'on obtient, c'est que , ce qui est toujours vrai.    Dans cet exercice, on regarde l'aire, le volume ou l'hypervolume du solide engendré par un ensemble de vecteurs.   Soit . Montrer que l'aire du parallélogramme engendré par ces vecteurs est .  Considérer la matrice et sa transposée et remarquer que l'expression dans la racine représente le déterminant de . On suit l'indication en définissant la matrice et sa transposée. Le déterminant de correspond à l'aire du parallélogramme engendré par et (positive ou négative). Cette expression est donc l'aire du parallélogramme. Soit . Montrer que le volume du parallélépipède engendré par ces vecteurs est . On suit l'indication en définissant la matrice et sa transposée. Le déterminant de correspond au volume du parallélépipède engendré par , et (positif ou négatif). Cette expression est donc le volume du parallélépipède.  Généraliser les résultats précédents pour montrer que est égal à l'hypervolume du solide à dimensions engendré par les vecteurs .  On continue avec la même démarche en définissant la matrice et sa transposée. Le déterminant de correspond à l'hypervolume du solide engendré par , et (positif ou négatif). . Cette expression est donc l'hypervolume de l'hyperparallélépipède (défi Scrabble du jour).  La méthode de Cramer  Généraliser les idées de l'exercice pour exprimer la solution à un système d'équations linéaires , où est une matrice , en fonction de déterminants.  On note que cette méthode n'est pas très pratique d'un point de vue calculatoire, car elle exige le calcul d'un grand nombre de déterminants. Elle est toutefois efficace dans le cas .  Soit , une matrice de format , , un vecteur et soit l'équation . Cette équation représente le système d'équations linéaires: . On pose et , pour pouvoir énoncer la méthode de Cramer. Alors, et les valeurs des variables sont données par . La preuve serait très longue à faire et suivrait le modèle de l'exercice . On choisit de généraliser l'idée sans la démontrer algébriquement.   Exercices Sage  Les exercices qui suivent sont conçus pour être réalisés avec Sage. Évidemment, il y a plusieurs manières d'arriver aux réponses.  On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de et démontrer ensuite le résultat.   Le déterminant est toujours égal à .  Voici une manière d'obtenir l'hypothèse.   Le code solution de l'exercice   def matexo(n): L=[] #On se définit une liste vide dans laquelle on va mettre les lignes de la matrice for i in range(n): #On crée chaque ligne de la matrice v=[j+1 for j in range(i+1)] #Les premières entrées de la ligne valent 1,2,3,... for j in range(n-(i+1)): #Pour les colonnes restantes, les entrées valent le numéro de la ligne (i+1 car Sage commence à 0) v.append(i+1) L.append(v) #On ajoute la ligne à la liste return matrix(L) #On retourne la matrice for k in range(6): show(matexo(k+1)) show(\"det(A_%d)=\" % (k+1),matexo(k+1).determinant())    Pour faire la démonstration, on peut procéder par induction ou par calcul direct.  Si , alors, de manière évidente, on a . On suppose que . En utilisant l'opération sur chaque ligne sous la première, on obtient . En utilisant l'opération , on obtient maintenant .  Puisque les opérations élémentaires de type ne changent pas le déterminant, en utilisant l'exercice on a , selon l'hypothèse d'induction.   On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de .    Le déterminant est .  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def diag0autres1(i,j): if i==j: return 0 else: return 1 A=matrix(ZZ,5,lambda i,j: diag0autres1(i,j)) for i in range(10): show(\"det(A_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: diag0autres1(i,j)).determinant())        "
},
{
  "id": "example-81",
  "level": "2",
  "url": "sec-detgen.html#example-81",
  "type": "Exemple",
  "number": "4.2.1",
  "title": "Le facteur de changement de volume: dynamique.",
  "body": " Le facteur de changement de volume: dynamique  On considère les transformations suivantes dans et l'on cherche à calculer le facteur de changement de volume.   On peut visualiser l'effet des trois transformations à l'aide de la figure interactive suivante.   Le facteur de changement de volume     La matrice est celle de l'exemple et représente un étirement simultané dans les directions et de facteur et , respectivement. Géométriquement, le cube unité voit l'une de ses longueurs multipliée par , l'autre par et la dernière par . Il semble donc logique que le volume du parallélépipède obtenu sera de unités cubiques. De plus, l'intuition de la section laisse entrevoir que le facteur entrainera probablement un changement dans l'orientation, ce qui devrait faire du déterminant de cette matrice . La seconde matrice est une matrice de rotation, dont le mouvement s'effectue plus précisément autour de l'axe des , telle qu'elle est définie à l'exemple . Puisqu'une rotation ne change pas le volume, le facteur de changement de volume ici est de .  La matrice est une matrice de réflexion autour du plan , définie à l'exemple . Une réflexion ne changeant pas le volume, le facteur de changement de volume est . L'exercice laisse toutefois présager un possible changement d'orientation, si la situation dans se répète aussi dans .  "
},
{
  "id": "fig-det3x3paradecom",
  "level": "2",
  "url": "sec-detgen.html#fig-det3x3paradecom",
  "type": "Figure",
  "number": "4.2.3",
  "title": "",
  "body": " Décomposition d'un parallélogramme   "
},
{
  "id": "def-orientationR3",
  "level": "2",
  "url": "sec-detgen.html#def-orientationR3",
  "type": "Définition",
  "number": "4.2.4",
  "title": "L’orientation dans <span class=\"process-math\">\\(\\R^3\\)<\/span>.",
  "body": " L'orientation dans  Soit , des vecteurs non nuls, non parallèles et qui ne sont pas tous dans le même plan. On note , le repère formé dans l'ordre des vecteurs et . On dit que est orienté positivement si le repère satisfait à la règle de la main droite:  On se place dans le plan engendré par les vecteurs et , de sorte que ceux-ci soient orientés positivement si l'on les voit comme des vecteurs de .  On place sa main droite sur le vecteur de sorte que la paume soit orientée vers le vecteur et que les doigts pointent vers .  Si le vecteur et le pouce «pointent» vers la même direction, alors l'orientation est positive. Sinon, elle est négative.  L'orientation d'un repère peut être visualisée dans la figure interactive .   L'orientation et la règle de la main droite     "
},
{
  "id": "ex-orientationR3",
  "level": "2",
  "url": "sec-detgen.html#ex-orientationR3",
  "type": "Exemple",
  "number": "4.2.6",
  "title": "L’orientation de certains repères : dynamique.",
  "body": " L'orientation de certains repères : dynamique   On considère les vecteurs des figures . On veut déterminer l'orientation des repères  ;  ;  .     Premier ensemble de vecteurs     Deuxième ensemble de vecteurs     Troisième ensemble de vecteurs      Pour les vecteurs de la figure , on constate que est orienté positivement. Intuitivement, si l'on renverse l'ordre de et , on s'attend à ce que l'orientation change de signe si l'on se fie aux observations faites dans la section . C'est en effet ce que l'on remarque si l'on manipule la figure pour voir le plan engendré par avec le repère orienté positivement. On voit alors le vecteur rentrer « dans» l'écran.  Pour le repère , on peut essayer de visualiser le plan engendré par les vecteurs dans la bonne orientation. On constate alors que est orienté positivement. On pourrait aussi partir de et voir que, pour avoir , on a échangé la position des vecteurs et dans le repère. Selon ce que l'on connait de l'orientation, celle de et celle devraient être différentes. Cette intuition est bien entendu vérifiée avec la méthode décrite précédemment.    Pour les vecteurs de la figure , on constate que, cette fois, le repère est orienté négativement. Selon les mêmes arguments que pour la première figure, on s'attend à ce que l'orientation de soit positive et celle de soit négative. Ceci est vérifié en regardant dans la bonne perspective la figure .    Pour les vecteurs de la figure , on constate que le repère est aussi orienté négativement. Selon les mêmes arguments que pour la première figure, on s'attend à ce que l'orientation de soit positive et celle de soit négative. Ceci est vérifié en regardant dans la bonne perspective la figure .   "
},
{
  "id": "def-determinant",
  "level": "2",
  "url": "sec-detgen.html#def-determinant",
  "type": "Définition",
  "number": "4.2.10",
  "title": "Le déterminant d’une matrice.",
  "body": " Le déterminant d'une matrice   Soit , une matrice de taille et , ses lignes. Le déterminant de est l'unique scalaire, noté , qui satisfait les quatre propriétés suivantes:   Propriétés à satisfaire   Si , alors ;  Multiplier une ligne par multiplie la valeur du déterminant par ce même , c'est-à-dire ;  Échanger la position de deux lignes change le signe du déterminant : ;  Ajouter à une ligne un multiple d'une autre ligne ne change pas le déterminant : .    Bien que dans la section on ait défini ces propriétés selon les colonnes afin de se coller aux transformations linéaires, on fait le choix ici plus standard de prendre la définition en fonction des lignes de la matrice. L'équivalence entre les deux sera montrée à la proposition . L'approche par les lignes permettra d'utiliser les opérations élémentaires sur les lignes plutôt que d'avoir à définir des opérations sur les colonnes.   "
},
{
  "id": "rem-existdef",
  "level": "2",
  "url": "sec-detgen.html#rem-existdef",
  "type": "Remarque",
  "number": "4.2.12",
  "title": "L’existence et l’unicité du déterminant.",
  "body": " L'existence et l'unicité du déterminant  À priori, rien n'indique que le déterminant existe, encore moins qu'il n'y en a qu'un seul pour une matrice donnée. On peut toutefois le démontrer, entre autres, grâce à Gauss-Jordan. Les détails de cette démonstration sont faits dans la section . "
},
{
  "id": "ex-det3x3-1",
  "level": "2",
  "url": "sec-detgen.html#ex-det3x3-1",
  "type": "Exemple",
  "number": "4.2.13",
  "title": "Un premier calcul de déterminant <span class=\"process-math\">\\(3\\times 3\\)<\/span>.",
  "body": " Un premier calcul de déterminant   On considère la matrice , que l'on a échelonnée à l'exemple . On cherche son déterminant.    On reproduit ici la démarche de l'exemple , mais cette fois en regardant l'effet sur le déterminant. .  Le déterminant de la matrice initiale vaut donc fois celui de la matrice identité, qui est . Ainsi . À noter que, lorsqu'on multiplie une ligne par , le déterminant est multiplié par . Si l'on ne veut rien changer au déterminant initial que l'on essaie de calculer, on doit diviser par . C'est pourquoi l'opération , par exemple, donne un facteur devant le déterminant et non pas .   "
},
{
  "id": "ex-det3x3-2",
  "level": "2",
  "url": "sec-detgen.html#ex-det3x3-2",
  "type": "Exemple",
  "number": "4.2.14",
  "title": "Un autre calcul de déterminant.",
  "body": " Un autre calcul de déterminant  On reprend la matrice de l'exemple et l'on calcule son déterminant.  Cette fois, on ne reproduit pas les étapes de l'algorithme de Gauss-Jordan. On se contente de relire la solution à l'exemple et de noter l'effet de chaque opération sur le déterminant.  La première opération permute les lignes un et deux. On obtient donc un changement de signe. On note cet effet sur le déterminant par  On divise ensuite la nouvelle ligne un par pour avoir le pivot égal à . Pour ne rien changer au déterminant, il faudra multiplier par .  L'opération suivante est une opération de combinaison linéaire. Elle n'a aucun effet sur le déterminant. On pourrait dire .  La prochaine opération consiste à échanger les lignes deux et trois. Ceci apporte un nouveau changement de signe, .  S'ensuit alors une autre combinaison linéaire, qui ne change pas le déterminant: .  On divise la ligne trois par afin de rendre le pivot égal à . Pour ne pas changer le déterminant, il faut multiplier par .  Toutes les autres opérations sont des opérations de combinaisons linéaires et ne changent pas le déterminant.    La matrice obtenue à la fin est la matrice identité. Le déterminant de est donc .  "
},
{
  "id": "prop-detmatelem",
  "level": "2",
  "url": "sec-detgen.html#prop-detmatelem",
  "type": "Proposition",
  "number": "4.2.15",
  "title": "Les matrices élémentaires et le déterminant.",
  "body": " Les matrices élémentaires et le déterminant   Soit , une matrice carrée de taille et soit et . Alors  ;  ;   si est n'importe quelle matrice élémentaire, alors .     On démontre facilement les trois premières propriétés, car celles-ci correspondent à l'application des propriétés , et des déterminants sur la matrice identité. Pour la propriété du produit, on note que l'effet de la multiplication à gauche par une matrice élémentaire sur la matrice revient à faire l'opération élémentaire sur la matrice. Comme les opérations élémentaires sont les mêmes que les propriétés , et , le résultat suit.  "
},
{
  "id": "thm-detprop",
  "level": "2",
  "url": "sec-detgen.html#thm-detprop",
  "type": "Théorème",
  "number": "4.2.16",
  "title": "Les propriétés du déterminant.",
  "body": " Les propriétés du déterminant  Soit , une matrice carrée et , son déterminant. On note par les lignes de la matrice . Alors   Les propriétés du déterminant   Les premières propriétés font état du lien entre les lignes de la matrice. On les décline en trois variantes.  Si deux lignes sont égales, soit pour certaines valeurs de , alors .  Si deux lignes sont parallèles, soit pour certaines valeurs de et , alors .  Si une ligne est une combinaison linéaire des autres, soit , alors .  Si une ligne est nulle, soit pour une certaine valeur de , alors .  La matrice est inversible si et seulement si et .  Le déterminant d'un produit est égal au produit des déterminants, c'est-à-dire si est une autre matrice , alors .  Si une ligne est écrite comme la somme de deux vecteurs, alors .  Le déterminant de la transposée est égal au déterminant de la matrice originale, c'est-à-dire .     On démontre les deux premières propriétés regroupées. La troisième est laissée à l'exercice .  Si deux lignes sont identiques, on applique la propriété sur ces lignes. Puisque cette opération ne change pas la matrice, les lignes étant identiques, on a . Ceci entraine que et que le déterminant est nul.  Si une ligne est un multiple d'une autre, alors on applique d'abord pour mettre en évidence le scalaire. On a alors selon la propriété précédente.   On veut maintenant démontrer que si une ligne est nulle, alors le déterminant est nul. Pour cela, il suffit de « mettre en évidence » un zéro de la ligne nulle pour utiliser la propriété pour avoir .   Si est inversible, alors se réduit à la matrice identité par une chaine de matrices élémentaires, soit . On applique à répétition le fait que le déterminant d'une matrice élémentaire est non nul et le déterminant du produit d'une matrice élémentaire avec une matrice , établi à la proposition pour conclure que .  Pour montrer que , on utilise la prochaine propriété. Bien qu'elle ne soit pas encore démontrée, sa preuve n'utilise pas la valeur explicite du déterminant de et l'argument n'est donc pas circulaire. De plus, puisque , on a selon que et ainsi, .   On suppose que n'est pas inversible. Alors, selon la proposition , le produit n'est pas inversible non plus. Dans ce cas, ce qui implique à son tour que .  Si est inversible et puisque , on peut écrire . On applique la propriété à répétition pour conclure que . De l'autre côté, et par le même argument, .   Cette propriété demande un peu plus de travail et de réflexion. Dans un premier temps, on suppose que est une combinaison linéaire des vecteurs , c'est-à-dire qu'il existe tel que . On a alors .  On passe maintenant au cas où n'est pas une combinaison linéaire des lignes de la matrice. Ceci signifie que l'équation ne possède pas de solutions (voir exercice ). Ainsi, selon le théorème , la matrice n'est pas inversible et non plus. On conclut avec la propriété que .  Deux choses sont maintenant possibles. Le vecteur peut être une combinaison linéaire des vecteurs , dans ce cas selon le théorème , on a et, en utilisant à répétition la propriété pour éliminer le terme , on a . Si n'est toutefois pas une combinaison linéaire des autres lignes. On remarque d'abord que n'est pas non plus une combinaison linéaire des autres lignes et de . Si c'était le cas, on pourrait isoler dans la combinaison linéaire et l'écrire en fonction des lignes de la matrice. On considère les trois équations , où est la matrice avec la ligne remplacée par le vecteur et est la matrice avec la ligne remplacée par . Ces trois équations n'ayant pas de solutions, on conclut par le théorème que ne sont pas inversibles et donc selon . En effet, si une solution à ces équations existait, on pourrait écrire les vecteurs respectifs comme une combinaison linéaire des colonnes des matrices transposées, et donc, des lignes de ou (voir exercice ). Puisque tous les déterminants sont nuls, la propriété est vraie, car .   Voir l'exercice  "
},
{
  "id": "thm-delamatriceinversev4",
  "level": "2",
  "url": "sec-detgen.html#thm-delamatriceinversev4",
  "type": "Théorème",
  "number": "4.2.18",
  "title": "Théorème de la matrice inverse, quatrième version.",
  "body": " Théorème de la matrice inverse, quatrième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible  Pour chaque vecteur , il existe un seul vecteur tel que .  Le rang de la matrice est égal à .  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité.  Aucune ligne n'est une combinaison linéaire des autres lignes.  Aucune colonne n'est une combinaison linéaire des autres colonnes.  Le déterminant de la matrice est non nul.    "
},
{
  "id": "def-mattriang",
  "level": "2",
  "url": "sec-detgen.html#def-mattriang",
  "type": "Définition",
  "number": "4.2.19",
  "title": "Les matrices triangulaires.",
  "body": " Les matrices triangulaires  Une matrice carrée est triangulaire inférieure si toutes les entrées au-dessus de la diagonale principale sont nulles. Similairement, une matrice carrée est triangulaire supérieure si toutes les entrées sous la diagonale principale sont nulles. On note souvent ces matrices par les lettres et , de l'anglais « lower, upper». Ci-dessous se retrouvent des exemples de matrices triangulaires de taille . Les entrées identifiées par peuvent prendre n'importe quelle valeur.   "
},
{
  "id": "prop-detmattriang",
  "level": "2",
  "url": "sec-detgen.html#prop-detmattriang",
  "type": "Proposition",
  "number": "4.2.20",
  "title": "Le déterminant d’une matrice triangulaire.",
  "body": " Le déterminant d'une matrice triangulaire   Soit , une matrice triangulaire inférieure ou supérieure. Alors le déterminant de est égal au produit des entrées sur la diagonale.   On suppose que est une matrice triangulaire supérieure. Puisque est une matrice triangulaire inférieure et que selon la propriété , il suffit de le montrer pour un des deux types.  Si l'une des entrées sur la diagonale est nulle, alors, en poursuivant les opérations élémentaires pour réduire , on aura éventuellement une ligne de zéros. Selon la propriété , le déterminant est égal à zéro. Cela correspond aussi au produit de la diagonale puisqu'un produit contenant un zéro est nul.  On suppose donc qu'aucune entrée sur la diagonale est nulle. La matrice est une matrice triangulaire supérieure qui ne contient que des sur sa diagonale. On peut poursuivre l'algorithme de Gauss-Jordan pour réduire à l'identité en n'utilisant que l'opération , qui ne change pas le déterminant. On a donc . Puisque , on isole dans l'équation .   "
},
{
  "id": "ex-det3x3-3",
  "level": "2",
  "url": "sec-detgen.html#ex-det3x3-3",
  "type": "Exemple",
  "number": "4.2.21",
  "title": "Le calcul d’un déterminant par la méthode triangulaire supérieure.",
  "body": " Le calcul d'un déterminant par la méthode triangulaire supérieure   Soit . On cherche le déterminant de .    On réduit la matrice jusqu'à l'apparition d'une forme triangulaire supérieure, sans forcer pour que la valeur des pivots soit . On a . Le produit de la diagonale de la dernière matrice est . Puisqu'on a effectué l'opération , ce déterminant est deux fois plus grand que celui de . On a donc .   "
},
{
  "id": "computation-29",
  "level": "2",
  "url": "sec-detgen.html#computation-29",
  "type": "Calcul",
  "number": "4.2.22",
  "title": "Les déterminants <span class=\"process-math\">\\(n\\times n\\)<\/span> et Sage.",
  "body": " Les déterminants et Sage  La même commande .determinant() sert à calculer le déterminant d'une matrice .   "
},
{
  "id": "exercise-223",
  "level": "2",
  "url": "sec-detgen.html#exercise-223",
  "type": "Exercice",
  "number": "4.2.3.1",
  "title": "",
  "body": "Étant donné le volume des figures suivantes, déterminer la valeur des déterminants demandés.  Le parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un parallélépipède     Que vaut ?  Puisque le volume du parallélépipède engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le volume du parallélépipède. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le volume du parallélépipède. On a donc .  Le prisme obtenu du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un prisme     Que vaut ?  Puisque le volume du prisme engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume du prisme est égal à la moitié du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. On a donc .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le double du volume du prisme. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le double du volume du prisme. On a donc .  La pyramide obtenue du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Une pyramide     Que vaut ?  Puisque le volume de la pyramide engendrée par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume de la pyramide est égal au tiers du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a ainsi .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est le triple du volume de la pyramide. On a donc .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est le triple du volume de la pyramide. On a donc .  Le tétraèdre obtenu du parallélépipède engendré par les vecteurs illustré à la figure a pour volume .   Un tétraèdre     Que vaut ?  Puisque le volume du tétraèdre engendré par les vecteurs est de , on sait que n'importe quel déterminant impliquant ces trois vecteurs vaudra ou . En effet, comme illustré à la figure , le volume du tétraèdre est égal au sixième du volume du parallélépipède. Il faut donc simplement déterminer l'orientation des vecteurs du déterminant.  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. On a ainsi .  Que vaut ?   En utilisant la règle de la main droite, on voit que le vecteur pointe dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc positive, de même pour le déterminant. Sa valeur est de six fois le volume du tétraèdre. On a ainsi .  Que vaut ?  En utilisant la règle de la main droite, on voit que le vecteur ne pointe pas dans la direction de notre pouce après avoir positionné nos doigts vers et notre paume vers . L'orientation de ces vecteurs est donc négative, de même pour le déterminant. Sa valeur est de six fois le volume du tétraèdre. On a ainsi . "
},
{
  "id": "exercise-224",
  "level": "2",
  "url": "sec-detgen.html#exercise-224",
  "type": "Exercice",
  "number": "4.2.3.2",
  "title": "",
  "body": " Utiliser la figure interactive suivante pour déterminer l'orientation du repère dans de manière géométrique.   L'orientation de trois vecteurs    Il suffit d'appliquer la règle de la main droite en dirigeant nos doigts vers , notre paume vers et en déterminant si notre pouce pointe vers ou non. Si c'est le cas, le repère est d'orientation positive, il est d'orientation négative autrement. En affichant le plan engendré par et , si notre vue est au-dessus du plan, que est plus vers la droite et vers la gauche, il sera facile de déterminer si pointe vers le pouce puisqu'il sera en pointillé s'il pointe dans une autre direction (sous le plan). "
},
{
  "id": "exercise-225",
  "level": "2",
  "url": "sec-detgen.html#exercise-225",
  "type": "Exercice",
  "number": "4.2.3.3",
  "title": "",
  "body": "Dans cet exercice, on s'intéresse à l'orientation d'un repère et à l'angle entre et , le produit vectoriel de et    On considère , et .  Déterminer l'orientation du repère . L'orientation du repère est positive. Il y a plus d'une façon de procéder, mais on considère que de calculer le déterminant et de regarder son signe est la meilleure approche. Pour calculer un déterminant, on peut procéder comme dans les exemples et , mais on préfère l'approche plus rapide de l'exemple . On échelonne donc la matrice obtenue en plaçant les vecteurs en lignes et l'on calcule sa trace. On remarque que l'on aurait aussi pu la construire en colonnes, par . Le produit de la diagonale de la dernière matrice est . Puisqu'on n'a effectué que des opérations du type , ce déterminant est le même que celui de . On a donc . Puisqu'il est positif, l'orientation du repère est aussi positive.  Calculer .     Calculer l'angle entre et .    Répéter l'étape avec les vecteurs et L'orientation du repère est négative.   Il y a plus d'une façon de procéder, mais on considère que de calculer le déterminant et de regarder son signe est la meilleure approche. Pour calculer un déterminant, on peut procéder comme dans les exemples et , mais on préfère l'approche plus rapide de l'exemple . On échelonne donc la matrice obtenue en plaçant les vecteurs en lignes et l'on calcule sa trace. On remarque que l'on aurait aussi pu la construire en colonnes, par . Le produit de la diagonale de la dernière matrice est . Puisqu'on n'a effectué que des opérations du type , ce déterminant est le même que celui de . On a donc . Puisqu'il est négatif, l'orientation du repère est aussi négative.  Pour le produit vectoriel, on a .  Et finalement pour l'angle, .  Formuler une hypothèse entre la relation du troisième vecteur d'un repère et le produit vectoriel des deux premiers vecteurs de ce repère. Notre hypothèse est que si l'orientation du repère de ces trois vecteurs est positive, alors l'angle entre le produit vectoriel des deux premiers vecteurs et le troisième vecteur sera un angle aigu .  À l'inverse, si l'orientation du repère de ces trois vecteurs est négative, alors l'angle entre le produit vectoriel des deux premiers vecteurs et le troisième vecteur sera un angle obtus .  Dans le cas où cet angle serait exactement égal à , le vecteur se situe dans le plan engendré par et , le déterminant est égal à zéro et l'orientation du repère n'est pas définie.  "
},
{
  "id": "exercise-226",
  "level": "2",
  "url": "sec-detgen.html#exercise-226",
  "type": "Exercice",
  "number": "4.2.3.4",
  "title": "",
  "body": " Montrer que la propriété peut être déduite à partir des propriétés et .  Voir l'exercice . Suivant l'indice, on utilise les mêmes étapes que dans l'exercice .  "
},
{
  "id": "exo-detveccomblin",
  "level": "2",
  "url": "sec-detgen.html#exo-detveccomblin",
  "type": "Exercice",
  "number": "4.2.3.5",
  "title": "",
  "body": " Démontrer la propriété .  On applique la propriété à répétition.  "
},
{
  "id": "exo-preuvedettranspo",
  "level": "2",
  "url": "sec-detgen.html#exo-preuvedettranspo",
  "type": "Exercice",
  "number": "4.2.3.6",
  "title": "",
  "body": " Dans cet exercice, on veut montrer que , donnant ainsi une preuve à la propriété .   Montrer que si est une matrice élémentaire, alors le résultat est valide.  Les opérations élémentaires sont les suivantes:  Interchanger la position de deux lignes;  Multiplier une ligne par une constante non nulle;  Ajouter à une ligne un multiple d'une autre.  Les matrices élémentaires sont donc dans ces trois catégories.  Une matrice élémentaire obtenue de la matrice identité en interchangeant deux lignes a comme déterminant par la propriété . Lorsqu'on la transpose, on obtient la même matrice. En effet, si les lignes et de la matrice identité sont interchangées, on obtient exactement la matrice où les colonnes et sont interchangées. Bref, elles ont le même déterminant.  Une matrice élémentaire obtenue de la matrice identité en multipliant une ligne par une constante non nulle a comme déterminant la valeur de cette constante, par la propriété . Cette matrice étant une matrice diagonale, elle est égale à sa transposée qui aura donc le même déterminant.  Une matrice élémentaire obtenue de la matrice identité en ajoutant à une ligne un multiple d'une autre ligne a comme déterminant par la propriété . La transposée est différente, mais peut être obtenue avec le même type d'opération, en inversant les deux lignes impliquées. Elle a donc le même déterminant, soit .    Démontrer maintenant la propriété .  Distinguer le cas inversible du cas non inversible et passer à une décomposition en produit de matrices élémentaires pour le premier cas. D'abord, si est inversible alors, par les conclusions de l'exercice , on peut écrire pour des matrices élémentaires inversibles . Ensuite, si est non inversible alors, par le théorème , on sait que la matrice n'est pas de rang maximal et que sa forme échelonnée réduite n'est pas la matrice identité. Elle a donc nécessairement une ligne de zéros et son déterminant est nul. Le déterminant de la matrice est donc aussi nul. La transposée de sera également de rang non maximal et son déterminant sera également nul.  Il s'ensuit que . "
},
{
  "id": "exo-detsousmatrice",
  "level": "2",
  "url": "sec-detgen.html#exo-detsousmatrice",
  "type": "Exercice",
  "number": "4.2.3.7",
  "title": "",
  "body": " Soit , une matrice telle que sa première ligne et sa première colonne sont nulles, sauf pour l'entrée et soit , la matrice obtenue à partir de en enlevant sa première ligne et sa première colonne : .  Montrer que .  Si est la forme échelonnée réduite de , à quoi ressemble la forme échelonnée réduite de ? Comme suggéré dans l'indication, on s'attarde aux formes échelonnées réduites de et de . Rappelons que l'on peut calculer le déterminant d'une matrice à partir de sa forme échelonnée réduite comme dans l'exemple . Soit , la forme échelonnée réduite de . Deux options sont possibles.  D'abord, si n'est pas la matrice identité, alors elle contient une ligne de zéros et son déterminant est nul par la propriété . Le déterminant de est donc aussi nul, puisqu'on multiplie par des constantes pour le calculer. La forme échelonnée réduite de sera la matrice augmentée des lignes et colonnes retranchées précédemment, puisque l'on referait l'échelonnage à partir de la deuxième colonne de , la première étant déjà pivot. Il en résulte que la forme échelonnée réduite de possèdera aussi une ligne de zéros et son déterminant sera aussi nul.  Ensuite, si est la matrice identité, alors est obtenu en multipliant toutes les constantes obtenues des opérations élémentaires de l'échelonnage. L'échelonnage de la matrice n'ajoutant aucune opération élémentaire, puisque la première colonne est déjà pivot, on obtient que son déterminant sera égal à sa forme échelonnée réduite étant également l'identité. Il s'ensuit que . "
},
{
  "id": "exercise-230",
  "level": "2",
  "url": "sec-detgen.html#exercise-230",
  "type": "Exercice",
  "number": "4.2.3.8",
  "title": "",
  "body": " Dans la section , on démontre que le produit  est inversible si et seulement si les matrices sont inversibles. Donner une preuve alternative de ce résultat en utilisant les déterminants.  On se sert des propriétés et . On a fait ce calcul pour démontrer que l'inverse de existe si et seulement si les inverses de et de existent. En effet, par le théorème , on sait qu'une matrice est inversible si et seulement si son déterminant est non nul. Le calcul précédent exige que si et seulement si et , étant donné que ce sont les conditions pour que l'égalité fonctionne. "
},
{
  "id": "exercise-231",
  "level": "2",
  "url": "sec-detgen.html#exercise-231",
  "type": "Exercice",
  "number": "4.2.3.9",
  "title": "",
  "body": " Dans l'exercice , on utilise le déterminant pour savoir si trois points sont alignés ou si deux vecteurs sont parallèles. On s'intéresse ici à l'équivalent dans .  Dans quelle(s) circonstance(s) géométrique(s) est-ce qu'un déterminant est nul? Si les vecteurs sont sur une même droite ou un même plan.  On vérifie que trois points sont alignés (colinéaires) dans en calculant un déterminant. Ce déterminant vaut zéro si les points sont alignés. Pour faire l'équivalent à trois dimensions, on considère quatre points. Que signifie le déterminant nul obtenu à partir de ces quatre points?  Il signifie que les quatre points sont sur un même plan dans . On peut affirmer que ces points sont coplanaires.  Formuler l'énoncé précédent en termes de vecteurs.  Trois vecteurs se situent dans un même plan si leur déterminant est nul, c'est-à-dire si . On peut affirmer que ces vecteurs sont coplanaires. "
},
{
  "id": "exercise-232",
  "level": "2",
  "url": "sec-detgen.html#exercise-232",
  "type": "Exercice",
  "number": "4.2.3.10",
  "title": "",
  "body": " Donner un argument géométrique au fait que le déterminant n'est défini que pour des matrices carrées.  Plusieurs réponses sont possibles. On utilise l'argument de l'interprétation géométrique du déterminant comme un facteur de changement (d'aire, de volume, etc.). Si le déterminant représente une constante associée à une transformation linéaire permettant de mesurer l'effet de la transformation linéaire en fonction d'un facteur de changement sur l'aire, le volume ou l'hypervolume, alors il faut absolument que la transformation soit d'un espace vers ce même espace. En effet, comment pourrait-on parler de facteur de changement d'aire si l'on passe de vers , par exemple pour une transformation linéaire représentée par une matrice ? Cela n'a pas de sens. Il faut donc absolument avoir une matrice pour pouvoir parler d'un déterminant. "
},
{
  "id": "exercise-233",
  "level": "2",
  "url": "sec-detgen.html#exercise-233",
  "type": "Exercice",
  "number": "4.2.3.11",
  "title": "",
  "body": " Soit et , les coordonnées d'un triangle dans . On sait que l'on peut calculer l'aire du triangle avec un déterminant par exemple en le divisant par deux.  Montrer que l'aire du triangle peut aussi être obtenue à l'aide du déterminant .  On peut faire une preuve algébrique ou une preuve géométrique qui seraient toutes les deux valables. On choisit ici de faire les deux pour satisfaire les préférences de tous et toutes.  Géométriquement, il faut réfléchir à ce que représente le déterminant . Les vecteurs colonnes de ce déterminant ont tous en commun une composante en égale à . Si l'on se positionne pour que l'axe des pointe vers nous, ce que l'on observe, c'est un triangle parallèle au plan formés par les points et positionnés de la même façon qu'ils l'étaient dans . Le prisme droit de hauteur a comme volume la même valeur que l'aire du triangle puisqu'on le calcule en multipliant l'aire de la base par sa hauteur, qui est . On a démontré, à la figure , que le volume d'une pyramide triangulaire vaut les deux tiers du volume du prisme dans lequel elle est encastrée. Puisqu'on calcule le volume de la pyramide en divisant le déterminant par trois, on a donc la chaine d'égalités suivantes:  .  Algébriquement, on peut simplement développer les deux expressions en présence et observer qu'elles sont égales. Pour développer , il faut échelonner la matrice pour avoir une matrice triangulaire supérieure. Puisque les opérations élémentaires effectuées étaient toutes du type , on obtient le déterminant en multipliant les éléments de la diagonale. Noter que l'on aurait pu arrêter les deux calculs deux lignes plus tôt puisqu'on avait déjà obtenu la même expression.  "
},
{
  "id": "exercise-234",
  "level": "2",
  "url": "sec-detgen.html#exercise-234",
  "type": "Exercice",
  "number": "4.2.3.12",
  "title": "",
  "body": "Montrer que Rendre la matrice triangulaire. On suit l'indice et l'on calcule le déterminant en échelonnant pour avoir une matrice triangulaire supérieure. Puisque les opérations élémentaires effectuées étaient toutes du type , on obtient le déterminant en multipliant les éléments de la diagonale.  "
},
{
  "id": "exo-detortho",
  "level": "2",
  "url": "sec-detgen.html#exo-detortho",
  "type": "Exercice",
  "number": "4.2.3.13",
  "title": "",
  "body": "Une matrice est dite orthogonale si , c'est-à-dire que son inverse est égal à sa transposée. Montrer que les matrices de rotation et de réflexion dans sont orthogonales. On connait ces matrices. Il suffit de faire le calcul. On commence par la matrice de rotation . On poursuit avec la matrice de réflexion .  Quelles sont les valeurs possibles pour le déterminant d'une matrice orthogonale? Il peut valoir ou . On utilise la définition précédente. Soit , une matrice orthogonale. Alors, on sait que . On calcule son déterminant. Si , alors il n'y a que deux options, soit ou . "
},
{
  "id": "exercise-236",
  "level": "2",
  "url": "sec-detgen.html#exercise-236",
  "type": "Exercice",
  "number": "4.2.3.14",
  "title": "",
  "body": " Une matrice antisymétrique est une matrice telle que . Si est une matrice antisymétrique de taille où est impair, montrer que . Pourquoi est-ce impossible dans le cas où est pair?  Soit , une matrice antisymétrique. On utilise les propriétés des déterminants pour calculer le déterminant de . Et donc, si , alors . On remarque que l'on a utilisé la propriété à la deuxième ligne fois, une fois pour chaque ligne.  Il est clair que si est pair, tout ce que l'on obtient, c'est que , ce qui est toujours vrai.  "
},
{
  "id": "exercise-237",
  "level": "2",
  "url": "sec-detgen.html#exercise-237",
  "type": "Exercice",
  "number": "4.2.3.15",
  "title": "",
  "body": " Dans cet exercice, on regarde l'aire, le volume ou l'hypervolume du solide engendré par un ensemble de vecteurs.   Soit . Montrer que l'aire du parallélogramme engendré par ces vecteurs est .  Considérer la matrice et sa transposée et remarquer que l'expression dans la racine représente le déterminant de . On suit l'indication en définissant la matrice et sa transposée. Le déterminant de correspond à l'aire du parallélogramme engendré par et (positive ou négative). Cette expression est donc l'aire du parallélogramme. Soit . Montrer que le volume du parallélépipède engendré par ces vecteurs est . On suit l'indication en définissant la matrice et sa transposée. Le déterminant de correspond au volume du parallélépipède engendré par , et (positif ou négatif). Cette expression est donc le volume du parallélépipède.  Généraliser les résultats précédents pour montrer que est égal à l'hypervolume du solide à dimensions engendré par les vecteurs .  On continue avec la même démarche en définissant la matrice et sa transposée. Le déterminant de correspond à l'hypervolume du solide engendré par , et (positif ou négatif). . Cette expression est donc l'hypervolume de l'hyperparallélépipède (défi Scrabble du jour). "
},
{
  "id": "exercise-238",
  "level": "2",
  "url": "sec-detgen.html#exercise-238",
  "type": "Exercice",
  "number": "4.2.3.16",
  "title": "La méthode de Cramer.",
  "body": "La méthode de Cramer  Généraliser les idées de l'exercice pour exprimer la solution à un système d'équations linéaires , où est une matrice , en fonction de déterminants.  On note que cette méthode n'est pas très pratique d'un point de vue calculatoire, car elle exige le calcul d'un grand nombre de déterminants. Elle est toutefois efficace dans le cas .  Soit , une matrice de format , , un vecteur et soit l'équation . Cette équation représente le système d'équations linéaires: . On pose et , pour pouvoir énoncer la méthode de Cramer. Alors, et les valeurs des variables sont données par . La preuve serait très longue à faire et suivrait le modèle de l'exercice . On choisit de généraliser l'idée sans la démontrer algébriquement. "
},
{
  "id": "exercise-239",
  "level": "2",
  "url": "sec-detgen.html#exercise-239",
  "type": "Exercice",
  "number": "4.2.3.17",
  "title": "",
  "body": "On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de et démontrer ensuite le résultat.   Le déterminant est toujours égal à .  Voici une manière d'obtenir l'hypothèse.   Le code solution de l'exercice   def matexo(n): L=[] #On se définit une liste vide dans laquelle on va mettre les lignes de la matrice for i in range(n): #On crée chaque ligne de la matrice v=[j+1 for j in range(i+1)] #Les premières entrées de la ligne valent 1,2,3,... for j in range(n-(i+1)): #Pour les colonnes restantes, les entrées valent le numéro de la ligne (i+1 car Sage commence à 0) v.append(i+1) L.append(v) #On ajoute la ligne à la liste return matrix(L) #On retourne la matrice for k in range(6): show(matexo(k+1)) show(\"det(A_%d)=\" % (k+1),matexo(k+1).determinant())    Pour faire la démonstration, on peut procéder par induction ou par calcul direct.  Si , alors, de manière évidente, on a . On suppose que . En utilisant l'opération sur chaque ligne sous la première, on obtient . En utilisant l'opération , on obtient maintenant .  Puisque les opérations élémentaires de type ne changent pas le déterminant, en utilisant l'exercice on a , selon l'hypothèse d'induction.  "
},
{
  "id": "exercise-240",
  "level": "2",
  "url": "sec-detgen.html#exercise-240",
  "type": "Exercice",
  "number": "4.2.3.18",
  "title": "",
  "body": "On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de .    Le déterminant est .  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def diag0autres1(i,j): if i==j: return 0 else: return 1 A=matrix(ZZ,5,lambda i,j: diag0autres1(i,j)) for i in range(10): show(\"det(A_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: diag0autres1(i,j)).determinant())     "
},
{
  "id": "sec-cofacteurs",
  "level": "1",
  "url": "sec-cofacteurs.html",
  "type": "Section",
  "number": "4.3",
  "title": "Les mineurs et les cofacteurs",
  "body": "  Les mineurs et les cofacteurs    Aller aux exercices de la section.  Dans la section , on est arrivée à une formule générale pour le déterminant d'une matrice . On s'intéresse maintenant à l'équivalent pour une matrice . La formule en soi ne sera pas particulièrement utile, mais le travail de réflexion permettra d'en retirer des outils théoriques qui serviront plus tard.  Dans cette section, on introduit les notions de mineur, de cofacteur et le développement de Laplace du déterminant.    Une formule pour le cas  Avec une matrice , le déterminant s'obtient en échelonnant la matrice, au moins jusqu'à l'obtention d'une forme triangulaire. Dans cette sous-section, on utilise plutôt les propriétés du déterminant pour montrer que .  Il semble, avec raison, plus difficile de retenir cette formule que de faire le calcul en échelonnant comme on l'a fait à la section . Toutefois, en analysant de l'équation , on sera en mesure d'en comprendre la structure et d'en généraliser l'idée. Dans un premier temps, on applique la formule pour calculer le déterminant d'une matrice.   Le déterminant d'une matrice avec la formule   On considère la matrice de l'exemple . On vérifie que le déterminant calculé avec la formule correspond à celui que l'on a calculé précédemment.    Il suffit d'appliquer la formule pour obtenir  . Ceci correspond bien au déterminant calculé à l'exemple .    On revient maintenant à la formule. Celle-ci peut être démontrée en utilisant les propriétés des déterminants. On en fait l'objet de la proposition suivante.   La formule pour le cas  Soit , une matrice . Alors .   Dans la proposition , on a essentiellement utilisé les opérations sur les lignes pour montrer que le déterminant d'une matrice est . On a dû étudier plusieurs cas en fonction des nombres valant , car on voulait utiliser la division. Pour le cas , on a accès à plus de propriétés du déterminant, ce qui devrait faciliter la tâche. Une démarche similaire aurait aussi pu être faite pour le cas . Cette démarche sera l'objet de l'exercice .  L'astuce est de considérer la première ligne et de la réécrire comme étant une somme de trois vecteurs: . On a alors .  On obtient donc la même formule qu'à l'équation plus haut.    Encore une fois, il convient de répéter qu'il n'est pas nécessaire de retenir cette formule. La façon de procéder est fastidieuse et demande un certain effort pour généraliser au cas . On peut toutefois étudier l'allure de la formule et en déduire certaines propriétés. Ces propriétés aideront à formuler une méthode alternative dans la sous-section suivante.    Les mineurs et les cofacteurs  On essaie maintenant d'analyser en détail la formule afin de trouver une manière de la généraliser. Dans un premier temps, on peut remarquer que la formule est composée de six termes, qui sont eux-mêmes constitués de trois facteurs. Parmi ces six termes, trois sont affectés d'un signe positif et les trois autres d'un signe négatif. De plus, chaque terme contient exactement un terme de chaque ligne et de chaque colonne de la matrice. En effet, dans le terme , la ligne n'apparait qu'au facteur et les lignes et respectivement aux facteurs et , alors que la colonne apparait seulement au terme et les colonnes et respectivement aux facteurs et .  D'ailleurs, on peut comprendre le fait qu'il y a six termes dans la formule en comptant le nombre de manières de sélectionner les entrées de la matrice afin d'avoir un représentant de chaque ligne et de chaque colonne.  On choisit un élément de la ligne . On a trois choix.  On choisit ensuite un élément de la ligne . On a seulement deux choix, car on ne peut pas prendre la même colonne que pour la ligne .  Finalement, il ne reste qu'un élément disponible pour la troisième ligne.  On multiplie ces possibilités pour obtenir .  Pour le cas , on arrive à possibilité, ce qui correspond bien au nombre de termes dans la formule .  En général, on devrait avoir termes dans la formule. Pour le seul cas , cela représente 24 termes.   On comprend maintenant d'où vient le nombre de termes et l'on sait comment les choisir. En fait, si l'on se permet de faire une permutation de colonnes additionnelle dans le dernier terme de l'équation , on arrive à (noter le changement de signe du troisième terme et la permutation des colonnes deux et trois) .  En comparant les déterminants de l'équation avec les entrées des matrices de l'équation , on arrive à la définition suivante.   Les mineurs  Soit , une matrice carrée de taille . On note , la matrice obtenue de en supprimant la ligne et la colonne . On appelle le mineur de la position , ou encore le mineur de l'élément le déterminant de la matrice .    Trois mineurs d'une matrice   On considère une matrice quelconque et l'on veut calculer les mineurs de la première ligne.    Si , alors et leurs déterminants respectifs sont , et .    Les trois mineurs obtenus à l'exemple précédent correspondent à ceux des matrices de l'équation . On passe maintenant aux signes des termes de l'équation . En particulier, les termes avec et sont multipliés par , alors que celui avec est multiplié par . L'idée est de partir de l'équation et de permuter les colonnes pour que la première ligne et la première colonne soient composées du vecteur , mais que l'ordre relatif des autres colonnes soit préservé. Ce n'était pas le cas pour le dernier terme de l'équation , car la dernière matrice a la colonne des après celle des . Une permutation supplémentaire a permis d'obtenir le résultat voulu à l'équation .  En général, le nombre de permutations de colonnes requis pour satisfaire cette contrainte est égal à , ce qui mène au signe . On préfère écrire l'exposant sous la forme pour des raisons qui deviendront claires sous peu. On veut maintenant introduire la notion de cofacteur. Pour cela, on généralise l'idée ci-dessus d'envoyer une entrée de la matrice à la position sans changer l'ordre relatif des lignes et colonnes.   Déplacer une entrée dans une matrice  Soit , une matrice quelconque avec la deuxième ligne et la troisième colonne ne contenant que des zéros sauf la valeur à l'intersection. On veut, à l'aide d'opérations élémentaires sur les lignes ou sur les colonnes (voir l'exercice ), déplacer le en position sans changer l'ordre relatif des lignes et des colonnes pour les autres entrées  On utilise Sage pour faire les calculs. La multiplication à gauche d'une matrice par une matrice de type a pour effet d'interchanger les lignes de , alors que la multiplication à droite par cette même matrice interchange les colonnes . On utilise Sage pour faire le calcul.   Si l'on regarde attentivement les entrées de la matrice , on constate que l'ordre relatif des lignes n'est pas respecté, mais que celui des colonnes l'est. Il faut donc faire une autre permutation des lignes pour avoir le résultat voulu.   Au total, on a eu besoin de trois matrices élémentaires pour faire le travail.    Maintenant, la définition du cofacteur.   Les cofacteurs  Soit , une matrice carrée de taille et , le mineur de la position . Le cofacteur de la position , noté , est le nombre .   Le terme est lié au nombre de permutations nécessaires pour envoyer l'entrée en position à la position . Les détails sont présentés à l'exercice .   Trois cofacteurs d'une matrice   On considère une matrice quelconque et l'on veut calculer les cofacteurs de la première ligne.    On a où les mineurs ont été calculés à l'exemple .    En regardant les cofacteurs, on se rend compte qu'on est très près de la formule pour l'équation d'un déterminant. En fait, devant chaque cofacteur, il ne manque que l'entrée . On a donc, pour une matrice de taille , .  Il n'y a rien de particulier avec la ligne , on peut, dans la preuve de la proposition , se servir d'une autre ligne ou même d'une colonne et arriver au même résultat. Finalement, on obtient le résultat suivant.   Le développement de Laplace du déterminant   Soit , une matrice et et , respectivement le mineur et le cofacteur de la position . Alors pour tout , on a . C'est le développement selon la ligne .  On a aussi, pour tout , le développement selon la colonne j: .    On fait la preuve pour les lignes, la preuve pour les colonnes étant presque identique.  On montre que la fonction satisfait les propriétés .  Dans un premier temps, si est la matrice identité de taille , alors le seul terme qui reste dans la fonction est . La sous-matrice est la matrice identité de taille et son déterminant vaut . Comme et que , on a bien .  Soit maintenant , une matrice de taille obtenue à partir de en multipliant la ligne par . On distingue deux cas. D'abord, si , la ligne choisie pour le développement, alors et donc . Enfin, si , alors chaque sous-matrice est égale à la sous-matrice , sauf pour une ligne qui a été multipliée par . Ainsi, . La propriété est ainsi respectée.  On regarde maintenant ce qui se passe si est obtenue de en permutant deux lignes. On distingue aussi deux cas. Le premier se présente si les lignes permutées ne sont pas celles avec lesquelles on développe. On aura alors , car les sous-matrices sont les mêmes à une inversion de lignes près.  Dans le second cas, si les lignes et ont été échangées, on procède comme suit. On suppose que . Si c'est l'inverse, l'idée est similaire. Soit , la ligne de la matrice , maintenant en position dans la matrice . On veut la remettre en ordre dans la sous-matrice . Cela prendra permutations. Par exemple, si et , les lignes de sont . Si l'on enlève la troisième ligne et que l'on veut réordonner les autres lignes, il faudra permutations: . On a donc et ainsi, . La fonction respecte donc la propriété .  La dernière partie consiste à montrer que la propriété est satisfaite. Si est obtenue de en ajoutant fois la ligne et est obtenue en remplaçant la ligne de par sa ligne , on remarque alors deux choses:  On a , car la matrice contient deux fois la ligne .  On a .    On distingue une fois de plus deux cas. Si , alors et l'on a . Si toutefois , alors . Ainsi satisfait la propriété .    En général, les cofacteurs constituent une manière inefficace de calculer un déterminant. Toutefois, pour le cas , ils peuvent s'avérer plus rapides que le calcul par Gauss-Jordan. Il y a un autre avantage, qui sera utile dans le chapitre , lorsque le déterminant contient des variables. Les cofacteurs ne nécessitant pas de division, on n'a pas de supposition à faire quant au fait que la variable pourrait s'avérer nulle lors d'une division. On regarde un exemple de calcul d'un déterminant avec la méthode des cofacteurs.   Le développement du déterminant par les cofacteurs   Soit . On veut calculer son déterminant en utilisant la méthode des cofacteurs.    En regardant la matrice, on constate que la seconde colonne ne contient qu'une entrée non nulle, en position . Si l'on fait un développement sur la deuxième colonne, il ne restera de l'équation que ce terme non nul: . On calcule en calculant le déterminant de la sous-matrice qui est obtenue en enlevant la deuxième ligne et la deuxième colonne: .  On a donc . Sage pourra confirmer ce résultat.     La proposition montre que la fonction déterminant existe. On peut toutefois se demander si elle est unique. Il pourrait en effet y avoir plus d'une fonction qui satisfait la définition . On peut maintenant montrer que le déterminant est unique.   Le déterminant d'une matrice est unique   Soit , une matrice et soit , deux fonctions qui satisfont les propriétés . Alors . On peut donc parler sans problème du déterminant de .    Le calcul repose sur le fait que, peu importe la fonction déterminant, les propriétés font en sorte que le déterminant des matrices élémentaires est le même. De plus, une fonction qui satisfait ces propriétés satisfait aussi toutes celles de la section , en particulier la propriété du produit dans la proposition . Finalement, on aura besoin du fait que la forme échelonnée réduite d'une matrice est unique, comme démontré à la proposition .  On fixe une manière d'échelonner la matrice jusqu'à sa forme échelonnée réduite . Ceci implique qu'il existe une suite de matrices élémentaires telles que . Comme les matrices élémentaires sont inversibles et sont aussi des matrices élémentaires, on peut alors écrire où . On a donc et .  Comme la matrice ERL est unique, on a . Si l'on utilise une autre chaine de matrices pour arriver à , on aura quand même pour cette autre chaine.    On termine avec des commandes Sage en lien avec la sous-section.   Les cofacteurs et Sage  Sage ne possède pas de fonction pour calculer les cofacteurs d'une matrice. On peut toutefois les calculer manuellement à l'aide de quelques commandes simples. En particulier, on peut accéder à une sous-matrice de à l'aide de la commande A[L1,L2] , où L1,L2 sont des listes des lignes ( L1 ) et des colonnes ( L2 ) que l'on veut garder. Par exemple, pour afficher la sous-matrice d'une matrice , on procède comme suit.   On peut ensuite calculer le cofacteur de cet élément en réécrivant la formule.   On peut ensuite calculer le déterminant en utilisant le développement selon une ligne ou une colonne déterminée.      La matrice adjointe  On termine cette section avec la notion de matrice adjointe. Cette matrice, encore une fois plus utile en théorie qu'en pratique, donne une formule pour l'inverse d'une matrice en fonction des cofacteurs. Elle permettra toutefois d'avoir une manière simple de calculer l'inverse d'une matrice .   La matrice adjointe  Soit , une matrice carrée d'ordre et , la matrice telle que , le cofacteur de la position de la matrice . La matrice adjointe de est la matrice   À titre d'exemple, on calcule la matrice adjointe d'une matrice spécifique et d'une matrice arbitraire.   Exemple de matrice adjointe   On considère la matrice de l'exemple et la matrice . On cherche la matrice adjointe de chacune de ces matrices.    On utilise Sage pour calculer chacun des cofacteurs de la matrice. Investiguer pourquoi on ne fait pas Lignes=liste , mais plutôt .copy() .     Pour une matrice , les cofacteurs sont simples à calculer directement. On a . La matrice adjointe est donc .    La principale utilité de la matrice adjointe est théorique et est en lien avec la matrice inverse.   L'adjointe et l'inverse d'une matrice   Soit , une matrice carrée inversible de taille et , sa matrice adjointe. Alors . On obtient une formule pour l'inverse qui dépend des entrées de la matrice. En particulier pour le cas d'une matrice , on a que l'on avait déjà obtenue à la section à l'équation .    On réarrange un peu l'équation en multipliant par de chaque côté pour démontrer plutôt où est la matrice des cofacteurs.  On analyse colonne par colonne le produit . Selon la définition du produit matriciel, la première colonne est (on constate l'effet de la transposition sur la colonne de en remarquant qu'on a tous les cofacteurs de la ligne ). On procède maintenant ligne par ligne pour obtenir les entrées de ce produit matrice vecteur. D'abord et donc, la première entrée correspond au déterminant de . Pour chaque entrée plus grande ou égale à deux, on obtient . En effet, pour , on obtient . Évidemment, les cofacteurs n'ont pas changé, mais les termes qui les multiplient ne correspondent pas au déterminant de . Toutefois, si l'on considère la matrice obtenue à partir de en remplaçant sa première ligne par sa deuxième, alors l'équation et ce déterminant est nul puisque la matrice contient deux lignes identiques.  Le raisonnement est analogue pour les autres colonnes de la matrice, le déterminant de se trouvant toujours en position . Le produit vaut donc , ce qui complète la preuve.    On termine avec des commandes Sage en lien avec la sous-section.   La matrice adjointe et Sage  Sage n'avait pas de commande directe pour calculer les cofacteurs, mais il en possède une pour la matrice adjointe. En anglais, il est plus courant d'utiliser le terme «adjugate », ainsi la commande est A.adjugate() . On l'utilise pour valider le calcul à l'exemple .        Les points importants de cette section sont:  La notion de mineurs et de cofacteurs ;  Le développement de Laplace du déterminant;  La matrice adjointe ;  L'équation de l'inverse d'une matrice en lien avec ses cofacteurs.  De plus avec Sage, la commande .adjugate() permet de calculer la matrice ajointe d'une matrice.      Exercices   En utilisant une méthode analogue à celle de la proposition , montrer que le déterminant d'une matrice quelconque est .   Comme dans la proposition , l'astuce est de considérer la première ligne et de la réécrire comme étant une somme de deux vecteurs: . On a alors .   Soit .  Calculer les cofacteurs ci-dessous.    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .  Calculer le déterminant de la matrice . Peu de calculs sont nécessaires si les cofacteurs ci-dessus ont tous été calculés. On utilise l'équation développée selon la troisième ligne ( ). L'équation devient: .    Soit , une matrice et , l'entrée en position . Montrer que pour amener en position sans changer l'ordre relatif des autres lignes et colonnes, on a besoin de faire permutations de lignes\/colonnes.  Comme chacune de ces permutations change le déterminant par un facteur , on a , ce qui explique la présence de ce terme dans la formule de la définition .  Essentiellement, il faut procéder en échangeant toujours deux lignes ou colonnes adjacentes. En commençant par les lignes, si l'on veut amener la ligne à la ligne et que toutes les autres lignes gardent le même ordre, il faut permuter la ligne et la ligne , puis la nouvelle ligne avec la ligne , ainsi de suite jusqu'à la ligne . Cela prend opérations.  Ensuite, pour les colonnes, en suivant le même principe, on déplacera la colonne à la première colonne sans changer l'ordre relatif des colonnes en opérations. Toutes ces opérations étant des permutations, le déterminant est donc multiplié par un facteur chaque fois et donc, un total de .    On considère la suite de matrices où en général la matrice est une matrice dont la diagonale principale vaut , où toutes les entrées sous la diagonale valent et où la diagonale au-dessus de la principale a aussi toutes ses entrées égales à .   Calculer .       Montrer qu'on a . Bien que la question soit énoncée comme une preuve, il faut comprendre qu'on doit simplement calculer et constater que cela donne , la somme des deux déterminants calculés plus tôt. Pour s'aider avec la preuve de la prochaine question, on va recalculer le déterminant en utilisant la propriété sur la première ligne. Cette façon de faire met la table pour démontrer le prochain résultat. Montrer qu'en général, lorsque . En gardant en tête l'exercice précédent, on développe le déterminant voulu selon la première ligne de la matrice .  Calculer à l'aide de cette relation le déterminant des matrices . Ces nombres sont-ils familiers?       Cette suite de nombres est la suite de Fibonacci.       Cette suite de nombres est la suite de Fibonacci.  On considère la matrice . Déterminer l'inverse de la matrice à l'aide de la formule . Pour utiliser la formule , il faut d'abord calculer le déterminant de la matrice . Ensuite, il faut calculer la matrice adjointe en utilisant les mineurs et les cofacteurs .   Aussi appelé, comment construire des matrices gentilles  Dans cet exercice, on considère une matrice quelconque dont les entrées sont toutes des entiers. Est-ce que la matrice inverse sera aussi composée d'entiers? La cellule Sage suivante montre qu'en général, ce n'est pas le cas.    Si ou , montrer que toutes les entrées de seront des entiers.  En utilisant la formule , on voit rapidement que la seule façon d'introduire des fractions dans le calcul de l'inverse est en multipliant par . En effet, comme la matrice ne contient que des entiers, tous les cofacteurs permettant de calculer la matrice adjointe seront des entiers puisqu'on les obtient à l'aide de la définition . Bref, toutes les entrées de l'inverse seront des entiers.  Si et sont toutes les deux composées d'entiers, montrer que .  Encore par la formule , on voit que si n'est formée que d'entiers, la matrice des cofacteurs ne sera elle aussi constituée que d'entiers et que ceux-ci seront tous divisés par . Si le résultat est lui aussi seulement constitué d'entiers, il faut absolument que , par lequel on a divisé, soit ou . Sinon, on aurait créé des fractions dans , ce qui contredit l'hypothèse.  Dans un examen, un professeur veut faire calculer l'inverse d'une matrice à ses élèves. Il ne veut pas que cet inverse soit trop complexe et veut éviter les fractions. Décrire comment obtenir une matrice qui sera composée d'entiers et telle que son inverse sera aussi composée d'entiers.  Considérer la proposition , les opérations élémentaires et la première partie de cet exercice. Il faut d'abord créer une matrice triangulaire supérieure ne contenant que des entiers telle que le produit des éléments de sa diagonale va donner ou . Par la proposion , il s'agit du déterminant de cette matrice. On obtient une matrice non triangulaire supérieure (avec des éléments non nuls partout si on le veut) en effectuant des opérations élémentaires ne changeant pas le déterminant autrement que par un changement de signe. On peut donc utiliser les permutations ou les combinaisons linéaires, mais pas les multiples de lignes. La matrice ainsi créée a comme déterminant ou et ne contient que des entiers.  On conclut en utilisant la première partie de l'exercice, qui garantit qu'une matrice dont les entrées sont des entiers et qui possède un déterminant de ou a aussi un inverse dont les entrées sont des entiers.   Soit , une matrice orthogonale, c'est-à-dire une matrice telle que . Montrer que .   Utiliser l'exercice .  Par l'exercice , on sait que la matrice orthogonale est telle que . Par l'équation , on sait que . Ainsi, on a .  Soit et , deux points distincts de . Montrer que l'équation de la droite passant par ces points est donnée par . On choisit de développer le déterminant pour voir si l'on obtient une expression correspondant à l'équation de cette droite. Cette expression rappelle l'équation normale d'une droite dans . Le vecteur normal serait donc . On sait qu'on peut retrouver un vecteur directeur ainsi: . Le membre de gauche de l'équation normale correspond à l'expression obtenue lorsqu'on construit l'équation normale avec le produit scalaire entre le vecteur normal et le vecteur avec , un point quelconque de la droite. En effet, ce qui est exactement ce qu'on avait obtenu en développant le déterminant initial.  Soit et , trois points non alignés de . Généraliser l'idée de l'exercice pour obtenir l'équation du plan passant par ces trois points. On choisit de commencer en construisant l'équation normale d'un plan dans .  La parabole (re)revisitée  Dans les exercices et , on a donné des méthodes vectorielles et matricielles pour trouver l'équation d'une parabole. Montrer que si et sont trois points non alignés de , alors l'équation de la parabole qui passe par ces trois points est donnée par .    Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Évidemment, il y a plusieurs manières d'arriver aux réponses.   On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de et démontrer le résultat. Calculer et . Vérifier que et qu'en général, on a . Si est impair, alors . Lorsque est pair et divisible par quatre, alors et si est pair, mais non divisible par quatre, alors .  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def diagsecond(i,j): if abs(i-j)==1: return 1 else: return 0 B=matrix(ZZ,4,lambda i,j: diagsecond(i,j)) for i in range(10): show(\"det(B_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: diagsecond(i,j)).determinant())    On remarque facilement que les premiers déterminants satisfont la relation et l'on tente maintenant de la démontrer. On développe le déterminant de selon la première ligne. On aura .   On considère la suite de matrices . Montrer en utilisant Sage que et démontrer algébriquement ce résultat.  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def matrice121(i,j): if i==j: return 2 elif abs(i-j)==1: return 1 else: return 0 F=matrix(ZZ,5,lambda i,j: matrice121(i,j)) for i in range(10): show(\"det(F_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: matrice121(i,j)).determinant())    Similairement à l'exercice précédent, on développe selon la première ligne. On aura alors .  On remarque que la matrice que l'on obtient pour est égale à . Pour , on a .  En combinant toutes les informations, on a .     "
},
{
  "id": "example-86",
  "level": "2",
  "url": "sec-cofacteurs.html#example-86",
  "type": "Exemple",
  "number": "4.3.1",
  "title": "Le déterminant d’une matrice <span class=\"process-math\">\\(3\\times 3\\)<\/span> avec la formule.",
  "body": " Le déterminant d'une matrice avec la formule   On considère la matrice de l'exemple . On vérifie que le déterminant calculé avec la formule correspond à celui que l'on a calculé précédemment.    Il suffit d'appliquer la formule pour obtenir  . Ceci correspond bien au déterminant calculé à l'exemple .   "
},
{
  "id": "prop-det3x3avecprop",
  "level": "2",
  "url": "sec-cofacteurs.html#prop-det3x3avecprop",
  "type": "Proposition",
  "number": "4.3.2",
  "title": "La formule pour le cas <span class=\"process-math\">\\(3\\times 3\\)<\/span>.",
  "body": " La formule pour le cas  Soit , une matrice . Alors .   Dans la proposition , on a essentiellement utilisé les opérations sur les lignes pour montrer que le déterminant d'une matrice est . On a dû étudier plusieurs cas en fonction des nombres valant , car on voulait utiliser la division. Pour le cas , on a accès à plus de propriétés du déterminant, ce qui devrait faciliter la tâche. Une démarche similaire aurait aussi pu être faite pour le cas . Cette démarche sera l'objet de l'exercice .  L'astuce est de considérer la première ligne et de la réécrire comme étant une somme de trois vecteurs: . On a alors .  On obtient donc la même formule qu'à l'équation plus haut.   "
},
{
  "id": "def-mineurs",
  "level": "2",
  "url": "sec-cofacteurs.html#def-mineurs",
  "type": "Définition",
  "number": "4.3.3",
  "title": "Les mineurs.",
  "body": " Les mineurs  Soit , une matrice carrée de taille . On note , la matrice obtenue de en supprimant la ligne et la colonne . On appelle le mineur de la position , ou encore le mineur de l'élément le déterminant de la matrice .  "
},
{
  "id": "ex-min3x3",
  "level": "2",
  "url": "sec-cofacteurs.html#ex-min3x3",
  "type": "Exemple",
  "number": "4.3.4",
  "title": "Trois mineurs d’une matrice <span class=\"process-math\">\\(3\\times 3\\)<\/span>.",
  "body": " Trois mineurs d'une matrice   On considère une matrice quelconque et l'on veut calculer les mineurs de la première ligne.    Si , alors et leurs déterminants respectifs sont , et .   "
},
{
  "id": "example-88",
  "level": "2",
  "url": "sec-cofacteurs.html#example-88",
  "type": "Exemple",
  "number": "4.3.5",
  "title": "Déplacer une entrée dans une matrice.",
  "body": " Déplacer une entrée dans une matrice  Soit , une matrice quelconque avec la deuxième ligne et la troisième colonne ne contenant que des zéros sauf la valeur à l'intersection. On veut, à l'aide d'opérations élémentaires sur les lignes ou sur les colonnes (voir l'exercice ), déplacer le en position sans changer l'ordre relatif des lignes et des colonnes pour les autres entrées  On utilise Sage pour faire les calculs. La multiplication à gauche d'une matrice par une matrice de type a pour effet d'interchanger les lignes de , alors que la multiplication à droite par cette même matrice interchange les colonnes . On utilise Sage pour faire le calcul.   Si l'on regarde attentivement les entrées de la matrice , on constate que l'ordre relatif des lignes n'est pas respecté, mais que celui des colonnes l'est. Il faut donc faire une autre permutation des lignes pour avoir le résultat voulu.   Au total, on a eu besoin de trois matrices élémentaires pour faire le travail.   "
},
{
  "id": "def-cofact",
  "level": "2",
  "url": "sec-cofacteurs.html#def-cofact",
  "type": "Définition",
  "number": "4.3.6",
  "title": "Les cofacteurs.",
  "body": " Les cofacteurs  Soit , une matrice carrée de taille et , le mineur de la position . Le cofacteur de la position , noté , est le nombre .  "
},
{
  "id": "example-89",
  "level": "2",
  "url": "sec-cofacteurs.html#example-89",
  "type": "Exemple",
  "number": "4.3.7",
  "title": "Trois cofacteurs d’une matrice <span class=\"process-math\">\\(3\\times 3\\)<\/span>.",
  "body": " Trois cofacteurs d'une matrice   On considère une matrice quelconque et l'on veut calculer les cofacteurs de la première ligne.    On a où les mineurs ont été calculés à l'exemple .   "
},
{
  "id": "prop-detcofact",
  "level": "2",
  "url": "sec-cofacteurs.html#prop-detcofact",
  "type": "Proposition",
  "number": "4.3.8",
  "title": "Le développement de Laplace du déterminant <span class=\"process-math\">\\(n\\times n\\)<\/span>.",
  "body": " Le développement de Laplace du déterminant   Soit , une matrice et et , respectivement le mineur et le cofacteur de la position . Alors pour tout , on a . C'est le développement selon la ligne .  On a aussi, pour tout , le développement selon la colonne j: .    On fait la preuve pour les lignes, la preuve pour les colonnes étant presque identique.  On montre que la fonction satisfait les propriétés .  Dans un premier temps, si est la matrice identité de taille , alors le seul terme qui reste dans la fonction est . La sous-matrice est la matrice identité de taille et son déterminant vaut . Comme et que , on a bien .  Soit maintenant , une matrice de taille obtenue à partir de en multipliant la ligne par . On distingue deux cas. D'abord, si , la ligne choisie pour le développement, alors et donc . Enfin, si , alors chaque sous-matrice est égale à la sous-matrice , sauf pour une ligne qui a été multipliée par . Ainsi, . La propriété est ainsi respectée.  On regarde maintenant ce qui se passe si est obtenue de en permutant deux lignes. On distingue aussi deux cas. Le premier se présente si les lignes permutées ne sont pas celles avec lesquelles on développe. On aura alors , car les sous-matrices sont les mêmes à une inversion de lignes près.  Dans le second cas, si les lignes et ont été échangées, on procède comme suit. On suppose que . Si c'est l'inverse, l'idée est similaire. Soit , la ligne de la matrice , maintenant en position dans la matrice . On veut la remettre en ordre dans la sous-matrice . Cela prendra permutations. Par exemple, si et , les lignes de sont . Si l'on enlève la troisième ligne et que l'on veut réordonner les autres lignes, il faudra permutations: . On a donc et ainsi, . La fonction respecte donc la propriété .  La dernière partie consiste à montrer que la propriété est satisfaite. Si est obtenue de en ajoutant fois la ligne et est obtenue en remplaçant la ligne de par sa ligne , on remarque alors deux choses:  On a , car la matrice contient deux fois la ligne .  On a .    On distingue une fois de plus deux cas. Si , alors et l'on a . Si toutefois , alors . Ainsi satisfait la propriété .   "
},
{
  "id": "ex-detcofact",
  "level": "2",
  "url": "sec-cofacteurs.html#ex-detcofact",
  "type": "Exemple",
  "number": "4.3.9",
  "title": "Le développement du déterminant par les cofacteurs.",
  "body": " Le développement du déterminant par les cofacteurs   Soit . On veut calculer son déterminant en utilisant la méthode des cofacteurs.    En regardant la matrice, on constate que la seconde colonne ne contient qu'une entrée non nulle, en position . Si l'on fait un développement sur la deuxième colonne, il ne restera de l'équation que ce terme non nul: . On calcule en calculant le déterminant de la sous-matrice qui est obtenue en enlevant la deuxième ligne et la deuxième colonne: .  On a donc . Sage pourra confirmer ce résultat.    "
},
{
  "id": "prop-detunique",
  "level": "2",
  "url": "sec-cofacteurs.html#prop-detunique",
  "type": "Proposition",
  "number": "4.3.10",
  "title": "Le déterminant d’une matrice est unique.",
  "body": " Le déterminant d'une matrice est unique   Soit , une matrice et soit , deux fonctions qui satisfont les propriétés . Alors . On peut donc parler sans problème du déterminant de .    Le calcul repose sur le fait que, peu importe la fonction déterminant, les propriétés font en sorte que le déterminant des matrices élémentaires est le même. De plus, une fonction qui satisfait ces propriétés satisfait aussi toutes celles de la section , en particulier la propriété du produit dans la proposition . Finalement, on aura besoin du fait que la forme échelonnée réduite d'une matrice est unique, comme démontré à la proposition .  On fixe une manière d'échelonner la matrice jusqu'à sa forme échelonnée réduite . Ceci implique qu'il existe une suite de matrices élémentaires telles que . Comme les matrices élémentaires sont inversibles et sont aussi des matrices élémentaires, on peut alors écrire où . On a donc et .  Comme la matrice ERL est unique, on a . Si l'on utilise une autre chaine de matrices pour arriver à , on aura quand même pour cette autre chaine.   "
},
{
  "id": "computation-30",
  "level": "2",
  "url": "sec-cofacteurs.html#computation-30",
  "type": "Calcul",
  "number": "4.3.11",
  "title": "Les cofacteurs et Sage.",
  "body": " Les cofacteurs et Sage  Sage ne possède pas de fonction pour calculer les cofacteurs d'une matrice. On peut toutefois les calculer manuellement à l'aide de quelques commandes simples. En particulier, on peut accéder à une sous-matrice de à l'aide de la commande A[L1,L2] , où L1,L2 sont des listes des lignes ( L1 ) et des colonnes ( L2 ) que l'on veut garder. Par exemple, pour afficher la sous-matrice d'une matrice , on procède comme suit.   On peut ensuite calculer le cofacteur de cet élément en réécrivant la formule.   On peut ensuite calculer le déterminant en utilisant le développement selon une ligne ou une colonne déterminée.   "
},
{
  "id": "def-matadjointe",
  "level": "2",
  "url": "sec-cofacteurs.html#def-matadjointe",
  "type": "Définition",
  "number": "4.3.12",
  "title": "La matrice adjointe.",
  "body": " La matrice adjointe  Soit , une matrice carrée d'ordre et , la matrice telle que , le cofacteur de la position de la matrice . La matrice adjointe de est la matrice  "
},
{
  "id": "ex-matadjointe",
  "level": "2",
  "url": "sec-cofacteurs.html#ex-matadjointe",
  "type": "Exemple",
  "number": "4.3.13",
  "title": "Exemple de matrice adjointe.",
  "body": " Exemple de matrice adjointe   On considère la matrice de l'exemple et la matrice . On cherche la matrice adjointe de chacune de ces matrices.    On utilise Sage pour calculer chacun des cofacteurs de la matrice. Investiguer pourquoi on ne fait pas Lignes=liste , mais plutôt .copy() .     Pour une matrice , les cofacteurs sont simples à calculer directement. On a . La matrice adjointe est donc .   "
},
{
  "id": "proposition-40",
  "level": "2",
  "url": "sec-cofacteurs.html#proposition-40",
  "type": "Proposition",
  "number": "4.3.14",
  "title": "L’adjointe et l’inverse d’une matrice.",
  "body": " L'adjointe et l'inverse d'une matrice   Soit , une matrice carrée inversible de taille et , sa matrice adjointe. Alors . On obtient une formule pour l'inverse qui dépend des entrées de la matrice. En particulier pour le cas d'une matrice , on a que l'on avait déjà obtenue à la section à l'équation .    On réarrange un peu l'équation en multipliant par de chaque côté pour démontrer plutôt où est la matrice des cofacteurs.  On analyse colonne par colonne le produit . Selon la définition du produit matriciel, la première colonne est (on constate l'effet de la transposition sur la colonne de en remarquant qu'on a tous les cofacteurs de la ligne ). On procède maintenant ligne par ligne pour obtenir les entrées de ce produit matrice vecteur. D'abord et donc, la première entrée correspond au déterminant de . Pour chaque entrée plus grande ou égale à deux, on obtient . En effet, pour , on obtient . Évidemment, les cofacteurs n'ont pas changé, mais les termes qui les multiplient ne correspondent pas au déterminant de . Toutefois, si l'on considère la matrice obtenue à partir de en remplaçant sa première ligne par sa deuxième, alors l'équation et ce déterminant est nul puisque la matrice contient deux lignes identiques.  Le raisonnement est analogue pour les autres colonnes de la matrice, le déterminant de se trouvant toujours en position . Le produit vaut donc , ce qui complète la preuve.   "
},
{
  "id": "computation-31",
  "level": "2",
  "url": "sec-cofacteurs.html#computation-31",
  "type": "Calcul",
  "number": "4.3.15",
  "title": "La matrice adjointe et Sage.",
  "body": " La matrice adjointe et Sage  Sage n'avait pas de commande directe pour calculer les cofacteurs, mais il en possède une pour la matrice adjointe. En anglais, il est plus courant d'utiliser le terme «adjugate », ainsi la commande est A.adjugate() . On l'utilise pour valider le calcul à l'exemple .   "
},
{
  "id": "exo-det2x2avecprop",
  "level": "2",
  "url": "sec-cofacteurs.html#exo-det2x2avecprop",
  "type": "Exercice",
  "number": "4.3.4.1",
  "title": "",
  "body": " En utilisant une méthode analogue à celle de la proposition , montrer que le déterminant d'une matrice quelconque est .   Comme dans la proposition , l'astuce est de considérer la première ligne et de la réécrire comme étant une somme de deux vecteurs: . On a alors .  "
},
{
  "id": "exercise-242",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-242",
  "type": "Exercice",
  "number": "4.3.4.2",
  "title": "",
  "body": "Soit .  Calculer les cofacteurs ci-dessous.    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .    On utilise les définitions de mineurs et de cofacteurs .  Calculer le déterminant de la matrice . Peu de calculs sont nécessaires si les cofacteurs ci-dessus ont tous été calculés. On utilise l'équation développée selon la troisième ligne ( ). L'équation devient: .  "
},
{
  "id": "exo-cof-iplusjmoins2",
  "level": "2",
  "url": "sec-cofacteurs.html#exo-cof-iplusjmoins2",
  "type": "Exercice",
  "number": "4.3.4.3",
  "title": "",
  "body": " Soit , une matrice et , l'entrée en position . Montrer que pour amener en position sans changer l'ordre relatif des autres lignes et colonnes, on a besoin de faire permutations de lignes\/colonnes.  Comme chacune de ces permutations change le déterminant par un facteur , on a , ce qui explique la présence de ce terme dans la formule de la définition .  Essentiellement, il faut procéder en échangeant toujours deux lignes ou colonnes adjacentes. En commençant par les lignes, si l'on veut amener la ligne à la ligne et que toutes les autres lignes gardent le même ordre, il faut permuter la ligne et la ligne , puis la nouvelle ligne avec la ligne , ainsi de suite jusqu'à la ligne . Cela prend opérations.  Ensuite, pour les colonnes, en suivant le même principe, on déplacera la colonne à la première colonne sans changer l'ordre relatif des colonnes en opérations. Toutes ces opérations étant des permutations, le déterminant est donc multiplié par un facteur chaque fois et donc, un total de .  "
},
{
  "id": "exercise-244",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-244",
  "type": "Exercice",
  "number": "4.3.4.4",
  "title": "",
  "body": " On considère la suite de matrices où en général la matrice est une matrice dont la diagonale principale vaut , où toutes les entrées sous la diagonale valent et où la diagonale au-dessus de la principale a aussi toutes ses entrées égales à .   Calculer .       Montrer qu'on a . Bien que la question soit énoncée comme une preuve, il faut comprendre qu'on doit simplement calculer et constater que cela donne , la somme des deux déterminants calculés plus tôt. Pour s'aider avec la preuve de la prochaine question, on va recalculer le déterminant en utilisant la propriété sur la première ligne. Cette façon de faire met la table pour démontrer le prochain résultat. Montrer qu'en général, lorsque . En gardant en tête l'exercice précédent, on développe le déterminant voulu selon la première ligne de la matrice .  Calculer à l'aide de cette relation le déterminant des matrices . Ces nombres sont-ils familiers?       Cette suite de nombres est la suite de Fibonacci.       Cette suite de nombres est la suite de Fibonacci. "
},
{
  "id": "exercise-245",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-245",
  "type": "Exercice",
  "number": "4.3.4.5",
  "title": "",
  "body": "On considère la matrice . Déterminer l'inverse de la matrice à l'aide de la formule . Pour utiliser la formule , il faut d'abord calculer le déterminant de la matrice . Ensuite, il faut calculer la matrice adjointe en utilisant les mineurs et les cofacteurs .  "
},
{
  "id": "exercise-246",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-246",
  "type": "Exercice",
  "number": "4.3.4.6",
  "title": "Aussi appelé, comment construire des matrices gentilles.",
  "body": "Aussi appelé, comment construire des matrices gentilles  Dans cet exercice, on considère une matrice quelconque dont les entrées sont toutes des entiers. Est-ce que la matrice inverse sera aussi composée d'entiers? La cellule Sage suivante montre qu'en général, ce n'est pas le cas.    Si ou , montrer que toutes les entrées de seront des entiers.  En utilisant la formule , on voit rapidement que la seule façon d'introduire des fractions dans le calcul de l'inverse est en multipliant par . En effet, comme la matrice ne contient que des entiers, tous les cofacteurs permettant de calculer la matrice adjointe seront des entiers puisqu'on les obtient à l'aide de la définition . Bref, toutes les entrées de l'inverse seront des entiers.  Si et sont toutes les deux composées d'entiers, montrer que .  Encore par la formule , on voit que si n'est formée que d'entiers, la matrice des cofacteurs ne sera elle aussi constituée que d'entiers et que ceux-ci seront tous divisés par . Si le résultat est lui aussi seulement constitué d'entiers, il faut absolument que , par lequel on a divisé, soit ou . Sinon, on aurait créé des fractions dans , ce qui contredit l'hypothèse.  Dans un examen, un professeur veut faire calculer l'inverse d'une matrice à ses élèves. Il ne veut pas que cet inverse soit trop complexe et veut éviter les fractions. Décrire comment obtenir une matrice qui sera composée d'entiers et telle que son inverse sera aussi composée d'entiers.  Considérer la proposition , les opérations élémentaires et la première partie de cet exercice. Il faut d'abord créer une matrice triangulaire supérieure ne contenant que des entiers telle que le produit des éléments de sa diagonale va donner ou . Par la proposion , il s'agit du déterminant de cette matrice. On obtient une matrice non triangulaire supérieure (avec des éléments non nuls partout si on le veut) en effectuant des opérations élémentaires ne changeant pas le déterminant autrement que par un changement de signe. On peut donc utiliser les permutations ou les combinaisons linéaires, mais pas les multiples de lignes. La matrice ainsi créée a comme déterminant ou et ne contient que des entiers.  On conclut en utilisant la première partie de l'exercice, qui garantit qu'une matrice dont les entrées sont des entiers et qui possède un déterminant de ou a aussi un inverse dont les entrées sont des entiers. "
},
{
  "id": "exercise-247",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-247",
  "type": "Exercice",
  "number": "4.3.4.7",
  "title": "",
  "body": " Soit , une matrice orthogonale, c'est-à-dire une matrice telle que . Montrer que .   Utiliser l'exercice .  Par l'exercice , on sait que la matrice orthogonale est telle que . Par l'équation , on sait que . Ainsi, on a . "
},
{
  "id": "exo-eqdroitedet",
  "level": "2",
  "url": "sec-cofacteurs.html#exo-eqdroitedet",
  "type": "Exercice",
  "number": "4.3.4.8",
  "title": "",
  "body": "Soit et , deux points distincts de . Montrer que l'équation de la droite passant par ces points est donnée par . On choisit de développer le déterminant pour voir si l'on obtient une expression correspondant à l'équation de cette droite. Cette expression rappelle l'équation normale d'une droite dans . Le vecteur normal serait donc . On sait qu'on peut retrouver un vecteur directeur ainsi: . Le membre de gauche de l'équation normale correspond à l'expression obtenue lorsqu'on construit l'équation normale avec le produit scalaire entre le vecteur normal et le vecteur avec , un point quelconque de la droite. En effet, ce qui est exactement ce qu'on avait obtenu en développant le déterminant initial. "
},
{
  "id": "exercise-249",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-249",
  "type": "Exercice",
  "number": "4.3.4.9",
  "title": "",
  "body": "Soit et , trois points non alignés de . Généraliser l'idée de l'exercice pour obtenir l'équation du plan passant par ces trois points. On choisit de commencer en construisant l'équation normale d'un plan dans . "
},
{
  "id": "exercise-250",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-250",
  "type": "Exercice",
  "number": "4.3.4.10",
  "title": "La parabole (re)revisitée.",
  "body": "La parabole (re)revisitée  Dans les exercices et , on a donné des méthodes vectorielles et matricielles pour trouver l'équation d'une parabole. Montrer que si et sont trois points non alignés de , alors l'équation de la parabole qui passe par ces trois points est donnée par .  "
},
{
  "id": "exercise-251",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-251",
  "type": "Exercice",
  "number": "4.3.4.11",
  "title": "",
  "body": "On considère la suite de matrices . Utiliser Sage pour formuler une hypothèse sur la valeur de et démontrer le résultat. Calculer et . Vérifier que et qu'en général, on a . Si est impair, alors . Lorsque est pair et divisible par quatre, alors et si est pair, mais non divisible par quatre, alors .  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def diagsecond(i,j): if abs(i-j)==1: return 1 else: return 0 B=matrix(ZZ,4,lambda i,j: diagsecond(i,j)) for i in range(10): show(\"det(B_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: diagsecond(i,j)).determinant())    On remarque facilement que les premiers déterminants satisfont la relation et l'on tente maintenant de la démontrer. On développe le déterminant de selon la première ligne. On aura .  "
},
{
  "id": "exercise-252",
  "level": "2",
  "url": "sec-cofacteurs.html#exercise-252",
  "type": "Exercice",
  "number": "4.3.4.12",
  "title": "",
  "body": "On considère la suite de matrices . Montrer en utilisant Sage que et démontrer algébriquement ce résultat.  Voici une fonction permettant de créer les matrices . Elle utilise la méthode de construction par une fonction intermédiaire lambda . Voir .   Le code solution pour l'exercice   def matrice121(i,j): if i==j: return 2 elif abs(i-j)==1: return 1 else: return 0 F=matrix(ZZ,5,lambda i,j: matrice121(i,j)) for i in range(10): show(\"det(F_%d)=\" %(i+1), matrix(ZZ,i+1,lambda i,j: matrice121(i,j)).determinant())    Similairement à l'exercice précédent, on développe selon la première ligne. On aura alors .  On remarque que la matrice que l'on obtient pour est égale à . Pour , on a .  En combinant toutes les informations, on a .  "
},
{
  "id": "sec-ssesp",
  "level": "1",
  "url": "sec-ssesp.html",
  "type": "Section",
  "number": "5.1",
  "title": "Sous-espaces vectoriels",
  "body": "  Sous-espaces vectoriels    Aller aux exercices de la section.  On considère deux vecteurs sur un plan. Si l'on additionne ces deux vecteurs, le résultat est-il encore sur le plan? Qu'en est-il d'un multiple d'un vecteur du plan, est-il aussi dans le plan? Si oui, un objet qui possède ces propriétés est dit fermé par rapport à l'addition et à la multiplication.  Un sous-espace est un espace à l'intérieur d'un autre espace. C'est une partie en général plus petite que l'espace dans lequel elle se situe, mais qui possède la même structure.  Dans cette section, on définit la notion de sous-espace vectoriel. On considère des exemples géométriques et algébriques et l'on explore les quatre sous-espaces fondamentaux en lien avec ces nouveaux concepts.    Sous-espace  On revient à la question d'introduction en considérant les plans . Les vecteurs dans le plan sont de la forme et les vecteurs dans le plan sont de la forme .  Si l'on prend deux vecteurs de , on peut montrer que leur somme est aussi dans le plan, car . Un multiple d'un vecteur de ce plan y demeure aussi, puisque .  Par contre, le plan ne possède pas ces propriétés. On peut prendre un exemple spécifique ou encore faire le cas général. Dans le cas de la somme quelconque, on a , alors que pour un cas spécifique avec un multiple, il suffit de prendre zéro fois le vecteur et de constater que .  Ceci motive la définition suivante.   Sous-espace vectoriel   Soit , un ensemble non vide de vecteurs (possiblement tous) de , de sorte que . On dit que est un sous-espace vectoriel si les vecteurs dans satisfont les propriétés suivantes:   Propriétés à satisfaire   Si deux vecteurs sont dans , alors leur somme est aussi dans , c'est-à-dire si , alors .  Si un vecteur est dans et qu'on le multiplie par un scalaire, alors le multiple est aussi dans , c'est-à-dire si , alors .   On dit que l'ensemble est fermé par rapport à l'addition et à la multiplication par un scalaire.    On débute avec des exemples de sous-espaces vectoriels.   Des sous-espaces vectoriels   On considère les ensembles vecteurs suivants, vus comme des sous-ensembles de pour approprié:  Le plan du début de section;  Les vecteurs de la forme ;  L'ensemble ne contenant que le vecteur nul : ;  L'espace au complet;  Une droite dans , passant par l'origine;  Un plan dans , passant par l'origine;  Un hyperplan dans , passant par l'origine.      La démonstration est faite à même le texte en début de section.    On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même composante en qu'en et que a lui aussi cette propriété. Pour la somme, on a , qui est dans . Pour la multiplication par un scalaire, on a , qui est également dans .    Puisque le vecteur nul est le seul vecteur de l'espace, on ne peut que considérer la somme . De même, puisque , l'ensemble est un espace vectoriel. On l'appelle souvent l'espace vectoriel trivial.    À priori, cette question semble évidente, puisqu'on a défini l'addition de vecteurs et la multiplication par un scalaire composante par composante, ce qui fait qu'un vecteur de additionné à un autre restera un vecteur de et de même pour la multiplication par un scalaire. On verra à la section que la situation pourrait être plus complexe.    Une droite passant par l'origine est caractérisée par l'ensemble des multiples d'un vecteur directeur . Un vecteur sur la droite s'écrit comme pour un certain . Afin de montrer que la somme de deux vecteurs sur la droite est aussi sur la droite et qu'un multiple d'un vecteur sur la droite l'est également, on prend et . Il faut montrer que la somme de et s'écrit comme un multiple réel de . La même idée s'appliquera pour la multiplication du vecteur par .  Dans un premier temps, on a . Comme , il s'ensuit que la somme des vecteurs est sur la droite.  Pour la multiplication par le scalaire, on a et, puisque , la multiplication est aussi sur la droite.    Voir l'exercice .    Un hyperplan peut être écrit comme le produit scalaire d'un vecteur avec le vecteur , c'est-à-dire où . Si l'hyperplan passe par l'origine, alors . Les vecteurs dans l'hyperplan sont donc l'ensemble des vecteurs tels que . Soit , des vecteurs de sur l'hyperplan, c'est-à-dire des vecteurs tels que et soit , un scalaire. On a . Le vecteur est donc aussi sur l'hyperplan. Pour la multiplication par un scalaire, on a . La multiplication par le scalaire est aussi sur l'hyperplan.    Afin de bien comprendre que tout sous-ensemble de vecteurs n'est pas un sous-espace vectoriel, on regarde maintenant quelques contrexemples.   Des ensembles qui ne sont pas des sous-espaces vectoriels   Les ensembles suivants ne sont pas des sous-espaces vectoriels de :  Le plan du début de la présente sous-section;  Les vecteurs pour lesquels au moins une des composantes est nulle. Ce sont les vecteurs sur les axes de coordonnées;  Une droite ne passant pas par l'origine.     La solution est faite à même le texte en début de sous-section.    Pour des fins de simplicité, on considère l'espace comme étant . Si l'on prend les vecteurs et , alors la somme ne possède pas au moins l'une de ses composantes nulles. Elle n'est donc pas dans le sous-ensemble, ce qui fait que ce n'est pas un espace vectoriel.  Il convient de rappeler ici le conseil .    Si la droite ne passe pas par l'origine, alors le vecteur n'est pas sur la droite. Soit , un vecteur sur la droite. Si l'on considère la multiplication par le scalaire , alors le résultat n'est pas sur la droite. Ce n'est donc pas un espace vectoriel.    Des exemples importants de sous-espaces vectoriels sont les ensembles solutions à un système d'équations linéaires homogènes, correspondant aux zéros de la transformation linéaire associée.   Les zéros d'une transformation forment un sous-espace vectoriel  Soit , la matrice d'une transformation linéaire. Alors les solutions à l'équation linéaire forment un sous-espace vectoriel de .  En fait, cette proposition est une reformulation de la proposition   Un résultat en apparence évident, mais qui aura son utilité à plus d'une reprise, est obtenu en considérant l'ensemble de toutes les combinaisons linéaires obtenues à partir d'un ensemble de vecteurs. Dans la section , on a appelé ce concept le des vecteurs. Cet ensemble est un sous-espace vectoriel.   L'espace engendré est un sous-espace vectoriel   Soit , des vecteurs quelconques. L'ensemble des combinaisons linéaires de ces vecteurs, noté et introduit à la définition , est un sous-espace vectoriel.    On vérifie directement, à l'aide de la définition, les propriétés. Soit , des vecteurs dans l'espace engendré . Puisque sont une combinaison linéaire de vecteurs dans l'espace engendré, on peut écrire . On a donc qui est aussi une combinaison linéaire des vecteurs . Ainsi, est dans .  De même, si , alors , qui est également combinaison linéaire et donc dans l'espace engendré.    En combinant les propositions précédentes, on peut arriver à caractériser les sous-espaces d'une manière géométrique. Puisque tout espace engendré par un ensemble de vecteurs est un sous-espace, il s'ensuit que les droites, plans et en général hyperplans passant par l'origine sont des sous-espaces vectoriels. On verra aussi à la prochaine section que, mis à part le sous-espace composé uniquement du vecteur nul, tout sous-espace peut être vu comme l'espace engendré par un certain nombre de vecteurs. Les sous-espaces ne sont donc qu'un autre terme utilisé pour décrire droites, plans et hyperplans. En fait, on verra plus tard qu'on peut considérer des espaces plus arbitraires que et que les mots droites et plans n'auront plus de sens dans ces espaces.  Les sous-espaces vectoriels possèdent certaines propriétés communes. La plus importante est certainement la présence du vecteur nul.   Le vecteur nul fait partie de tous les sous-espaces vectoriels  Soit , un sous-espace vectoriel. Alors .  Géométriquement, cela signifie que les droites, plans et hyperplans sont des sous-espaces seulement s'ils passent par l'origine.   On prend un vecteur quelconque dans (Le fait que l'ensemble est un sous-espace implique qu'il est non vide). Puisque est un sous-espace, la propriété dit que les multiples de sont aussi dans le sous-espace. Il suffit alors de considérer le multiple .   D'autres propriétés seront explorées dans les exercices.  On termine avec une définition importante pour la suite et qui introduit le concept de complément orthogonal.   Le complément orthogonal  Soit , un sous-ensemble de . On définit le complément orthogonal de comme étant l'ensemble des vecteurs dans tels que est orthogonal à tous les vecteurs de . On le note .   On regarde des exemples géométriques de compléments orthogonaux.   Compléments orthogonaux de droites et plans   On considère les ensembles suivants: . On cherche le complément orthogonal de chacun de ces ensembles de points.    Les points sur ont comme caractéristiques d'être des multiples du vecteur directeur de la droite, soit . Dans , tout vecteur perpendiculaire à un de ces multiples sera de la forme . Le complément orthogonal de la droite est donc aussi une droite, perpendiculaire à . Son équation vectorielle est .   Les points sur ont comme caractéristiques d'être des multiples du vecteur directeur de la droite, soit . Dans , tout vecteur perpendiculaire à un de ces multiples sera sur le plan d'équation normale , dont le vecteur normal est le vecteur directeur de .   Les points sur le plan sont tous perpendiculaires aux points sur la droite ayant comme vecteur directeur le vecteur normal du plan. On peut calculer ce vecteur en utilisant le produit vectoriel: . Le complément orthogonal du plan est donc la droite .     Le complément orthogonal n'est pas réservé aux sous-espaces vectoriels  On peut déterminer le complément orthogonal de n'importe quel ensemble de vecteurs, non pas uniquement des ensembles qui sont des sous-espaces vectoriels. Par exemple, si l'on considère la droite , ce n'est pas un sous-espace vectoriel, car la droite ne passe pas par l'origine. On peut toutefois trouver son complément orthogonal en raisonnant géométriquement. On pourrait penser que les vecteurs se trouveront sur la droite perpendiculaire à et passant par le point , mais la situation réelle est plus complexe. Puisque chaque valeur de apporte une direction différente (dû à l'addition du point ), il y a en fait une infinité de droites qui composent le complément orthogonal. Comme on va principalement se concentrer sur les sous-espaces vectoriels dans le cadre de ces notes, on s'arrête à cette remarque.   On a déjà rencontré des sous-espaces orthogonalement complémentaires à la section . On y revient dans la prochaine sous-section. Pour le moment, on regarde les propriétés du complément orthogonal lorsque l'ensemble est un sous-espace vectoriel.   Le complément orthogonal est un sous-espace vectoriel  Soit , un sous-espace vectoriel et , son complément orthogonal. Alors est aussi un sous-espace vectoriel.  Soit , des vecteurs de . Alors pour tous les vecteurs  . De même, si , alors . Ainsi, le complément orthogonal est un sous-espace vectoriel.   On regarde deux autres propriétés du complément orthogonal qui seront utiles dans la sous-section suivante.   Les vecteurs orthogonaux et le complément orthogonal   Soit , des sous-espaces vectoriels tels que pour tout vecteur et . Alors .   Par définition, le complément orthogonal de consiste à l'ensemble de tous les vecteurs pour lesquels avec . Puisque les vecteurs dans ont cette propriété par hypothèse, ces vecteurs sont certainement aussi dans .  Cela dit, étant donnés deux ensembles et qui possèdent cette propriété, peut-on dire que ? L'exercice permettra réfléchir à cette question.     Complément orthogonal et inclusion  Soit , des sous-espaces vectoriels tels que . Alors .   On veut montrer que tout vecteur dans est aussi dans . Or, si est dans , cela signifie que est perpendiculaire à tous les vecteurs dans . Comme est inclus dans , le vecteur est aussi perpendiculaire à tous les vecteurs dans . On peut donc affirmer que est dans . Ainsi .     Le complément orthogonal du vecteur nul   Soit , le sous-espace trivial qui ne contient que le vecteur nul . Alors .    Puisque pour tout vecteur on a , tous les vecteurs de sont dans le complément orthogonal.      Les quatre sous-espaces vectoriels  À la section , on a défini la notion des quatre sous-espaces fondamentaux d'une matrice. Ces quatre sous-ensembles sont aussi des sous-espaces vectoriels.   Les sous-espaces fondamentaux sont des sous-espaces vectoriels   Soit , une matrice . Alors les espaces nul, colonne, ligne et nul gauche sont des sous-espaces fondamentaux.    On débute avec l'espace nul. C'est un sous-espace vectoriel selon la proposition . Comme l'espace nul gauche est équivalent à l'espace nul de la transposée, la même proposition confirme que c'est aussi un sous-espace vectoriel.  L'espace colonne (ligne) est défini comme étant l'ensemble des combinaisons linéaires des colonnes (lignes). On peut ainsi le voir comme le de ces colonnes (lignes), ce qui en fait donc un sous-espace vectoriel en vertu de la proposition .    On regarde un exemple des espaces colonne et nul sous l'œil des sous-espaces vectoriels.   Les sous-espaces fondamentaux comme sous-espaces vectoriels   On considère la matrice . L'espace nul est un sous-espace de et l'espace colonne est un sous-espace de . On cherche à les caractériser en tant que sous-espaces vectoriels.   La forme échelonnée réduite de est .  De cette matrice , on peut déduire les solutions de base . Les solutions à l'équation s'écrivent donc comme . C'est un sous-espace vectoriel qui consiste en un plan de de vecteurs directeurs .  L'espace colonne s'écrit évidemment comme . La proposition donne toutefois une autre manière de trouver l'espace colonne. Les calculs suivants sur Sage   permettent d'obtenir la matrice . Afin d'être compatible, la dernière ligne doit être nulle et le vecteur doit satisfaire l'équation . On reconnait ici l'équation normale d'un plan. L'espace colonne peut aussi être vu comme un plan dans .  Intuitivement, on devrait ainsi être en mesure de réduire le nombre de vecteurs qui génèrent le de quatre à deux, puisque la dimension d'un plan est deux. La prochaine section précisera quels vecteurs choisir et garder pour décrire de manière efficace les espaces colonne et ligne.    On regarde un autre exemple qui va permettre de contextualiser une partie de la preuve de la proposition . C'est un exemple semblable au dernier, mais avec plus d'une ligne nulle.   L'espace colonne vu comme un espace nul  Soit , une matrice et , un vecteur de l'image. On donne la forme échelonnée réduite de la matrice augmentée du vecteur : . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .   On effectue maintenant une première étape vers le théorème fondamental de l'algèbre linéaire, cité pour la première fois à la proposition . On peut reformuler deux des énoncés en utilisant le complément orthogonal.   Les espaces fondamentaux et le complément orthogonal   Soit , une matrice . Alors  ;  ;  ;  .   On observe évidemment la symétrie de ces énoncés. En particulier, il semble que , mais le résultat n'est pas aussi évident qu'il parait et va nécessiter des outils de la prochaine section. Pour les espaces fondamentaux, on peut, par contre, démontrer cela en s'appuyant sur la géométrie.    On veut montrer que le complément orthogonal de l'espace ligne correspond à l'espace nul. On sait déjà que les vecteurs de l'espace nul sont orthogonaux avec les lignes de . En vertu de la proposition (généralisée) , il s'ensuit que l'espace nul est un sous-ensemble du complément orthogonal de l'espace ligne.  Soit , un vecteur du complément orthogonal de l'espace ligne de . Ce vecteur est perpendiculaire à toutes les combinaisons linéaires des lignes de et plus particulièrement, il est perpendiculaire aux lignes de . Cela signifie que , selon la définition du produit matrice vecteur et que le vecteur est dans l'espace nul. Le complément orthogonal est ainsi un sous-ensemble de l'espace nul.  En combinant les deux arguments précédents, on a que   Il suffit de remplacer par dans la preuve de la propriété précédente.  Puisque les vecteurs dans sont perpendiculaires aux vecteurs dans (selon la proposition ), on sait que l'espace colonne est un sous-ensemble du complément orthogonal de l'espace nul gauche, selon la proposition . On a par conséquent .  Il faut donc montrer que les vecteurs dans le complément orthogonal de l'espace nul gauche sont dans l'espace colonne.  Soit , le rang de . Si , alors il n'y a pas de ligne nulle et l'espace colonne est au complet. Le seul vecteur perpendiculaire à tout est le vecteur nul. Ainsi, , entrainant par la proposition que . Si toutefois , alors il y a lignes nulles.  À la manière de l'exemple , on peut définir des vecteurs et une matrice tels que l'espace colonne de corresponde à l'espace nul de . Selon la première partie de cette proposition, . De plus, les lignes de sont perpendiculaires à l'image de (le vecteur ), et . Ceci revient à dire que . À partir de la propriété , on peut conclure que .  En combinant les deux arguments, on conclut que .   On remplace par dans l'argument précédent.    Égalité de deux ensembles  Lorsqu'on veut montrer que deux ensembles sont égaux, une manière efficace de le faire est de montrer que tous les éléments de sont aussi dans , signifiant que , et que tous les éléments de sont dans , entrainant que . La seule conclusion est alors que . C'est ce principe qui est utilisé dans la preuve de la proposition .  Le même principe est aussi utilisé pour démontrer l'égalité de deux nombres . On peut, dans un premier temps, montrer que et ensuite que , ce qui entraine l'égalité.   On termine avec des commandes Sage en lien avec la sous-section.   Les espaces fondamentaux et le complément orthogonal  À l'exemple , on a vu comment déterminer des vecteurs dont le sera un des quatre espaces fondamentaux d'une matrice . Ces vecteurs sont ce que l'on appelle une base de ces espaces. Les bases seront le principal sujet de la prochaine section. Pour l'instant, on s'intéresse à vérifier l'orthogonalité des espaces fondamentaux comme indiqué à la proposition .  On commence par définir la matrice de l'exemple et les éléments qui génèrent chacun de ses quatre espaces fondamentaux.   On fait ensuite le produit scalaire de toutes les combinaisons possibles d'un vecteur de l'espace nul avec un vecteur de l'espace ligne.   Même chose ci-dessous, mais avec les vecteurs de l'espace nul gauche et les vecteurs de l'espace colonne.   Le produit scalaire entre les générateurs étant nul, le produit scalaire de chaque élément des espaces nul et ligne et chaque élément des espaces nul gauche et colonne sera aussi nul, comme le garantit la proposition .       Les éléments importants de cette section sont  La définition d'un sous-espace vectoriel;  Le fait que l'espace engendré par un ensemble de vecteurs ( ) est toujours un sous-espace vectoriel ;  La définition du complément orthogonal;  Le fait que les quatre sous-espaces fondamentaux d'une matrice sont des sous-espaces vectoriels ;  La complémentarité des sous-espaces fondamentaux.       Exercices    Montrer que chacun des sous-ensembles ci-dessous est un sous-espace vectoriel en utilisant la définition .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même forme que les vecteurs initiaux, de même pour . Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a aussi , également dans .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même composante en qu'en et que a aussi cette propriété. Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a , également dans .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même forme que les vecteurs initiaux, de même pour . Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a , également dans .     Pour ce sous-espace, on choisit d'exprimer différemment l'appartenance à l'ensemble. Soit deux vecteurs dans et un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et respectent également la condition de l'espace. Pour la somme, on a , pour lequel il faut vérifier la condition. Cela confirme que le vecteur est également dans .  Pour la multiplication par un scalaire, on a aussi , pour lequel il faut également vérifier la condition. Cela confirme que le vecteur est lui aussi dans .     Pour ce sous-espace, on choisit d'exprimer l'appartenance à l'ensemble comme à la question précédente. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et respectent également la condition de l'espace. Pour la somme, on a , pour lequel il faut vérifier la condition. Contrairement à tous les exercices précédents, on n'arrive pas à la condition de façon algébrique. Il faut donc réfléchir un peu plus puisqu'on a dit qu'il s'agit d'un sous-espace vectoriel. En regardant de plus près à la condition, on réalise que le seul vecteur qui peut satisfaire la condition est le vecteur nul. Bref, on travaille inutilement puisqu'on a déjà montré que l'ensemble formé uniquement du vecteur nul est un sous-espace vectoriel à l'exemple .  Pour la multiplication par un scalaire, on peut cependant le montrer algébriquement. On vérifie la condition. Cela confirme que le vecteur est également dans , ce que l'on savait déjà puisque .    Montrer que chacun des sous-ensembles ci-dessous n'est pas un sous-espace vectoriel en utilisant la définition .    Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui est dans l'ensemble , puisque . Alors, et . On aurait donc pu choisir une valeur de spécifique dans ce contrexemple, mais on a choisit de garder l'ensemble des valeurs possibles. Cela confirme que la multiplication d'un vecteur par un scalaire peut donner un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui sont dans l'ensemble , puisque et . Alors, et . Cela confirme que la somme de ces vecteurs donne un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisi d'utiliser la propriété .  Soit , qui sont dans l'ensemble , puisque et . Alors, et . Cela confirme que la somme de ces vecteurs donne un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui est dans l'ensemble , puisque . Alors, si l'on choisit , on a et . Cela confirme que la multiplication d'un vecteur par un scalaire peut donner un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.  Compléter la preuve de l'exemple en montrant qu'un plan passant par l'origine est un sous-espace vectoriel, en utilisant la définition.  Un plan passant par l'origine est caractérisé par l'ensemble des combinaisons linéaires de deux vecteurs directeurs . Un vecteur sur le plan s'écrit pour certains .  Afin de montrer que la somme de deux vecteurs sur le plan est aussi sur le plan et qu'un multiple d'un vecteur sur le plan l'est aussi, on prend et . Il faut montrer que la somme de et s'écrit comme une combinaison linéaire de . La même idée s'appliquera pour la multiplication du vecteur par .  Dans un premier temps, on a . Comme et , il s'ensuit que la somme des vecteurs est sur le plan.  Pour la multiplication par le scalaire, on a et, puisque , la multiplication est aussi sur le plan.   Soit , un plan. Si (n'est pas l'origine), ce plan peut-il être un espace vectoriel? Et pourquoi? Oui.  Ce sera un espace vectoriel à une condition. Par la proposition , tout sous-espace doit impérativement contenir le vecteur nul. Ainsi, ce plan peut être un sous-espace à la condition qu'il passe par l'origine. Autrement dit, il faut qu'il existe des valeurs telles que . On rappelle donc par cet exercice qu'il est important de comprendre qu'une équation vectorielle de tout objet géométrique n'est pas nécessairement dans sa plus simple expression. En effet, il suffit d'un point de départ qui peut être n'importe où sur l'objet.   Soit , des sous-espaces vectoriels de . Montrer que les ensembles suivants sont aussi des sous-espaces vectoriels.   L'ensemble des vecteurs qui sont à la fois dans et dans , noté .  Donner un exemple géométrique de sous-espaces vectoriels et dans .   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme des conditions énoncées. On ne peut donc pas constater l'appartenance algébriquement, ce qui rend la preuve plus difficile conceptuellement. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent les conditions de l'espace et que et aussi que . On doit montrer que et respectent également les conditions de l'espace. Pour la somme, on a , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Dès lors, puisque respecte ces deux conditions, on sait que .  Pour la multiplication par un scalaire, on a , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Par conséquent, puisque respecte ces deux conditions, on sait que . Cela montre que les deux propriétés des sous-espaces sont respectées par l'ensemble et qu'il s'agit bien d'un sous-espace vectoriel.  Un exemple géométrique simple de cet ensemble est l'intersection de deux plans passant par l'origine dans . En effet, on a montré à l'exercice qu'un plan passant par l'origine est un sous-espace vectoriel de , ce qui s'applique à . L'intersection de ces deux plans est une droite dans passant aussi par l'origine. On a montré également à l'exemple qu'une telle droite est un sous-espace de , ce qui s'applique aussi à .   L'ensemble des vecteurs qui s'écrivent comme la somme d'un vecteur dans et d'un vecteur dans , noté .  Donner un exemple géométrique de sous-espaces vectoriels et dans .   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme des conditions énoncées. On ne peut donc pas constater l'appartenance algébriquement, ce qui rend la preuve plus difficile conceptuellement. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent les conditions de l'espace, que et que . On doit montrer que et respectent également les conditions de l'espace. Pour la somme, on a On a que , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Donc, puisque est l'addition de deux vecteurs, l'un appartenant à et l'autre à , on sait que .  Pour la multiplication par un scalaire, on a On a que , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Donc, puisque est l'addition de deux vecteurs,l'un appartenant à et l'autre à , on sait que .  Un exemple géométrique simple de cet ensemble est l'addition de deux droites passant par l'origine dans . En effet, on a montré à l'exercice qu'une droite passant par l'origine est un sous-espace vectoriel de , ce qui s'applique à . L'addition de ces deux droites est un plan dans passant aussi par l'origine. On a montré également à l'exemple qu'un tel plan est un sous-espace de , ce qui s'applique aussi à . Il peut sembler difficile à visualiser que l'addition de deux droites telle que définie dans cet exercice forme un plan. Cependant, lorsqu'on réalise que l'addition vectorielle de toute paire de vecteurs provenant de deux droites non parallèles est en réalité l'ensemble des combinaisons linéaires possibles des vecteurs directeurs de ces droites, cela devient évident.     Soit , des sous-espaces vectoriels de . On définit l'union de et comme l'ensemble des vecteurs qui sont soit dans , soit dans (potentiellement les deux), noté .   Est-ce que est un sous-espace vectoriel? Si oui, démontrer et si non, donner un exemple de sous-espaces tels que l'union n'en est pas un.  Non. Par exemple, deux droites non parallèles dans passant par l'origine. Non, il ne s'agit pas d'un sous-espace vectoriel. Il sera possible de trouver un contrexemple où l'on additionnera deux vecteurs provenant l'un de et l'autre de , de telle sorte qu'ils sont tous les deux dans , pour obtenir un vecteur qui ne sera ni dans ni dans et non plus pas dans . Cela sera donc un contrexemple à la propriété des sous-espaces vectoriels.  On suggère comme contrexemple deux droites non parallèles dans passant par l'origine. Spécifiquement, on pose et . Pour et , ces deux vecteurs sont tous les deux dans . On calcule qui n'est ni dans ni dans et non plus pas non plus dans . Peu importe la réponse à la partie précédente, donner des exemples de sous-espaces vectoriels dans tels que est aussi un sous-espace vectoriel. Afin de trouver des exemples, il faut réfléchir à ce qui ferait en sorte que cela devienne un sous-espace vectoriel. Il est clair que si ou bien si , alors respectivement ou bien . Par exemple, si est une droite dans et est un plan qui contient cette droite, tous les deux passant par l'origine, alors les deux espaces sont des sous-espaces vectoriels de tels que est aussi un sous-espace vectoriel, puisqu'il est égal à . On a un autre exemple si et est une droite ou même un plan passant par l'origine, puisque le même principe s'applique.   Soit , une matrice carrée.   Montrer que les solutions à l'équation forment un sous-espace vectoriel.  Reformuler afin d'écrire l'ensemble solution comme l'espace nul d'une matrice. On suit l'indice et l'on transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice .  Soit , un nombre réel. Montrer que les solutions à l'équation forment un espace vectoriel.  De façon semblable, on transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice .   Soit , deux matrices . Montrer que l'ensemble solution à l'équation est un sous-espace vectoriel.  On transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice .   Soit , une matrice et soit , des sous-espaces vectoriels. Montrer que l'ensemble est un sous-espace vectoriel de .  Cela implique qu'un sous-espace vectoriel dans l'image provient d'un sous-espace vectoriel dans le domaine.   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme de la condition énoncée. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et sont également tels que leur transformation par est dans . Pour la somme, on a que , car étant lui-même un sous-espace, l'addition de deux éléments de donne un vecteur dans . L'espace respecte donc la condition .  Pour la multiplication par un scalaire, on a , car étant lui-même un sous-espace, la multiplication par un scalaire d'un vecteur de donne un vecteur dans .  L'espace respecte donc la condition . Il s'agit bien d'un sous-espace vectoriel.  Montrer que l'ensemble est un sous-espace vectoriel.  Cela implique que l'image d'un sous-espace vectoriel par une transformation linéaire est un sous-espace vectoriel.   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme de la condition énoncée. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et sont également tels qu'il existe un vecteur de qu'on peut transformer par pour les obtenir. Pour la somme, on a que . Le vecteur est dans , puisqu'il est l'addition de deux vecteurs de ce sous-espace. Ainsi, le vecteur est dans et dans ce cas, cet espace respecte la condition .  Pour la multiplication par un scalaire, on a . Le vecteur est dans puisqu'il est la multiplication par un scalaire d'un vecteur de ce sous-espace. Le vecteur est donc dans et cet espace respecte donc la condition . Conséquemment, il est lui-même un sous-espace vectoriel.    Soit , un sous-espace vectoriel de . Quel est le seul vecteur qui est à la fois dans et dans son complément orthogonal?  Le vecteur nul. Par la définition , on sait que pour faire partie du complément orthogonal de , il faut qu'un vecteur soit orthogonal à tous les vecteurs de . En particulier, si un vecteur est à la fois dans et dans son complément orthogonal, il doit être orthogonal à lui-même. Ainsi, on obtient que , car le vecteur nul est le seul vecteur de norme égale à zéro.   Soit , un sous-espace vectoriel de . Montrer que .  En fait, on a que , mais l'autre inclusion est plus difficile à démontrer. On le fera avec les outils de la section .  Soit . Il faut montrer que ce vecteur fait partie de . Autrement dit, il faut que pour tout vecteur , selon la définition . Mais, on sait qu'un vecteur de est tel que pour tout vecteur , toujours selon la définition . Cela est vrai en particulier pour le vecteur énoncé au début de la preuve. Ainsi, on sait que et que .  Dans cet exercice, on s'intéresse à deux sous-espaces tels que pour tout .  Donner un exemple de sous-espaces possédant cette propriété, mais tels que et . Penser à . Un plan et une droite ayant comme vecteur directeur le vecteur normal du plan ont cette propriété, mais sont des compléments orthogonaux. Il faut penser un peu plus petit que le plan. On doit prendre comme sous-espaces deux droites dans passant par l'origine qui sont perpendiculaires l'une à l'autre. Par exemple, on prend spécifiquement les droites: et . Alors, on a que pour tout . On a également qu'ils ne sont pas les compléments l'un de l'autre, comme on l'énonce dans l'indication, car le complément orthogonal d'une droite est un plan dans . Finalement, ils ne sont de toute évidence pas égaux au sous-espace vectoriel trivial.   Soit , une matrice carrée symétrique et , un sous-espace vectoriel tels que pour tout . Montrer que pour tout vecteur .   Utiliser l'exercice .   Soit et soit . On note que par hypothèse. Afin de vérifier que est aussi dans , on calcule le produit scalaire entre et . On a alors . Ainsi, le vecteur est perpendiculaire à tous les vecteurs dans et en conséquence, .    Soit , un ensemble de vecteurs et , un vecteur différent des vecteurs . On cherche à caractériser l'effet de l'ajout du vecteur au .   On considère les vecteurs ainsi que les vecteurs .  Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur n'ajoute rien à l'espace puisqu'il est parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur n'ajoute rien à l'espace puisqu'il est parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est une droite et un plan contenant cette droite. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise, en travaillant un peu, que le vecteur n'ajoute rien à l'espace puisqu'il est une combinaison linéaire des vecteurs . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est une droite et un plan contenant cette droite. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise, en travaillant un peu, que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas une combinaison linéaire des vecteurs . En effet, on a:   , qui n'a aucune solution. Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est un plan et l'espace au complet. On verra dans la section comment catégoriser ces différents sous-espaces en termes de dimensions. Montrer que si et seulement si . On construit la preuve en deux temps puisqu'il s'agit d'une équivalence.  Tout d'abord, si , on doit montrer que . Puisque les deux espaces initiaux sont égaux, il est clair que le vecteur supplémentaire dans le second espace, n'ajoute rien à cet espace. Il est donc nécessairement une combinaison linéaire des autres vecteurs, ce qui revient à dire que .  Dans l'autre direction, si , alors on peut écrire . Ainsi, tout vecteur peut s'écrire: ce qui est également dans également. Ces deux espaces sont donc égaux, ce qui complète la preuve.   Soit et , deux matrices équivalentes par une suite d'opérations élémentaires.  Montrer que . La généralisation de l'exercice peut être utile. Si et sont équivalentes, cela implique que l'on peut obtenir de avec une suite d' opérations élémentaires . On sait que l'espace ligne est l'ensemble des combinaisons linéaires des lignes de (span). Par la généralisation à plusieurs vecteurs de l'exercice , on sait que le span de combinaisons linéaires des vecteurs d'un espace donnera le même espace. Ainsi, les lignes de la matrice pouvant être obtenues des lignes de en faisant des combinaisons linéaires (opérations élémentaires), le span des lignes de sera égal à celui des lignes de . Autrement dit, . Montrer que . Il est possible d'utiliser la partie précédente et la proposition . Par la proposition , on a que . Est-ce que ? Non. Ce n'est pas le cas. Les opérations élémentaires changent l'espace colonne. On utilise un contrexemple simple pour s'en convaincre. Soit et . On peut montrer rapidement que est équivalente à en utilisant l'opération élémentaire . Cependant, on voit que .  Pour chacune des matrices ci-dessous, déterminer une matrice telle que , à la manière de l'exemple . Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . La condition sur l'image est donc . On pose . Ainsi, les vecteurs de l'image sont caractérisés par les vecteurs tels que .  Si l'on réécrit cette équation sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux que l'on retrouve dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux que l'on retrouve dans l'espace nul de .   Que peut-on dire des quatre espaces fondamentaux d'une matrice symétrique ? On peut dire plusieurs choses qui découlent toutes du fait qu'une matrice symétrique est telle que . On peut comprendre de cette équation que les lignes et les colonnes de la matrice sont identiques. Conséquemment, on aura:   Soit , deux matrices compatibles pour le produit . Montrer que . Soit , un vecteur qui est tel que , par définition de l'espace nul. Alors, on a . Ainsi, ce même vecteur est nécessairement dans l'espace nul de . Il s'ensuit donc que . Montrer que . Soit , un vecteur qu'il est possible d'exprimer comme une combinaison linéaire des colonnes de . Cependant, par la définition du produit matriciel , on sait que chaque colonne de peut s'exprimer comme un produit matrice vecteur où les sont les colonnes de . Ainsi, si la matrice est de format et la matrice de format , on peut écrire : . Le vecteur est donc une combinaison linéaire des colonnes de , ce qui signifie qu'il est dans son espace colonne et que . Montrer que lorsque est une matrice carrée inversible. On a déjà montré plus haut que . Il reste à montrer que pour compléter l'égalité.  Soit , un vecteur qui est tel que , par définition de l'espace nul. On a alors . Cela implique que fait aussi partie de l'espace nul de . On a et finalement .   "
},
{
  "id": "def-ssesp",
  "level": "2",
  "url": "sec-ssesp.html#def-ssesp",
  "type": "Définition",
  "number": "5.1.1",
  "title": "Sous-espace vectoriel.",
  "body": " Sous-espace vectoriel   Soit , un ensemble non vide de vecteurs (possiblement tous) de , de sorte que . On dit que est un sous-espace vectoriel si les vecteurs dans satisfont les propriétés suivantes:   Propriétés à satisfaire   Si deux vecteurs sont dans , alors leur somme est aussi dans , c'est-à-dire si , alors .  Si un vecteur est dans et qu'on le multiplie par un scalaire, alors le multiple est aussi dans , c'est-à-dire si , alors .   On dit que l'ensemble est fermé par rapport à l'addition et à la multiplication par un scalaire.   "
},
{
  "id": "ex-ssesp",
  "level": "2",
  "url": "sec-ssesp.html#ex-ssesp",
  "type": "Exemple",
  "number": "5.1.3",
  "title": "Des sous-espaces vectoriels.",
  "body": " Des sous-espaces vectoriels   On considère les ensembles vecteurs suivants, vus comme des sous-ensembles de pour approprié:  Le plan du début de section;  Les vecteurs de la forme ;  L'ensemble ne contenant que le vecteur nul : ;  L'espace au complet;  Une droite dans , passant par l'origine;  Un plan dans , passant par l'origine;  Un hyperplan dans , passant par l'origine.      La démonstration est faite à même le texte en début de section.    On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même composante en qu'en et que a lui aussi cette propriété. Pour la somme, on a , qui est dans . Pour la multiplication par un scalaire, on a , qui est également dans .    Puisque le vecteur nul est le seul vecteur de l'espace, on ne peut que considérer la somme . De même, puisque , l'ensemble est un espace vectoriel. On l'appelle souvent l'espace vectoriel trivial.    À priori, cette question semble évidente, puisqu'on a défini l'addition de vecteurs et la multiplication par un scalaire composante par composante, ce qui fait qu'un vecteur de additionné à un autre restera un vecteur de et de même pour la multiplication par un scalaire. On verra à la section que la situation pourrait être plus complexe.    Une droite passant par l'origine est caractérisée par l'ensemble des multiples d'un vecteur directeur . Un vecteur sur la droite s'écrit comme pour un certain . Afin de montrer que la somme de deux vecteurs sur la droite est aussi sur la droite et qu'un multiple d'un vecteur sur la droite l'est également, on prend et . Il faut montrer que la somme de et s'écrit comme un multiple réel de . La même idée s'appliquera pour la multiplication du vecteur par .  Dans un premier temps, on a . Comme , il s'ensuit que la somme des vecteurs est sur la droite.  Pour la multiplication par le scalaire, on a et, puisque , la multiplication est aussi sur la droite.    Voir l'exercice .    Un hyperplan peut être écrit comme le produit scalaire d'un vecteur avec le vecteur , c'est-à-dire où . Si l'hyperplan passe par l'origine, alors . Les vecteurs dans l'hyperplan sont donc l'ensemble des vecteurs tels que . Soit , des vecteurs de sur l'hyperplan, c'est-à-dire des vecteurs tels que et soit , un scalaire. On a . Le vecteur est donc aussi sur l'hyperplan. Pour la multiplication par un scalaire, on a . La multiplication par le scalaire est aussi sur l'hyperplan.   "
},
{
  "id": "example-93",
  "level": "2",
  "url": "sec-ssesp.html#example-93",
  "type": "Exemple",
  "number": "5.1.4",
  "title": "Des ensembles qui ne sont pas des sous-espaces vectoriels.",
  "body": " Des ensembles qui ne sont pas des sous-espaces vectoriels   Les ensembles suivants ne sont pas des sous-espaces vectoriels de :  Le plan du début de la présente sous-section;  Les vecteurs pour lesquels au moins une des composantes est nulle. Ce sont les vecteurs sur les axes de coordonnées;  Une droite ne passant pas par l'origine.     La solution est faite à même le texte en début de sous-section.    Pour des fins de simplicité, on considère l'espace comme étant . Si l'on prend les vecteurs et , alors la somme ne possède pas au moins l'une de ses composantes nulles. Elle n'est donc pas dans le sous-ensemble, ce qui fait que ce n'est pas un espace vectoriel.  Il convient de rappeler ici le conseil .    Si la droite ne passe pas par l'origine, alors le vecteur n'est pas sur la droite. Soit , un vecteur sur la droite. Si l'on considère la multiplication par le scalaire , alors le résultat n'est pas sur la droite. Ce n'est donc pas un espace vectoriel.   "
},
{
  "id": "prop-Ax0ssesp",
  "level": "2",
  "url": "sec-ssesp.html#prop-Ax0ssesp",
  "type": "Proposition",
  "number": "5.1.5",
  "title": "Les zéros d’une transformation forment un sous-espace vectoriel.",
  "body": " Les zéros d'une transformation forment un sous-espace vectoriel  Soit , la matrice d'une transformation linéaire. Alors les solutions à l'équation linéaire forment un sous-espace vectoriel de .  En fait, cette proposition est une reformulation de la proposition  "
},
{
  "id": "prop-vspanssespvec",
  "level": "2",
  "url": "sec-ssesp.html#prop-vspanssespvec",
  "type": "Proposition",
  "number": "5.1.6",
  "title": "L’espace engendré est un sous-espace vectoriel.",
  "body": " L'espace engendré est un sous-espace vectoriel   Soit , des vecteurs quelconques. L'ensemble des combinaisons linéaires de ces vecteurs, noté et introduit à la définition , est un sous-espace vectoriel.    On vérifie directement, à l'aide de la définition, les propriétés. Soit , des vecteurs dans l'espace engendré . Puisque sont une combinaison linéaire de vecteurs dans l'espace engendré, on peut écrire . On a donc qui est aussi une combinaison linéaire des vecteurs . Ainsi, est dans .  De même, si , alors , qui est également combinaison linéaire et donc dans l'espace engendré.   "
},
{
  "id": "prop-vecnulssesp",
  "level": "2",
  "url": "sec-ssesp.html#prop-vecnulssesp",
  "type": "Proposition",
  "number": "5.1.7",
  "title": "Le vecteur nul fait partie de tous les sous-espaces vectoriels.",
  "body": " Le vecteur nul fait partie de tous les sous-espaces vectoriels  Soit , un sous-espace vectoriel. Alors .  Géométriquement, cela signifie que les droites, plans et hyperplans sont des sous-espaces seulement s'ils passent par l'origine.   On prend un vecteur quelconque dans (Le fait que l'ensemble est un sous-espace implique qu'il est non vide). Puisque est un sous-espace, la propriété dit que les multiples de sont aussi dans le sous-espace. Il suffit alors de considérer le multiple .  "
},
{
  "id": "def-comportho",
  "level": "2",
  "url": "sec-ssesp.html#def-comportho",
  "type": "Définition",
  "number": "5.1.8",
  "title": "Le complément orthogonal.",
  "body": " Le complément orthogonal  Soit , un sous-ensemble de . On définit le complément orthogonal de comme étant l'ensemble des vecteurs dans tels que est orthogonal à tous les vecteurs de . On le note .  "
},
{
  "id": "example-94",
  "level": "2",
  "url": "sec-ssesp.html#example-94",
  "type": "Exemple",
  "number": "5.1.9",
  "title": "Compléments orthogonaux de droites et plans.",
  "body": " Compléments orthogonaux de droites et plans   On considère les ensembles suivants: . On cherche le complément orthogonal de chacun de ces ensembles de points.    Les points sur ont comme caractéristiques d'être des multiples du vecteur directeur de la droite, soit . Dans , tout vecteur perpendiculaire à un de ces multiples sera de la forme . Le complément orthogonal de la droite est donc aussi une droite, perpendiculaire à . Son équation vectorielle est .   Les points sur ont comme caractéristiques d'être des multiples du vecteur directeur de la droite, soit . Dans , tout vecteur perpendiculaire à un de ces multiples sera sur le plan d'équation normale , dont le vecteur normal est le vecteur directeur de .   Les points sur le plan sont tous perpendiculaires aux points sur la droite ayant comme vecteur directeur le vecteur normal du plan. On peut calculer ce vecteur en utilisant le produit vectoriel: . Le complément orthogonal du plan est donc la droite .   "
},
{
  "id": "remark-17",
  "level": "2",
  "url": "sec-ssesp.html#remark-17",
  "type": "Remarque",
  "number": "5.1.10",
  "title": "Le complément orthogonal n’est pas réservé aux sous-espaces vectoriels.",
  "body": " Le complément orthogonal n'est pas réservé aux sous-espaces vectoriels  On peut déterminer le complément orthogonal de n'importe quel ensemble de vecteurs, non pas uniquement des ensembles qui sont des sous-espaces vectoriels. Par exemple, si l'on considère la droite , ce n'est pas un sous-espace vectoriel, car la droite ne passe pas par l'origine. On peut toutefois trouver son complément orthogonal en raisonnant géométriquement. On pourrait penser que les vecteurs se trouveront sur la droite perpendiculaire à et passant par le point , mais la situation réelle est plus complexe. Puisque chaque valeur de apporte une direction différente (dû à l'addition du point ), il y a en fait une infinité de droites qui composent le complément orthogonal. Comme on va principalement se concentrer sur les sous-espaces vectoriels dans le cadre de ces notes, on s'arrête à cette remarque.  "
},
{
  "id": "proposition-44",
  "level": "2",
  "url": "sec-ssesp.html#proposition-44",
  "type": "Proposition",
  "number": "5.1.11",
  "title": "Le complément orthogonal est un sous-espace vectoriel.",
  "body": " Le complément orthogonal est un sous-espace vectoriel  Soit , un sous-espace vectoriel et , son complément orthogonal. Alors est aussi un sous-espace vectoriel.  Soit , des vecteurs de . Alors pour tous les vecteurs  . De même, si , alors . Ainsi, le complément orthogonal est un sous-espace vectoriel.  "
},
{
  "id": "prop-orthoinccomp",
  "level": "2",
  "url": "sec-ssesp.html#prop-orthoinccomp",
  "type": "Proposition",
  "number": "5.1.12",
  "title": "Les vecteurs orthogonaux et le complément orthogonal.",
  "body": " Les vecteurs orthogonaux et le complément orthogonal   Soit , des sous-espaces vectoriels tels que pour tout vecteur et . Alors .   Par définition, le complément orthogonal de consiste à l'ensemble de tous les vecteurs pour lesquels avec . Puisque les vecteurs dans ont cette propriété par hypothèse, ces vecteurs sont certainement aussi dans .  Cela dit, étant donnés deux ensembles et qui possèdent cette propriété, peut-on dire que ? L'exercice permettra réfléchir à cette question.   "
},
{
  "id": "prop-compinclusion",
  "level": "2",
  "url": "sec-ssesp.html#prop-compinclusion",
  "type": "Proposition",
  "number": "5.1.13",
  "title": "Complément orthogonal et inclusion.",
  "body": " Complément orthogonal et inclusion  Soit , des sous-espaces vectoriels tels que . Alors .   On veut montrer que tout vecteur dans est aussi dans . Or, si est dans , cela signifie que est perpendiculaire à tous les vecteurs dans . Comme est inclus dans , le vecteur est aussi perpendiculaire à tous les vecteurs dans . On peut donc affirmer que est dans . Ainsi .   "
},
{
  "id": "prop-orthozero",
  "level": "2",
  "url": "sec-ssesp.html#prop-orthozero",
  "type": "Proposition",
  "number": "5.1.14",
  "title": "Le complément orthogonal du vecteur nul.",
  "body": " Le complément orthogonal du vecteur nul   Soit , le sous-espace trivial qui ne contient que le vecteur nul . Alors .    Puisque pour tout vecteur on a , tous les vecteurs de sont dans le complément orthogonal.   "
},
{
  "id": "prop-espfondssespvec",
  "level": "2",
  "url": "sec-ssesp.html#prop-espfondssespvec",
  "type": "Proposition",
  "number": "5.1.15",
  "title": "Les sous-espaces fondamentaux sont des sous-espaces vectoriels.",
  "body": " Les sous-espaces fondamentaux sont des sous-espaces vectoriels   Soit , une matrice . Alors les espaces nul, colonne, ligne et nul gauche sont des sous-espaces fondamentaux.    On débute avec l'espace nul. C'est un sous-espace vectoriel selon la proposition . Comme l'espace nul gauche est équivalent à l'espace nul de la transposée, la même proposition confirme que c'est aussi un sous-espace vectoriel.  L'espace colonne (ligne) est défini comme étant l'ensemble des combinaisons linéaires des colonnes (lignes). On peut ainsi le voir comme le de ces colonnes (lignes), ce qui en fait donc un sous-espace vectoriel en vertu de la proposition .   "
},
{
  "id": "example-95",
  "level": "2",
  "url": "sec-ssesp.html#example-95",
  "type": "Exemple",
  "number": "5.1.16",
  "title": "Les sous-espaces fondamentaux comme sous-espaces vectoriels.",
  "body": " Les sous-espaces fondamentaux comme sous-espaces vectoriels   On considère la matrice . L'espace nul est un sous-espace de et l'espace colonne est un sous-espace de . On cherche à les caractériser en tant que sous-espaces vectoriels.   La forme échelonnée réduite de est .  De cette matrice , on peut déduire les solutions de base . Les solutions à l'équation s'écrivent donc comme . C'est un sous-espace vectoriel qui consiste en un plan de de vecteurs directeurs .  L'espace colonne s'écrit évidemment comme . La proposition donne toutefois une autre manière de trouver l'espace colonne. Les calculs suivants sur Sage   permettent d'obtenir la matrice . Afin d'être compatible, la dernière ligne doit être nulle et le vecteur doit satisfaire l'équation . On reconnait ici l'équation normale d'un plan. L'espace colonne peut aussi être vu comme un plan dans .  Intuitivement, on devrait ainsi être en mesure de réduire le nombre de vecteurs qui génèrent le de quatre à deux, puisque la dimension d'un plan est deux. La prochaine section précisera quels vecteurs choisir et garder pour décrire de manière efficace les espaces colonne et ligne.   "
},
{
  "id": "ex-espcolcommenul",
  "level": "2",
  "url": "sec-ssesp.html#ex-espcolcommenul",
  "type": "Exemple",
  "number": "5.1.17",
  "title": "L’espace colonne vu comme un espace nul.",
  "body": " L'espace colonne vu comme un espace nul  Soit , une matrice et , un vecteur de l'image. On donne la forme échelonnée réduite de la matrice augmentée du vecteur : . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .  "
},
{
  "id": "prop-espfondcomportho",
  "level": "2",
  "url": "sec-ssesp.html#prop-espfondcomportho",
  "type": "Proposition",
  "number": "5.1.18",
  "title": "Les espaces fondamentaux et le complément orthogonal.",
  "body": " Les espaces fondamentaux et le complément orthogonal   Soit , une matrice . Alors  ;  ;  ;  .   On observe évidemment la symétrie de ces énoncés. En particulier, il semble que , mais le résultat n'est pas aussi évident qu'il parait et va nécessiter des outils de la prochaine section. Pour les espaces fondamentaux, on peut, par contre, démontrer cela en s'appuyant sur la géométrie.    On veut montrer que le complément orthogonal de l'espace ligne correspond à l'espace nul. On sait déjà que les vecteurs de l'espace nul sont orthogonaux avec les lignes de . En vertu de la proposition (généralisée) , il s'ensuit que l'espace nul est un sous-ensemble du complément orthogonal de l'espace ligne.  Soit , un vecteur du complément orthogonal de l'espace ligne de . Ce vecteur est perpendiculaire à toutes les combinaisons linéaires des lignes de et plus particulièrement, il est perpendiculaire aux lignes de . Cela signifie que , selon la définition du produit matrice vecteur et que le vecteur est dans l'espace nul. Le complément orthogonal est ainsi un sous-ensemble de l'espace nul.  En combinant les deux arguments précédents, on a que   Il suffit de remplacer par dans la preuve de la propriété précédente.  Puisque les vecteurs dans sont perpendiculaires aux vecteurs dans (selon la proposition ), on sait que l'espace colonne est un sous-ensemble du complément orthogonal de l'espace nul gauche, selon la proposition . On a par conséquent .  Il faut donc montrer que les vecteurs dans le complément orthogonal de l'espace nul gauche sont dans l'espace colonne.  Soit , le rang de . Si , alors il n'y a pas de ligne nulle et l'espace colonne est au complet. Le seul vecteur perpendiculaire à tout est le vecteur nul. Ainsi, , entrainant par la proposition que . Si toutefois , alors il y a lignes nulles.  À la manière de l'exemple , on peut définir des vecteurs et une matrice tels que l'espace colonne de corresponde à l'espace nul de . Selon la première partie de cette proposition, . De plus, les lignes de sont perpendiculaires à l'image de (le vecteur ), et . Ceci revient à dire que . À partir de la propriété , on peut conclure que .  En combinant les deux arguments, on conclut que .   On remplace par dans l'argument précédent.  "
},
{
  "id": "con-egalensemble",
  "level": "2",
  "url": "sec-ssesp.html#con-egalensemble",
  "type": "Conseil",
  "number": "5.1.19",
  "title": "Égalité de deux ensembles.",
  "body": " Égalité de deux ensembles  Lorsqu'on veut montrer que deux ensembles sont égaux, une manière efficace de le faire est de montrer que tous les éléments de sont aussi dans , signifiant que , et que tous les éléments de sont dans , entrainant que . La seule conclusion est alors que . C'est ce principe qui est utilisé dans la preuve de la proposition .  Le même principe est aussi utilisé pour démontrer l'égalité de deux nombres . On peut, dans un premier temps, montrer que et ensuite que , ce qui entraine l'égalité.  "
},
{
  "id": "computation-32",
  "level": "2",
  "url": "sec-ssesp.html#computation-32",
  "type": "Calcul",
  "number": "5.1.20",
  "title": "Les espaces fondamentaux et le complément orthogonal.",
  "body": " Les espaces fondamentaux et le complément orthogonal  À l'exemple , on a vu comment déterminer des vecteurs dont le sera un des quatre espaces fondamentaux d'une matrice . Ces vecteurs sont ce que l'on appelle une base de ces espaces. Les bases seront le principal sujet de la prochaine section. Pour l'instant, on s'intéresse à vérifier l'orthogonalité des espaces fondamentaux comme indiqué à la proposition .  On commence par définir la matrice de l'exemple et les éléments qui génèrent chacun de ses quatre espaces fondamentaux.   On fait ensuite le produit scalaire de toutes les combinaisons possibles d'un vecteur de l'espace nul avec un vecteur de l'espace ligne.   Même chose ci-dessous, mais avec les vecteurs de l'espace nul gauche et les vecteurs de l'espace colonne.   Le produit scalaire entre les générateurs étant nul, le produit scalaire de chaque élément des espaces nul et ligne et chaque élément des espaces nul gauche et colonne sera aussi nul, comme le garantit la proposition .  "
},
{
  "id": "exercise-253",
  "level": "2",
  "url": "sec-ssesp.html#exercise-253",
  "type": "Exercice",
  "number": "5.1.3.1",
  "title": "",
  "body": " Montrer que chacun des sous-ensembles ci-dessous est un sous-espace vectoriel en utilisant la définition .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même forme que les vecteurs initiaux, de même pour . Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a aussi , également dans .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même composante en qu'en et que a aussi cette propriété. Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a , également dans .     On considère deux vecteurs et un scalaire quelconque. On doit montrer que a la même forme que les vecteurs initiaux, de même pour . Pour la somme, on a , qui est dans .  Pour la multiplication par un scalaire, on a , également dans .     Pour ce sous-espace, on choisit d'exprimer différemment l'appartenance à l'ensemble. Soit deux vecteurs dans et un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et respectent également la condition de l'espace. Pour la somme, on a , pour lequel il faut vérifier la condition. Cela confirme que le vecteur est également dans .  Pour la multiplication par un scalaire, on a aussi , pour lequel il faut également vérifier la condition. Cela confirme que le vecteur est lui aussi dans .     Pour ce sous-espace, on choisit d'exprimer l'appartenance à l'ensemble comme à la question précédente. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et respectent également la condition de l'espace. Pour la somme, on a , pour lequel il faut vérifier la condition. Contrairement à tous les exercices précédents, on n'arrive pas à la condition de façon algébrique. Il faut donc réfléchir un peu plus puisqu'on a dit qu'il s'agit d'un sous-espace vectoriel. En regardant de plus près à la condition, on réalise que le seul vecteur qui peut satisfaire la condition est le vecteur nul. Bref, on travaille inutilement puisqu'on a déjà montré que l'ensemble formé uniquement du vecteur nul est un sous-espace vectoriel à l'exemple .  Pour la multiplication par un scalaire, on peut cependant le montrer algébriquement. On vérifie la condition. Cela confirme que le vecteur est également dans , ce que l'on savait déjà puisque .  "
},
{
  "id": "exercise-254",
  "level": "2",
  "url": "sec-ssesp.html#exercise-254",
  "type": "Exercice",
  "number": "5.1.3.2",
  "title": "",
  "body": " Montrer que chacun des sous-ensembles ci-dessous n'est pas un sous-espace vectoriel en utilisant la définition .    Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui est dans l'ensemble , puisque . Alors, et . On aurait donc pu choisir une valeur de spécifique dans ce contrexemple, mais on a choisit de garder l'ensemble des valeurs possibles. Cela confirme que la multiplication d'un vecteur par un scalaire peut donner un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui sont dans l'ensemble , puisque et . Alors, et . Cela confirme que la somme de ces vecteurs donne un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisi d'utiliser la propriété .  Soit , qui sont dans l'ensemble , puisque et . Alors, et . Cela confirme que la somme de ces vecteurs donne un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace.   Il faut trouver un contrexemple pour l'une ou l'autre des propriétés de la définition . Ici, on choisit d'utiliser la propriété .  Soit , qui est dans l'ensemble , puisque . Alors, si l'on choisit , on a et . Cela confirme que la multiplication d'un vecteur par un scalaire peut donner un vecteur à l'extérieur de cet ensemble et qu'il ne s'agit pas d'un sous-espace. "
},
{
  "id": "exo-ssespplan",
  "level": "2",
  "url": "sec-ssesp.html#exo-ssespplan",
  "type": "Exercice",
  "number": "5.1.3.3",
  "title": "",
  "body": "Compléter la preuve de l'exemple en montrant qu'un plan passant par l'origine est un sous-espace vectoriel, en utilisant la définition.  Un plan passant par l'origine est caractérisé par l'ensemble des combinaisons linéaires de deux vecteurs directeurs . Un vecteur sur le plan s'écrit pour certains .  Afin de montrer que la somme de deux vecteurs sur le plan est aussi sur le plan et qu'un multiple d'un vecteur sur le plan l'est aussi, on prend et . Il faut montrer que la somme de et s'écrit comme une combinaison linéaire de . La même idée s'appliquera pour la multiplication du vecteur par .  Dans un premier temps, on a . Comme et , il s'ensuit que la somme des vecteurs est sur le plan.  Pour la multiplication par le scalaire, on a et, puisque , la multiplication est aussi sur le plan.  "
},
{
  "id": "exercise-256",
  "level": "2",
  "url": "sec-ssesp.html#exercise-256",
  "type": "Exercice",
  "number": "5.1.3.4",
  "title": "",
  "body": "Soit , un plan. Si (n'est pas l'origine), ce plan peut-il être un espace vectoriel? Et pourquoi? Oui.  Ce sera un espace vectoriel à une condition. Par la proposition , tout sous-espace doit impérativement contenir le vecteur nul. Ainsi, ce plan peut être un sous-espace à la condition qu'il passe par l'origine. Autrement dit, il faut qu'il existe des valeurs telles que . On rappelle donc par cet exercice qu'il est important de comprendre qu'une équation vectorielle de tout objet géométrique n'est pas nécessairement dans sa plus simple expression. En effet, il suffit d'un point de départ qui peut être n'importe où sur l'objet. "
},
{
  "id": "exercise-257",
  "level": "2",
  "url": "sec-ssesp.html#exercise-257",
  "type": "Exercice",
  "number": "5.1.3.5",
  "title": "",
  "body": " Soit , des sous-espaces vectoriels de . Montrer que les ensembles suivants sont aussi des sous-espaces vectoriels.   L'ensemble des vecteurs qui sont à la fois dans et dans , noté .  Donner un exemple géométrique de sous-espaces vectoriels et dans .   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme des conditions énoncées. On ne peut donc pas constater l'appartenance algébriquement, ce qui rend la preuve plus difficile conceptuellement. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent les conditions de l'espace et que et aussi que . On doit montrer que et respectent également les conditions de l'espace. Pour la somme, on a , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Dès lors, puisque respecte ces deux conditions, on sait que .  Pour la multiplication par un scalaire, on a , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Par conséquent, puisque respecte ces deux conditions, on sait que . Cela montre que les deux propriétés des sous-espaces sont respectées par l'ensemble et qu'il s'agit bien d'un sous-espace vectoriel.  Un exemple géométrique simple de cet ensemble est l'intersection de deux plans passant par l'origine dans . En effet, on a montré à l'exercice qu'un plan passant par l'origine est un sous-espace vectoriel de , ce qui s'applique à . L'intersection de ces deux plans est une droite dans passant aussi par l'origine. On a montré également à l'exemple qu'une telle droite est un sous-espace de , ce qui s'applique aussi à .   L'ensemble des vecteurs qui s'écrivent comme la somme d'un vecteur dans et d'un vecteur dans , noté .  Donner un exemple géométrique de sous-espaces vectoriels et dans .   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme des conditions énoncées. On ne peut donc pas constater l'appartenance algébriquement, ce qui rend la preuve plus difficile conceptuellement. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent les conditions de l'espace, que et que . On doit montrer que et respectent également les conditions de l'espace. Pour la somme, on a On a que , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Donc, puisque est l'addition de deux vecteurs, l'un appartenant à et l'autre à , on sait que .  Pour la multiplication par un scalaire, on a On a que , car est lui-même un sous-espace respectant la condition . De même, on sait que , car est lui-même un sous-espace respectant la condition . Donc, puisque est l'addition de deux vecteurs,l'un appartenant à et l'autre à , on sait que .  Un exemple géométrique simple de cet ensemble est l'addition de deux droites passant par l'origine dans . En effet, on a montré à l'exercice qu'une droite passant par l'origine est un sous-espace vectoriel de , ce qui s'applique à . L'addition de ces deux droites est un plan dans passant aussi par l'origine. On a montré également à l'exemple qu'un tel plan est un sous-espace de , ce qui s'applique aussi à . Il peut sembler difficile à visualiser que l'addition de deux droites telle que définie dans cet exercice forme un plan. Cependant, lorsqu'on réalise que l'addition vectorielle de toute paire de vecteurs provenant de deux droites non parallèles est en réalité l'ensemble des combinaisons linéaires possibles des vecteurs directeurs de ces droites, cela devient évident.  "
},
{
  "id": "exercise-258",
  "level": "2",
  "url": "sec-ssesp.html#exercise-258",
  "type": "Exercice",
  "number": "5.1.3.6",
  "title": "",
  "body": " Soit , des sous-espaces vectoriels de . On définit l'union de et comme l'ensemble des vecteurs qui sont soit dans , soit dans (potentiellement les deux), noté .   Est-ce que est un sous-espace vectoriel? Si oui, démontrer et si non, donner un exemple de sous-espaces tels que l'union n'en est pas un.  Non. Par exemple, deux droites non parallèles dans passant par l'origine. Non, il ne s'agit pas d'un sous-espace vectoriel. Il sera possible de trouver un contrexemple où l'on additionnera deux vecteurs provenant l'un de et l'autre de , de telle sorte qu'ils sont tous les deux dans , pour obtenir un vecteur qui ne sera ni dans ni dans et non plus pas dans . Cela sera donc un contrexemple à la propriété des sous-espaces vectoriels.  On suggère comme contrexemple deux droites non parallèles dans passant par l'origine. Spécifiquement, on pose et . Pour et , ces deux vecteurs sont tous les deux dans . On calcule qui n'est ni dans ni dans et non plus pas non plus dans . Peu importe la réponse à la partie précédente, donner des exemples de sous-espaces vectoriels dans tels que est aussi un sous-espace vectoriel. Afin de trouver des exemples, il faut réfléchir à ce qui ferait en sorte que cela devienne un sous-espace vectoriel. Il est clair que si ou bien si , alors respectivement ou bien . Par exemple, si est une droite dans et est un plan qui contient cette droite, tous les deux passant par l'origine, alors les deux espaces sont des sous-espaces vectoriels de tels que est aussi un sous-espace vectoriel, puisqu'il est égal à . On a un autre exemple si et est une droite ou même un plan passant par l'origine, puisque le même principe s'applique. "
},
{
  "id": "exercise-259",
  "level": "2",
  "url": "sec-ssesp.html#exercise-259",
  "type": "Exercice",
  "number": "5.1.3.7",
  "title": "",
  "body": " Soit , une matrice carrée.   Montrer que les solutions à l'équation forment un sous-espace vectoriel.  Reformuler afin d'écrire l'ensemble solution comme l'espace nul d'une matrice. On suit l'indice et l'on transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice .  Soit , un nombre réel. Montrer que les solutions à l'équation forment un espace vectoriel.  De façon semblable, on transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice . "
},
{
  "id": "exercise-260",
  "level": "2",
  "url": "sec-ssesp.html#exercise-260",
  "type": "Exercice",
  "number": "5.1.3.8",
  "title": "",
  "body": " Soit , deux matrices . Montrer que l'ensemble solution à l'équation est un sous-espace vectoriel.  On transforme l'équation matricielle ainsi: . Par la proposition , on peut conclure que ces solutions sont un sous-espace vectoriel puisqu'ils sont les zéros de la transformation linéaire de la matrice . "
},
{
  "id": "exercise-261",
  "level": "2",
  "url": "sec-ssesp.html#exercise-261",
  "type": "Exercice",
  "number": "5.1.3.9",
  "title": "",
  "body": " Soit , une matrice et soit , des sous-espaces vectoriels. Montrer que l'ensemble est un sous-espace vectoriel de .  Cela implique qu'un sous-espace vectoriel dans l'image provient d'un sous-espace vectoriel dans le domaine.   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme de la condition énoncée. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et sont également tels que leur transformation par est dans . Pour la somme, on a que , car étant lui-même un sous-espace, l'addition de deux éléments de donne un vecteur dans . L'espace respecte donc la condition .  Pour la multiplication par un scalaire, on a , car étant lui-même un sous-espace, la multiplication par un scalaire d'un vecteur de donne un vecteur dans .  L'espace respecte donc la condition . Il s'agit bien d'un sous-espace vectoriel.  Montrer que l'ensemble est un sous-espace vectoriel.  Cela implique que l'image d'un sous-espace vectoriel par une transformation linéaire est un sous-espace vectoriel.   Pour ce sous-espace, on doit exprimer l'appartenance à l'ensemble sous la forme de la condition énoncée. Soit , deux vecteurs dans et , un scalaire quelconque. On peut affirmer que ces vecteurs respectent la condition de l'espace et que . On doit montrer que et sont également tels qu'il existe un vecteur de qu'on peut transformer par pour les obtenir. Pour la somme, on a que . Le vecteur est dans , puisqu'il est l'addition de deux vecteurs de ce sous-espace. Ainsi, le vecteur est dans et dans ce cas, cet espace respecte la condition .  Pour la multiplication par un scalaire, on a . Le vecteur est dans puisqu'il est la multiplication par un scalaire d'un vecteur de ce sous-espace. Le vecteur est donc dans et cet espace respecte donc la condition . Conséquemment, il est lui-même un sous-espace vectoriel.  "
},
{
  "id": "exercise-262",
  "level": "2",
  "url": "sec-ssesp.html#exercise-262",
  "type": "Exercice",
  "number": "5.1.3.10",
  "title": "",
  "body": " Soit , un sous-espace vectoriel de . Quel est le seul vecteur qui est à la fois dans et dans son complément orthogonal?  Le vecteur nul. Par la définition , on sait que pour faire partie du complément orthogonal de , il faut qu'un vecteur soit orthogonal à tous les vecteurs de . En particulier, si un vecteur est à la fois dans et dans son complément orthogonal, il doit être orthogonal à lui-même. Ainsi, on obtient que , car le vecteur nul est le seul vecteur de norme égale à zéro. "
},
{
  "id": "exercise-263",
  "level": "2",
  "url": "sec-ssesp.html#exercise-263",
  "type": "Exercice",
  "number": "5.1.3.11",
  "title": "",
  "body": " Soit , un sous-espace vectoriel de . Montrer que .  En fait, on a que , mais l'autre inclusion est plus difficile à démontrer. On le fera avec les outils de la section .  Soit . Il faut montrer que ce vecteur fait partie de . Autrement dit, il faut que pour tout vecteur , selon la définition . Mais, on sait qu'un vecteur de est tel que pour tout vecteur , toujours selon la définition . Cela est vrai en particulier pour le vecteur énoncé au début de la preuve. Ainsi, on sait que et que . "
},
{
  "id": "exo-orthoinccomp",
  "level": "2",
  "url": "sec-ssesp.html#exo-orthoinccomp",
  "type": "Exercice",
  "number": "5.1.3.12",
  "title": "",
  "body": "Dans cet exercice, on s'intéresse à deux sous-espaces tels que pour tout .  Donner un exemple de sous-espaces possédant cette propriété, mais tels que et . Penser à . Un plan et une droite ayant comme vecteur directeur le vecteur normal du plan ont cette propriété, mais sont des compléments orthogonaux. Il faut penser un peu plus petit que le plan. On doit prendre comme sous-espaces deux droites dans passant par l'origine qui sont perpendiculaires l'une à l'autre. Par exemple, on prend spécifiquement les droites: et . Alors, on a que pour tout . On a également qu'ils ne sont pas les compléments l'un de l'autre, comme on l'énonce dans l'indication, car le complément orthogonal d'une droite est un plan dans . Finalement, ils ne sont de toute évidence pas égaux au sous-espace vectoriel trivial. "
},
{
  "id": "exercise-265",
  "level": "2",
  "url": "sec-ssesp.html#exercise-265",
  "type": "Exercice",
  "number": "5.1.3.13",
  "title": "",
  "body": " Soit , une matrice carrée symétrique et , un sous-espace vectoriel tels que pour tout . Montrer que pour tout vecteur .   Utiliser l'exercice .   Soit et soit . On note que par hypothèse. Afin de vérifier que est aussi dans , on calcule le produit scalaire entre et . On a alors . Ainsi, le vecteur est perpendiculaire à tous les vecteurs dans et en conséquence, .  "
},
{
  "id": "exercise-266",
  "level": "2",
  "url": "sec-ssesp.html#exercise-266",
  "type": "Exercice",
  "number": "5.1.3.14",
  "title": "",
  "body": " Soit , un ensemble de vecteurs et , un vecteur différent des vecteurs . On cherche à caractériser l'effet de l'ajout du vecteur au .   On considère les vecteurs ainsi que les vecteurs .  Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur n'ajoute rien à l'espace puisqu'il est parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur n'ajoute rien à l'espace puisqu'il est parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est une droite et un plan contenant cette droite. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Égaux. Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise, en travaillant un peu, que le vecteur n'ajoute rien à l'espace puisqu'il est une combinaison linéaire des vecteurs . En effet, on a: . Ainsi, les combinaisons linéaires de s'écrivent comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc égaux. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise rapidement que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas parallèle à . En effet, on a: . Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est une droite et un plan contenant cette droite. Comparer avec . Sont-ils égaux, différents, l'un inclus dans l'autre? Différents, Ces espaces engendrés étant l'ensemble des combinaisons linéaires des vecteurs donnés, on réalise, en travaillant un peu, que le vecteur ajoute une nouvelle dimension à l'espace puisqu'il n'est pas une combinaison linéaire des vecteurs . En effet, on a:   , qui n'a aucune solution. Ainsi, les combinaisons linéaires de ne peuvent s'écrire comme des combinaisons linéaires utilisant uniquement . Ces deux espaces sont donc différents et . Géométriquement, est un plan et l'espace au complet. On verra dans la section comment catégoriser ces différents sous-espaces en termes de dimensions. Montrer que si et seulement si . On construit la preuve en deux temps puisqu'il s'agit d'une équivalence.  Tout d'abord, si , on doit montrer que . Puisque les deux espaces initiaux sont égaux, il est clair que le vecteur supplémentaire dans le second espace, n'ajoute rien à cet espace. Il est donc nécessairement une combinaison linéaire des autres vecteurs, ce qui revient à dire que .  Dans l'autre direction, si , alors on peut écrire . Ainsi, tout vecteur peut s'écrire: ce qui est également dans également. Ces deux espaces sont donc égaux, ce qui complète la preuve.  "
},
{
  "id": "exercise-267",
  "level": "2",
  "url": "sec-ssesp.html#exercise-267",
  "type": "Exercice",
  "number": "5.1.3.15",
  "title": "",
  "body": "Soit et , deux matrices équivalentes par une suite d'opérations élémentaires.  Montrer que . La généralisation de l'exercice peut être utile. Si et sont équivalentes, cela implique que l'on peut obtenir de avec une suite d' opérations élémentaires . On sait que l'espace ligne est l'ensemble des combinaisons linéaires des lignes de (span). Par la généralisation à plusieurs vecteurs de l'exercice , on sait que le span de combinaisons linéaires des vecteurs d'un espace donnera le même espace. Ainsi, les lignes de la matrice pouvant être obtenues des lignes de en faisant des combinaisons linéaires (opérations élémentaires), le span des lignes de sera égal à celui des lignes de . Autrement dit, . Montrer que . Il est possible d'utiliser la partie précédente et la proposition . Par la proposition , on a que . Est-ce que ? Non. Ce n'est pas le cas. Les opérations élémentaires changent l'espace colonne. On utilise un contrexemple simple pour s'en convaincre. Soit et . On peut montrer rapidement que est équivalente à en utilisant l'opération élémentaire . Cependant, on voit que . "
},
{
  "id": "exercise-268",
  "level": "2",
  "url": "sec-ssesp.html#exercise-268",
  "type": "Exercice",
  "number": "5.1.3.16",
  "title": "",
  "body": "Pour chacune des matrices ci-dessous, déterminer une matrice telle que , à la manière de l'exemple . Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux qui se retrouvent dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . La condition sur l'image est donc . On pose . Ainsi, les vecteurs de l'image sont caractérisés par les vecteurs tels que .  Si l'on réécrit cette équation sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux que l'on retrouve dans l'espace nul de .  Si est une matrice et est un vecteur de l'image de , alors la forme échelonnée réduite (on s'épargne les calculs) de la matrice augmentée du vecteur est: . Les conditions sur l'image sont donc et . On pose et . Les vecteurs de l'image sont donc caractérisés par les vecteurs tels que .  Si l'on réécrit ces équations sous forme matricielle, on a où . Les vecteurs dans l'image de sont donc les mêmes vecteurs que ceux que l'on retrouve dans l'espace nul de .  "
},
{
  "id": "exercise-269",
  "level": "2",
  "url": "sec-ssesp.html#exercise-269",
  "type": "Exercice",
  "number": "5.1.3.17",
  "title": "",
  "body": "Que peut-on dire des quatre espaces fondamentaux d'une matrice symétrique ? On peut dire plusieurs choses qui découlent toutes du fait qu'une matrice symétrique est telle que . On peut comprendre de cette équation que les lignes et les colonnes de la matrice sont identiques. Conséquemment, on aura:  "
},
{
  "id": "exercise-270",
  "level": "2",
  "url": "sec-ssesp.html#exercise-270",
  "type": "Exercice",
  "number": "5.1.3.18",
  "title": "",
  "body": "Soit , deux matrices compatibles pour le produit . Montrer que . Soit , un vecteur qui est tel que , par définition de l'espace nul. Alors, on a . Ainsi, ce même vecteur est nécessairement dans l'espace nul de . Il s'ensuit donc que . Montrer que . Soit , un vecteur qu'il est possible d'exprimer comme une combinaison linéaire des colonnes de . Cependant, par la définition du produit matriciel , on sait que chaque colonne de peut s'exprimer comme un produit matrice vecteur où les sont les colonnes de . Ainsi, si la matrice est de format et la matrice de format , on peut écrire : . Le vecteur est donc une combinaison linéaire des colonnes de , ce qui signifie qu'il est dans son espace colonne et que . Montrer que lorsque est une matrice carrée inversible. On a déjà montré plus haut que . Il reste à montrer que pour compléter l'égalité.  Soit , un vecteur qui est tel que , par définition de l'espace nul. On a alors . Cela implique que fait aussi partie de l'espace nul de . On a et finalement . "
},
{
  "id": "sec-bases",
  "level": "1",
  "url": "sec-bases.html",
  "type": "Section",
  "number": "5.2",
  "title": "Base d’un sous-espace vectoriel",
  "body": "  Base d'un sous-espace vectoriel    Aller aux exercices de la section.  Jusqu'à maintenant, on a fait plusieurs suppositions, naturelles peut-être, mais qu'il convient de clarifier. Par exemple, quand on écrit un vecteur , que signifient les nombres ? On a vu qu'ils font implicitement référence aux vecteurs , au sens où . Des questions demeurent. Pourquoi ces vecteurs? Est-ce que la manière d'écrire comme une combinaison linéaire de est unique?  Étant donné un sous-espace vectoriel égal au d'un certain nombre de vecteurs, est-ce que tous les vecteurs sont nécessaires pour engendrer le sous-espace? On a déjà vu la réponse à cette question quand on a parlé des espaces ligne et colonne. S'il y a trois lignes à une matrice, son espace ligne peut s'écrire de manière évidente comme le des trois lignes, mais on a aussi remarqué que parfois, une seule ligne suffit, parfois deux. Alors, comment décrire un sous-espace vectoriel comme un de manière efficace?  On a aussi souvent parlé de dimension en s'appuyant beaucoup sur la géométrie. Une droite est un objet à une dimension, un plan est un objet à deux dimensions et ainsi de suite. Ces descriptions sont intuitives, mais, lorsqu'on parle de sous-espace quelconque, peut-on définir sa dimension sans avoir accès à sa géométrie?  Dans cette section, on introduit la notion d'indépendance linéaire, la notion de base d'un (sous) espace et la notion de dimension. On revient aussi aux quatre espaces afin de déterminer une manière de décrire ceux-ci efficacement.    Indépendance linéaire  Étant donné un ensemble de vecteurs de et un vecteur lui aussi dans , peut-on écrire comme une combinaison linéaire des vecteurs ? Si oui, est-ce qu'il n'y a qu'une seule manière? On reconnait ici une question à laquelle on peut répondre avec les techniques du chapitre .   Combinaisons linéaires et unicité   On considère les vecteurs ainsi que les vecteurs . Est-ce que les vecteurs s'écrivent comme une combinaison linéaire des vecteurs ? De manière unique?    On recherche l'existence de constantes telles que et de constantes telles que .  Sous forme matricielle, avec , les systèmes d'équations linéaires sont équivalents à la matrice augmentée . Avec Sage,   on trouve la solution à ces systèmes en échelonnant la matrice : . Le vecteur ne s'écrit pas comme une combinaison linéaire des vecteurs . Il n'est donc pas dans l'espace colonne de la matrice . Par contre, le vecteur , lui, en fait partie. Il y a même une infinité de manières de l'écrire. Par exemple, on a , mais aussi .  En observant la matrice augmentée (ou l'expression de la solution), on peut arriver à la conclusion que si le troisième vecteur n'était pas là, on pourrait quand même écrire le vecteur et, qui plus est, la solution serait unique.    La première question à laquelle on veut répondre concerne l'unicité de l'écriture. Étant donné un ensemble de vecteurs et un vecteur , quand peut-on être assuré de l'unicité de la combinaison linéaire des vecteurs qui produit . Il s'avère que pour répondre à cette question, il suffit de regarder la réponse avec le vecteur nul. On sait que le vecteur nul peut toujours s'écrire comme . Si c'est la seule manière, alors les autres vecteurs s'écriront aussi de manière unique.   Unicité des combinaisons linéaires dans le  Soit , des vecteurs de . Si la seule combinaison linéaire de ces vecteurs qui produit le vecteur nul est la combinaison triviale, alors tous les vecteurs dans s'écrivent de manière unique comme une combinaison linéaire des vecteurs . Mathématiquement, si la seule solution à l'équation est la solution où , alors l'écriture est unique pour tout vecteur    On suppose qu'il existe et telles que et . On peut alors écrire le vecteur nul comme . Comme l'écriture du vecteur nul est unique par hypothèse, il s'ensuit que et que l'écriture de est aussi unique.    En particulier, si chaque écriture est unique, aucun des vecteurs ne peut être écrit comme une combinaison linéaire des autres, puisque l'écriture doit être unique. Cette observation motive la définition importante d'indépendance linéaire, mais d'abord, un exemple concret de cette observation.   Écriture unique et vecteur nul   On reprend les vecteurs . On détermine les solutions à l'équation . On s'attend évidemment à avoir une infinité de solutions puisque l'écriture du vecteur de l'exemple n'était pas unique.    Pour résoudre le problème, on peut échelonner la matrice , travail qui a déjà été fait à l'exemple . On obtient . Comme attendu, on a une infinité de solutions, car il y a des variables libres. En particulier, le vecteur nul peut s'écrire comme .    L'importance de l'unicité de l'écriture motive la définition d'indépendance linéaire.   Indépendance linéaire   Soit , un ensemble de vecteurs de . L'ensemble est dit linéairement indépendant (on dit parfois aussi que les vecteurs sont linéairement indépendants) si la seule solution à l'équation est la solution triviale où .  Dans le cas contraire, on dit que l'ensemble de vecteurs est linéairement dépendant (on dit parfois aussi que les vecteurs sont linéairement dépendants).     L'indépendance (linéaire)  Il arrive souvent qu'on ne mentionne pas le terme linéairement dans l'expression linéairement indépendant. Puisqu'on a qu'un seul type d'indépendance, le contexte est toujours celui de l'indépendance linéaire.    L'indépendance linéaire de deux vecteurs spécifiques   On considère deux des trois vecteurs de l'exemple , à savoir les vecteurs . On montre que ces vecteurs sont linéairement indépendants.   Pour résoudre l'équation , on utilise la forme échelonnée réduite de la matrice . On obtient alors , qui donne comme unique solution . Les vecteurs sont donc linéairement indépendants.   On poursuit avec un exemple plus théorique qui permet d'obtenir d'autres ensembles de vecteurs à partir d'un ensemble donné.   Combinaisons linéaires de vecteurs linéairement indépendants   Soit , deux vecteurs formant un ensemble linéairement indépendant. On montre que l'ensemble formé des vecteurs est aussi linéairement indépendant.    On tente d'écrire le vecteur nul comme une combinaison linéaire des vecteurs . On a . Parce que forment un ensemble indépendant, on peut conclure que et , car la seule combinaison linéaire de ces vecteurs qui donne le vecteur nul est la combinaison triviale. De ces nouvelles contraintes, on déduit que et , ce qui n'est possible que lorsque . Ainsi, l'ensemble composé des vecteurs est linéairement indépendant.    On peut décrire l'équation représentant l'indépendance linéaire sous forme matricielle. On obtient alors une proposition utilisant le rang d'une matrice.   Indépendance linéaire et rang   Soit , un ensemble de vecteurs de et soit , la matrice contenant les vecteurs dans ses colonnes. Alors l'ensemble des vecteurs est linéairement indépendant si et seulement si .    On commence avec l'implication que si est un ensemble de vecteurs linéairement indépendant, alors le rang de la matrice vaut .  Puisque l'équation possède une solution unique, cela signifie que toutes les colonnes sont pivots dans la forme échelonnée réduite de la matrice , car il ne peut pas y avoir de variables libres. Ainsi .  On regarde maintenant l'implication du rang égal à sur l'indépendance des vecteurs .  À l'inverse de l'argument précédent, si le rang de la matrice est égal à , alors toutes les colonnes sont pivots. Dans l'équation matricielle , il n'y aura pas de variables libres, la solution sera unique et sera celle où . Ainsi, la seule combinaison linéaire des vecteurs   donnant le vecteur nul est la combinaison linéaire triviale, est donc un ensemble linéairement indépendant.    On regarde maintenant la géométrie d'ensembles linéairement indépendants simples, afin de simplifier le critère d'indépendance pour ces cas.   Indépendance linéaire pour deux ou trois vecteurs   Soit , des vecteurs de . Alors  Les vecteurs sont linéairement indépendants si et seulement s'ils ne sont pas parallèles;  Les vecteurs sont linéairement indépendants si et seulement s'ils ne sont pas sur un même plan.   Ceci permet aisément de tester l'indépendance de deux ou trois vecteurs, en particulier, on pourra utiliser le déterminant à cet effet.    On commence avec des vecteurs linéairement indépendants et l'on tente de montrer que les vecteurs ne peuvent pas être parallèles.  Soit , des vecteurs linéairement indépendants. Si les vecteurs étaient parallèles, par exemple , alors on pourrait écrire , ce qui donnerait une combinaison non triviale des vecteurs donnant le vecteur nul. Comme les vecteurs sont indépendants par hypothèse, c'est impossible.  On poursuit maintenant avec deux vecteurs non parallèles et l'on montre qu'ils doivent être indépendants.  Soit , des vecteurs non parallèles. Si ces vecteurs étaient linéairement dépendants, alors il existerait des constantes qui ne sont pas toutes les deux nulles telles que . On suppose que , l'argument est le même si , mais que , en inversant le rôle de et . On peut donc écrire , ce qui entraine que les vecteurs sont parallèles, contredisant l'hypothèse initiale. Il faut donc que les vecteurs soient indépendants.    On commence avec trois vecteurs indépendants et l'on montre que ces vecteurs ne sont pas sur un même plan. De la même manière qu'à la partie précédente, on suppose que les vecteurs sont sur un même plan. On peut, dans un premier temps, supposer qu'aucune paire de vecteurs n'est parallèle, car la partie précédente entraine que les vecteurs seraient dépendants. Comme aucun vecteur n'est parallèle, on peut prendre les vecteurs comme vecteurs directeurs du plan. Il existe donc tels que , car est dans le plan de ces vecteurs. Or en écrivant , on obtient une combinaison linéaire non triviale des vecteurs donnant le vecteur nul, ce qui est impossible, car les vecteurs sont indépendants par hypothèse.  En contrepartie, si l'on suppose que les vecteurs ne sont pas sur un même plan et que l'on considère une combinaison linéaire des vecteurs donnant le vecteur nul, par exemple .  On sait qu'au moins l'une de ces constantes est non nulle. On suppose que est non nulle, l'argument sera similaire dans les autres cas. On peut alors isoler . Or ceci signifie que est une combinaison linéaire des vecteurs et serait dans le même plan que ces vecteurs, ce qui contredit l'hypothèse initiale. Ainsi, les vecteurs sont indépendants.    La généralisation naturelle de ces situations est donnée dans la proposition suivante.   Indépendance linéaire et espace engendré  Soit , des vecteurs formant un ensemble linéairement indépendant et soit . Alors l'ensemble est linéairement indépendant si et seulement si .  Si , cela signifie en particulier que les espaces engendrés par et par sont différents.   Voir l'exercice .   On termine avec des commandes Sage en lien avec la sous-section.   Sage et l'indépendance linéaire  Pour vérifier si un ensemble de vecteurs est linéairement indépendant, il existe plusieurs options. La première consiste à utiliser la définition . On peut alors résoudre l'équation en utilisant les techniques du chapitre et valider avec la définition .   On peut aussi utiliser la proposition et simplement calculer le rang de la matrice dans la cellule Sage précédente.   Puisque ce rang correspond au nombre de vecteurs, les vecteurs sont linéairement indépendants.  Une autre manière, un peu plus complexe, consiste à utiliser la commande .linear_dependance . Elle nécessite toutefois la création d'un espace vectoriel sous-jacent, concept qui sera défini dans la prochaine section. On en montre toutefois un exemple et les premières lignes seront clarifiées dans la section suivante.   Le résultat est un ensemble vide, ce qui signifie qu'il n'y a pas de dépendance linéaire. Afin de comparer avec un exemple où il y aurait dépendance, on ajoute deux vecteurs supplémentaires à la liste L.   Le résultat est une possible combinaison linéaire des vecteurs donnant le vecteur nul. Dans ce cas-ci, on a , puisque a été défini ainsi.  Finalement, on peut utiliser la proposition . Les commandes utilisent également des concepts de la section suivante.      Base d'un sous-espace vectoriel  On sait maintenant comment garantir l'unicité de l'écriture d'un vecteur en termes des combinaisons linéaires d'un ensemble de vecteurs. Si ces vecteurs forment un ensemble linéairement indépendant, alors il y a unicité. Cette propriété est attrayante, car lorsque l'ensemble de vecteurs est clair, il n'y a qu'une représentation possible pour écrire les autres vecteurs en fonction de cet ensemble. Bien entendu, on ne peut pas toujours écrire un vecteur comme une combinaison linéaire des vecteurs dans l'ensemble. Il faut qu'il soit dans le pour que ce soit possible. On arrive donc à la définition de base d'un sous-espace vectoriel.   Base d'un sous-espace vectoriel   Soit , un sous-espace vectoriel et soit , un ensemble de vecteurs dans . On dit que ces vecteurs forment une base de si  les vecteurs génèrent , c'est-à-dire ;  les vecteurs forment un ensemble linéairement indépendant.     On commence avec quelques exemples de sous-espaces vectoriels et des bases de ces sous-espaces.   Base de sous-espaces vectoriels   On considère quelques-uns des sous-espaces vectoriels de l'exemple , soit  Le plan du début de section;  Les vecteurs de la forme ;  L'ensemble ne contenant que le vecteur nul : ;  Ĺ'espace au complet. On cherche à déterminer une base pour chacun de ces exemples.    On sait que, pour générer un plan, on doit avoir deux vecteurs non parallèles (et donc indépendants!). En isolant dans l'équation normale du plan , on peut écrire les points du plan comme les points . On obtient deux vecteurs et tels que . Puisque les vecteurs sont non parallèles, ils sont indépendants (proposition ). Ces vecteurs forment donc une base du plan .    Les vecteurs de la forme peuvent tous s'écrire comme un multiple de . Ainsi, ce vecteur génère le sous-espace vectoriel. Comme la seule combinaison linéaire de ce vecteur donnant le vecteur nul est , ce vecteur est linéairement indépendant (est-ce qu'un vecteur seul est toujours linéairement indépendant? Voir l'exercice ). Il forme donc une base de ce sous-espace.    Le vecteur nul engendre par défaut le vecteur nul, puisque pour tout scalaire . Par contre, pour la même raison, il n'est pas linéairement indépendant. Ce n'est donc pas une base. En fait, le sous-espace vectoriel est le seul sous-espace qui ne possède pas de base.   On sait qu'on peut décomposer un vecteur de comme une combinaison linéaire des vecteurs . Ces vecteurs engendrent donc . De plus, si l'on les place dans les colonnes d'une matrice, on obtient la matrice identité, de rang . Les vecteurs sont alors linéairement indépendants et forment ainsi une base de .   Un sous-espace peut avoir plusieurs bases. Par exemple, un plan peut être décrit par une infinité de vecteurs directeurs. Selon la base utilisée, un même vecteur peut être décrit différemment.   Plusieurs bases d'un sous-espace   On reprend certains des sous-espaces vectoriels possédant une base de l'exemple précédent et l'on trouve des bases alternatives pour ces espaces:  Le plan du début de section;  Les vecteurs de la forme .    La base révélée à l'exemple   a été trouvée selon la méthode prescrite par le chapitre (en isolant pour en faire une variable pivot). Il suffit toutefois de trouver n'importe quel ensemble de vecteurs linéairement indépendants qui génère le plan. Plusieurs autres options sont possibles. Par exemple, en isolant ou dans l'équation normale du plan, on a ou encore . Dans chacun des cas, les vecteurs sont linéairement indépendants et engendrent le plan.  Pour avoir un autre exemple, on prend des vecteurs indépendants qui satisfont l'équation jusqu'à l'obtention d'un ensemble qui génère le plan. Par exemple, si l'on prend , ce vecteur est sur le plan. Par lui-même, il engendre une droite et il faut donc en ajouter un autre pour obtenir le plan. Une possibilité est , qui est indépendant de . Ensemble, ils engendrent le plan. Par exemple, on peut montrer que et , la base originale du plan est alors dans . De même, on a et et donc, la base formée des vecteurs et est dans le sous-espace engendré par la base originale. Ces bases engendrent ainsi bel et bien le même espace.    Le sous-espace formé des vecteurs de la forme peut avoir comme base n'importe quel vecteur non nul parallèle à . Un tel vecteur va, bien entendu, générer la droite représentant ce sous-espace. En fait, un vecteur non nul par lui-même est toujours indépendant.    L'existence de plusieurs bases pour décrire un même espace doit se traduire par une manière concrète de parler des éléments de l'espace par rapport à une base donnée. On introduit donc le concept de composantes d'un vecteur, relatif à une base (ordonnée).   Composantes d'un vecteur relatives à une base  Soit , une base d'un sous-espace . On note par la base ordonnée de ces vecteurs, c'est-à-dire la base où l'ordre des vecteurs est important. Soit , un vecteur du sous-espace peut-être égal à l'un des vecteurs de . Parce que est une base de , il existe tels que . Les nombres sont appelés les composantes de dans la base ordonnée et l'on écrit .   Tel que mentionné précédemment, le concept de vecteur algébrique fait déjà explicitement référence à la notion de composantes. Pour cela, on considère comme standard l'écriture d'un vecteur en fonction des vecteurs . Ces vecteurs forment ce qu'on pourrait appeler la base canonique de . De ce fait, lorsque cette base est utilisée, on omet l'indice dans l'écriture des composantes du vecteur. Ainsi, si l'on écrit , il est sous-entendu que la base est .  On regarde maintenant des exemples d'écritures de vecteurs d'un espace avec différentes bases.   Bases et composantes de vecteurs   On considère les vecteurs tirés de l'exemple calculatoire . Ces trois vecteurs forment une base de . On considère aussi le vecteur . On définit les trois bases ordonnées . On cherche à écrire le vecteur dans chacune de ces trois bases.    On cherche la combinaison linéaire des vecteurs et qui donne le vecteur . On peut faire ce calcul facilement avec Sage.   Ainsi, on peut écrire .    La seule différence entre la base ordonnée et la base ordonnée est l'ordre des vecteurs. On devrait donc avoir .    On procède comme pour la première méthode. Toujours avec Sage, on trouve que     Lorsqu'on se restreint à un sous-espace de , la description d'un vecteur par ses composantes relatives à la base du sous-espace pourrait ne pas contenir le même nombre de composantes que celle qui est relative à l'espace au complet. Cela est dû au nombre de vecteurs dans la base du sous-espace qui est potentiellement différent du nombre de vecteurs nécessaire pour engendrer .   Composantes d'un vecteur dans un sous-espace  On considère le plan dans engendré par les vecteurs de l'exemple . On considère également le vecteur , qui est donc dans le plan. Si l'on ne s'intéresse qu'au sous-espace vectoriel, on peut alors décrire dans la base comme étant . Même si la description ne comporte que deux composantes, on comprend que ce vecteur est toujours dans , puisque les vecteurs de sont dans .   On s'attarde maintenant à démontrer quelques résultats sur les bases d'un sous-espace vectoriel. Ultimement, on veut en arriver à affirmer que toutes les bases d'un sous-espace vectoriel contiennent le même nombre de vecteurs. Ceci va permettre de définir concrètement la notion de dimension d'un sous-espace, déjà utilisée de manière informelle, principalement lorsqu'on parle de droite et plan. D'abord, un résultat sur l'existence d'une base pour un sous-espace vectoriel.   (Presque) tous les sous-espaces ont une base  Soit , un sous-espace vectoriel de différent du sous-espace nul. Alors, il existe une base pour .  Ce résultat implique donc que tous les sous-espaces possèdent une base, sauf le sous-espace trivial qui ne contient que le vecteur nul. La raison est que le vecteur nul n'est pas indépendant de lui-même. La discussion a été menée à l'exemple .   L'idée est de construire séquentiellement une base pour . On commence en choisissant un vecteur non nul dans , qu'on nomme . Si , alors c'est terminé, car est indépendant et génère . Il forme donc une base. Si , on prend alors un vecteur du sous-espace . En vertu de la proposition , l'ensemble est linéairement indépendant. Si , alors on a terminé, sinon on poursuit ce processus avec un vecteur . Pour les mêmes raisons, le nouvel ensemble sera indépendant.  Après un maximum de étapes, on est assuré d'avoir trouvé une base. En effet, si l'on a vecteurs de linéairement indépendants, alors tout autre vecteur différent de ces vecteurs doit appartenir à . Ceci découle de la proposition . Comme il est impossible pour une matrice d'avoir un rang égal à , la dépendance est forcée. Si tous les vecteurs additionnels sont dans , on peut alors conclure que .    Maintenant qu'il est établi que chaque sous-espace contient une base, on est en mesure de généraliser la proposition sur le complément orthogonal du complément orthogonal.   Le complément orthogonal du complément orthogonal   Soit , un sous-espace vectoriel. Alors .    Dans un premier temps, on sépare en deux cas. D'abord, si , alors pour tout vecteur dans on a , comme il est remarqué à la proposition . Dans ce cas, quel est le complément orthogonal de ? On y revient dans la seconde partie.  Soit , un sous-espace vectoriel différent de . Soit , une base de ce sous-espace dont l'existence est garantie par la proposition . On place ces vecteurs dans les colonnes d'une matrice de taille . Par construction, on a . Selon la proposition , on a et .  Plus particulièrement, si , on peut prendre les vecteurs comme base et la matrice . Dans ce cas, on a , puisque . On a donc aussi , ce qui complète la preuve.    Dans la prochaine sous-section, on s'attarde à montrer que toutes les bases d'un sous-espace vectoriel vont contenir le même nombre de vecteurs. Ceci va définir de manière formelle la dimension du sous-espace.  On termine avec des commandes Sage en lien avec la sous-section.   Les bases et Sage  Avec Sage, on peut facilement déterminer une base d'un sous-espace vectoriel. La méthode la plus simple consiste à créer le d'un certain nombre de vecteurs et ensuite de demander une base à Sage. Comme il existe plusieurs bases, Sage en choisit une selon l'algorithme qui a été programmé.  Pour tester, on reprend les vecteurs de l'exemple et l'on cherche une base aux sous-espaces créés par les différents      La dimension d'un sous-espace vectoriel  La proposition dit que chaque sous-espace possède une base. En réalité, il existe une infinité de bases pour chaque sous-espace vectoriel en possédant au moins une. Ceci pourrait être vu comme un désavantage, mais heureusement, toutes ces bases ont un point commun: elles possèdent le même nombre de vecteurs. On commence par démontrer que si un ensemble de vecteurs d'un sous-espace contient plus de vecteurs qu'une base de ce même sous-espace, alors l'ensemble est nécessairement dépendant.   Dépendance linéaire et nombre de vecteurs   Soit , un sous-espace vectoriel et soit , une base de ce sous-espace. On considère un ensemble de vecteurs du sous-espace . Si , alors les vecteurs sont linéairement dépendants.    On écrit les vecteurs comme des combinaisons linéaires des vecteurs , cela étant possible en vertu du fait que les vecteurs forment une base. On a donc et l'on note par la matrice dont les colonnes correspondent aux composantes des vecteurs dans la base ordonnée . On note aussi par la matrice des vecteurs en colonne dans leur écriture initiale. Finalement, on fait la même chose avec les vecteurs en les mettant en colonne dans une matrice .  On peut alors écrire , en vertu de la définition du produit matriciel.  Si l'on montre que l'équation possède des solutions autres que le vecteur nul, cela implique qu'il existe une combinaison linéaire des colonnes de et donc, des vecteurs , qui donne le vecteur nul. Les vecteurs seraient alors dépendants.  Puisque et que la matrice est de taille , il ne peut pas y avoir de pivot dans toutes les colonnes de la forme échelonnée réduite de . L'équation matricielle possède donc une infinité de solutions, car il y a au moins une variable libre. On note par une solution non triviale à cette équation. On a alors .  Ainsi, le vecteur offre une combinaison linéaire non triviale des vecteurs donnant le vecteur nul. Les vecteurs sont donc dépendants.     L'indépendance linéaire n'était pas nécessaire  Dans la proposition , les vecteurs forment une base. On dit alors que tout ensemble comprenant plus de vecteurs est forcément dépendant. En fait, on peut alléger un peu les hypothèses de la proposition et exiger seulement que les vecteurs génèrent , c'est-à-dire que . Les détails sont examinés à l'exercice   On obtient alors, grâce à cette proposition, le résultat principal de cette sous-section   Nombre de vecteurs dans une base d'un sous-espace   Soit , un sous-espace vectoriel et soit et , deux bases de ce sous-espace. Alors .    La preuve est une application de la proposition qui va comme suit. Dans un premier temps, parce que les vecteurs forment une base, on peut dire que ces vecteurs sont linéairement indépendants. De plus, parce que les vecteurs forment aussi une base, on doit conclure que , sinon la proposition entrainerait que les vecteurs sont dépendants.  On utilise le même argument, mais en renversant le rôle des vecteurs et :  Parce que les vecteurs forment une base, on peut dire que ces vecteurs sont linéairement indépendants. De plus, parce que les vecteurs forment aussi une base, on doit conclure que , sinon la proposition entrainerait que les vecteurs sont dépendants.  Finalement, on obtient que et , ce qui force à avoir .    La conséquence immédiate de la proposition précédente est que toutes les bases auront le même nombre de vecteurs. On donne un nom à ce nombre.   La dimension d'un sous-espace vectoriel   Soit , un sous-espace vectoriel. On appelle la dimension de , noté , le nombre de vecteurs dans une base de .  Afin d'uniformiser les résultats qui suivent, on prend comme convention que .     La dimension de sous-espaces vectoriels  On reprend les sous-espaces de l'exemple et l'on détermine leur dimension.   À l'exemple , on a trouvé comme base du plan les vecteurs et . Sans surprise, la dimension de l'espace est .    Toujours à l'exemple , on a trouvé que le vecteur forme une base de ce sous-espace. La dimension est ainsi égale à .    Par définition, le sous-espace composé uniquement du vecteur nul a pour dimension .    Encore à l'exemple , on a établi que les vecteurs formaient une base de et donc, la dimension de est égale à .    On sait qu'une droite qui passe par l'origine peut être engendrée par un vecteur. Un vecteur seul étant indépendant, il forme une base de la droite. La dimension d'une droite est donc égale à , comme on pouvait s'y attendre.    Un plan peut être engendré par deux vecteurs non parallèles et donc qui sont indépendants. Ces deux vecteurs forment alors une base. Ainsi, la dimension d'un plan est égale à , comme attendu.   Un hyperplan passant par l'origine dans est caractérisé par l'équation . En considérant cette équation d'un point de vue matriciel, la matrice associée à cette équation n'aura qu'un pivot et variables libres. Ces variables libres amèneront solutions de base, donnant ainsi un sous-espace à dimension.   L'exemple précédent fait allusion aux solutions de base d'un système d'équations linéaires. On est maintenant en mesure de comprendre l'utilisation du terme « de base ». Les solutions à l'équation forment un sous-espace vectoriel, l'espace nul. Cet espace est engendré par les vecteurs solutions de base définis à la section . Les solutions de base sont toujours indépendantes (voir l'exercice ) et forment bel et bien une base de l'espace nul. On reviendra aux quatre espaces fondamentaux dans la prochaine section.  On regarde à présent quelques propriétés de la dimension de sous-espaces vectoriels. La première sert à caractériser un ensemble de vecteurs par rapport à la dimension du sous-espace auquel ils appartiennent.   Ensemble de vecteurs et dimension  Soit , un sous-espace vectoriel de dimension et soit , un ensemble de vecteurs dans .  Si , alors ;  Si , alors les vecteurs sont dépendants;  Si : et si , alors les vecteurs sont aussi indépendants et forment donc une base;  et si sont indépendants, alors et forment une base.       On suppose que les vecteurs sont indépendants. Si ce n'est pas le cas, l'argument ci-dessous fonctionne avec vecteurs indépendants parmi les vecteurs tels que le de ces vecteurs est égal au des vecteurs originaux.  On pose . Comme les vecteurs sont indépendants, ils forment une base de et ce sous-ensemble est de dimension . Si , on aurait , ce qui est impossible dans ce cas.   C'est exactement le contenu de la proposition .   On démontre chacune des deux affirmations lorsque ci-dessous.  Dans un premier temps, on suppose que . Si l'ensemble était linéairement dépendant, alors au moins un des vecteurs pourrait s'écrire comme une combinaison linéaire des autres vecteurs. On suppose par simplicité que c'est . Cela signifie aussi que . Selon l'exercice , en lien avec la remarque ,tout ensemble de plus de devrait être dépendant. Comme , une base va nécessairement contenir vecteurs indépendants. Il est donc impossible que les vecteurs soient dépendants.  Pour l'autre énoncé, on place les vecteurs dans les lignes d'une matrice . Si , il existe alors un vecteur tel que est indépendant selon la proposition . On obtient donc vecteurs indépendants, ce qui contredit la proposition .    Maintenant, un résultat assez intuitif sur la dimension d'un sous-ensemble.   Dimension et inclusion   Soit , des sous-espaces vectoriels de tels que . Alors et si , alors .    Soit , la dimension de et , la dimension de . Soit , un ensemble de vecteurs formant une base pour . Si , alors est un ensemble de vecteurs dans un ensemble ( , car ) de taille plus grande que la dimension, ce qui signifie selon la proposition que est linéairement dépendant, contredisant le fait que c'est une base pour . Ainsi, on doit avoir .  On suppose que la . Soit , une base de . Si , il existe un vecteur qui n'est pas dans . On considère l'ensemble . Selon la proposition , cet ensemble est linéairement indépendant. Par contre, puisque la dimension de est aussi , la proposition affirme qu'un ensemble de vecteurs est dépendant. Ceci contredit la propostion , on conclut donc qu'il n'existe pas de vecteur qui ne soit pas aussi dans . On a donc . Combiné à l'hypothèse que , on conclut que .    On regarde comment à partir d'un ensemble de vecteurs on peut trouver une base pour l'espace engendré par ces vecteurs.   Base à l'intérieur du span   On considère les vecteurs et l'on note . On cherche une base pour .  Les quatre vecteurs ne peuvent pas former une base, puisque , qui est de dimension . Ceci contredirait les propositions et . Ces vecteurs sont donc dépendants. On regarde les solutions à l'équation . Ceci permettra de trouver quelle(s) combinaison(s) linéaire(s) des quatre vecteurs donne le vecteur nul. On utilise Sage pour résoudre le système.   On trouve deux variables libres, donc deux solutions de bases: . Ainsi, on peut conclure que de même que . On peut alors écrire comme une combinaison linéaire de et . On a alors . De plus, les vecteurs sont indépendants, car ils ne sont pas parallèles. Ils forment donc une base de .  Plus généralement, on va montrer dans la prochaine section qu'on peut obtenir une base pour en prenant les colonnes (de la matrice ) qui sont pivots (dans la forme ).    On termine avec des commandes Sage en lien avec la sous-section.   Les bases et Sage  Avec Sage, on peut aussi automatiquement obtenir la dimension d'un sous-espace vectoriel.  Pour tester, on reprend encore les vecteurs de l'exemple et l'on calcule la dimension à l'aide de la commande dimension .        Les points importants de cette section sont:  La notion d'indépendance linéaire ;  Le lien entre l'indépendance linéaire et le rang;  La géométrie de l'indépendance linéaire de deux ou trois vecteurs;  La condition pour la préservation de l'indépendance lors de l'ajout d'un vecteur à un ensemble d'autres vecteurs;  La notion d'une base d'un sous-espace vectoriel et le fait qu'une base existe (presque) toujours;  La notion de dimension d'un sous-espace vectoriel.  La possibilité de décomposer un vecteur selon un sous-espace vectoriel et son complément orthogonal.       Exercices    Déterminer si les vecteurs suivants sont linéairement dépendants ou linéairement indépendants.    Linéairement dépendants On peut se servir de la définition ou de la proposition . On peut également utiliser la proposition . Au fil des solutions, on utilisera ces différentes options, mais il est possible de toujours procéder de la même manière.  Ici, on voit rapidement que avec . En effet, on a . Ainsi, par la proposition , ils sont linéairement dépendants, car ils sont parallèles.    Linéairement indépendants On voit rapidement que ces vecteurs ne sont pas parallèles. Par la proposition , ils sont donc linéairement indépendants. On choisit tout de même de le montrer avec la définition pour varier les approches. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Donc, les vecteurs sont bel et bien linéairement indépendants.    Linéairement dépendants On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui n'est pas égal au nombre de vecteurs donnés, ils sont donc linéairement dépendants. On remarque qu'on aurait pu arriver directement à cette conclusion grâce à la proposition . En effet, trois vecteurs dans , qui est clairement de dimension , n'ont pas d'autre choix que d'être dépendants.    Linéairement dépendants On voit rapidement que avec . En effet, on a . Ainsi, par la proposition , ils sont linéairement dépendants, car ils sont parallèles.    Linéairement dépendants On choisit de procéder avec la définition pour varier les approches. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Ce SEL correspond à l'équation matricielle où le vecteur inconnu est et la matrice des coefficients: . La forme échelonnée réduite de cette matrice est : . Ce système ayant une infinité de solutions, on conclut donc qu'il existe d'autres solutions que la solution triviale. En conclusion, ces vecteurs sont linéairement dépendants.  Remarquons qu'il aurait été beaucoup plus rapide d'utiliser la proposition et d'échelonner directement la matrice de ces vecteurs en colonnes.    Linéairement dépendants On choisit de procéder avec la définition puisqu'il est possible de voir une combinaison linéaire non triviale directement. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Par contre, on peut écrire: . La combinaison linéaire non triviale permet d'écrire le vecteur nul en fonction de ces trois vecteurs. Ils sont donc linéairement dépendants. On remarque que même si , cette solution n'est pas la solution triviale où TOUS les coefficients doivent être nuls.    Linéairement indépendants On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.    Considérer le parallélépipède de la figure et répondre aux questions suivantes.   Pour chaque ensemble de vecteurs ci-dessous, déterminer s'il est dépendant ou indépendant.    Linéairement dépendants On peut se servir de la définition ou de la proposition . Bien que l'on n'ait pas les expressions algébriques des vecteurs, on peut déterminer les conditions pour l'indépendance ou la dépendance à l'aide de la figure.  Ici, on voit que avec . Par la proposition , ils sont linéairement dépendants, car ils sont parallèles. On voit leur parallélisme dans la figure directement.    Linéairement indépendants On voit que peu importe la valeur de . On le voit sur la figure puisqu'ils ne sont pas parallèles. Par la proposition , ils sont linéairement indépendants, car ils ne sont pas parallèles.    Linéairement indépendants On voit sur la figure que les trois vecteurs mentionnés ne sont pas dans un même plan. Une façon de s'en convaincre est de remarquer que et . En exprimant ainsi ces trois vecteurs à partir de , on voit que et ne sont pas sur un même plan. Par la proposition , ils sont linéairement indépendants.    Linéairement dépendants On choisit de procéder avec la définition puisqu'il est possible de voir une combinaison linéaire non triviale directement. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul (déplacement nul) comme combinaison linéaire de sera la combinaison triviale. En remarquant sur la figure que , on peut écrire: . La combinaison linéaire non triviale permet d'écrire le vecteur nul en termes de ces trois vecteurs. Ils sont donc linéairement dépendants. On remarque que même si , cette solution n'est pas la solution triviale où TOUS les coefficients doivent être nuls.    Linéairement indépendants On voit sur la figure que les trois vecteurs mentionnés ne sont pas dans un même plan. Une façon de s'en convaincre est de remarquer que et . En exprimant ainsi ces trois vecteurs à partir de , on voit que et ne sont pas sur un même plan. Par la proposition , ils sont linéairement indépendants.    Linéairement dépendants On peut directement conclure à la dépendance grâce à la proposition . En effet, quatre vecteurs dans , qui est clairement de dimension , n'ont pas d'autre choix que d'être dépendants.  Pour chaque ensemble dépendant de la partie précédente, donner une combinaison linéaire non triviale des vecteurs qui donne le vecteur nul.    On a déjà établi que . Ainsi, on obtient la combinaison non triviale .  On a aussi établi pour un autre ensemble dépendant que .  Finalement, pour l'ensemble dépendant , on doit faire le travail puisqu'on avait utilisé une approche indirecte pour montrer la dépendance. Cependant, en observant que , plusieurs options rapides s'offrent à nous. Comme exemple simple, on donne: .  Exprimer les vecteurs et dans la base .      On exprime chaque vecteur comme une combinaison linéaire des vecteurs de . On le fait en quelques étapes en partant du vecteur initial et en le décomposant, puis en remplaçant par des vecteurs égaux dans .       Pour chaque ensemble de vecteurs ci-dessous, montrer que les vecteurs sont linéairement indépendants et forment une base de . Exprimer ensuite le vecteur dans les composantes de la base .   et  Comme à l'exercice , on peut se servir de la définition ou de la proposition . On peut également utiliser la proposition . Au fil des solutions, on utilisera ces différentes options, mais il est possible de toujours procéder de la même manière.  Ici, on voit rapidement que , peu importe la valeur de . En effet, on a . Ainsi, par la proposition , ils sont linéairement indépendants, car ils ne sont pas parallèles.  On exprime dans la base . Donc, on obtient .   et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On résoud ce SEL avec la méthode de Gauss-Jordan. Donc, et l'on obtient . On remarque que la matrice que l'on a d'abord échelonnée pour montrer l'indépendance est la même que pour trouver la combinaison linéaire. On aurait donc pu montrer l'indépendance en même temps que l'on aurait pu trouver la combinaison linéaire. Pour plus de clarté, on continue à séparer les deux étapes dans les prochaines solutions.  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  Montrer qu'un vecteur seul est linéairement indépendant si et seulement si . Soit tel que . On suppose dans un premier temps que est linéairement indépendant. Cela signifie que est la seule valeur pour laquelle . Plus particulièrement, si , tout donnerait le vecteur nul lorsque multiplié par , on doit donc avoir .  On suppose maintenant que . Cette fois, le seul multiple de ce vecteur non nul qui peut donner le vecteur est lorsque . On a donc indépendance linéaire du vecteur avec lui-même.  On considère une base d'un sous-espace quelconque et un vecteur . Pour chaque ensemble ci-dessous, déterminer s'il forme aussi une base. Si oui, donner les composantes du vecteur dans cette base et si non, expliquer pourquoi. Oui, . On rappelle que, par la définition , les conditions pour qu'un ensemble de vecteurs soit une base sont qu'ils génèrent le sous-espace et qu'ils soient linéairement indépendants. Cependant, par la proposition , il est possible de ne vérifier que l'une de ces deux conditions si l'on a le bon nombre de vecteurs. En effet, puisqu'on sait que est une base et qu'elle ne compte que deux vecteurs, tout autre ensemble contenant exactement deux vecteurs a le potentiel d'être une base. À l'opposé, si un ensemble ne contient pas exactement deux vecteurs, on sait immédiatement que ce n'est pas une base.  Ici, on a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de .  On exprime donc dans cette base en changeant le signe de sa première composante: . Oui, . On a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de . Par la proposition , ils forment une base.  On exprime donc dans cette base en changeant l'ordre des composantes : . Oui, . On a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de . Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a deux vecteurs. Cependant, on voit rapidement qu'ils sont linéairement dépendants, car ils sont parallèles. Par la définition , ils ne forment pas une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a trois vecteurs. Par la proposition , ils ne forment pas une base, puisque l'on sait que la dimension de cet espace est de deux étant donné que c'est le nombre de vecteurs dans la base donnée initialement. Ces vecteurs sont donc dépendants, ce qui contrevient à une des conditions pour qu'ils forment une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a un seul vecteur. Par la proposition , ils ne forment pas une base, puisque l'on sait que la dimension de cet espace est de deux étant donné que c'est le nombre de vecteurs dans la base donnée initialement. Il n'y a donc pas suffisamment de vecteurs pour générer l'espace , celui-ci ne peut en conséquence être une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. Bien qu'on ait deux vecteurs, plusieurs conditions ne sont pas satisfaites pour qu'ils forment une base. D'abord, il est impossible que cet ensemble génère un espace de dimension deux puisque le seul vecteur pour lequel les combinaisons linéaires permettront un réel déplacement est . Autrement dit, .  De plus, ces vecteurs ne peuvent être linéairement indépendants puisque le vecteur nul est par définition toujours dépendant. En effet, on peut créer une combinaison non triviale en le multipliant par n'importe quelle constante et obtenir un déplacement nul.   Dans cet exercice, on s'intéresse à l'indépendance linéaire de vecteurs perpendiculaires.  Soit , un vecteur non nul de et son perpendiculaire. Montrer qu'ils sont linéairement indépendants.   Selon la proposition , deux vecteurs non parallèles sont indépendants.  Soit , deux vecteurs non nuls de tels que . Montrer que et sont linéairement indépendants. Est-ce que la preuve serait différente si les vecteurs étaient dans ?  Du fait que les deux vecteurs sont perpendiculaires (et non nuls), on peut conclure qu'ils sont non parallèles. Toujours selon la proposition , les vecteurs sont indépendants.  Le fait qu'ils soient dans ou dans ne change pas l'argument précédent. Soit , des vecteurs non nuls de tels que dès que , c'est-à-dire des vecteurs perpendiculaires deux à deux. Montrer que l'ensemble est linéairement indépendant. Considérer une combinaison linéaire de ces vecteurs qui donne le vecteur nul et faire le produit scalaire avec chacun des vecteurs et . Soit , une combinaison linéaire de ces trois vecteurs qui donne le vecteur nul.  On considère le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  On considère maintenant le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  Finalement, on considère maintenant le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  La seule combinaison linéaire des vecteurs qui donne le vecteur nul est donc la combinaison triviale.  Finalement, soit des vecteurs non nuls de tels que dès que , c'est-à-dire des vecteurs perpendiculaires deux à deux. Montrer que l'ensemble est linéairement indépendant.  On utilise le même argument que dans la partie précédente. Pour , on a . Comme , on conclut que si , c'est que .  La seule combinaison linéaire des vecteurs qui donne le vecteur nul est donc la combinaison triviale.  Montrer que vecteurs perpendiculaires deux à deux dans forment une base de . On sait déjà, par la partie précédente, que ces vecteurs sont indépendants. En vertu de la proposition , ces vecteurs indépendants forment une base.   Soit , une matrice telle que l'équation possède des solutions non triviales et soit les solutions de base à cette équation. Montrer que les vecteurs sont linéairement indépendants.  Soit , une combinaison linéaire des solutions de base donnant le vecteur nul. Soit , l'indice de la variable libre correspondant à la solution . Par définition , l'entrée de vaut et l'entrée des autres vecteurs est . La seule manière d'obtenir que la composante de la combinaison linéaire soit égale à est de prendre .  Par un argument similaire, on montre qu'on doit avoir . Les vecteurs sont donc indépendants.   Soit , des vecteurs non nuls perpendiculaires deux à deux de et soit un vecteur quelconque. En considérant d'abord les vecteurs , décrire en mots comment obtenir les composantes de . Commencer par réfléchir au cas et faire un dessin. On devrait obtenir que la composante corresponde dans une certaine mesure à la projection orthogonale du vecteur sur le vecteur .  Montrer que les composantes de dans la base sont ce qui a été déterminé dans la partie précédente. Puisque les vecteurs sont perpendiculaires, utiliser le produit scalaire avec l'écriture de dans la base pour déterminer les coefficients de la combinaison linéaire. Le coefficient de la combinaison linéaire vaut Soit , l'écriture de dans la base des vecteurs . On considère le produit scalaire de dans cette écriture avec le vecteur . On a . On a donc . Puisque , on peut isoler le coefficient pour avoir . Ce facteur correspond au coefficient devant le vecteur lorsqu'on fait la projection orthogonale de sur .  De la même manière, on obtient .   Soit , une base de et soit , la matrice d'une transformation linéaire. Donner un exemple de vecteurs et de matrice pour lesquels n'est pas une base. Un exemple dans à partir des vecteurs suffit.  On prend et . Comme cette matrice possède des colonnes identiques, on a que les vecteurs sont envoyés sur , ce qui fait que et ne peuvent pas être une base de .  Si est une matrice carrée inversible, montrer que l'ensemble est une base de . Comme il y a vecteurs, il suffit de montrer qu'ils sont linéairement indépendants et d'utiliser la proposition . Soit , une combinaison linéaire des vecteurs transformés qui donne le vecteur nul. On peut mettre la matrice en évidence pour avoir . Par hypothèse, la matrice est inversible, l'unique solution à cette équation matricielle est donc .  De plus, comme les vecteurs sont une base de , ils sont indépendants ainsi, la seule combinaison de ces vecteurs qui donne le vecteur nul est la combinaison triviale. On a donc et l'on conclut que les vecteurs forment aussi une base de .  Soit , une matrice . Montrer que si est un ensemble indépendant, alors est aussi indépendant. Soit , une combinaison linéaire donnant le vecteur nul. On multiplie chaque côté de cette équation par la matrice . On obtient .  Puisque les vecteurs sont indépendants par hypothèse, on doit avoir que . Les vecteurs sont donc aussi indépendants.  Soit , une matrice de rang et soit , des vecteurs linéairement indépendants. Montrer que les vecteurs sont aussi linéairement indépendants. Expliquer en quoi le rang est nécessaire. Soit , une combinaison linéaire donnant le vecteur nul. On met la matrice en évidence . Puisque le rang de la matrice est , toutes les variables sont pivots. Il y a donc une solution unique à cette équation, qui doit être le vecteur nul. On a donc . Comme les vecteurs sont indépendants, la seule combinaison linéaire donnant le vecteur nul est celle où . Les vecteurs sont aussi linéairement indépendants.  Soit , un ensemble de vecteurs linéairement dépendants et soit . Montrer que peut s'écrire d'une infinité de manières comme combinaison linéaire des vecteurs .  Soit , la matrice de taille qui contient les vecteurs en colonne. On cherche le nombre de solutions à l'équation , puisque cette équation représente les combinaisons linéaires des colonnes de la matrice . Selon la proposition , la matrice n'est pas de rang , car ses colonnes sont des vecteurs dépendants. Ainsi, il y a au moins une variable libre dans la forme échelonnée réduite de la matrice . Puisque , on sait qu'il doit exister des solutions à l'équation . Le fait que le rang ne soit pas égal à confirme qu'il y en a une infinité.    Soit , un ensemble de vecteurs linéairement indépendants et soit , des vecteurs de cet ensemble, où . Montrer que les vecteurs sont aussi linéairement indépendants.   Soit , une combinaison linéaire de ces vecteurs qui donnent le vecteur nul. Soit , les vecteurs dans l'ensemble qui ne sont pas dans le sous-ensemble . On peut alors écrire . On a alors une combinaison linéaire de tous les vecteurs de qui donne le vecteur nul. Comme l'ensemble est un ensemble linéairement indépendant, il s'ensuit que les coefficients sont tous nuls.     Déterminer la dimension des sous-espaces suivants.    On considère l'équation matricielle afin de déterminer si des vecteurs s'écrivent comme une combinaison linéaire des autres vecteurs. On utilise Sage pour réduire le système.   Il y a une variable libre et donc, une solution de base, qui est . Cela signifie que . En isolant par exemple , on a que et que ces trois vecteurs sont indépendants. La dimension est donc égale à .  On convertit le système d'équations linéaires sous la forme matricielle. Le sous-espace vectoriel correspondant aux solutions de l'équation est le sous-espace de l'énoncé. On utilise Sage pour réduire la matrice.   Cette fois, il y a deux solutions de base. Comme ici on cherche la dimension des solutions à l'équation , on obtient .  On peut réfléchir géométriquement dans ce cas. Les vecteurs sont non parallèles et forment un plan dans . Géométriquement, on sait que le complément orthogonal d'un plan dans est une droite dont le vecteur directeur correspond au vecteur normal du plan. La dimension de ce sous-espace est donc de .   Cette fois, on ne peut pas (encore du moins) s'appuyer sur la géométrie pour répondre à la question. Soit , un vecteur dans le complément orthogonal de l'ensemble . On a alors . Toujours avec Sage, on échelonne la matrice associée à ce système.   Deux variables libres, ce qui signifie que la dimension de l'espace solution à ces équations est égale à .   Donner une preuve alternative de la proposition en utilisant la proposition .  Soit , des vecteurs linéairement indépendants et soit , un vecteur dans . On s'intéresse au nombre de solutions à l'équation . On peut décortiquer toutes les solutions à cette équation comme selon la proposition , où est une solution correspondant à une écriture possible du vecteur dans la base des vecteurs , et est l'ensemble de toutes les solutions à l'équation homogène .  Puisque par hypothèse , on conclut que toute solution est égale à et que la solution est unique.     Soit , un sous-espace vectoriel et des vecteurs tels que . Montrer que tout ensemble contenant vecteurs de sera linéairement dépendant.   Soit , des vecteurs dans . Puisque , on peut écrire chaque vecteur comme une combinaison linéaire des vecteurs . Ainsi, on a pour chaque vecteur avec .  On a donc une liste de coefficients. Soit , la matrice de ces coefficients. Puisque , l'équation matricielle possède une infinité de solutions. Soit , une de ces solutions différentes de . On montre que ce vecteur fournit les coefficients nécessaires pour avoir une combinaison linéaire non triviale des vecteurs qui donne le vecteur nul.  En effet, on a . Ainsi, on a une combinaison linéaire non triviale qui donne le vecteur nul. Les vecteurs sont dépendants.    "
},
{
  "id": "ex-comblinuni",
  "level": "2",
  "url": "sec-bases.html#ex-comblinuni",
  "type": "Exemple",
  "number": "5.2.1",
  "title": "Combinaisons linéaires et unicité.",
  "body": " Combinaisons linéaires et unicité   On considère les vecteurs ainsi que les vecteurs . Est-ce que les vecteurs s'écrivent comme une combinaison linéaire des vecteurs ? De manière unique?    On recherche l'existence de constantes telles que et de constantes telles que .  Sous forme matricielle, avec , les systèmes d'équations linéaires sont équivalents à la matrice augmentée . Avec Sage,   on trouve la solution à ces systèmes en échelonnant la matrice : . Le vecteur ne s'écrit pas comme une combinaison linéaire des vecteurs . Il n'est donc pas dans l'espace colonne de la matrice . Par contre, le vecteur , lui, en fait partie. Il y a même une infinité de manières de l'écrire. Par exemple, on a , mais aussi .  En observant la matrice augmentée (ou l'expression de la solution), on peut arriver à la conclusion que si le troisième vecteur n'était pas là, on pourrait quand même écrire le vecteur et, qui plus est, la solution serait unique.   "
},
{
  "id": "prop-soluniquezero",
  "level": "2",
  "url": "sec-bases.html#prop-soluniquezero",
  "type": "Proposition",
  "number": "5.2.2",
  "title": "Unicité des combinaisons linéaires dans le <span class=\"process-math\">\\(\\vspan\\)<\/span>.",
  "body": " Unicité des combinaisons linéaires dans le  Soit , des vecteurs de . Si la seule combinaison linéaire de ces vecteurs qui produit le vecteur nul est la combinaison triviale, alors tous les vecteurs dans s'écrivent de manière unique comme une combinaison linéaire des vecteurs . Mathématiquement, si la seule solution à l'équation est la solution où , alors l'écriture est unique pour tout vecteur    On suppose qu'il existe et telles que et . On peut alors écrire le vecteur nul comme . Comme l'écriture du vecteur nul est unique par hypothèse, il s'ensuit que et que l'écriture de est aussi unique.   "
},
{
  "id": "example-98",
  "level": "2",
  "url": "sec-bases.html#example-98",
  "type": "Exemple",
  "number": "5.2.3",
  "title": "Écriture unique et vecteur nul.",
  "body": " Écriture unique et vecteur nul   On reprend les vecteurs . On détermine les solutions à l'équation . On s'attend évidemment à avoir une infinité de solutions puisque l'écriture du vecteur de l'exemple n'était pas unique.    Pour résoudre le problème, on peut échelonner la matrice , travail qui a déjà été fait à l'exemple . On obtient . Comme attendu, on a une infinité de solutions, car il y a des variables libres. En particulier, le vecteur nul peut s'écrire comme .   "
},
{
  "id": "def-indlin",
  "level": "2",
  "url": "sec-bases.html#def-indlin",
  "type": "Définition",
  "number": "5.2.4",
  "title": "Indépendance linéaire.",
  "body": " Indépendance linéaire   Soit , un ensemble de vecteurs de . L'ensemble est dit linéairement indépendant (on dit parfois aussi que les vecteurs sont linéairement indépendants) si la seule solution à l'équation est la solution triviale où .  Dans le cas contraire, on dit que l'ensemble de vecteurs est linéairement dépendant (on dit parfois aussi que les vecteurs sont linéairement dépendants).   "
},
{
  "id": "remark-18",
  "level": "2",
  "url": "sec-bases.html#remark-18",
  "type": "Remarque",
  "number": "5.2.5",
  "title": "L’indépendance (linéaire).",
  "body": " L'indépendance (linéaire)  Il arrive souvent qu'on ne mentionne pas le terme linéairement dans l'expression linéairement indépendant. Puisqu'on a qu'un seul type d'indépendance, le contexte est toujours celui de l'indépendance linéaire.  "
},
{
  "id": "example-99",
  "level": "2",
  "url": "sec-bases.html#example-99",
  "type": "Exemple",
  "number": "5.2.6",
  "title": "L’indépendance linéaire de deux vecteurs spécifiques.",
  "body": " L'indépendance linéaire de deux vecteurs spécifiques   On considère deux des trois vecteurs de l'exemple , à savoir les vecteurs . On montre que ces vecteurs sont linéairement indépendants.   Pour résoudre l'équation , on utilise la forme échelonnée réduite de la matrice . On obtient alors , qui donne comme unique solution . Les vecteurs sont donc linéairement indépendants.  "
},
{
  "id": "example-100",
  "level": "2",
  "url": "sec-bases.html#example-100",
  "type": "Exemple",
  "number": "5.2.7",
  "title": "Combinaisons linéaires de vecteurs linéairement indépendants.",
  "body": " Combinaisons linéaires de vecteurs linéairement indépendants   Soit , deux vecteurs formant un ensemble linéairement indépendant. On montre que l'ensemble formé des vecteurs est aussi linéairement indépendant.    On tente d'écrire le vecteur nul comme une combinaison linéaire des vecteurs . On a . Parce que forment un ensemble indépendant, on peut conclure que et , car la seule combinaison linéaire de ces vecteurs qui donne le vecteur nul est la combinaison triviale. De ces nouvelles contraintes, on déduit que et , ce qui n'est possible que lorsque . Ainsi, l'ensemble composé des vecteurs est linéairement indépendant.   "
},
{
  "id": "prop-indeprang",
  "level": "2",
  "url": "sec-bases.html#prop-indeprang",
  "type": "Proposition",
  "number": "5.2.8",
  "title": "Indépendance linéaire et rang.",
  "body": " Indépendance linéaire et rang   Soit , un ensemble de vecteurs de et soit , la matrice contenant les vecteurs dans ses colonnes. Alors l'ensemble des vecteurs est linéairement indépendant si et seulement si .    On commence avec l'implication que si est un ensemble de vecteurs linéairement indépendant, alors le rang de la matrice vaut .  Puisque l'équation possède une solution unique, cela signifie que toutes les colonnes sont pivots dans la forme échelonnée réduite de la matrice , car il ne peut pas y avoir de variables libres. Ainsi .  On regarde maintenant l'implication du rang égal à sur l'indépendance des vecteurs .  À l'inverse de l'argument précédent, si le rang de la matrice est égal à , alors toutes les colonnes sont pivots. Dans l'équation matricielle , il n'y aura pas de variables libres, la solution sera unique et sera celle où . Ainsi, la seule combinaison linéaire des vecteurs   donnant le vecteur nul est la combinaison linéaire triviale, est donc un ensemble linéairement indépendant.   "
},
{
  "id": "prop-indep2-3",
  "level": "2",
  "url": "sec-bases.html#prop-indep2-3",
  "type": "Proposition",
  "number": "5.2.9",
  "title": "Indépendance linéaire pour deux ou trois vecteurs.",
  "body": " Indépendance linéaire pour deux ou trois vecteurs   Soit , des vecteurs de . Alors  Les vecteurs sont linéairement indépendants si et seulement s'ils ne sont pas parallèles;  Les vecteurs sont linéairement indépendants si et seulement s'ils ne sont pas sur un même plan.   Ceci permet aisément de tester l'indépendance de deux ou trois vecteurs, en particulier, on pourra utiliser le déterminant à cet effet.    On commence avec des vecteurs linéairement indépendants et l'on tente de montrer que les vecteurs ne peuvent pas être parallèles.  Soit , des vecteurs linéairement indépendants. Si les vecteurs étaient parallèles, par exemple , alors on pourrait écrire , ce qui donnerait une combinaison non triviale des vecteurs donnant le vecteur nul. Comme les vecteurs sont indépendants par hypothèse, c'est impossible.  On poursuit maintenant avec deux vecteurs non parallèles et l'on montre qu'ils doivent être indépendants.  Soit , des vecteurs non parallèles. Si ces vecteurs étaient linéairement dépendants, alors il existerait des constantes qui ne sont pas toutes les deux nulles telles que . On suppose que , l'argument est le même si , mais que , en inversant le rôle de et . On peut donc écrire , ce qui entraine que les vecteurs sont parallèles, contredisant l'hypothèse initiale. Il faut donc que les vecteurs soient indépendants.    On commence avec trois vecteurs indépendants et l'on montre que ces vecteurs ne sont pas sur un même plan. De la même manière qu'à la partie précédente, on suppose que les vecteurs sont sur un même plan. On peut, dans un premier temps, supposer qu'aucune paire de vecteurs n'est parallèle, car la partie précédente entraine que les vecteurs seraient dépendants. Comme aucun vecteur n'est parallèle, on peut prendre les vecteurs comme vecteurs directeurs du plan. Il existe donc tels que , car est dans le plan de ces vecteurs. Or en écrivant , on obtient une combinaison linéaire non triviale des vecteurs donnant le vecteur nul, ce qui est impossible, car les vecteurs sont indépendants par hypothèse.  En contrepartie, si l'on suppose que les vecteurs ne sont pas sur un même plan et que l'on considère une combinaison linéaire des vecteurs donnant le vecteur nul, par exemple .  On sait qu'au moins l'une de ces constantes est non nulle. On suppose que est non nulle, l'argument sera similaire dans les autres cas. On peut alors isoler . Or ceci signifie que est une combinaison linéaire des vecteurs et serait dans le même plan que ces vecteurs, ce qui contredit l'hypothèse initiale. Ainsi, les vecteurs sont indépendants.   "
},
{
  "id": "prop-indepspan",
  "level": "2",
  "url": "sec-bases.html#prop-indepspan",
  "type": "Proposition",
  "number": "5.2.10",
  "title": "Indépendance linéaire et espace engendré.",
  "body": " Indépendance linéaire et espace engendré  Soit , des vecteurs formant un ensemble linéairement indépendant et soit . Alors l'ensemble est linéairement indépendant si et seulement si .  Si , cela signifie en particulier que les espaces engendrés par et par sont différents.   Voir l'exercice .  "
},
{
  "id": "sageex-indlin",
  "level": "2",
  "url": "sec-bases.html#sageex-indlin",
  "type": "Calcul",
  "number": "5.2.11",
  "title": "Sage et l’indépendance linéaire.",
  "body": " Sage et l'indépendance linéaire  Pour vérifier si un ensemble de vecteurs est linéairement indépendant, il existe plusieurs options. La première consiste à utiliser la définition . On peut alors résoudre l'équation en utilisant les techniques du chapitre et valider avec la définition .   On peut aussi utiliser la proposition et simplement calculer le rang de la matrice dans la cellule Sage précédente.   Puisque ce rang correspond au nombre de vecteurs, les vecteurs sont linéairement indépendants.  Une autre manière, un peu plus complexe, consiste à utiliser la commande .linear_dependance . Elle nécessite toutefois la création d'un espace vectoriel sous-jacent, concept qui sera défini dans la prochaine section. On en montre toutefois un exemple et les premières lignes seront clarifiées dans la section suivante.   Le résultat est un ensemble vide, ce qui signifie qu'il n'y a pas de dépendance linéaire. Afin de comparer avec un exemple où il y aurait dépendance, on ajoute deux vecteurs supplémentaires à la liste L.   Le résultat est une possible combinaison linéaire des vecteurs donnant le vecteur nul. Dans ce cas-ci, on a , puisque a été défini ainsi.  Finalement, on peut utiliser la proposition . Les commandes utilisent également des concepts de la section suivante.   "
},
{
  "id": "def-base",
  "level": "2",
  "url": "sec-bases.html#def-base",
  "type": "Définition",
  "number": "5.2.12",
  "title": "Base d’un sous-espace vectoriel.",
  "body": " Base d'un sous-espace vectoriel   Soit , un sous-espace vectoriel et soit , un ensemble de vecteurs dans . On dit que ces vecteurs forment une base de si  les vecteurs génèrent , c'est-à-dire ;  les vecteurs forment un ensemble linéairement indépendant.    "
},
{
  "id": "ex-baseex",
  "level": "2",
  "url": "sec-bases.html#ex-baseex",
  "type": "Exemple",
  "number": "5.2.13",
  "title": "Base de sous-espaces vectoriels.",
  "body": " Base de sous-espaces vectoriels   On considère quelques-uns des sous-espaces vectoriels de l'exemple , soit  Le plan du début de section;  Les vecteurs de la forme ;  L'ensemble ne contenant que le vecteur nul : ;  Ĺ'espace au complet. On cherche à déterminer une base pour chacun de ces exemples.    On sait que, pour générer un plan, on doit avoir deux vecteurs non parallèles (et donc indépendants!). En isolant dans l'équation normale du plan , on peut écrire les points du plan comme les points . On obtient deux vecteurs et tels que . Puisque les vecteurs sont non parallèles, ils sont indépendants (proposition ). Ces vecteurs forment donc une base du plan .    Les vecteurs de la forme peuvent tous s'écrire comme un multiple de . Ainsi, ce vecteur génère le sous-espace vectoriel. Comme la seule combinaison linéaire de ce vecteur donnant le vecteur nul est , ce vecteur est linéairement indépendant (est-ce qu'un vecteur seul est toujours linéairement indépendant? Voir l'exercice ). Il forme donc une base de ce sous-espace.    Le vecteur nul engendre par défaut le vecteur nul, puisque pour tout scalaire . Par contre, pour la même raison, il n'est pas linéairement indépendant. Ce n'est donc pas une base. En fait, le sous-espace vectoriel est le seul sous-espace qui ne possède pas de base.   On sait qu'on peut décomposer un vecteur de comme une combinaison linéaire des vecteurs . Ces vecteurs engendrent donc . De plus, si l'on les place dans les colonnes d'une matrice, on obtient la matrice identité, de rang . Les vecteurs sont alors linéairement indépendants et forment ainsi une base de .  "
},
{
  "id": "example-102",
  "level": "2",
  "url": "sec-bases.html#example-102",
  "type": "Exemple",
  "number": "5.2.14",
  "title": "Plusieurs bases d’un sous-espace.",
  "body": " Plusieurs bases d'un sous-espace   On reprend certains des sous-espaces vectoriels possédant une base de l'exemple précédent et l'on trouve des bases alternatives pour ces espaces:  Le plan du début de section;  Les vecteurs de la forme .    La base révélée à l'exemple   a été trouvée selon la méthode prescrite par le chapitre (en isolant pour en faire une variable pivot). Il suffit toutefois de trouver n'importe quel ensemble de vecteurs linéairement indépendants qui génère le plan. Plusieurs autres options sont possibles. Par exemple, en isolant ou dans l'équation normale du plan, on a ou encore . Dans chacun des cas, les vecteurs sont linéairement indépendants et engendrent le plan.  Pour avoir un autre exemple, on prend des vecteurs indépendants qui satisfont l'équation jusqu'à l'obtention d'un ensemble qui génère le plan. Par exemple, si l'on prend , ce vecteur est sur le plan. Par lui-même, il engendre une droite et il faut donc en ajouter un autre pour obtenir le plan. Une possibilité est , qui est indépendant de . Ensemble, ils engendrent le plan. Par exemple, on peut montrer que et , la base originale du plan est alors dans . De même, on a et et donc, la base formée des vecteurs et est dans le sous-espace engendré par la base originale. Ces bases engendrent ainsi bel et bien le même espace.    Le sous-espace formé des vecteurs de la forme peut avoir comme base n'importe quel vecteur non nul parallèle à . Un tel vecteur va, bien entendu, générer la droite représentant ce sous-espace. En fait, un vecteur non nul par lui-même est toujours indépendant.   "
},
{
  "id": "definition-45",
  "level": "2",
  "url": "sec-bases.html#definition-45",
  "type": "Définition",
  "number": "5.2.15",
  "title": "Composantes d’un vecteur relatives à une base.",
  "body": " Composantes d'un vecteur relatives à une base  Soit , une base d'un sous-espace . On note par la base ordonnée de ces vecteurs, c'est-à-dire la base où l'ordre des vecteurs est important. Soit , un vecteur du sous-espace peut-être égal à l'un des vecteurs de . Parce que est une base de , il existe tels que . Les nombres sont appelés les composantes de dans la base ordonnée et l'on écrit .  "
},
{
  "id": "example-103",
  "level": "2",
  "url": "sec-bases.html#example-103",
  "type": "Exemple",
  "number": "5.2.16",
  "title": "Bases et composantes de vecteurs.",
  "body": " Bases et composantes de vecteurs   On considère les vecteurs tirés de l'exemple calculatoire . Ces trois vecteurs forment une base de . On considère aussi le vecteur . On définit les trois bases ordonnées . On cherche à écrire le vecteur dans chacune de ces trois bases.    On cherche la combinaison linéaire des vecteurs et qui donne le vecteur . On peut faire ce calcul facilement avec Sage.   Ainsi, on peut écrire .    La seule différence entre la base ordonnée et la base ordonnée est l'ordre des vecteurs. On devrait donc avoir .    On procède comme pour la première méthode. Toujours avec Sage, on trouve que    "
},
{
  "id": "example-104",
  "level": "2",
  "url": "sec-bases.html#example-104",
  "type": "Exemple",
  "number": "5.2.17",
  "title": "Composantes d’un vecteur dans un sous-espace.",
  "body": " Composantes d'un vecteur dans un sous-espace  On considère le plan dans engendré par les vecteurs de l'exemple . On considère également le vecteur , qui est donc dans le plan. Si l'on ne s'intéresse qu'au sous-espace vectoriel, on peut alors décrire dans la base comme étant . Même si la description ne comporte que deux composantes, on comprend que ce vecteur est toujours dans , puisque les vecteurs de sont dans .  "
},
{
  "id": "prop-baseexiste",
  "level": "2",
  "url": "sec-bases.html#prop-baseexiste",
  "type": "Proposition",
  "number": "5.2.18",
  "title": "(Presque) tous les sous-espaces ont une base.",
  "body": " (Presque) tous les sous-espaces ont une base  Soit , un sous-espace vectoriel de différent du sous-espace nul. Alors, il existe une base pour .  Ce résultat implique donc que tous les sous-espaces possèdent une base, sauf le sous-espace trivial qui ne contient que le vecteur nul. La raison est que le vecteur nul n'est pas indépendant de lui-même. La discussion a été menée à l'exemple .   L'idée est de construire séquentiellement une base pour . On commence en choisissant un vecteur non nul dans , qu'on nomme . Si , alors c'est terminé, car est indépendant et génère . Il forme donc une base. Si , on prend alors un vecteur du sous-espace . En vertu de la proposition , l'ensemble est linéairement indépendant. Si , alors on a terminé, sinon on poursuit ce processus avec un vecteur . Pour les mêmes raisons, le nouvel ensemble sera indépendant.  Après un maximum de étapes, on est assuré d'avoir trouvé une base. En effet, si l'on a vecteurs de linéairement indépendants, alors tout autre vecteur différent de ces vecteurs doit appartenir à . Ceci découle de la proposition . Comme il est impossible pour une matrice d'avoir un rang égal à , la dépendance est forcée. Si tous les vecteurs additionnels sont dans , on peut alors conclure que .   "
},
{
  "id": "prop-comporthocomportho",
  "level": "2",
  "url": "sec-bases.html#prop-comporthocomportho",
  "type": "Proposition",
  "number": "5.2.19",
  "title": "Le complément orthogonal du complément orthogonal.",
  "body": " Le complément orthogonal du complément orthogonal   Soit , un sous-espace vectoriel. Alors .    Dans un premier temps, on sépare en deux cas. D'abord, si , alors pour tout vecteur dans on a , comme il est remarqué à la proposition . Dans ce cas, quel est le complément orthogonal de ? On y revient dans la seconde partie.  Soit , un sous-espace vectoriel différent de . Soit , une base de ce sous-espace dont l'existence est garantie par la proposition . On place ces vecteurs dans les colonnes d'une matrice de taille . Par construction, on a . Selon la proposition , on a et .  Plus particulièrement, si , on peut prendre les vecteurs comme base et la matrice . Dans ce cas, on a , puisque . On a donc aussi , ce qui complète la preuve.   "
},
{
  "id": "sageex-base",
  "level": "2",
  "url": "sec-bases.html#sageex-base",
  "type": "Calcul",
  "number": "5.2.20",
  "title": "Les bases et Sage.",
  "body": " Les bases et Sage  Avec Sage, on peut facilement déterminer une base d'un sous-espace vectoriel. La méthode la plus simple consiste à créer le d'un certain nombre de vecteurs et ensuite de demander une base à Sage. Comme il existe plusieurs bases, Sage en choisit une selon l'algorithme qui a été programmé.  Pour tester, on reprend les vecteurs de l'exemple et l'on cherche une base aux sous-espaces créés par les différents   "
},
{
  "id": "prop-depnbr",
  "level": "2",
  "url": "sec-bases.html#prop-depnbr",
  "type": "Proposition",
  "number": "5.2.21",
  "title": "Dépendance linéaire et nombre de vecteurs.",
  "body": " Dépendance linéaire et nombre de vecteurs   Soit , un sous-espace vectoriel et soit , une base de ce sous-espace. On considère un ensemble de vecteurs du sous-espace . Si , alors les vecteurs sont linéairement dépendants.    On écrit les vecteurs comme des combinaisons linéaires des vecteurs , cela étant possible en vertu du fait que les vecteurs forment une base. On a donc et l'on note par la matrice dont les colonnes correspondent aux composantes des vecteurs dans la base ordonnée . On note aussi par la matrice des vecteurs en colonne dans leur écriture initiale. Finalement, on fait la même chose avec les vecteurs en les mettant en colonne dans une matrice .  On peut alors écrire , en vertu de la définition du produit matriciel.  Si l'on montre que l'équation possède des solutions autres que le vecteur nul, cela implique qu'il existe une combinaison linéaire des colonnes de et donc, des vecteurs , qui donne le vecteur nul. Les vecteurs seraient alors dépendants.  Puisque et que la matrice est de taille , il ne peut pas y avoir de pivot dans toutes les colonnes de la forme échelonnée réduite de . L'équation matricielle possède donc une infinité de solutions, car il y a au moins une variable libre. On note par une solution non triviale à cette équation. On a alors .  Ainsi, le vecteur offre une combinaison linéaire non triviale des vecteurs donnant le vecteur nul. Les vecteurs sont donc dépendants.   "
},
{
  "id": "rem-depnbr",
  "level": "2",
  "url": "sec-bases.html#rem-depnbr",
  "type": "Remarque",
  "number": "5.2.22",
  "title": "L’indépendance linéaire n’était pas nécessaire.",
  "body": " L'indépendance linéaire n'était pas nécessaire  Dans la proposition , les vecteurs forment une base. On dit alors que tout ensemble comprenant plus de vecteurs est forcément dépendant. En fait, on peut alléger un peu les hypothèses de la proposition et exiger seulement que les vecteurs génèrent , c'est-à-dire que . Les détails sont examinés à l'exercice  "
},
{
  "id": "proposition-57",
  "level": "2",
  "url": "sec-bases.html#proposition-57",
  "type": "Proposition",
  "number": "5.2.23",
  "title": "Nombre de vecteurs dans une base d’un sous-espace.",
  "body": " Nombre de vecteurs dans une base d'un sous-espace   Soit , un sous-espace vectoriel et soit et , deux bases de ce sous-espace. Alors .    La preuve est une application de la proposition qui va comme suit. Dans un premier temps, parce que les vecteurs forment une base, on peut dire que ces vecteurs sont linéairement indépendants. De plus, parce que les vecteurs forment aussi une base, on doit conclure que , sinon la proposition entrainerait que les vecteurs sont dépendants.  On utilise le même argument, mais en renversant le rôle des vecteurs et :  Parce que les vecteurs forment une base, on peut dire que ces vecteurs sont linéairement indépendants. De plus, parce que les vecteurs forment aussi une base, on doit conclure que , sinon la proposition entrainerait que les vecteurs sont dépendants.  Finalement, on obtient que et , ce qui force à avoir .   "
},
{
  "id": "def-dimension",
  "level": "2",
  "url": "sec-bases.html#def-dimension",
  "type": "Définition",
  "number": "5.2.24",
  "title": "La dimension d’un sous-espace vectoriel.",
  "body": " La dimension d'un sous-espace vectoriel   Soit , un sous-espace vectoriel. On appelle la dimension de , noté , le nombre de vecteurs dans une base de .  Afin d'uniformiser les résultats qui suivent, on prend comme convention que .   "
},
{
  "id": "example-105",
  "level": "2",
  "url": "sec-bases.html#example-105",
  "type": "Exemple",
  "number": "5.2.25",
  "title": "La dimension de sous-espaces vectoriels.",
  "body": " La dimension de sous-espaces vectoriels  On reprend les sous-espaces de l'exemple et l'on détermine leur dimension.   À l'exemple , on a trouvé comme base du plan les vecteurs et . Sans surprise, la dimension de l'espace est .    Toujours à l'exemple , on a trouvé que le vecteur forme une base de ce sous-espace. La dimension est ainsi égale à .    Par définition, le sous-espace composé uniquement du vecteur nul a pour dimension .    Encore à l'exemple , on a établi que les vecteurs formaient une base de et donc, la dimension de est égale à .    On sait qu'une droite qui passe par l'origine peut être engendrée par un vecteur. Un vecteur seul étant indépendant, il forme une base de la droite. La dimension d'une droite est donc égale à , comme on pouvait s'y attendre.    Un plan peut être engendré par deux vecteurs non parallèles et donc qui sont indépendants. Ces deux vecteurs forment alors une base. Ainsi, la dimension d'un plan est égale à , comme attendu.   Un hyperplan passant par l'origine dans est caractérisé par l'équation . En considérant cette équation d'un point de vue matriciel, la matrice associée à cette équation n'aura qu'un pivot et variables libres. Ces variables libres amèneront solutions de base, donnant ainsi un sous-espace à dimension.  "
},
{
  "id": "prop-ensemblevecetdim",
  "level": "2",
  "url": "sec-bases.html#prop-ensemblevecetdim",
  "type": "Proposition",
  "number": "5.2.26",
  "title": "Ensemble de vecteurs et dimension.",
  "body": " Ensemble de vecteurs et dimension  Soit , un sous-espace vectoriel de dimension et soit , un ensemble de vecteurs dans .  Si , alors ;  Si , alors les vecteurs sont dépendants;  Si : et si , alors les vecteurs sont aussi indépendants et forment donc une base;  et si sont indépendants, alors et forment une base.       On suppose que les vecteurs sont indépendants. Si ce n'est pas le cas, l'argument ci-dessous fonctionne avec vecteurs indépendants parmi les vecteurs tels que le de ces vecteurs est égal au des vecteurs originaux.  On pose . Comme les vecteurs sont indépendants, ils forment une base de et ce sous-ensemble est de dimension . Si , on aurait , ce qui est impossible dans ce cas.   C'est exactement le contenu de la proposition .   On démontre chacune des deux affirmations lorsque ci-dessous.  Dans un premier temps, on suppose que . Si l'ensemble était linéairement dépendant, alors au moins un des vecteurs pourrait s'écrire comme une combinaison linéaire des autres vecteurs. On suppose par simplicité que c'est . Cela signifie aussi que . Selon l'exercice , en lien avec la remarque ,tout ensemble de plus de devrait être dépendant. Comme , une base va nécessairement contenir vecteurs indépendants. Il est donc impossible que les vecteurs soient dépendants.  Pour l'autre énoncé, on place les vecteurs dans les lignes d'une matrice . Si , il existe alors un vecteur tel que est indépendant selon la proposition . On obtient donc vecteurs indépendants, ce qui contredit la proposition .   "
},
{
  "id": "prop-diminclusion",
  "level": "2",
  "url": "sec-bases.html#prop-diminclusion",
  "type": "Proposition",
  "number": "5.2.27",
  "title": "Dimension et inclusion.",
  "body": " Dimension et inclusion   Soit , des sous-espaces vectoriels de tels que . Alors et si , alors .    Soit , la dimension de et , la dimension de . Soit , un ensemble de vecteurs formant une base pour . Si , alors est un ensemble de vecteurs dans un ensemble ( , car ) de taille plus grande que la dimension, ce qui signifie selon la proposition que est linéairement dépendant, contredisant le fait que c'est une base pour . Ainsi, on doit avoir .  On suppose que la . Soit , une base de . Si , il existe un vecteur qui n'est pas dans . On considère l'ensemble . Selon la proposition , cet ensemble est linéairement indépendant. Par contre, puisque la dimension de est aussi , la proposition affirme qu'un ensemble de vecteurs est dépendant. Ceci contredit la propostion , on conclut donc qu'il n'existe pas de vecteur qui ne soit pas aussi dans . On a donc . Combiné à l'hypothèse que , on conclut que .   "
},
{
  "id": "example-106",
  "level": "2",
  "url": "sec-bases.html#example-106",
  "type": "Exemple",
  "number": "5.2.28",
  "title": "Base à l’intérieur du span.",
  "body": " Base à l'intérieur du span   On considère les vecteurs et l'on note . On cherche une base pour .  Les quatre vecteurs ne peuvent pas former une base, puisque , qui est de dimension . Ceci contredirait les propositions et . Ces vecteurs sont donc dépendants. On regarde les solutions à l'équation . Ceci permettra de trouver quelle(s) combinaison(s) linéaire(s) des quatre vecteurs donne le vecteur nul. On utilise Sage pour résoudre le système.   On trouve deux variables libres, donc deux solutions de bases: . Ainsi, on peut conclure que de même que . On peut alors écrire comme une combinaison linéaire de et . On a alors . De plus, les vecteurs sont indépendants, car ils ne sont pas parallèles. Ils forment donc une base de .  Plus généralement, on va montrer dans la prochaine section qu'on peut obtenir une base pour en prenant les colonnes (de la matrice ) qui sont pivots (dans la forme ).   "
},
{
  "id": "sageex-dimension",
  "level": "2",
  "url": "sec-bases.html#sageex-dimension",
  "type": "Calcul",
  "number": "5.2.29",
  "title": "Les bases et Sage.",
  "body": " Les bases et Sage  Avec Sage, on peut aussi automatiquement obtenir la dimension d'un sous-espace vectoriel.  Pour tester, on reprend encore les vecteurs de l'exemple et l'on calcule la dimension à l'aide de la commande dimension .   "
},
{
  "id": "exo-lindep-linind",
  "level": "2",
  "url": "sec-bases.html#exo-lindep-linind",
  "type": "Exercice",
  "number": "5.2.4.1",
  "title": "",
  "body": " Déterminer si les vecteurs suivants sont linéairement dépendants ou linéairement indépendants.    Linéairement dépendants On peut se servir de la définition ou de la proposition . On peut également utiliser la proposition . Au fil des solutions, on utilisera ces différentes options, mais il est possible de toujours procéder de la même manière.  Ici, on voit rapidement que avec . En effet, on a . Ainsi, par la proposition , ils sont linéairement dépendants, car ils sont parallèles.    Linéairement indépendants On voit rapidement que ces vecteurs ne sont pas parallèles. Par la proposition , ils sont donc linéairement indépendants. On choisit tout de même de le montrer avec la définition pour varier les approches. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Donc, les vecteurs sont bel et bien linéairement indépendants.    Linéairement dépendants On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui n'est pas égal au nombre de vecteurs donnés, ils sont donc linéairement dépendants. On remarque qu'on aurait pu arriver directement à cette conclusion grâce à la proposition . En effet, trois vecteurs dans , qui est clairement de dimension , n'ont pas d'autre choix que d'être dépendants.    Linéairement dépendants On voit rapidement que avec . En effet, on a . Ainsi, par la proposition , ils sont linéairement dépendants, car ils sont parallèles.    Linéairement dépendants On choisit de procéder avec la définition pour varier les approches. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Ce SEL correspond à l'équation matricielle où le vecteur inconnu est et la matrice des coefficients: . La forme échelonnée réduite de cette matrice est : . Ce système ayant une infinité de solutions, on conclut donc qu'il existe d'autres solutions que la solution triviale. En conclusion, ces vecteurs sont linéairement dépendants.  Remarquons qu'il aurait été beaucoup plus rapide d'utiliser la proposition et d'échelonner directement la matrice de ces vecteurs en colonnes.    Linéairement dépendants On choisit de procéder avec la définition puisqu'il est possible de voir une combinaison linéaire non triviale directement. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul comme combinaison linéaire de sera la combinaison triviale. Par contre, on peut écrire: . La combinaison linéaire non triviale permet d'écrire le vecteur nul en fonction de ces trois vecteurs. Ils sont donc linéairement dépendants. On remarque que même si , cette solution n'est pas la solution triviale où TOUS les coefficients doivent être nuls.    Linéairement indépendants On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  "
},
{
  "id": "exercise-272",
  "level": "2",
  "url": "sec-bases.html#exercise-272",
  "type": "Exercice",
  "number": "5.2.4.2",
  "title": "",
  "body": " Considérer le parallélépipède de la figure et répondre aux questions suivantes.   Pour chaque ensemble de vecteurs ci-dessous, déterminer s'il est dépendant ou indépendant.    Linéairement dépendants On peut se servir de la définition ou de la proposition . Bien que l'on n'ait pas les expressions algébriques des vecteurs, on peut déterminer les conditions pour l'indépendance ou la dépendance à l'aide de la figure.  Ici, on voit que avec . Par la proposition , ils sont linéairement dépendants, car ils sont parallèles. On voit leur parallélisme dans la figure directement.    Linéairement indépendants On voit que peu importe la valeur de . On le voit sur la figure puisqu'ils ne sont pas parallèles. Par la proposition , ils sont linéairement indépendants, car ils ne sont pas parallèles.    Linéairement indépendants On voit sur la figure que les trois vecteurs mentionnés ne sont pas dans un même plan. Une façon de s'en convaincre est de remarquer que et . En exprimant ainsi ces trois vecteurs à partir de , on voit que et ne sont pas sur un même plan. Par la proposition , ils sont linéairement indépendants.    Linéairement dépendants On choisit de procéder avec la définition puisqu'il est possible de voir une combinaison linéaire non triviale directement. Par cette définition, si ces vecteurs sont indépendants, alors la seule façon d'écrire le vecteur nul (déplacement nul) comme combinaison linéaire de sera la combinaison triviale. En remarquant sur la figure que , on peut écrire: . La combinaison linéaire non triviale permet d'écrire le vecteur nul en termes de ces trois vecteurs. Ils sont donc linéairement dépendants. On remarque que même si , cette solution n'est pas la solution triviale où TOUS les coefficients doivent être nuls.    Linéairement indépendants On voit sur la figure que les trois vecteurs mentionnés ne sont pas dans un même plan. Une façon de s'en convaincre est de remarquer que et . En exprimant ainsi ces trois vecteurs à partir de , on voit que et ne sont pas sur un même plan. Par la proposition , ils sont linéairement indépendants.    Linéairement dépendants On peut directement conclure à la dépendance grâce à la proposition . En effet, quatre vecteurs dans , qui est clairement de dimension , n'ont pas d'autre choix que d'être dépendants.  Pour chaque ensemble dépendant de la partie précédente, donner une combinaison linéaire non triviale des vecteurs qui donne le vecteur nul.    On a déjà établi que . Ainsi, on obtient la combinaison non triviale .  On a aussi établi pour un autre ensemble dépendant que .  Finalement, pour l'ensemble dépendant , on doit faire le travail puisqu'on avait utilisé une approche indirecte pour montrer la dépendance. Cependant, en observant que , plusieurs options rapides s'offrent à nous. Comme exemple simple, on donne: .  Exprimer les vecteurs et dans la base .      On exprime chaque vecteur comme une combinaison linéaire des vecteurs de . On le fait en quelques étapes en partant du vecteur initial et en le décomposant, puis en remplaçant par des vecteurs égaux dans .     "
},
{
  "id": "exercise-273",
  "level": "2",
  "url": "sec-bases.html#exercise-273",
  "type": "Exercice",
  "number": "5.2.4.3",
  "title": "",
  "body": " Pour chaque ensemble de vecteurs ci-dessous, montrer que les vecteurs sont linéairement indépendants et forment une base de . Exprimer ensuite le vecteur dans les composantes de la base .   et  Comme à l'exercice , on peut se servir de la définition ou de la proposition . On peut également utiliser la proposition . Au fil des solutions, on utilisera ces différentes options, mais il est possible de toujours procéder de la même manière.  Ici, on voit rapidement que , peu importe la valeur de . En effet, on a . Ainsi, par la proposition , ils sont linéairement indépendants, car ils ne sont pas parallèles.  On exprime dans la base . Donc, on obtient .   et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On résoud ce SEL avec la méthode de Gauss-Jordan. Donc, et l'on obtient . On remarque que la matrice que l'on a d'abord échelonnée pour montrer l'indépendance est la même que pour trouver la combinaison linéaire. On aurait donc pu montrer l'indépendance en même temps que l'on aurait pu trouver la combinaison linéaire. Pour plus de clarté, on continue à séparer les deux étapes dans les prochaines solutions.  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient .  et  On décide d'utiliser la proposition . La matrice des vecteurs en colonnes est : et sa forme échelonnée réduite est : . Cette matrice étant de rang , ce qui est égal au nombre de vecteurs donnés, ces vecteurs sont linéairement indépendants.  On exprime dans la base . On solutionne ce SEL avec la méthode de Gauss-Jordan. Donc, et on obtient . "
},
{
  "id": "exo-unveclinind",
  "level": "2",
  "url": "sec-bases.html#exo-unveclinind",
  "type": "Exercice",
  "number": "5.2.4.4",
  "title": "",
  "body": "Montrer qu'un vecteur seul est linéairement indépendant si et seulement si . Soit tel que . On suppose dans un premier temps que est linéairement indépendant. Cela signifie que est la seule valeur pour laquelle . Plus particulièrement, si , tout donnerait le vecteur nul lorsque multiplié par , on doit donc avoir .  On suppose maintenant que . Cette fois, le seul multiple de ce vecteur non nul qui peut donner le vecteur est lorsque . On a donc indépendance linéaire du vecteur avec lui-même. "
},
{
  "id": "exercise-275",
  "level": "2",
  "url": "sec-bases.html#exercise-275",
  "type": "Exercice",
  "number": "5.2.4.5",
  "title": "",
  "body": "On considère une base d'un sous-espace quelconque et un vecteur . Pour chaque ensemble ci-dessous, déterminer s'il forme aussi une base. Si oui, donner les composantes du vecteur dans cette base et si non, expliquer pourquoi. Oui, . On rappelle que, par la définition , les conditions pour qu'un ensemble de vecteurs soit une base sont qu'ils génèrent le sous-espace et qu'ils soient linéairement indépendants. Cependant, par la proposition , il est possible de ne vérifier que l'une de ces deux conditions si l'on a le bon nombre de vecteurs. En effet, puisqu'on sait que est une base et qu'elle ne compte que deux vecteurs, tout autre ensemble contenant exactement deux vecteurs a le potentiel d'être une base. À l'opposé, si un ensemble ne contient pas exactement deux vecteurs, on sait immédiatement que ce n'est pas une base.  Ici, on a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de .  On exprime donc dans cette base en changeant le signe de sa première composante: . Oui, . On a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de . Par la proposition , ils forment une base.  On exprime donc dans cette base en changeant l'ordre des composantes : . Oui, . On a deux vecteurs. On montre rapidement que . En effet, ainsi, les combinaisons linéaires des vecteurs de sont exprimables en fonction des vecteurs de . Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a deux vecteurs. Cependant, on voit rapidement qu'ils sont linéairement dépendants, car ils sont parallèles. Par la définition , ils ne forment pas une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a trois vecteurs. Par la proposition , ils ne forment pas une base, puisque l'on sait que la dimension de cet espace est de deux étant donné que c'est le nombre de vecteurs dans la base donnée initialement. Ces vecteurs sont donc dépendants, ce qui contrevient à une des conditions pour qu'ils forment une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. On a un seul vecteur. Par la proposition , ils ne forment pas une base, puisque l'on sait que la dimension de cet espace est de deux étant donné que c'est le nombre de vecteurs dans la base donnée initialement. Il n'y a donc pas suffisamment de vecteurs pour générer l'espace , celui-ci ne peut en conséquence être une base.  Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Oui, . On a deux vecteurs. On montre qu'ils ne sont pas parallèles. Cette dernière équation impliquerait que les vecteurs de la base originale sont parallèles, ce qui contredirait la condition qu'ils sont linéairement indépendants. Ainsi, et les deux vecteurs de la base sont indépendants. Par la proposition , ils forment une base.  On exprime donc dans cette base en calculant les nouvelles composantes ainsi: . Non. Bien qu'on ait deux vecteurs, plusieurs conditions ne sont pas satisfaites pour qu'ils forment une base. D'abord, il est impossible que cet ensemble génère un espace de dimension deux puisque le seul vecteur pour lequel les combinaisons linéaires permettront un réel déplacement est . Autrement dit, .  De plus, ces vecteurs ne peuvent être linéairement indépendants puisque le vecteur nul est par définition toujours dépendant. En effet, on peut créer une combinaison non triviale en le multipliant par n'importe quelle constante et obtenir un déplacement nul.  "
},
{
  "id": "exercise-276",
  "level": "2",
  "url": "sec-bases.html#exercise-276",
  "type": "Exercice",
  "number": "5.2.4.6",
  "title": "",
  "body": "Dans cet exercice, on s'intéresse à l'indépendance linéaire de vecteurs perpendiculaires.  Soit , un vecteur non nul de et son perpendiculaire. Montrer qu'ils sont linéairement indépendants.   Selon la proposition , deux vecteurs non parallèles sont indépendants.  Soit , deux vecteurs non nuls de tels que . Montrer que et sont linéairement indépendants. Est-ce que la preuve serait différente si les vecteurs étaient dans ?  Du fait que les deux vecteurs sont perpendiculaires (et non nuls), on peut conclure qu'ils sont non parallèles. Toujours selon la proposition , les vecteurs sont indépendants.  Le fait qu'ils soient dans ou dans ne change pas l'argument précédent. Soit , des vecteurs non nuls de tels que dès que , c'est-à-dire des vecteurs perpendiculaires deux à deux. Montrer que l'ensemble est linéairement indépendant. Considérer une combinaison linéaire de ces vecteurs qui donne le vecteur nul et faire le produit scalaire avec chacun des vecteurs et . Soit , une combinaison linéaire de ces trois vecteurs qui donne le vecteur nul.  On considère le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  On considère maintenant le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  Finalement, on considère maintenant le produit scalaire de cette combinaison linéaire avec : . Comme , on conclut que si , c'est que .  La seule combinaison linéaire des vecteurs qui donne le vecteur nul est donc la combinaison triviale.  Finalement, soit des vecteurs non nuls de tels que dès que , c'est-à-dire des vecteurs perpendiculaires deux à deux. Montrer que l'ensemble est linéairement indépendant.  On utilise le même argument que dans la partie précédente. Pour , on a . Comme , on conclut que si , c'est que .  La seule combinaison linéaire des vecteurs qui donne le vecteur nul est donc la combinaison triviale.  Montrer que vecteurs perpendiculaires deux à deux dans forment une base de . On sait déjà, par la partie précédente, que ces vecteurs sont indépendants. En vertu de la proposition , ces vecteurs indépendants forment une base. "
},
{
  "id": "exo-solbaseindep",
  "level": "2",
  "url": "sec-bases.html#exo-solbaseindep",
  "type": "Exercice",
  "number": "5.2.4.7",
  "title": "",
  "body": " Soit , une matrice telle que l'équation possède des solutions non triviales et soit les solutions de base à cette équation. Montrer que les vecteurs sont linéairement indépendants.  Soit , une combinaison linéaire des solutions de base donnant le vecteur nul. Soit , l'indice de la variable libre correspondant à la solution . Par définition , l'entrée de vaut et l'entrée des autres vecteurs est . La seule manière d'obtenir que la composante de la combinaison linéaire soit égale à est de prendre .  Par un argument similaire, on montre qu'on doit avoir . Les vecteurs sont donc indépendants.  "
},
{
  "id": "exercise-278",
  "level": "2",
  "url": "sec-bases.html#exercise-278",
  "type": "Exercice",
  "number": "5.2.4.8",
  "title": "",
  "body": "Soit , des vecteurs non nuls perpendiculaires deux à deux de et soit un vecteur quelconque. En considérant d'abord les vecteurs , décrire en mots comment obtenir les composantes de . Commencer par réfléchir au cas et faire un dessin. On devrait obtenir que la composante corresponde dans une certaine mesure à la projection orthogonale du vecteur sur le vecteur .  Montrer que les composantes de dans la base sont ce qui a été déterminé dans la partie précédente. Puisque les vecteurs sont perpendiculaires, utiliser le produit scalaire avec l'écriture de dans la base pour déterminer les coefficients de la combinaison linéaire. Le coefficient de la combinaison linéaire vaut Soit , l'écriture de dans la base des vecteurs . On considère le produit scalaire de dans cette écriture avec le vecteur . On a . On a donc . Puisque , on peut isoler le coefficient pour avoir . Ce facteur correspond au coefficient devant le vecteur lorsqu'on fait la projection orthogonale de sur .  De la même manière, on obtient .  "
},
{
  "id": "exercise-279",
  "level": "2",
  "url": "sec-bases.html#exercise-279",
  "type": "Exercice",
  "number": "5.2.4.9",
  "title": "",
  "body": "Soit , une base de et soit , la matrice d'une transformation linéaire. Donner un exemple de vecteurs et de matrice pour lesquels n'est pas une base. Un exemple dans à partir des vecteurs suffit.  On prend et . Comme cette matrice possède des colonnes identiques, on a que les vecteurs sont envoyés sur , ce qui fait que et ne peuvent pas être une base de .  Si est une matrice carrée inversible, montrer que l'ensemble est une base de . Comme il y a vecteurs, il suffit de montrer qu'ils sont linéairement indépendants et d'utiliser la proposition . Soit , une combinaison linéaire des vecteurs transformés qui donne le vecteur nul. On peut mettre la matrice en évidence pour avoir . Par hypothèse, la matrice est inversible, l'unique solution à cette équation matricielle est donc .  De plus, comme les vecteurs sont une base de , ils sont indépendants ainsi, la seule combinaison de ces vecteurs qui donne le vecteur nul est la combinaison triviale. On a donc et l'on conclut que les vecteurs forment aussi une base de . "
},
{
  "id": "exercise-280",
  "level": "2",
  "url": "sec-bases.html#exercise-280",
  "type": "Exercice",
  "number": "5.2.4.10",
  "title": "",
  "body": "Soit , une matrice . Montrer que si est un ensemble indépendant, alors est aussi indépendant. Soit , une combinaison linéaire donnant le vecteur nul. On multiplie chaque côté de cette équation par la matrice . On obtient .  Puisque les vecteurs sont indépendants par hypothèse, on doit avoir que . Les vecteurs sont donc aussi indépendants. "
},
{
  "id": "exercise-281",
  "level": "2",
  "url": "sec-bases.html#exercise-281",
  "type": "Exercice",
  "number": "5.2.4.11",
  "title": "",
  "body": "Soit , une matrice de rang et soit , des vecteurs linéairement indépendants. Montrer que les vecteurs sont aussi linéairement indépendants. Expliquer en quoi le rang est nécessaire. Soit , une combinaison linéaire donnant le vecteur nul. On met la matrice en évidence . Puisque le rang de la matrice est , toutes les variables sont pivots. Il y a donc une solution unique à cette équation, qui doit être le vecteur nul. On a donc . Comme les vecteurs sont indépendants, la seule combinaison linéaire donnant le vecteur nul est celle où . Les vecteurs sont aussi linéairement indépendants. "
},
{
  "id": "exercise-282",
  "level": "2",
  "url": "sec-bases.html#exercise-282",
  "type": "Exercice",
  "number": "5.2.4.12",
  "title": "",
  "body": "Soit , un ensemble de vecteurs linéairement dépendants et soit . Montrer que peut s'écrire d'une infinité de manières comme combinaison linéaire des vecteurs .  Soit , la matrice de taille qui contient les vecteurs en colonne. On cherche le nombre de solutions à l'équation , puisque cette équation représente les combinaisons linéaires des colonnes de la matrice . Selon la proposition , la matrice n'est pas de rang , car ses colonnes sont des vecteurs dépendants. Ainsi, il y a au moins une variable libre dans la forme échelonnée réduite de la matrice . Puisque , on sait qu'il doit exister des solutions à l'équation . Le fait que le rang ne soit pas égal à confirme qu'il y en a une infinité.  "
},
{
  "id": "exercise-283",
  "level": "2",
  "url": "sec-bases.html#exercise-283",
  "type": "Exercice",
  "number": "5.2.4.13",
  "title": "",
  "body": " Soit , un ensemble de vecteurs linéairement indépendants et soit , des vecteurs de cet ensemble, où . Montrer que les vecteurs sont aussi linéairement indépendants.   Soit , une combinaison linéaire de ces vecteurs qui donnent le vecteur nul. Soit , les vecteurs dans l'ensemble qui ne sont pas dans le sous-ensemble . On peut alors écrire . On a alors une combinaison linéaire de tous les vecteurs de qui donne le vecteur nul. Comme l'ensemble est un ensemble linéairement indépendant, il s'ensuit que les coefficients sont tous nuls.  "
},
{
  "id": "exercise-284",
  "level": "2",
  "url": "sec-bases.html#exercise-284",
  "type": "Exercice",
  "number": "5.2.4.14",
  "title": "",
  "body": "Déterminer la dimension des sous-espaces suivants.    On considère l'équation matricielle afin de déterminer si des vecteurs s'écrivent comme une combinaison linéaire des autres vecteurs. On utilise Sage pour réduire le système.   Il y a une variable libre et donc, une solution de base, qui est . Cela signifie que . En isolant par exemple , on a que et que ces trois vecteurs sont indépendants. La dimension est donc égale à .  On convertit le système d'équations linéaires sous la forme matricielle. Le sous-espace vectoriel correspondant aux solutions de l'équation est le sous-espace de l'énoncé. On utilise Sage pour réduire la matrice.   Cette fois, il y a deux solutions de base. Comme ici on cherche la dimension des solutions à l'équation , on obtient .  On peut réfléchir géométriquement dans ce cas. Les vecteurs sont non parallèles et forment un plan dans . Géométriquement, on sait que le complément orthogonal d'un plan dans est une droite dont le vecteur directeur correspond au vecteur normal du plan. La dimension de ce sous-espace est donc de .   Cette fois, on ne peut pas (encore du moins) s'appuyer sur la géométrie pour répondre à la question. Soit , un vecteur dans le complément orthogonal de l'ensemble . On a alors . Toujours avec Sage, on échelonne la matrice associée à ce système.   Deux variables libres, ce qui signifie que la dimension de l'espace solution à ces équations est égale à .  "
},
{
  "id": "exercise-285",
  "level": "2",
  "url": "sec-bases.html#exercise-285",
  "type": "Exercice",
  "number": "5.2.4.15",
  "title": "",
  "body": "Donner une preuve alternative de la proposition en utilisant la proposition .  Soit , des vecteurs linéairement indépendants et soit , un vecteur dans . On s'intéresse au nombre de solutions à l'équation . On peut décortiquer toutes les solutions à cette équation comme selon la proposition , où est une solution correspondant à une écriture possible du vecteur dans la base des vecteurs , et est l'ensemble de toutes les solutions à l'équation homogène .  Puisque par hypothèse , on conclut que toute solution est égale à et que la solution est unique.  "
},
{
  "id": "exo-depnbr",
  "level": "2",
  "url": "sec-bases.html#exo-depnbr",
  "type": "Exercice",
  "number": "5.2.4.16",
  "title": "",
  "body": " Soit , un sous-espace vectoriel et des vecteurs tels que . Montrer que tout ensemble contenant vecteurs de sera linéairement dépendant.   Soit , des vecteurs dans . Puisque , on peut écrire chaque vecteur comme une combinaison linéaire des vecteurs . Ainsi, on a pour chaque vecteur avec .  On a donc une liste de coefficients. Soit , la matrice de ces coefficients. Puisque , l'équation matricielle possède une infinité de solutions. Soit , une de ces solutions différentes de . On montre que ce vecteur fournit les coefficients nécessaires pour avoir une combinaison linéaire non triviale des vecteurs qui donne le vecteur nul.  En effet, on a . Ainsi, on a une combinaison linéaire non triviale qui donne le vecteur nul. Les vecteurs sont dépendants.  "
},
{
  "id": "sec-4esp",
  "level": "1",
  "url": "sec-4esp.html",
  "type": "Section",
  "number": "5.3",
  "title": "Retour sur les quatre sous-espaces fondamentaux",
  "body": "  Retour sur les quatre sous-espaces fondamentaux    Aller aux exercices de la section.  Dans la section , on définit les quatre sous-espaces fondamentaux d'une matrice. À la sous-section , on a ensuite montré que ces ensembles sont des sous-espaces vectoriels et qu'il existe une relation de complément orthogonal entre certains de ces ensembles pris deux à deux.  Dans cette section, on cherche à établir une base et la dimension de chacun de ces sous-espaces. On donne une marche à suivre pour trouver une base pour les quatre sous-espaces d'une matrice. On définit également une importante relation entre la dimension des sous-espaces fondamentaux qui sont compléments orthogonaux.    Une base pour les sous-espaces fondamentaux  On débute cette section avec la recherche d'une base pour les quatre espaces fondamentaux. À partir de là, on pourra obtenir la dimension de chaque espace directement en comptant le nombre de vecteurs dans la base trouvée.   Une base pour l'espace ligne et une base pour l'espace nul   Soit , une matrice et soit , sa forme échelonnée réduite. Alors  Les lignes non nulles de forment une base de ;  Les solutions de base à l'équation sont une base de l'espace nul.     Les lignes de sont nécessairement indépendantes, puisqu'en regardant les positions pivots, la seule manière d'obtenir le vecteur nul avec une combinaison linéaire est de prendre zéro fois chaque ligne. Puisque les lignes nulles de ne contribuent pas à , on a que est égal au span des lignes non nulles de . Comme elles sont indépendantes, elles forment une base en vertu de la proposition .  De plus, puisqu'on obtient à partir de par une suite d'opérations élémentaires, toutes réversibles, les lignes de peuvent s'écrire comme une combinaison linéaire des lignes de . Ceci entraine que . Les lignes de forment donc une base pour l'espace ligne de .   Tout vecteur dans peut bien sûr s'écrire comme une combinaison linéaire des solutions de base par construction de celles-ci. Ainsi, elles engendrent . De plus, l'exercice montre que les solutions de bases sont indépendantes. Elles forment donc bel et bien une base de l'espace nul.   Afin de déterminer si un ensemble de vecteurs est indépendant ou non, on sait déjà qu'on pouvait utiliser le rang . Si jamais les vecteurs ne sont pas indépendants, la proposition permet de trouver une base de leur espace engendré.   Base de l'espace ligne   On considère la matrice et l'on cherche une base de son espace ligne. On cherche aussi la dimension de l'espace ligne.    On utilise Sage pour échelonner la matrice et trouver la base.   Une base pour est . La dimension de l'espace ligne est et c'est un sous-espace vectoriel de .    Puisque et que l'espace nul gauche est défini avec la transposée, on pourrait appliquer le résultat de la proposition pour obtenir une base de ces espaces. On propose toutefois une alternative directe avec la matrice . On aura besoin du résultat suivant, qui sera démontré dans les exercices.   L'espace nul de la transposée d'une matrice échelonnée réduite   Soit , une matrice de rang qui est échelonnée réduite et soit , les vecteurs de la base standard de . Alors une base possible pour l'espace nul gauche est .    Voir l'exercice .     Une base pour l'espace colonne et l'espace nul gauche   Soit , une matrice , sa forme échelonnée réduite et soit , une matrice telle que (la matrice correspond à la multiplication de matrices élémentaires permettant d'échelonner ). Alors  Les colonnes pivots de (celles qui sont pivots dans ) forment une base de ;  Les lignes de qui sont aux mêmes positions que les lignes nulles de forment une base de l'espace nul gauche.     Soit , l'indice des colonnes de contenant un pivot, avec . Soit , les colonnes de correspondant à ces positions. On veut montrer que ces colonnes forment une base de .  D'abord la question de l'indépendance. Soit tels que . On pose , le vecteur qui a une valeur en position si et qui vaut aux positions . Le vecteur est donc une solution à l'équation . Par le fait même, on a . Ceci entraine que , où est la -ème colonne de . Puisque, par définition, celles-ci sont pivots, ces colonnes ne contiennent qu'un et des zéros partout ailleurs. On conclut que et que les colonnes de qui correspondent aux positions pivots de sont indépendantes.  Il reste à montrer que ces colonnes engendrent . Évidemment, . Si l'on montre que les colonnes qui ne sont pas pivots peuvent s'écrire comme une combinaison linéaire des colonnes pivots, alors on pourra les retirer du et il ne restera dans celui-ci que les colonnes pivots.  Dans la matrice , on a vu comment lire les solutions de base à partir des colonnes qui ne sont pas pivots. Ces solutions de base offrent une solution à l'équation . Elles donnent une combinaison linéaire de la colonne libre ainsi que des colonnes pivots à sa gauche donnant le vecteur nul. Puisque l'équation possède les mêmes solutions que l'équation , on obtient aussi une combinaison linéaire des colonnes correspondantes dans qui donne le vecteur nul. En isolant la colonne correspondant à la colonne libre, on voit qu'elle s'écrit comme une combinaison linéaire des colonnes pivots.  On a donc bel et bien que , les colonnes pivots de .    Finalement, on veut montrer que les lignes de qui sont aux mêmes positions que les lignes nulles de forment une base pour l'espace nul gauche. La matrice est la matrice obtenue en multipliant chaque matrice élémentaire transformant en . Chaque matrice élémentaire étant inversible, leur produit l'est aussi, comme indiqué à la proposition (sa généralisation). Les lignes de sont donc indépendantes, plus particulièrement celles qui correspondent aux lignes nulles de . Il reste à montrer que ces lignes engendrent l'espace nul gauche.  L'espace nul gauche est consistué de l'ensemble des vecteurs tels que . Puisque , on réécrit en vertu des propriétés de la transposée . On a donc . On conclut que . Selon le lemme , l'espace nul de est engendré par les derniers vecteurs de la base standard de , où est le rang de . Le vecteur est donc une combinaison linéaire de ces vecteurs. Si l'on isole dans l'équation , on obtient . Puisque est une combinaison linéaire des derniers vecteurs de la base standard, le vecteur est une combinaison linéaire des dernières colonnes de et donc, aux lignes de . Ce sont exactement ces lignes qui correspondent aux lignes nulles de . Ceci montre que les lignes de forment une base pour .    Dans la pratique, il est souvent plus simple de déterminer une base de l'espace nul gauche de en considérant directement l'espace nul de sa transposée, mais la proposition donne une manière différente à partir de et de son processus d'échelonnage. On montre tout de même un exemple complet utilisant les propositions et .   Une base des quatre espaces fondamentaux d'une matrice   On considère la matrice . On cherche une base pour les quatre espaces fondamentaux.   On commence par échelonner la matrice en gardant bien en vue les opérations élémentaires effectuées dans le but de créer la matrice . . À chaque opération élémentaire correspond une matrice élémentaire. On a . Finalement, , que l'on calcule avec Sage.   Selon la proposition , l'espace ligne est engendré par les lignes non nulles de . On a donc . Toujours selon cette proposition, l'espace nul est engendré par les solutions de base à l'équation qui se trouvent à même la matrice , comme indiqué à l'exemple . On a donc .  Selon la proposition , l'espace colonne est engendré par les colonnes de qui correspondent aux colonnes pivots de sa forme échelonnée réduite . On a donc . Toujours selon cette proposition, l'espace nul gauche est engendré par les lignes de la matrice qui correspondent aux lignes nulles de la matrice . On a donc .    On a déjà observé la relation de complément orthogonal des sous-espaces fondamentaux à la proposition . Toutefois, les sous-espaces fondamentaux gagnent en importance par le lien entre leur dimension et l'espace dans lequel ils vivent.   La dimension des quatre espaces fondamentaux  Soit , une matrice de rang . Alors  ;  ;  .    Plus particulièrement, on remarque que la somme des espaces ligne et nul, qui sont des sous-espaces de , donne et que la dimension des espaces colonne et nul gauche, qui sont des sous-espaces de , donne .    Pour les espaces ligne et colonne, le nombre de vecteurs dans la base correspond respectivement au nombre de lignes non nulles de la forme échelonnée réduite de la matrice et au nombre de colonnes pivots de cette même matrice échelonnée réduite. Dans les deux cas, ce nombre est égal au rang de la matrice. La dimension est donc égale au rang, soit .  Pour l'espace nul, le nombre de vecteurs dans la base correspond au nombre de solutions de base. Celles-ci sont aussi nombreuses qu'il y a de variables libres, soit ( variables moins les qui sont pivots).  Finalement pour l'espace nul gauche, le nombre de vecteurs dans la base correspond au nombre de lignes nulles dans la forme échelonnée réduite. Celles-ci sont en nombre de ( lignes moins les qui contiennent un pivot).    Ensemble, les propositions et donnent le théorème fondamental de l'algèbre linéaire. L'adjectif fondamental de ce théorème n'est pas aussi répandu que son homologue en calcul différentiel et intégral. Il a été caractérisé ainsi pour la première fois par Gilbert Strang, professeur au MIT.   Théorème fondamental de l'algèbre linéaire   Soit , une matrice de rang . Alors  ;  et ;  et .     Le résultat découle des propositions et .    La figure ci-dessous illustre le concept du théorème fondamental de l'algèbre linéaire. Les espaces fondamentaux y sont dessinés comme des plans, mais peuvent bien entendu être d'une dimension quelconque.   Une image du théorème fondamental de l'algèbre linéaire   À gauche, deux rectangles sont dessinés, se touchant en un coin à quatre-vingt-dix degrés. Sur le rectangle supérieur, on peut lire \"dimension r\" et \"espace ligne\". Sur le rectangle inférieur, on peut lire \"espace nul\" et \"dimension n moins r\". À droite un dessin similaire est présent, avec sur le rectangle supérieur les mots \"dimension r\" et \"espace colonne\" alors que sur le rectangle inférieur on peut lire les mots \"espace nul gauche\" et \"dimension m moins r\".     Pour voir une application concrète de ce théorème, on considère le problème familier suivant dans . On a un plan dans l'espace et un point qui n'appartient pas au plan. On aimerait connaitre le point sur le plan qui est le plus près de . Ce point est le même que celui à la figure . On peut déjà le trouver grâce à la projection orthogonale. Si l'on voulait toutefois résoudre le même problème, mais pour un sous-espace de dimension 5 dans , la méthode de la projection orthogonale ne fonctionnerait pas parce qu'il y aurait plus qu'une direction perpendiculaire. On regarde donc ce problème à nouveau avec les concepts des espaces fondamentaux.   Le point le plus proche  On considère le plan engendré par les vecteurs et ainsi que le point . On cherche le point sur le plan qui est le plus près de .   On commence par former la matrice dont les colonnes sont les vecteurs directeurs du plan: . Puisque le point sur le plan le plus proche du point est un point pour lequel le vecteur est perpendiculaire au plan, on peut déduire du théorème que ce vecteur est dans l'espace nul gauche de la matrice , pour laquelle le plan représente l'espace colonne. Il faut donc que soit dans l'espace nul gauche ou, de façon équivalente, il faut que .  Pour progresser, on remarque que, comme le point est sur le plan, il doit nécessairement exister un vecteur tel que . Ainsi, .  Concrètement, on peut calculer toutes ces matrices et obtenir un système simple à résoudre. On utilise Sage pour faire ces calculs.   Le point est donc obtenu en trouvant la valeur du vecteur pour lequel . Ce système se résout facilement à l'aide de n'importe quelle méthode des chapitres précédents. Avec Sage:   Le point est finalement obtenu en utilisant ce vecteur et la matrice : .    Ce dernier exemple peut sembler long et fastidieux, surtout que les outils de la section permettaient une résolution beaucoup plus rapide. En regardant attentivement la démarche de l'exemple , on peut déduire une méthode générale pour ce genre de problème qui est fondamentale en statistique et en informatique (apprentissage profond et intelligence artificielle): la méthode des moindres carrés. Elle sera présentée plus en détail dans le chapitre .  On termine avec des commandes Sage en lien avec la sous-section.   Base des quatre espaces sur Sage  Dans la section , on a introduit des commandes permettant de trouver une base des espaces fondamentaux sans avoir défini au préalable la notion de base. Ceci a été fait à l'exemple calculatoire . On reprend ici ces commandes avec la notion de base maintenant bien définie.  Les commandes pour les espaces ligne, colonne, nul et nul gauche sont respectivement row_space().basis(),column_space().basis(),right_kernel(basis=\"pivot\").basis(),left_kernel(basis=\"pivot\").basis() . On les utilise pour retrouver la base de chacun des quatre espaces de l'exemple .   À noter que pour l'espace colonne, Sage ne retourne pas la base prescrite par la proposition . En fait, il préfère trouver une base de l'espace ligne de . On peut toutefois créer une fonction retournant la base suggérée par la proposition grâce à la fonction pivots() . C'est l'objet de l'exercice .     Quelques résultats supplémentaires  À la proposition , on a montré que si est un sous-espace vectoriel, alors . On peut se demander si la relation entre les dimensions d'un sous-espace quelconque et son complément orthogonal est aussi complémentaire à l'espace sous-jacent.   La dimension du complément orthogonal  Soit , un sous-espace vectoriel de dimension . La dimension de son complément orthogonal est .   Si , alors et le complément orthogonal de est . La dimension est bien .  Si , alors selon la proposition , on peut trouver une base engendrant . On crée une matrice ligne avec ces vecteurs. Par construction, l'espace ligne de la matrice correspond à et est de dimension , puisque les vecteurs sont indépendants. Selon le théorème , l'espace nul de (qui est le complément de ) est de dimension .    Dans l'espace à deux dimensions, les seuls sous-espaces non triviaux sont les droites passant par l'origine. Dans le cas d'une de ces droites, avec vecteur directeur , son complément orthogonal est aussi une droite passant par l'origine avec vecteur directeur qui lui est perpendiculaire ( . N'importe quel vecteur de peut s'écrire comme une combinaison linéaire de et . Dans l'espace à trois dimensions, on peut ajouter les plans passant par l'origine comme sous-espace non trivial. Puisque le complément orthogonal d'un plan est la droite ayant comme vecteur directeur le vecteur normal du plan, et que les deux vecteurs directeurs du plan et ce vecteur normal forment une base, il s'avère que l'on peut écrire n'importe quel vecteur de comme la somme d'un vecteur du plan et de son complément orthogonal. Ce résultat est aussi valide pour les autres espaces vectoriels. Il est illustré à la figure et est l'objet de la prochaine proposition.   Décomposition d'un vecteur selon un sous-espace et son complément orthogonal   Un sous-espace vectoriel V est illustré sous la forme d'un plan. Son complément orthogonal est aussi présent, sous la forme d'une droite. On y voit trois vecteurs, l'un dans V, un autre dans le complément et le troisième est quelconque. On peut voir la décomposition de ce troisième vecteur comme la somme des deux autres grâce à des lignes pointillées.      Décomposition d'un vecteur par rapport à des sous-espaces orthogonaux   Soit , un sous-espace vectoriel. Alors n'importe quel vecteur de peut s'écrire de manière unique comme la somme d'un vecteur dans et d'un vecteur dans . Ceci implique en particulier que se \"décompose\": .    Si la dimension de est , alors son complément orthogonal est et il s'ensuit que tout vecteur peut s'écrire comme . La situation est similaire si .  Soit , la dimension de . Selon le théorème , la dimension de est . Pour chacun de ces sous-espaces vectoriels, on peut trouver une base. Soit , une base pour et , une base pour . On souhaite montrer que ces vecteurs génèrent . Cela entrainera que tout vecteur peut s'écrire comme une combinaison linéaire de cet ensemble. La partie de la combinaison linéaire avec les premiers vecteurs sera dans et l'autre partie dans . Pour l'unicité, cela découle du fait que les vecteurs forment une base, puisqu'on aura vecteurs indépendants dans .  Pour montrer l'indépendance des vecteurs, on suppose que l'on connait une combinaison linéaire donnant le vecteur nul: . On peut réécrire cette équation en séparant les vecteurs dans et pour avoir . Comme le membre de droite s'écrit comme une combinaison linéaire de vecteurs dans et que est un sous-espace vectoriel, il faut que le membre de droite soit aussi dans . Par contre, le membre de droite est une combinaison linéaire de vecteurs dans et doit donc être dans . Le seul vecteur commun à et est le vecteur nul. On obtient ainsi . Comme les vecteurs forment une base de , il faut que les coefficients soient tous égaux à zéro. De même, les vecteurs formant une base de , les coefficients sont aussi nuls.     Un commentaire additionnel  La proposition dit que deux sous-espaces orthogonaux \"décomposent\" l'espace en deux parties. Cela ne signifie toutefois pas que tous les vecteurs de sont soit dans ou soit dans . En effet, si, par exemple, on prend un vecteur et , alors le vecteur n'est ni dans , ni dans . La figure illustre ceci avec les quatre sous-espaces fondamentaux.    Décomposition d'un vecteur selon des sous-espaces orthogonaux  Afin d'illustrer la proposition , on décompose le vecteur en une composante provenant de et son complément orthogonal.   On commence par trouver une base pour le complément orthogonal. Si l'on pose , alors correspond à l'espace ligne de cette matrice et son complément orthogonal est l'espace nul. On peut y trouver une base avec Sage.   Donc, . Pour exprimer le vecteur en fonction de la base générée par , on met les quatre vecteurs dans une matrice colonne et l'on utilise Sage à nouveau pour échelonner la matrice augmentée du vecteur .   Ainsi, le vecteur peut s'écrire comme . La composante de qui fait partie du sous-espace est donc et la composante faisant partie du complément orthogonal est .    Avec les quatre espaces fondamentaux, la décomposition est particulièrement intéressante. On considère une matrice de taille quelconque. Tout vecteur peut s'écrire comme une somme avec et , en vertu de la proposition . Quel est l'effet de la matrice sur le vecteur ? La décomposition combinée à la linéarité de la multiplication matrice vecteur donne la réponse. La composante de provenant de l'espace nul est envoyée sur le vecteur nul et la composante provenant de l'espace ligne est envoyée dans l'espace colonne. Cela signifie que, bien que le domaine de la transformation linéaire soit au complet, il est seulement utile de connaitre l'image de l'espace ligne pour connaitre l'image de la transformation. On bonifie l'image de la figure afin d'illustrer l'effet d'une matrice comme fonction de vers .   Décomposition orthogonale et quatre espaces fondamentaux   Une reproduction des quatre espaces fondamentaux est faite comme celle d'une image précédente. Sur celle-ci est ajouté un point à gauche, décomposé en deux morceaux, l'un sur le rectangle représentant l'espace ligne et l'autre sur le rectangle représentant l'espace nul. Des flèches représentant l'effet d'une matrice A sur ces morceaux sont tracés. Le vecteur x et celui dans l'espace ligne sont envoyés dans le rectangle de l'espace colonne à droite alors que celui dans l'espace nul est envoyé à l'intersection des rectangles à droite.     Avec ces nouvelles notions, on peut augmenter une fois de plus les conditions équivalentes du théorème de la matrice inverse, qui découle du théorème fondamental de l'algèbre linéaire.   Théorème de la matrice inverse, cinquième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots;  La forme échelonnée réduite de est la matrice identité;  Aucune ligne n'est une combinaison linéaire des autres lignes;  Aucune colonne n'est une combinaison linéaire des autres colonnes;  Le déterminant de la matrice est non nul;  L'espace colonne est de dimension ;  L'espace ligne est de dimension ;  L'espace nul est de dimension ;  L'espace nul gauche est de dimension .       La géométrie de la transposée et un retour sur l'inverse à gauche et à droite  Lorsqu'on a introduit la transposée à la section , on l'a fait par besoin algébrique pour la suite, sans avoir tous les outils nécessaires à la compréhension de sa géométrie. Une matrice de taille est une fonction de vers . Le et la proposition disent que la matrice décompose le domaine et l'ensemble d'arrivée en deux sous-espaces dont les dimensions sont complémentaires et que chaque vecteur de l'espace peut-être écrit comme la somme de vecteurs dans chacun de ces sous-espaces. On considère les deux transformations linéaires et . La matrice envoie tous les vecteurs de (son espace nul) sur le vecteur et la matrice envoie tous les vecteurs de (aussi son espace nul) sur le vecteur . Qui plus est, la dimension des espaces colonnes et lignes de la matrice est la même et l'on a bien sûr que et . Tout ceci suggère que envoie son espace ligne sur l'espace colonne et envoie l'espace colonne de sur son espace ligne. On pourrait (à tort) penser que la transposée doit alors être l'inverse de la matrice . En se rappelant la remarque , il peut exister des vecteurs en dehors de l'espace ligne ou de l'espace nul, mais qui s'écrivent comme combinaison linéaire de vecteurs dans ces espaces. Comme le montre la figure , deux vecteurs peuvent être envoyés sur le même vecteur dans l'espace colonne. En général, la transposée ne retournera même pas le vecteur sur la composante provenant de l'espace ligne. On a toutefois le résultat suivant.   Relation entre et  Soit , une matrice . Pour chaque vecteur dans l'espace colonne , il existe un unique vecteur dans l'espace ligne de tel que .   Soit , la dimension de l'espace ligne et de l'espace colonne et soit , une base de l'espace ligne. Dans ce cas, les vecteurs sont tous dans . Si l'on montre qu'ils sont indépendants, ils formeront alors une base de . On considère une combinaison linéaire de ces vecteurs donnant le vecteur nul: . En mettant la matrice en évidence, on obtient que et que la combinaison linéaire est dans l'espace nul de la matrice . Or comme les vecteurs sont une base pour l'espace ligne et que celui-ci est un sous-espace vectoriel, la combinaison linéaire est aussi dans l'espace ligne. Le seul vecteur qui est à la fois dans l'espace ligne et l'espace nul étant le vecteur nul, on conclut que . Ceci entraine à son tour que les coefficients sont tous nuls, puisque les vecteurs sont indépendants. Ainsi, la seule combinaison linéaire des vecteurs donnant le vecteur nul étant celle où tous les coefficients sont nuls, on peut conclure que ces vecteurs sont aussi indépendants et, puisque la dimension de l'espace colonne est , ils forment une base de cet espace.  On considère maintenant un vecteur . Puisque forment une base de l'espace colonne, il existe une unique manière d'écrire comme une combinaison linéaire de ces vecteurs: , où . La preuve que ce vecteur est unique est faite dans l'exercice .    Lorsque la matrice est carrée, on connait une multitude d'équivalences pour déterminer si la matrice est inversible ou non. Celles-ci sont répertoriées dans le théorème . À la section , on a brièvement mentionné la notion d'inverse à gauche et d'inverse à droite pour les matrices rectangulaires, notamment au théorème . Le théorème fondamental de l'algèbre linéaire permet d'apporter un autre point de vue sur la non-existence des inverses. En effet, si une matrice est de taille avec , alors l'espace nul gauche de la matrice est de dimension supérieure ou égale à . Cela entraine que l'équation peut ne pas avoir de solution si le vecteur se trouve dans l'espace nul gauche. On ne peut donc pas inverser à gauche la matrice et écrire . De la même manière, si la matrice est de taille avec et possède un inverse à droite , alors est un inverse à gauche pour , puisque . Le même argument appliqué à la matrice signifie que, parce que l'espace nul de est de dimension plus grande ou égale à , l'équation peut ne pas avoir de solution si le vecteur se trouve dans l'espace colonne de , ou de façon équivalente dans l'espace ligne de .  On a des conditions pour la non-existence des inverses des matrices rectangulaires, mais qu'en est-il pour leur existence? Tout est basé sur le rang, le nombre de pivots ou encore la dimension des espaces lignes et colonne. Une matrice de taille peut avoir pour rang maximal la valeur minimale entre et . Il ne peut pas y avoir plus de pivots qu'il y a de lignes ou de colonnes, la plus petite de ces dimensions. Pour trouver un inverse à droite, il faut une matrice de taille telle que . La matrice multiplie chaque colonne de pour avoir l'identité. Il faut donc que les colonnes de l'identité soient dans l'espace colonne. Si le rang de la matrice est , alors . Si, au contraire, on cherche un inverse à gauche, c'est-à-dire une matrice de taille telle que , alors un argument utilisant l'équation et l'idée ci-dessus montre que si le rang de la matrice est , c'est-à-dire maximal pour les colonnes, on aura une solution.  Ces idées sont résumées dans la proposition ci-dessous.   L'existence d'inverse à gauche et à droite  Soit , une matrice de taille avec rang .  Si , alors, il existe une inverse à droite;  Si , alors, il existe une inverse à gauche.     Dans le cas où le rang est égal au nombre de lignes, on peut trouver colonnes pivots qui sont indépendantes et génèrent . On voit qu'il y a toujours une solution à l'équation , puisque l'espace colonne est au complet. On peut donc trouver une matrice inverse en résolvant les équations matrices vecteurs et placer ces vecteurs dans les colonnes d'une matrice .  Dans le cas où le rang est égal au nombre de colonnes, la dimension de l'espace ligne est donc égale à . En regardant la transposée de la matrice , on déduit que celle-ci possède un inverse à droite. L'équation dit alors que celui-ci est un inverse à gauche pour la matrice .     Quelques précisions sur les inverses  Il faut noter que, contrairement à l'inverse d'une matrice carrée , qui est unique, une matrice rectangulaire peut, si elle en a, avoir plusieurs inverses à gauche et à droite. De plus, l'équation est liée à la notion d'inverse lorsque la matrice est carrée. Si la matrice est inversible, alors il existe une solution unique donnée par . Dans le cas d'une matrice rectangulaire, l'existence d'un inverse à droite implique qu'une solution existe toujours. En effet, puisque , on a que . Ainsi est une solution. Par contre, cette solution n'est peut-être pas unique. Si un autre inverse existe, il pourrait mener à une solution différente. Si la matrice possède plutôt un inverse à gauche, alors là la solution, si elle existe, sera unique. D'une part, si est un inverse à gauche, alors est une solution puisque et donc . De plus, si est un inverse à gauche différent de , alors par le même raisonnement, est aussi une solution. Or on a . Il est toutefois possible que le vecteur ne soit pas dans l'espace colonne et qu'il n'y ait pas de solution.  En résumé, pour une matrice de rang , l'équation possède ou une infinité de solutions, alors que pour une matrice de rang , elle en possède ou une. Lorsque (et que le rang est maximal), la solution ne peut être qu'unique.       Les points importants de cette section sont:  Comment obtenir une base pour l'espace ligne et l'espace nul ;  Comment obtenir une base pour l'espace colonne et l'espace nul gauche ;  La dimension des quatre espaces fondamentaux et le lien avec le rang de la matrice;  Le .  La nouvelle version du théorème de la matrice inverse ;  La relation entre l'espace ligne et l'espace colonne d'une matrice;  Les conditions d'existence pour les inverses à gauche et à droite, détaillées à la proposition .        Exercices  Pour chaque matrice ci-dessous, déterminer une base pour les quatre espaces fondamentaux.   Les réponses peuvent varier.        On peut remarquer que les deux lignes de la matrice sont parallèles. Ceci signifie que l'espace ligne et l'espace colonne seront de dimension . De même, la dimension de l'espace nul et de l'espace nul gauche sera aussi 1. Pour l'espace ligne, on peut prendre n'importe quelle ligne de la matrice : . Similairement, l'espace colonne est engendré par le vecteur . Pour l'espace nul, on utilise le fait que celui-ci est orthogonal à l'espace ligne. Le vecteur engendre l'espace nul. De même, l'espace nul gauche est orthogonal à l'espace colonne. Il sera engendré par .    Les réponses peuvent varier.    : Aucune base.  : Aucune base.    On remarque (par exemple avec le déterminant) que la matrice est inversible. Cela signifie que l'espace nul sera composé du vecteur nul uniquement et que les espaces ligne et colonne seront de dimension et seront au complet. On a alors et . Il n'existe pas de base pour le sous-espace ne contenant que le vecteur nul.     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires .   L'espace ligne est engendré par , l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche par et .     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires .   L'espace ligne est engendré par et , l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et et l'espace nul gauche par .     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par , l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche par et .     Les réponses peuvent varier.     , aucune base.     On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche n'est composé que du vecteur nul et ne possède pas de base.     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche est engendré par .     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche est engendré par .     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par , et , l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par , et et l'espace nul gauche par .   Donner la dimension des quatre espaces fondamentaux d'une matrice ayant les caractéristiques suivantes, ou dire pourquoi une dimension ne peut être donnée. La matrice est de taille et son rang est ;          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. On a donc  ;  ;  ;  .   La matrice est de taille et est inversible;          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. De plus, selon le théorème , une matrice inversible est de rang maximal. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. On a donc  ;  ;  ;  .   La matrice est de taille . Les trois premières colonnes sont, dans l'ordre, les vecteurs et les deux dernières colonnes sont nulles.          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. Comme chaque ligne contient un pivot, la matrice est de rang 3. On a donc  ;  ;  ;  .   La matrice est de taille . Les trois premières colonnes sont, dans l'ordre, les vecteurs et les trois dernières colonnes une copie des trois premières, dans le même ordre.          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. Comme les trois premières lignes contiennent un pivot, la matrice est de rang 3. On a donc  ;  ;  ;  .   La matrice est de taille et toutes les solutions à l'équation sont parallèles au vecteur .          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. De plus, la dimension de l'espace ligne est toujours la même que celle de l'espace colonne. Comme les solutions à l'espace nul sont sur une ligne, la dimension de l'espace nul est .  ;  ;  ;  .     On considère la matrice . Pour chaque situation ci-dessous, donner une matrice de format demandé respectant la condition ou dire pourquoi une telle matrice n'existe pas.   Donner une matrice de taille telle que .  Les réponses peuvent varier. Voici une solution: On commence par déterminer l'espace ligne de la matrice en l'échelonnant.   L'espace ligne est donc à trois dimensions et engendré par les vecteurs . Pour avoir une matrice de format qui produira un espace colonne égal à l'espace ligne de , on peut prendre une matrice dont trois des colonnes sont les vecteurs ci-dessus et les deux autres colonnes sont des combinaisons linéaires de ces mêmes vecteurs. Voici un exemple: .   Donner une matrice de taille telle que .  Impossible C'est impossible, puisque l'espace ligne de la matrice est de dimension . La dimension de l'espace ligne d'une telle matrice pourrait être au maximum .  Donner une matrice de taille telle que .  En regardant les calculs Sage faits précédemment, on constate que l'espace colonne de la matrice est généré par les trois premières colonnes. Pour créer la matrice demandée, il suffit de mettre les trois premières colonnes de comme lignes d'une matrice et d'ajouter une ligne qui est une combinaison linéaire de ces trois premières lignes. Voici un exemple: .  Donner une matrice de taille telle que .  Impossible L'espace colonne de la matrice est un sous-espace vectoriel de . On ne peut l'obtenir à partir de vecteurs dans .  Donner une matrice de taille telle que .  Toujours selon les calculs Sage précédents, le rang de la matrice est . Cela signifie que la dimension de l'espace nul sera égale à selon le . On peut trouver une base de l'espace nul en regardant la solution de base telle que définie à la section . On trouve le vecteur comme générateur de l'espace nul. Pour satisfaire les conditions de taille de la matrice , il suffit de copier ce vecteur ou l'un de ses multiples dans les trois colonnes d'une matrice . Ainsi, fait l'affaire.  Donner une matrice de taille telle que .  L'espace nul de la matrice est engendré par le vecteur . Pour obtenir une matrice dont l'espace ligne sera engendré par ce vecteur, il suffit de le placer comme les quatre lignes d'une matrice. La matrice est un exemple.   Donner une base pour le complément orthogonal de chacun des ensembles de vecteurs suivants.  . Les réponses peuvent varier. Voici une possibilité: . On utilise le fait que les espaces ligne et nul sont orthogonaux et qu'on peut trouver assez facilement une base de ces espaces. En plaçant les deux vecteurs engendrant dans les lignes d'une matrice, on pourra trouver une base de l'espace nul de cette matrice qui sera une base pour du complément orthogonal de .   À partir de ce calcul, on peut trouver les solutions de base pour engendrer l'espace nul. On pose . Ces vecteurs forment une base de .  . Soit , la matrice pour laquelle le système correspond aux conditions caractéristiques du sous-espace . Par définition, les solutions à ce système correspondent à l'espace nul de la matrice et donc, le sous-espace est équivalent à l'espace nul de la matrice . Le complément orthogonal de l'espace nul étant l'espace ligne, on conclut que , puisque la matrice est déjà échelonnée réduite.  À la proposition , on a montré que tout espace vectoriel de dimension plus grande à possédait une base. Voici un processus qui permet de compléter un ensemble de vecteurs indépendants afin de trouver une base d'un espace vectoriel de dimension connue.  On considère les vecteurs de suivants: . L'idée est de créer une matrice dont l'espace colonne sera et dont les colonnes pivots donneront une base qui contiendra les vecteurs . Pour cela, on considère la matrice . Donner une base de contenant les vecteurs .    Il faut échelonner la matrice afin de déterminer les colonnes pivots. On utilise Sage.   En ajoutant les vecteurs aux vecteurs , on obtient une base de .  Répéter avec les vecteurs .  Il faut échelonner la matrice contenant ces trois vecteurs dans les premières colonnes et augmentée de l'identité afin de déterminer les colonnes pivots. On utilise Sage.   En ajoutant les vecteurs aux vecteurs , on obtient une base de .  Expliquer pourquoi ce processus fonctionne pour former une base à partir de vecteurs indépendants de .  En plaçant une copie de la matrice identité dans la matrice créée, on garantit que l'espace colonne de la matrice sera . Puisque les vecteurs sont indépendants, on s'assure qu'ils seront des pivots dans la matrice en les plaçant au début de .   Démontrer le lemme . Si la matrice est de rang , alors l'espace nul gauche est de dimension . Il faut donc trouver vecteurs indépendants qui font partie de l'espace nul gauche pour produire une base, en vertu de la proposition . Les vecteurs sont indépendants puisqu'ils font partie de la base standard de . Si l'on vérifie qu'ils sont dans l'espace nul gauche de , alors il sera démontré qu'ils forment une base. On considère le produit matrice vecteur pour des valeurs de allant de à . Puisque, par définition, est une matrice échelonnée réduite de rang , ses dernières lignes sont nulles. Cela signifie que les dernières colonnes de sont aussi nulles. Or lorsqu'on multiplie une matrice par un vecteur de la forme , on obtient la colonne de la matrice. Ainsi, tous les produits matrice vecteur pour des valeurs de allant de à valent . Ces vecteurs sont tous dans l'espace nul gauche.  À l'exercice , on a montré qu'une matrice de rang peut s'écrire comme . À quoi correspondent les quatre espaces fondamentaux d'une telle matrice en fonction des vecteurs ? Selon la démonstration de l'exercice , on a construit le vecteur afin qu'il représente la première ligne non nulle de la matrice . Puisque est de rang , toutes les lignes sont parallèles à . On peut alors conclure que .  En regardant l'équation , on constate que les colonnes de sont toutes un multiple du vecteur . Il s'ensuit alors que .  En vertu du théorème , on conclut que et que .   Soit . Selon la proposition , il est possible de décomposer tout vecteur de comme la somme d'un vecteur de et d'un vecteur de . Décomposer le vecteur de cette manière. Le vecteur est déjà dans l'espace ligne puisque . On prend donc ce vecteur dans l'espace ligne et le vecteur nul dans l'espace nul. Décomposer le vecteur de cette manière. Dans un premier temps, on calcule le vecteur . Selon l'équation , le produit vectoriel des lignes de est . Puisque ce vecteur est perpendiculaire aux lignes de (par définition du produit vectoriel), on conclut que le vecteur est dans l'espace nul de . On prend donc le vecteur nul comme élément de l'espace ligne pour écrire Décomposer le vecteur de cette manière. La question est équivalente à décomposer le vecteur dans la base de donnée par les vecteurs (les lignes de la matrice ) et le vecteur (le produit vectoriel des deux premiers vecteurs) et de combiner les contributions des vecteurs de l'espace ligne. On place ces trois vecteurs dans une matrice colonne afin de résoudre le système.   On peut donc écrire . En combinant les deux premiers vecteurs, on a avec le vecteur et le vecteur .  Décomposer le vecteur de cette manière. On utilise la même idée qu'au problème précédent. On ajuste les calculs avec Sage en vertu des remarques de l'exemple .   On peut donc écrire . En combinant les deux premiers vecteurs, on a avec le vecteur et le vecteur .   Soit . Décomposer n'importe quel vecteur de comme la somme d'un vecteur dans l'espace ligne et d'un vecteur dans l'espace nul. . On se base sur l'exercice précédent. Les deux lignes de la matrice sont indépendantes. L'espace ligne étant de dimension , l'espace nul le sera aussi. Comme la matrice est déjà sous une forme échelonnée réduite, les solutions de base peuvent s'obtenir directement afin de compléter la base requise. On pose Avec les lignes , on pourra écrire n'importe quel vecteur de comme la somme d'un vecteur de l'espace ligne et d'un vecteur de l'espace nul.   La solution à ce système est . En combinant les vecteurs et les vecteurs , on obtient une décomposition de comme la somme d'un vecteur de l'espace ligne et d'un vecteur de l'espace nul.  Soit . Trouver un vecteur dans tel que . Ceci revient à trouver quelles valeurs de satisfont l'équation matricielle . En distribuant la matrice , cela revient à trouver comment écrire le vecteur en fonction des vecteurs images de chaque ligne. Puisque et , on trouve rapidement . Le vecteur est la solution cherchée. Trouver trois vecteurs de différents de celui trouvé à la partie précédente pour lesquels le produit par la matrice donne aussi . Il suffit d'ajouter au vecteur n'importe quel vecteur de l'espace nul, en vertu de l'équation . Puisque l'espace nul est engendré par les vecteurs , on, a par exemple, ; ; et .  Soit , une matrice et , une matrice . Montrer que l'espace nul de est contenu dans l'espace nul du produit , c'est-à-dire . Soit , un vecteur de l'espace nul de la matrice . On a alors . On doit montrer que ce vecteur est dans l'espace nul de . On a puisque le vecteur nul est toujours envoyé sur le vecteur nul. Montrer que si est une matrice carrée inversible. On sait déjà que . Si l'on montre la relation inverse, c'est-à-dire , on aura démontré le résultat. On a l'hypothèse additionnelle que est une matrice carrée inversible. On commence avec un vecteur . On veut montrer que ce vecteur est aussi dans l'espace nul de la matrice . Le fait que soit dans l'espace nul du produit signifie que . Puisque est inversible, on peut alors écrire , car le vecteur nul ne peut être envoyé que sur le vecteur nul par la matrice . Ainsi, on conclut que est dans l'espace nul de la matrice . Montrer que l'espace colonne du produit est contenu dans l'espace colonne de , c'est-à-dire . On prend un vecteur dans l'espace colonne de la matrice . On veut montrer que ce vecteur est aussi dans l'espace colonne de la matrice , c'est-à-dire qu'il existe tel que . Si est dans l'espace colonne de la matrice , alors il existe pour lequel . On pose . Alors est un vecteur de , car est une matrice . De plus, on a l'équation , ce qui montre que . Montrer que si est une matrice carrée inversible. On sait déjà que . Si l'on montre la relation inverse, c'est-à-dire , on aura démontré le résultat. On a l'hypothèse additionnelle que est une matrice carrée et inversible.  On commence avec un vecteur et l'on veut montrer que ce vecteur est aussi dans l'espace colonne du produit . Il existe donc tel que . On considère ce vecteur et l'équation . Puisque est une matrice inversible, on sait qu'il existe une solution unique à cette équation. On pose . On a alors . Ainsi, le vecteur est dans l'espace colonne du produit .    Soit , une matrice et , une matrice . On s'intéresse maintenant au rang du produit en lien avec les rangs de et de .  Montrer que en utilisant les espaces fondamentaux. On note qu'on a démontré ce résultat à l'exercice Utiliser le résultat de l'exercice et la proposition . Soit , le rang de la matrice . Selon l'exercice , on a . La dimension de l'espace nul est . Selon la proposition , on a alors . Puisque la dimension de est égale à , on a , qui, en réarrangeant et en utilisant , devient . Montrer que si est une matrice carrée inversible, alors . Utiliser l'exercice . Selon l'exercice , si la matrice est inversible, alors . On a donc . À la manière de l'exercice précédent, on obtient , qui devient, en simplifiant, .  Montrer que . Conclure que . Utiliser l'exercice et la proposition . Soit , le rang de la matrice . Selon l'exercice , on a . Comme le rang correspond à la dimension de l'espace colonne, on obtient selon la proposition  . Puisque et , on doit avoir . Montrer que si est une matrice carrée inversible, alors . Utiliser l'exercice . Selon l'exercice , si la matrice est inversible, alors . Il s'ensuit donc de cet exercice que dans ce cas, .   À l'exercice , on a montré que si , alors il n'est pas nécessaire que ou soit la matrice nulle (contrairement aux nombres réels). Dans cet exercice, on donne une condition nécessaire et suffisante sur les matrices pour avoir un produit nul.  Soit , des matrices de formats appropriés. Montrer que si et seulement si .  On doit montrer les deux directions de cette double implication. On commence par montrer que si , alors . Intuitivement, cela signifie que si l'image de la matrice est inclus dans l'espace nul de la matrice , alors le produit sera nul. En fait, ce sont seulement les colonnes de qui doivent faire partie de l'espace nul de , puisque le produit peut être vu comme une matrice dont les colonnes sont données par les produits matrice vecteur pour chaque colonne de la matrice (voir la définition ).  Plus concrètement, si l'on a des matrices telles que , alors, en vertu de la définition , on a .  À l'inverse, si l'on commence avec une matrice dont le produit , on souhaite montrer que l'espace colonne de est inclus dans l'espace nul de . Puisque , on conclut que, pour chaque colonne du produit, on a . Cela signifie que toutes les colonnes de la matrice sont dans l'espace nul de la matrice . Puisque et que le produit matrice vecteur est linéaire, toute combinaison linéaire des colonnes de sera aussi dans l'espace nul de . On a donc .  Si sont deux matrices de taille et de rang , est-ce qu'il est possible que ? Non Si la matrice est de rang , alors son espace colonne est de dimension . Si la matrice est aussi de rang , alors son espace nul est de dimension . Comme on ne peut avoir un espace de dimension inclus dans un espace de dimension , on ne peut avoir , qui est équivalent au produit . Si sont deux matrices de taille et de rang , est-ce qu'il est possible que ? Oui Si la matrice est de rang , alors son espace colonne est de dimension . Si la matrice est aussi de rang , alors son espace nul est de dimension . Comme on peut avoir un espace de dimension inclus dans un espace de dimension , il est possible que , qui est équivalent au produit . Donner deux matrices de rang pour lesquelles . Plusieurs réponses sont possibles. Pour que le produit soit , il faut que l'espace colonne de soit inclus dans l'espace nul de la matrice . On commence avec une matrice de rang arbitraire. Pour cela, il suffit que les lignes soient parallèles. On pose . Géométriquement, l'espace ligne de cette matrice est une droite de vecteur directeur . L'espace nul est donc un plan de vecteur normal . Pour que l'espace colonne de la matrice soit inclus dans cet espace nul, il suffit de prendre comme colonne un vecteur du plan . Le vecteur fera l'affaire. On pose alors . On vérifie avec Sage que le produit de ces matrices donne bien la matrice nulle et qu'elles sont de rang 1.    Soit , une matrice quelconque de taille . Montrer que . Une partie du travail est accompli par l'exercice , pour l'autre partie, montrer que est à la fois dans et . Qu'est-ce que cela signifie? En vertu de l'exercice , on sait déjà que . Comme la matrice n'est pas nécessairement carrée et inversible, on ne peut pas utiliser l'exercice pour conclure. Il faut montrer que si l'on a un vecteur dans , alors ce vecteur est aussi dans .  On prend donc un vecteur dans et l'on s'intéresse au produit . Par définition, le vecteur est dans l'espace colonne de la matrice . De plus, puisque , on a . Ceci signifie que le vecteur est dans l'espace nul de la matrice . Comme l'espace nul de la matrice est par définition l'espace nul gauche de la matrice , on conclut que le vecteur est à la fois dans l'espace colonne de et dans son espace nul gauche. Puisque ces deux espaces sont orthogonaux selon le , le seul vecteur qui peut être simultanément dans ces deux espaces est le vecteur nul. On a donc , ce qui signifie que .  Montrer que . Soit , le rang de et , la dimension de l'espace nul de . En vertu de la partie précédente, c'est aussi la dimension de . On note que la matrice est de taille Selon le théorème fondamental, la dimension de l'espace ligne de la matrice sera aussi de puisqu'on doit avoir . Ainsi, le rang de est égal à celui de . Montrer que . Dans un premier temps, l'espace nul de la matrice correspond à l'espace nul gauche de la transposée . On a donc De plus, puisque la matrice est symétrique (voir l'exercice , en particulier la deuxième partie) et que , on a que l'espace nul gauche et l'espace nul de sont égaux. Cela entraine que . Selon la première partie de cet exercice, , ce qui entraine par le théorème fondamental que . En vertu des remarques précédentes, on a .  On considère une matrice carrée de taille telle que . Montrer que . Par définition, l'espace colonne est l'ensemble des vecteurs pour lesquels il existe un vecteur tel que . En multipliant chaque côté de cette équation par , on trouve , mais comme , l'équation devient . Puisque par hypothèse, on a . Tous les vecteurs dans l'espace colonne doivent donc satisfaire cette propriété. Montrer que . On montre l'égalité entre ces deux ensembles en utilisant un argument d'inclusion. D'une part, si , alors . On a . Donc est bien l'image d'un vecteur par la matrice et ainsi, .  D'un autre côté, si , alors il existe pour lequel . On a . On a donc et en combinant les deux arguments, on obtient l'égalité.  Montrer que . Soit . Alors par la première partie de cet exercice, et comme est dans l'espace nul, on a . On obtient alors . Montrer que tout vecteur dans peut s'écrire comme la somme d'un vecteur dans et d'un vecteur dans . Soit , un vecteur quelconque de . On peut toujours écrire . On pose et . Selon la partie , le vecteur est dans l'espace nul de , car il est dans l'espace colonne de . De plus, comme , ce vecteur est dans l'espace colonne de . On a donc décomposé tout vecteur comme la somme d'un vecteur de l'espace nul et d'un vecteur de l'espace colonne.  Montrer que le vecteur de la proposition est unique. Soit , deux vecteurs de l'espace ligne tels que et . Alors, puisque est un sous-espace vectoriel, le vecteur est aussi dans l'espace ligne. D'un autre côté, on a . Le vecteur est donc aussi dans l'espace nul. Le seul vecteur qui puisse être à la fois dans l'espace nul et dans l'espace ligne est le vecteur nul. Ainsi , ce qui entraine l'égalité entre et .   Dans cet exercice, on s'intéresse à la situation où la transposée est l'inverse. Ce type de matrice sera l'objet central du chapitre . Soit , une matrice telle que . Montrer que les colonnes de sont des vecteurs deux à deux orthogonaux et de norme . On interprète le produit comme une série de produits scalaires. L'entrée en position du produit est donnée par le produit scalaire de la ligne de la matrice et de la colonne de la matrice . Comme le produit de ces deux matrices est l'identité, on déduit que si , le produit est . De plus, comme la ligne de est aussi la colonne de la matrice , on conclut que les colonnes sont orthogonales, leur produit scalaire donnant . Lorsque , on se retrouve avec le produit scalaire d'une colonne avec elle-même, ce qui donne la norme du vecteur élevée au carré. Comme le résultat est l'entrée de la matrice identité, on obtient que la norme des colonnes est . Soit , une matrice telle que ses colonnes sont un ensemble de vecteurs deux à deux orthogonaux. Montrer que . Il suffit de faire le calcul inverse de la preuve précédente. On interprète le calcul de comme une série de produits scalaires. Si l'on cherche l'entrée en position , alors on fait le produit scalaire de la ligne de avec la ligne de . Puisqu'une ligne de est aussi une colonne de , on obtient que si , alors le produit scalaire est nul et si , alors le produit scalaire donne , puisque par hypothèse, les vecteurs sont unitaires. Énoncer une condition sur pour que . Une matrice est telle que si et seulement si ses lignes sont des vecteurs deux à deux orthogonaux et unitaires. Il suffit d'échanger le rôle de et dans les parties précédentes. Des matrices qui ont cette propriété sont dites orthogonales. Elles sont la généralisation des rotations et réflexions dans .  Dans cet exercice, on donne deux formules pratiques pour obtenir un inverse à gauche ou un inverse à droite, selon ce qui est prescrit par la proposition . Soit , une matrice quelconque de taille . Montrer que si est de rang , alors la matrice est inversible. Utiliser l'exercice . Selon l'exercice , le rang de la matrice est égal au rang de la matrice , soit . Puisque la matrice est de taille , le théorème de la matrice inverse implique qu'elle est inversible. Soit , une matrice quelconque de taille . Montrer que si est de rang , alors la matrice est inversible. Utiliser l'exercice en interchangeant les rôles de et . On sait que et ont le même rang. Selon l'exercice , le rang de la matrice est égal au rang de la matrice , soit . Puisque la matrice est de taille , le théorème de la matrice inverse implique qu'elle est inversible. Expliquer pourquoi on ne peut toutefois pas écrire ou . Quelles sont les dimensions de la matrice ? La proposition stipule que le produit de deux matrices carrées est inversible si et seulement si chacune des matrices l'est. Toutefois ici, la matrice et sa transposée ne sont peut-être pas carrées. Dans ce cas, les matrices et ne sont même pas définies. Si est une matrice de taille et de rang , montrer que est un inverse à droite. Il suffit de calculer le produit : . Si est une matrice de taille et de rang , montrer que est un inverse à gauche. Il suffit de calculer le produit : .   Exercices Sage   Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.   Pour déterminer une base de l'espace colonne, la proposition dit qu'on doit prendre les colonnes de la matrice initiale qui correspondent aux positions pivots de sa forme échelonnée réduite. À l'exemple , on a utilisé la commande A.column_space().basis() pour obtenir une base de l'espace colonne de la matrice , mais ce n'est pas la base donnée par la proposition . On peut construire une fonction qui retourne cette base grâce à la fonction A.pivots() qui retourne la position des colonnes pivots (si l'on avait voulu les lignes pivots, on aurait utilisé la commande A.pivots_rows() ).  Construire une fonction colbase qui prend comme entrée une matrice et retourne la base de son espace colonne telle que donnée par la proposition . Tester avec les matrices de l'exercice .   La solution pour l'exercice   def colbase(A): L=A.pivots() B=[] for i in L: B.append(A.column(i)) return B    En utilisant les formules de l'exercice , déterminer un inverse à gauche ou un inverse à droite des matrices suivantes. Dans le cas d'une matrice carrée, calculer les deux inverses et vérifier qu'ils correspondent à l'inverse traditionnel. Toutes les matrices sont de rang maximal. Puisque , la matrice ne peut posséder qu'un inverse à droite.   Cette fois, et la matrice ne peut posséder qu'un inverse à gauche.   La matrice est carrée et, par hypothèse du problème de rang 2, donc inversible. On calcule les inverses à gauche, à droite et au sens usuel du terme et l'on vérifie que les trois sont égaux.     Puisque , la matrice ne peut posséder qu'un inverse à droite.   Puisque , la matrice ne peut posséder qu'un inverse à gauche.    Créer une fonction qui prend comme argument une matrice. La fonction retourne  Son inverse à gauche telle que donnée par la formule de l'exercice s'il existe, ainsi que la mention c'est un inverse à gauche ;  Son inverse à droite telle que donnée par la formule de l'exercice s'il existe, ainsi que la mention c'est un inverse à droite ;  Son inverse si la matrice est carrée et inversible;  La chaine de caractère La matrice ne possède pas d'inverse dans les autres cas.   Le code solution de l'exercice   def matinverse(A): m=len(A.rows()) n=len(A.columns()) r=A.rank() if r!=min(m,n): print(\"La matrice ne possède pas d'inverse\") elif m==n: print(\"La matrice est inversible\") return A.inverse() elif m<n: print(\"C'est un inverse à droite\") AT=A.transpose() AATinv=(A*AT).inverse() return AT*AATinv elif n<m: print(\"C'est un inverse à gauche\") AT=A.transpose() ATAinv=(AT*A).inverse() return ATAinv*AT      "
},
{
  "id": "prop-baseesplignenul",
  "level": "2",
  "url": "sec-4esp.html#prop-baseesplignenul",
  "type": "Proposition",
  "number": "5.3.1",
  "title": "Une base pour l’espace ligne et une base pour l’espace nul.",
  "body": " Une base pour l'espace ligne et une base pour l'espace nul   Soit , une matrice et soit , sa forme échelonnée réduite. Alors  Les lignes non nulles de forment une base de ;  Les solutions de base à l'équation sont une base de l'espace nul.     Les lignes de sont nécessairement indépendantes, puisqu'en regardant les positions pivots, la seule manière d'obtenir le vecteur nul avec une combinaison linéaire est de prendre zéro fois chaque ligne. Puisque les lignes nulles de ne contribuent pas à , on a que est égal au span des lignes non nulles de . Comme elles sont indépendantes, elles forment une base en vertu de la proposition .  De plus, puisqu'on obtient à partir de par une suite d'opérations élémentaires, toutes réversibles, les lignes de peuvent s'écrire comme une combinaison linéaire des lignes de . Ceci entraine que . Les lignes de forment donc une base pour l'espace ligne de .   Tout vecteur dans peut bien sûr s'écrire comme une combinaison linéaire des solutions de base par construction de celles-ci. Ainsi, elles engendrent . De plus, l'exercice montre que les solutions de bases sont indépendantes. Elles forment donc bel et bien une base de l'espace nul.  "
},
{
  "id": "example-107",
  "level": "2",
  "url": "sec-4esp.html#example-107",
  "type": "Exemple",
  "number": "5.3.2",
  "title": "Base de l’espace ligne.",
  "body": " Base de l'espace ligne   On considère la matrice et l'on cherche une base de son espace ligne. On cherche aussi la dimension de l'espace ligne.    On utilise Sage pour échelonner la matrice et trouver la base.   Une base pour est . La dimension de l'espace ligne est et c'est un sous-espace vectoriel de .   "
},
{
  "id": "lem-NRT",
  "level": "2",
  "url": "sec-4esp.html#lem-NRT",
  "type": "Lemme",
  "number": "5.3.3",
  "title": "L’espace nul de la transposée d’une matrice échelonnée réduite.",
  "body": " L'espace nul de la transposée d'une matrice échelonnée réduite   Soit , une matrice de rang qui est échelonnée réduite et soit , les vecteurs de la base standard de . Alors une base possible pour l'espace nul gauche est .    Voir l'exercice .   "
},
{
  "id": "prop-baseespcolnulg",
  "level": "2",
  "url": "sec-4esp.html#prop-baseespcolnulg",
  "type": "Proposition",
  "number": "5.3.4",
  "title": "Une base pour l’espace colonne et l’espace nul gauche.",
  "body": " Une base pour l'espace colonne et l'espace nul gauche   Soit , une matrice , sa forme échelonnée réduite et soit , une matrice telle que (la matrice correspond à la multiplication de matrices élémentaires permettant d'échelonner ). Alors  Les colonnes pivots de (celles qui sont pivots dans ) forment une base de ;  Les lignes de qui sont aux mêmes positions que les lignes nulles de forment une base de l'espace nul gauche.     Soit , l'indice des colonnes de contenant un pivot, avec . Soit , les colonnes de correspondant à ces positions. On veut montrer que ces colonnes forment une base de .  D'abord la question de l'indépendance. Soit tels que . On pose , le vecteur qui a une valeur en position si et qui vaut aux positions . Le vecteur est donc une solution à l'équation . Par le fait même, on a . Ceci entraine que , où est la -ème colonne de . Puisque, par définition, celles-ci sont pivots, ces colonnes ne contiennent qu'un et des zéros partout ailleurs. On conclut que et que les colonnes de qui correspondent aux positions pivots de sont indépendantes.  Il reste à montrer que ces colonnes engendrent . Évidemment, . Si l'on montre que les colonnes qui ne sont pas pivots peuvent s'écrire comme une combinaison linéaire des colonnes pivots, alors on pourra les retirer du et il ne restera dans celui-ci que les colonnes pivots.  Dans la matrice , on a vu comment lire les solutions de base à partir des colonnes qui ne sont pas pivots. Ces solutions de base offrent une solution à l'équation . Elles donnent une combinaison linéaire de la colonne libre ainsi que des colonnes pivots à sa gauche donnant le vecteur nul. Puisque l'équation possède les mêmes solutions que l'équation , on obtient aussi une combinaison linéaire des colonnes correspondantes dans qui donne le vecteur nul. En isolant la colonne correspondant à la colonne libre, on voit qu'elle s'écrit comme une combinaison linéaire des colonnes pivots.  On a donc bel et bien que , les colonnes pivots de .    Finalement, on veut montrer que les lignes de qui sont aux mêmes positions que les lignes nulles de forment une base pour l'espace nul gauche. La matrice est la matrice obtenue en multipliant chaque matrice élémentaire transformant en . Chaque matrice élémentaire étant inversible, leur produit l'est aussi, comme indiqué à la proposition (sa généralisation). Les lignes de sont donc indépendantes, plus particulièrement celles qui correspondent aux lignes nulles de . Il reste à montrer que ces lignes engendrent l'espace nul gauche.  L'espace nul gauche est consistué de l'ensemble des vecteurs tels que . Puisque , on réécrit en vertu des propriétés de la transposée . On a donc . On conclut que . Selon le lemme , l'espace nul de est engendré par les derniers vecteurs de la base standard de , où est le rang de . Le vecteur est donc une combinaison linéaire de ces vecteurs. Si l'on isole dans l'équation , on obtient . Puisque est une combinaison linéaire des derniers vecteurs de la base standard, le vecteur est une combinaison linéaire des dernières colonnes de et donc, aux lignes de . Ce sont exactement ces lignes qui correspondent aux lignes nulles de . Ceci montre que les lignes de forment une base pour .   "
},
{
  "id": "ex-base4esp",
  "level": "2",
  "url": "sec-4esp.html#ex-base4esp",
  "type": "Exemple",
  "number": "5.3.5",
  "title": "Une base des quatre espaces fondamentaux d’une matrice.",
  "body": " Une base des quatre espaces fondamentaux d'une matrice   On considère la matrice . On cherche une base pour les quatre espaces fondamentaux.   On commence par échelonner la matrice en gardant bien en vue les opérations élémentaires effectuées dans le but de créer la matrice . . À chaque opération élémentaire correspond une matrice élémentaire. On a . Finalement, , que l'on calcule avec Sage.   Selon la proposition , l'espace ligne est engendré par les lignes non nulles de . On a donc . Toujours selon cette proposition, l'espace nul est engendré par les solutions de base à l'équation qui se trouvent à même la matrice , comme indiqué à l'exemple . On a donc .  Selon la proposition , l'espace colonne est engendré par les colonnes de qui correspondent aux colonnes pivots de sa forme échelonnée réduite . On a donc . Toujours selon cette proposition, l'espace nul gauche est engendré par les lignes de la matrice qui correspondent aux lignes nulles de la matrice . On a donc .   "
},
{
  "id": "prop-dim4esp",
  "level": "2",
  "url": "sec-4esp.html#prop-dim4esp",
  "type": "Proposition",
  "number": "5.3.6",
  "title": "La dimension des quatre espaces fondamentaux.",
  "body": " La dimension des quatre espaces fondamentaux  Soit , une matrice de rang . Alors  ;  ;  .    Plus particulièrement, on remarque que la somme des espaces ligne et nul, qui sont des sous-espaces de , donne et que la dimension des espaces colonne et nul gauche, qui sont des sous-espaces de , donne .    Pour les espaces ligne et colonne, le nombre de vecteurs dans la base correspond respectivement au nombre de lignes non nulles de la forme échelonnée réduite de la matrice et au nombre de colonnes pivots de cette même matrice échelonnée réduite. Dans les deux cas, ce nombre est égal au rang de la matrice. La dimension est donc égale au rang, soit .  Pour l'espace nul, le nombre de vecteurs dans la base correspond au nombre de solutions de base. Celles-ci sont aussi nombreuses qu'il y a de variables libres, soit ( variables moins les qui sont pivots).  Finalement pour l'espace nul gauche, le nombre de vecteurs dans la base correspond au nombre de lignes nulles dans la forme échelonnée réduite. Celles-ci sont en nombre de ( lignes moins les qui contiennent un pivot).   "
},
{
  "id": "thm-fondalg",
  "level": "2",
  "url": "sec-4esp.html#thm-fondalg",
  "type": "Théorème",
  "number": "5.3.7",
  "title": "Théorème fondamental de l’algèbre linéaire.",
  "body": " Théorème fondamental de l'algèbre linéaire   Soit , une matrice de rang . Alors  ;  et ;  et .     Le résultat découle des propositions et .   "
},
{
  "id": "fig-fondalg",
  "level": "2",
  "url": "sec-4esp.html#fig-fondalg",
  "type": "Figure",
  "number": "5.3.8",
  "title": "",
  "body": " Une image du théorème fondamental de l'algèbre linéaire   À gauche, deux rectangles sont dessinés, se touchant en un coin à quatre-vingt-dix degrés. Sur le rectangle supérieur, on peut lire \"dimension r\" et \"espace ligne\". Sur le rectangle inférieur, on peut lire \"espace nul\" et \"dimension n moins r\". À droite un dessin similaire est présent, avec sur le rectangle supérieur les mots \"dimension r\" et \"espace colonne\" alors que sur le rectangle inférieur on peut lire les mots \"espace nul gauche\" et \"dimension m moins r\".    "
},
{
  "id": "ex-pointplusprochemoindrescarres",
  "level": "2",
  "url": "sec-4esp.html#ex-pointplusprochemoindrescarres",
  "type": "Exemple",
  "number": "5.3.9",
  "title": "Le point le plus proche.",
  "body": " Le point le plus proche  On considère le plan engendré par les vecteurs et ainsi que le point . On cherche le point sur le plan qui est le plus près de .   On commence par former la matrice dont les colonnes sont les vecteurs directeurs du plan: . Puisque le point sur le plan le plus proche du point est un point pour lequel le vecteur est perpendiculaire au plan, on peut déduire du théorème que ce vecteur est dans l'espace nul gauche de la matrice , pour laquelle le plan représente l'espace colonne. Il faut donc que soit dans l'espace nul gauche ou, de façon équivalente, il faut que .  Pour progresser, on remarque que, comme le point est sur le plan, il doit nécessairement exister un vecteur tel que . Ainsi, .  Concrètement, on peut calculer toutes ces matrices et obtenir un système simple à résoudre. On utilise Sage pour faire ces calculs.   Le point est donc obtenu en trouvant la valeur du vecteur pour lequel . Ce système se résout facilement à l'aide de n'importe quelle méthode des chapitres précédents. Avec Sage:   Le point est finalement obtenu en utilisant ce vecteur et la matrice : .   "
},
{
  "id": "computation-36",
  "level": "2",
  "url": "sec-4esp.html#computation-36",
  "type": "Calcul",
  "number": "5.3.10",
  "title": "Base des quatre espaces sur Sage.",
  "body": " Base des quatre espaces sur Sage  Dans la section , on a introduit des commandes permettant de trouver une base des espaces fondamentaux sans avoir défini au préalable la notion de base. Ceci a été fait à l'exemple calculatoire . On reprend ici ces commandes avec la notion de base maintenant bien définie.  Les commandes pour les espaces ligne, colonne, nul et nul gauche sont respectivement row_space().basis(),column_space().basis(),right_kernel(basis=\"pivot\").basis(),left_kernel(basis=\"pivot\").basis() . On les utilise pour retrouver la base de chacun des quatre espaces de l'exemple .   À noter que pour l'espace colonne, Sage ne retourne pas la base prescrite par la proposition . En fait, il préfère trouver une base de l'espace ligne de . On peut toutefois créer une fonction retournant la base suggérée par la proposition grâce à la fonction pivots() . C'est l'objet de l'exercice .  "
},
{
  "id": "proposition-63",
  "level": "2",
  "url": "sec-4esp.html#proposition-63",
  "type": "Proposition",
  "number": "5.3.11",
  "title": "La dimension du complément orthogonal.",
  "body": " La dimension du complément orthogonal  Soit , un sous-espace vectoriel de dimension . La dimension de son complément orthogonal est .   Si , alors et le complément orthogonal de est . La dimension est bien .  Si , alors selon la proposition , on peut trouver une base engendrant . On crée une matrice ligne avec ces vecteurs. Par construction, l'espace ligne de la matrice correspond à et est de dimension , puisque les vecteurs sont indépendants. Selon le théorème , l'espace nul de (qui est le complément de ) est de dimension .   "
},
{
  "id": "fig-decomportho",
  "level": "2",
  "url": "sec-4esp.html#fig-decomportho",
  "type": "Figure",
  "number": "5.3.12",
  "title": "",
  "body": " Décomposition d'un vecteur selon un sous-espace et son complément orthogonal   Un sous-espace vectoriel V est illustré sous la forme d'un plan. Son complément orthogonal est aussi présent, sous la forme d'une droite. On y voit trois vecteurs, l'un dans V, un autre dans le complément et le troisième est quelconque. On peut voir la décomposition de ce troisième vecteur comme la somme des deux autres grâce à des lignes pointillées.    "
},
{
  "id": "prop-decomportho",
  "level": "2",
  "url": "sec-4esp.html#prop-decomportho",
  "type": "Proposition",
  "number": "5.3.13",
  "title": "Décomposition d’un vecteur par rapport à des sous-espaces orthogonaux.",
  "body": " Décomposition d'un vecteur par rapport à des sous-espaces orthogonaux   Soit , un sous-espace vectoriel. Alors n'importe quel vecteur de peut s'écrire de manière unique comme la somme d'un vecteur dans et d'un vecteur dans . Ceci implique en particulier que se \"décompose\": .    Si la dimension de est , alors son complément orthogonal est et il s'ensuit que tout vecteur peut s'écrire comme . La situation est similaire si .  Soit , la dimension de . Selon le théorème , la dimension de est . Pour chacun de ces sous-espaces vectoriels, on peut trouver une base. Soit , une base pour et , une base pour . On souhaite montrer que ces vecteurs génèrent . Cela entrainera que tout vecteur peut s'écrire comme une combinaison linéaire de cet ensemble. La partie de la combinaison linéaire avec les premiers vecteurs sera dans et l'autre partie dans . Pour l'unicité, cela découle du fait que les vecteurs forment une base, puisqu'on aura vecteurs indépendants dans .  Pour montrer l'indépendance des vecteurs, on suppose que l'on connait une combinaison linéaire donnant le vecteur nul: . On peut réécrire cette équation en séparant les vecteurs dans et pour avoir . Comme le membre de droite s'écrit comme une combinaison linéaire de vecteurs dans et que est un sous-espace vectoriel, il faut que le membre de droite soit aussi dans . Par contre, le membre de droite est une combinaison linéaire de vecteurs dans et doit donc être dans . Le seul vecteur commun à et est le vecteur nul. On obtient ainsi . Comme les vecteurs forment une base de , il faut que les coefficients soient tous égaux à zéro. De même, les vecteurs formant une base de , les coefficients sont aussi nuls.   "
},
{
  "id": "rem-decomportho",
  "level": "2",
  "url": "sec-4esp.html#rem-decomportho",
  "type": "Remarque",
  "number": "5.3.14",
  "title": "Un commentaire additionnel.",
  "body": " Un commentaire additionnel  La proposition dit que deux sous-espaces orthogonaux \"décomposent\" l'espace en deux parties. Cela ne signifie toutefois pas que tous les vecteurs de sont soit dans ou soit dans . En effet, si, par exemple, on prend un vecteur et , alors le vecteur n'est ni dans , ni dans . La figure illustre ceci avec les quatre sous-espaces fondamentaux.  "
},
{
  "id": "example-110",
  "level": "2",
  "url": "sec-4esp.html#example-110",
  "type": "Exemple",
  "number": "5.3.15",
  "title": "Décomposition d’un vecteur selon des sous-espaces orthogonaux.",
  "body": " Décomposition d'un vecteur selon des sous-espaces orthogonaux  Afin d'illustrer la proposition , on décompose le vecteur en une composante provenant de et son complément orthogonal.   On commence par trouver une base pour le complément orthogonal. Si l'on pose , alors correspond à l'espace ligne de cette matrice et son complément orthogonal est l'espace nul. On peut y trouver une base avec Sage.   Donc, . Pour exprimer le vecteur en fonction de la base générée par , on met les quatre vecteurs dans une matrice colonne et l'on utilise Sage à nouveau pour échelonner la matrice augmentée du vecteur .   Ainsi, le vecteur peut s'écrire comme . La composante de qui fait partie du sous-espace est donc et la composante faisant partie du complément orthogonal est .   "
},
{
  "id": "fig-decomportho4esp",
  "level": "2",
  "url": "sec-4esp.html#fig-decomportho4esp",
  "type": "Figure",
  "number": "5.3.16",
  "title": "",
  "body": " Décomposition orthogonale et quatre espaces fondamentaux   Une reproduction des quatre espaces fondamentaux est faite comme celle d'une image précédente. Sur celle-ci est ajouté un point à gauche, décomposé en deux morceaux, l'un sur le rectangle représentant l'espace ligne et l'autre sur le rectangle représentant l'espace nul. Des flèches représentant l'effet d'une matrice A sur ces morceaux sont tracés. Le vecteur x et celui dans l'espace ligne sont envoyés dans le rectangle de l'espace colonne à droite alors que celui dans l'espace nul est envoyé à l'intersection des rectangles à droite.    "
},
{
  "id": "thm-delamatriceinversev5",
  "level": "2",
  "url": "sec-4esp.html#thm-delamatriceinversev5",
  "type": "Théorème",
  "number": "5.3.17",
  "title": "Théorème de la matrice inverse, cinquième version.",
  "body": " Théorème de la matrice inverse, cinquième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots;  La forme échelonnée réduite de est la matrice identité;  Aucune ligne n'est une combinaison linéaire des autres lignes;  Aucune colonne n'est une combinaison linéaire des autres colonnes;  Le déterminant de la matrice est non nul;  L'espace colonne est de dimension ;  L'espace ligne est de dimension ;  L'espace nul est de dimension ;  L'espace nul gauche est de dimension .    "
},
{
  "id": "prop-relesplignecol",
  "level": "2",
  "url": "sec-4esp.html#prop-relesplignecol",
  "type": "Proposition",
  "number": "5.3.18",
  "title": "Relation entre <span class=\"process-math\">\\(\\mathcal{L}(A)\\)<\/span> et <span class=\"process-math\">\\(\\mathcal{C}(A)\\)<\/span>.",
  "body": " Relation entre et  Soit , une matrice . Pour chaque vecteur dans l'espace colonne , il existe un unique vecteur dans l'espace ligne de tel que .   Soit , la dimension de l'espace ligne et de l'espace colonne et soit , une base de l'espace ligne. Dans ce cas, les vecteurs sont tous dans . Si l'on montre qu'ils sont indépendants, ils formeront alors une base de . On considère une combinaison linéaire de ces vecteurs donnant le vecteur nul: . En mettant la matrice en évidence, on obtient que et que la combinaison linéaire est dans l'espace nul de la matrice . Or comme les vecteurs sont une base pour l'espace ligne et que celui-ci est un sous-espace vectoriel, la combinaison linéaire est aussi dans l'espace ligne. Le seul vecteur qui est à la fois dans l'espace ligne et l'espace nul étant le vecteur nul, on conclut que . Ceci entraine à son tour que les coefficients sont tous nuls, puisque les vecteurs sont indépendants. Ainsi, la seule combinaison linéaire des vecteurs donnant le vecteur nul étant celle où tous les coefficients sont nuls, on peut conclure que ces vecteurs sont aussi indépendants et, puisque la dimension de l'espace colonne est , ils forment une base de cet espace.  On considère maintenant un vecteur . Puisque forment une base de l'espace colonne, il existe une unique manière d'écrire comme une combinaison linéaire de ces vecteurs: , où . La preuve que ce vecteur est unique est faite dans l'exercice .   "
},
{
  "id": "prop-invgauchedroite",
  "level": "2",
  "url": "sec-4esp.html#prop-invgauchedroite",
  "type": "Proposition",
  "number": "5.3.19",
  "title": "L’existence d’inverse à gauche et à droite.",
  "body": " L'existence d'inverse à gauche et à droite  Soit , une matrice de taille avec rang .  Si , alors, il existe une inverse à droite;  Si , alors, il existe une inverse à gauche.     Dans le cas où le rang est égal au nombre de lignes, on peut trouver colonnes pivots qui sont indépendantes et génèrent . On voit qu'il y a toujours une solution à l'équation , puisque l'espace colonne est au complet. On peut donc trouver une matrice inverse en résolvant les équations matrices vecteurs et placer ces vecteurs dans les colonnes d'une matrice .  Dans le cas où le rang est égal au nombre de colonnes, la dimension de l'espace ligne est donc égale à . En regardant la transposée de la matrice , on déduit que celle-ci possède un inverse à droite. L'équation dit alors que celui-ci est un inverse à gauche pour la matrice .   "
},
{
  "id": "remark-21",
  "level": "2",
  "url": "sec-4esp.html#remark-21",
  "type": "Remarque",
  "number": "5.3.20",
  "title": "Quelques précisions sur les inverses.",
  "body": " Quelques précisions sur les inverses  Il faut noter que, contrairement à l'inverse d'une matrice carrée , qui est unique, une matrice rectangulaire peut, si elle en a, avoir plusieurs inverses à gauche et à droite. De plus, l'équation est liée à la notion d'inverse lorsque la matrice est carrée. Si la matrice est inversible, alors il existe une solution unique donnée par . Dans le cas d'une matrice rectangulaire, l'existence d'un inverse à droite implique qu'une solution existe toujours. En effet, puisque , on a que . Ainsi est une solution. Par contre, cette solution n'est peut-être pas unique. Si un autre inverse existe, il pourrait mener à une solution différente. Si la matrice possède plutôt un inverse à gauche, alors là la solution, si elle existe, sera unique. D'une part, si est un inverse à gauche, alors est une solution puisque et donc . De plus, si est un inverse à gauche différent de , alors par le même raisonnement, est aussi une solution. Or on a . Il est toutefois possible que le vecteur ne soit pas dans l'espace colonne et qu'il n'y ait pas de solution.  En résumé, pour une matrice de rang , l'équation possède ou une infinité de solutions, alors que pour une matrice de rang , elle en possède ou une. Lorsque (et que le rang est maximal), la solution ne peut être qu'unique.  "
},
{
  "id": "exo-base4esp",
  "level": "2",
  "url": "sec-4esp.html#exo-base4esp",
  "type": "Exercice",
  "number": "5.3.4.1",
  "title": "",
  "body": "Pour chaque matrice ci-dessous, déterminer une base pour les quatre espaces fondamentaux.   Les réponses peuvent varier.        On peut remarquer que les deux lignes de la matrice sont parallèles. Ceci signifie que l'espace ligne et l'espace colonne seront de dimension . De même, la dimension de l'espace nul et de l'espace nul gauche sera aussi 1. Pour l'espace ligne, on peut prendre n'importe quelle ligne de la matrice : . Similairement, l'espace colonne est engendré par le vecteur . Pour l'espace nul, on utilise le fait que celui-ci est orthogonal à l'espace ligne. Le vecteur engendre l'espace nul. De même, l'espace nul gauche est orthogonal à l'espace colonne. Il sera engendré par .    Les réponses peuvent varier.    : Aucune base.  : Aucune base.    On remarque (par exemple avec le déterminant) que la matrice est inversible. Cela signifie que l'espace nul sera composé du vecteur nul uniquement et que les espaces ligne et colonne seront de dimension et seront au complet. On a alors et . Il n'existe pas de base pour le sous-espace ne contenant que le vecteur nul.     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires .   L'espace ligne est engendré par , l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche par et .     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires .   L'espace ligne est engendré par et , l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et et l'espace nul gauche par .     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par , l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche par et .     Les réponses peuvent varier.     , aucune base.     On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par les vecteurs obtenus des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche n'est composé que du vecteur nul et ne possède pas de base.     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche est engendré par .     Les réponses peuvent varier.         On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par et l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par et l'espace nul gauche est engendré par .     Les réponses peuvent varier.        On utilise Sage pour échelonner la matrice et déterminer les bases à l'aide des propositions et . On utilise la commande echelon_form(transformation=True) , car celle-ci retourne la matrice obtenue de la multiplication des matrices élémentaires . À noter que cette commande n'échelonne pas jusqu'au bout, elle n'utilise pas de divisions. On peut aussi faire apparaitre la forme échelonnée réduite.   L'espace ligne est engendré par , et , l'espace nul par le vecteur obtenu des solutions de base: . L'espace colonne est engendré par , et et l'espace nul gauche par .  "
},
{
  "id": "exercise-288",
  "level": "2",
  "url": "sec-4esp.html#exercise-288",
  "type": "Exercice",
  "number": "5.3.4.2",
  "title": "",
  "body": "Donner la dimension des quatre espaces fondamentaux d'une matrice ayant les caractéristiques suivantes, ou dire pourquoi une dimension ne peut être donnée. La matrice est de taille et son rang est ;          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. On a donc  ;  ;  ;  .   La matrice est de taille et est inversible;          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. De plus, selon le théorème , une matrice inversible est de rang maximal. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. On a donc  ;  ;  ;  .   La matrice est de taille . Les trois premières colonnes sont, dans l'ordre, les vecteurs et les deux dernières colonnes sont nulles.          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. Comme chaque ligne contient un pivot, la matrice est de rang 3. On a donc  ;  ;  ;  .   La matrice est de taille . Les trois premières colonnes sont, dans l'ordre, les vecteurs et les trois dernières colonnes une copie des trois premières, dans le même ordre.          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. La dimension de l'espace ligne et celle de l'espace colonne correspondent toujours au rang de la matrice. Comme les trois premières lignes contiennent un pivot, la matrice est de rang 3. On a donc  ;  ;  ;  .   La matrice est de taille et toutes les solutions à l'équation sont parallèles au vecteur .          Selon le , les dimensions de l'espace ligne et de l'espace nul s'additionnent pour donner le nombre de colonnes de la matrice et les dimensions de l'espace colonne et de l'espace nul gauche s'additionnent pour donner le nombre de lignes de la matrice. De plus, la dimension de l'espace ligne est toujours la même que celle de l'espace colonne. Comme les solutions à l'espace nul sont sur une ligne, la dimension de l'espace nul est .  ;  ;  ;  .   "
},
{
  "id": "exercise-289",
  "level": "2",
  "url": "sec-4esp.html#exercise-289",
  "type": "Exercice",
  "number": "5.3.4.3",
  "title": "",
  "body": " On considère la matrice . Pour chaque situation ci-dessous, donner une matrice de format demandé respectant la condition ou dire pourquoi une telle matrice n'existe pas.   Donner une matrice de taille telle que .  Les réponses peuvent varier. Voici une solution: On commence par déterminer l'espace ligne de la matrice en l'échelonnant.   L'espace ligne est donc à trois dimensions et engendré par les vecteurs . Pour avoir une matrice de format qui produira un espace colonne égal à l'espace ligne de , on peut prendre une matrice dont trois des colonnes sont les vecteurs ci-dessus et les deux autres colonnes sont des combinaisons linéaires de ces mêmes vecteurs. Voici un exemple: .   Donner une matrice de taille telle que .  Impossible C'est impossible, puisque l'espace ligne de la matrice est de dimension . La dimension de l'espace ligne d'une telle matrice pourrait être au maximum .  Donner une matrice de taille telle que .  En regardant les calculs Sage faits précédemment, on constate que l'espace colonne de la matrice est généré par les trois premières colonnes. Pour créer la matrice demandée, il suffit de mettre les trois premières colonnes de comme lignes d'une matrice et d'ajouter une ligne qui est une combinaison linéaire de ces trois premières lignes. Voici un exemple: .  Donner une matrice de taille telle que .  Impossible L'espace colonne de la matrice est un sous-espace vectoriel de . On ne peut l'obtenir à partir de vecteurs dans .  Donner une matrice de taille telle que .  Toujours selon les calculs Sage précédents, le rang de la matrice est . Cela signifie que la dimension de l'espace nul sera égale à selon le . On peut trouver une base de l'espace nul en regardant la solution de base telle que définie à la section . On trouve le vecteur comme générateur de l'espace nul. Pour satisfaire les conditions de taille de la matrice , il suffit de copier ce vecteur ou l'un de ses multiples dans les trois colonnes d'une matrice . Ainsi, fait l'affaire.  Donner une matrice de taille telle que .  L'espace nul de la matrice est engendré par le vecteur . Pour obtenir une matrice dont l'espace ligne sera engendré par ce vecteur, il suffit de le placer comme les quatre lignes d'une matrice. La matrice est un exemple. "
},
{
  "id": "exercise-290",
  "level": "2",
  "url": "sec-4esp.html#exercise-290",
  "type": "Exercice",
  "number": "5.3.4.4",
  "title": "",
  "body": " Donner une base pour le complément orthogonal de chacun des ensembles de vecteurs suivants.  . Les réponses peuvent varier. Voici une possibilité: . On utilise le fait que les espaces ligne et nul sont orthogonaux et qu'on peut trouver assez facilement une base de ces espaces. En plaçant les deux vecteurs engendrant dans les lignes d'une matrice, on pourra trouver une base de l'espace nul de cette matrice qui sera une base pour du complément orthogonal de .   À partir de ce calcul, on peut trouver les solutions de base pour engendrer l'espace nul. On pose . Ces vecteurs forment une base de .  . Soit , la matrice pour laquelle le système correspond aux conditions caractéristiques du sous-espace . Par définition, les solutions à ce système correspondent à l'espace nul de la matrice et donc, le sous-espace est équivalent à l'espace nul de la matrice . Le complément orthogonal de l'espace nul étant l'espace ligne, on conclut que , puisque la matrice est déjà échelonnée réduite. "
},
{
  "id": "exercise-291",
  "level": "2",
  "url": "sec-4esp.html#exercise-291",
  "type": "Exercice",
  "number": "5.3.4.5",
  "title": "",
  "body": "À la proposition , on a montré que tout espace vectoriel de dimension plus grande à possédait une base. Voici un processus qui permet de compléter un ensemble de vecteurs indépendants afin de trouver une base d'un espace vectoriel de dimension connue.  On considère les vecteurs de suivants: . L'idée est de créer une matrice dont l'espace colonne sera et dont les colonnes pivots donneront une base qui contiendra les vecteurs . Pour cela, on considère la matrice . Donner une base de contenant les vecteurs .    Il faut échelonner la matrice afin de déterminer les colonnes pivots. On utilise Sage.   En ajoutant les vecteurs aux vecteurs , on obtient une base de .  Répéter avec les vecteurs .  Il faut échelonner la matrice contenant ces trois vecteurs dans les premières colonnes et augmentée de l'identité afin de déterminer les colonnes pivots. On utilise Sage.   En ajoutant les vecteurs aux vecteurs , on obtient une base de .  Expliquer pourquoi ce processus fonctionne pour former une base à partir de vecteurs indépendants de .  En plaçant une copie de la matrice identité dans la matrice créée, on garantit que l'espace colonne de la matrice sera . Puisque les vecteurs sont indépendants, on s'assure qu'ils seront des pivots dans la matrice en les plaçant au début de .  "
},
{
  "id": "exo-NRT",
  "level": "2",
  "url": "sec-4esp.html#exo-NRT",
  "type": "Exercice",
  "number": "5.3.4.6",
  "title": "",
  "body": "Démontrer le lemme . Si la matrice est de rang , alors l'espace nul gauche est de dimension . Il faut donc trouver vecteurs indépendants qui font partie de l'espace nul gauche pour produire une base, en vertu de la proposition . Les vecteurs sont indépendants puisqu'ils font partie de la base standard de . Si l'on vérifie qu'ils sont dans l'espace nul gauche de , alors il sera démontré qu'ils forment une base. On considère le produit matrice vecteur pour des valeurs de allant de à . Puisque, par définition, est une matrice échelonnée réduite de rang , ses dernières lignes sont nulles. Cela signifie que les dernières colonnes de sont aussi nulles. Or lorsqu'on multiplie une matrice par un vecteur de la forme , on obtient la colonne de la matrice. Ainsi, tous les produits matrice vecteur pour des valeurs de allant de à valent . Ces vecteurs sont tous dans l'espace nul gauche. "
},
{
  "id": "exercise-293",
  "level": "2",
  "url": "sec-4esp.html#exercise-293",
  "type": "Exercice",
  "number": "5.3.4.7",
  "title": "",
  "body": "À l'exercice , on a montré qu'une matrice de rang peut s'écrire comme . À quoi correspondent les quatre espaces fondamentaux d'une telle matrice en fonction des vecteurs ? Selon la démonstration de l'exercice , on a construit le vecteur afin qu'il représente la première ligne non nulle de la matrice . Puisque est de rang , toutes les lignes sont parallèles à . On peut alors conclure que .  En regardant l'équation , on constate que les colonnes de sont toutes un multiple du vecteur . Il s'ensuit alors que .  En vertu du théorème , on conclut que et que .  "
},
{
  "id": "exercise-294",
  "level": "2",
  "url": "sec-4esp.html#exercise-294",
  "type": "Exercice",
  "number": "5.3.4.8",
  "title": "",
  "body": "Soit . Selon la proposition , il est possible de décomposer tout vecteur de comme la somme d'un vecteur de et d'un vecteur de . Décomposer le vecteur de cette manière. Le vecteur est déjà dans l'espace ligne puisque . On prend donc ce vecteur dans l'espace ligne et le vecteur nul dans l'espace nul. Décomposer le vecteur de cette manière. Dans un premier temps, on calcule le vecteur . Selon l'équation , le produit vectoriel des lignes de est . Puisque ce vecteur est perpendiculaire aux lignes de (par définition du produit vectoriel), on conclut que le vecteur est dans l'espace nul de . On prend donc le vecteur nul comme élément de l'espace ligne pour écrire Décomposer le vecteur de cette manière. La question est équivalente à décomposer le vecteur dans la base de donnée par les vecteurs (les lignes de la matrice ) et le vecteur (le produit vectoriel des deux premiers vecteurs) et de combiner les contributions des vecteurs de l'espace ligne. On place ces trois vecteurs dans une matrice colonne afin de résoudre le système.   On peut donc écrire . En combinant les deux premiers vecteurs, on a avec le vecteur et le vecteur .  Décomposer le vecteur de cette manière. On utilise la même idée qu'au problème précédent. On ajuste les calculs avec Sage en vertu des remarques de l'exemple .   On peut donc écrire . En combinant les deux premiers vecteurs, on a avec le vecteur et le vecteur .  "
},
{
  "id": "exercise-295",
  "level": "2",
  "url": "sec-4esp.html#exercise-295",
  "type": "Exercice",
  "number": "5.3.4.9",
  "title": "",
  "body": "Soit . Décomposer n'importe quel vecteur de comme la somme d'un vecteur dans l'espace ligne et d'un vecteur dans l'espace nul. . On se base sur l'exercice précédent. Les deux lignes de la matrice sont indépendantes. L'espace ligne étant de dimension , l'espace nul le sera aussi. Comme la matrice est déjà sous une forme échelonnée réduite, les solutions de base peuvent s'obtenir directement afin de compléter la base requise. On pose Avec les lignes , on pourra écrire n'importe quel vecteur de comme la somme d'un vecteur de l'espace ligne et d'un vecteur de l'espace nul.   La solution à ce système est . En combinant les vecteurs et les vecteurs , on obtient une décomposition de comme la somme d'un vecteur de l'espace ligne et d'un vecteur de l'espace nul.  Soit . Trouver un vecteur dans tel que . Ceci revient à trouver quelles valeurs de satisfont l'équation matricielle . En distribuant la matrice , cela revient à trouver comment écrire le vecteur en fonction des vecteurs images de chaque ligne. Puisque et , on trouve rapidement . Le vecteur est la solution cherchée. Trouver trois vecteurs de différents de celui trouvé à la partie précédente pour lesquels le produit par la matrice donne aussi . Il suffit d'ajouter au vecteur n'importe quel vecteur de l'espace nul, en vertu de l'équation . Puisque l'espace nul est engendré par les vecteurs , on, a par exemple, ; ; et . "
},
{
  "id": "exercise-296",
  "level": "2",
  "url": "sec-4esp.html#exercise-296",
  "type": "Exercice",
  "number": "5.3.4.10",
  "title": "",
  "body": "Soit , une matrice et , une matrice . Montrer que l'espace nul de est contenu dans l'espace nul du produit , c'est-à-dire . Soit , un vecteur de l'espace nul de la matrice . On a alors . On doit montrer que ce vecteur est dans l'espace nul de . On a puisque le vecteur nul est toujours envoyé sur le vecteur nul. Montrer que si est une matrice carrée inversible. On sait déjà que . Si l'on montre la relation inverse, c'est-à-dire , on aura démontré le résultat. On a l'hypothèse additionnelle que est une matrice carrée inversible. On commence avec un vecteur . On veut montrer que ce vecteur est aussi dans l'espace nul de la matrice . Le fait que soit dans l'espace nul du produit signifie que . Puisque est inversible, on peut alors écrire , car le vecteur nul ne peut être envoyé que sur le vecteur nul par la matrice . Ainsi, on conclut que est dans l'espace nul de la matrice . Montrer que l'espace colonne du produit est contenu dans l'espace colonne de , c'est-à-dire . On prend un vecteur dans l'espace colonne de la matrice . On veut montrer que ce vecteur est aussi dans l'espace colonne de la matrice , c'est-à-dire qu'il existe tel que . Si est dans l'espace colonne de la matrice , alors il existe pour lequel . On pose . Alors est un vecteur de , car est une matrice . De plus, on a l'équation , ce qui montre que . Montrer que si est une matrice carrée inversible. On sait déjà que . Si l'on montre la relation inverse, c'est-à-dire , on aura démontré le résultat. On a l'hypothèse additionnelle que est une matrice carrée et inversible.  On commence avec un vecteur et l'on veut montrer que ce vecteur est aussi dans l'espace colonne du produit . Il existe donc tel que . On considère ce vecteur et l'équation . Puisque est une matrice inversible, on sait qu'il existe une solution unique à cette équation. On pose . On a alors . Ainsi, le vecteur est dans l'espace colonne du produit .  "
},
{
  "id": "exo-rangproduit2",
  "level": "2",
  "url": "sec-4esp.html#exo-rangproduit2",
  "type": "Exercice",
  "number": "5.3.4.11",
  "title": "",
  "body": " Soit , une matrice et , une matrice . On s'intéresse maintenant au rang du produit en lien avec les rangs de et de .  Montrer que en utilisant les espaces fondamentaux. On note qu'on a démontré ce résultat à l'exercice Utiliser le résultat de l'exercice et la proposition . Soit , le rang de la matrice . Selon l'exercice , on a . La dimension de l'espace nul est . Selon la proposition , on a alors . Puisque la dimension de est égale à , on a , qui, en réarrangeant et en utilisant , devient . Montrer que si est une matrice carrée inversible, alors . Utiliser l'exercice . Selon l'exercice , si la matrice est inversible, alors . On a donc . À la manière de l'exercice précédent, on obtient , qui devient, en simplifiant, .  Montrer que . Conclure que . Utiliser l'exercice et la proposition . Soit , le rang de la matrice . Selon l'exercice , on a . Comme le rang correspond à la dimension de l'espace colonne, on obtient selon la proposition  . Puisque et , on doit avoir . Montrer que si est une matrice carrée inversible, alors . Utiliser l'exercice . Selon l'exercice , si la matrice est inversible, alors . Il s'ensuit donc de cet exercice que dans ce cas, . "
},
{
  "id": "exercise-298",
  "level": "2",
  "url": "sec-4esp.html#exercise-298",
  "type": "Exercice",
  "number": "5.3.4.12",
  "title": "",
  "body": " À l'exercice , on a montré que si , alors il n'est pas nécessaire que ou soit la matrice nulle (contrairement aux nombres réels). Dans cet exercice, on donne une condition nécessaire et suffisante sur les matrices pour avoir un produit nul.  Soit , des matrices de formats appropriés. Montrer que si et seulement si .  On doit montrer les deux directions de cette double implication. On commence par montrer que si , alors . Intuitivement, cela signifie que si l'image de la matrice est inclus dans l'espace nul de la matrice , alors le produit sera nul. En fait, ce sont seulement les colonnes de qui doivent faire partie de l'espace nul de , puisque le produit peut être vu comme une matrice dont les colonnes sont données par les produits matrice vecteur pour chaque colonne de la matrice (voir la définition ).  Plus concrètement, si l'on a des matrices telles que , alors, en vertu de la définition , on a .  À l'inverse, si l'on commence avec une matrice dont le produit , on souhaite montrer que l'espace colonne de est inclus dans l'espace nul de . Puisque , on conclut que, pour chaque colonne du produit, on a . Cela signifie que toutes les colonnes de la matrice sont dans l'espace nul de la matrice . Puisque et que le produit matrice vecteur est linéaire, toute combinaison linéaire des colonnes de sera aussi dans l'espace nul de . On a donc .  Si sont deux matrices de taille et de rang , est-ce qu'il est possible que ? Non Si la matrice est de rang , alors son espace colonne est de dimension . Si la matrice est aussi de rang , alors son espace nul est de dimension . Comme on ne peut avoir un espace de dimension inclus dans un espace de dimension , on ne peut avoir , qui est équivalent au produit . Si sont deux matrices de taille et de rang , est-ce qu'il est possible que ? Oui Si la matrice est de rang , alors son espace colonne est de dimension . Si la matrice est aussi de rang , alors son espace nul est de dimension . Comme on peut avoir un espace de dimension inclus dans un espace de dimension , il est possible que , qui est équivalent au produit . Donner deux matrices de rang pour lesquelles . Plusieurs réponses sont possibles. Pour que le produit soit , il faut que l'espace colonne de soit inclus dans l'espace nul de la matrice . On commence avec une matrice de rang arbitraire. Pour cela, il suffit que les lignes soient parallèles. On pose . Géométriquement, l'espace ligne de cette matrice est une droite de vecteur directeur . L'espace nul est donc un plan de vecteur normal . Pour que l'espace colonne de la matrice soit inclus dans cet espace nul, il suffit de prendre comme colonne un vecteur du plan . Le vecteur fera l'affaire. On pose alors . On vérifie avec Sage que le produit de ces matrices donne bien la matrice nulle et qu'elles sont de rang 1.   "
},
{
  "id": "exercise-299",
  "level": "2",
  "url": "sec-4esp.html#exercise-299",
  "type": "Exercice",
  "number": "5.3.4.13",
  "title": "",
  "body": "Soit , une matrice quelconque de taille . Montrer que . Une partie du travail est accompli par l'exercice , pour l'autre partie, montrer que est à la fois dans et . Qu'est-ce que cela signifie? En vertu de l'exercice , on sait déjà que . Comme la matrice n'est pas nécessairement carrée et inversible, on ne peut pas utiliser l'exercice pour conclure. Il faut montrer que si l'on a un vecteur dans , alors ce vecteur est aussi dans .  On prend donc un vecteur dans et l'on s'intéresse au produit . Par définition, le vecteur est dans l'espace colonne de la matrice . De plus, puisque , on a . Ceci signifie que le vecteur est dans l'espace nul de la matrice . Comme l'espace nul de la matrice est par définition l'espace nul gauche de la matrice , on conclut que le vecteur est à la fois dans l'espace colonne de et dans son espace nul gauche. Puisque ces deux espaces sont orthogonaux selon le , le seul vecteur qui peut être simultanément dans ces deux espaces est le vecteur nul. On a donc , ce qui signifie que .  Montrer que . Soit , le rang de et , la dimension de l'espace nul de . En vertu de la partie précédente, c'est aussi la dimension de . On note que la matrice est de taille Selon le théorème fondamental, la dimension de l'espace ligne de la matrice sera aussi de puisqu'on doit avoir . Ainsi, le rang de est égal à celui de . Montrer que . Dans un premier temps, l'espace nul de la matrice correspond à l'espace nul gauche de la transposée . On a donc De plus, puisque la matrice est symétrique (voir l'exercice , en particulier la deuxième partie) et que , on a que l'espace nul gauche et l'espace nul de sont égaux. Cela entraine que . Selon la première partie de cet exercice, , ce qui entraine par le théorème fondamental que . En vertu des remarques précédentes, on a . "
},
{
  "id": "exo-4espacesidempotente",
  "level": "2",
  "url": "sec-4esp.html#exo-4espacesidempotente",
  "type": "Exercice",
  "number": "5.3.4.14",
  "title": "",
  "body": "On considère une matrice carrée de taille telle que . Montrer que . Par définition, l'espace colonne est l'ensemble des vecteurs pour lesquels il existe un vecteur tel que . En multipliant chaque côté de cette équation par , on trouve , mais comme , l'équation devient . Puisque par hypothèse, on a . Tous les vecteurs dans l'espace colonne doivent donc satisfaire cette propriété. Montrer que . On montre l'égalité entre ces deux ensembles en utilisant un argument d'inclusion. D'une part, si , alors . On a . Donc est bien l'image d'un vecteur par la matrice et ainsi, .  D'un autre côté, si , alors il existe pour lequel . On a . On a donc et en combinant les deux arguments, on obtient l'égalité.  Montrer que . Soit . Alors par la première partie de cet exercice, et comme est dans l'espace nul, on a . On obtient alors . Montrer que tout vecteur dans peut s'écrire comme la somme d'un vecteur dans et d'un vecteur dans . Soit , un vecteur quelconque de . On peut toujours écrire . On pose et . Selon la partie , le vecteur est dans l'espace nul de , car il est dans l'espace colonne de . De plus, comme , ce vecteur est dans l'espace colonne de . On a donc décomposé tout vecteur comme la somme d'un vecteur de l'espace nul et d'un vecteur de l'espace colonne. "
},
{
  "id": "exo-vecuniqueespligne",
  "level": "2",
  "url": "sec-4esp.html#exo-vecuniqueespligne",
  "type": "Exercice",
  "number": "5.3.4.15",
  "title": "",
  "body": "Montrer que le vecteur de la proposition est unique. Soit , deux vecteurs de l'espace ligne tels que et . Alors, puisque est un sous-espace vectoriel, le vecteur est aussi dans l'espace ligne. D'un autre côté, on a . Le vecteur est donc aussi dans l'espace nul. Le seul vecteur qui puisse être à la fois dans l'espace nul et dans l'espace ligne est le vecteur nul. Ainsi , ce qui entraine l'égalité entre et . "
},
{
  "id": "exercise-302",
  "level": "2",
  "url": "sec-4esp.html#exercise-302",
  "type": "Exercice",
  "number": "5.3.4.16",
  "title": "",
  "body": " Dans cet exercice, on s'intéresse à la situation où la transposée est l'inverse. Ce type de matrice sera l'objet central du chapitre . Soit , une matrice telle que . Montrer que les colonnes de sont des vecteurs deux à deux orthogonaux et de norme . On interprète le produit comme une série de produits scalaires. L'entrée en position du produit est donnée par le produit scalaire de la ligne de la matrice et de la colonne de la matrice . Comme le produit de ces deux matrices est l'identité, on déduit que si , le produit est . De plus, comme la ligne de est aussi la colonne de la matrice , on conclut que les colonnes sont orthogonales, leur produit scalaire donnant . Lorsque , on se retrouve avec le produit scalaire d'une colonne avec elle-même, ce qui donne la norme du vecteur élevée au carré. Comme le résultat est l'entrée de la matrice identité, on obtient que la norme des colonnes est . Soit , une matrice telle que ses colonnes sont un ensemble de vecteurs deux à deux orthogonaux. Montrer que . Il suffit de faire le calcul inverse de la preuve précédente. On interprète le calcul de comme une série de produits scalaires. Si l'on cherche l'entrée en position , alors on fait le produit scalaire de la ligne de avec la ligne de . Puisqu'une ligne de est aussi une colonne de , on obtient que si , alors le produit scalaire est nul et si , alors le produit scalaire donne , puisque par hypothèse, les vecteurs sont unitaires. Énoncer une condition sur pour que . Une matrice est telle que si et seulement si ses lignes sont des vecteurs deux à deux orthogonaux et unitaires. Il suffit d'échanger le rôle de et dans les parties précédentes. Des matrices qui ont cette propriété sont dites orthogonales. Elles sont la généralisation des rotations et réflexions dans . "
},
{
  "id": "exo-formulesinversegauchedroite",
  "level": "2",
  "url": "sec-4esp.html#exo-formulesinversegauchedroite",
  "type": "Exercice",
  "number": "5.3.4.17",
  "title": "",
  "body": "Dans cet exercice, on donne deux formules pratiques pour obtenir un inverse à gauche ou un inverse à droite, selon ce qui est prescrit par la proposition . Soit , une matrice quelconque de taille . Montrer que si est de rang , alors la matrice est inversible. Utiliser l'exercice . Selon l'exercice , le rang de la matrice est égal au rang de la matrice , soit . Puisque la matrice est de taille , le théorème de la matrice inverse implique qu'elle est inversible. Soit , une matrice quelconque de taille . Montrer que si est de rang , alors la matrice est inversible. Utiliser l'exercice en interchangeant les rôles de et . On sait que et ont le même rang. Selon l'exercice , le rang de la matrice est égal au rang de la matrice , soit . Puisque la matrice est de taille , le théorème de la matrice inverse implique qu'elle est inversible. Expliquer pourquoi on ne peut toutefois pas écrire ou . Quelles sont les dimensions de la matrice ? La proposition stipule que le produit de deux matrices carrées est inversible si et seulement si chacune des matrices l'est. Toutefois ici, la matrice et sa transposée ne sont peut-être pas carrées. Dans ce cas, les matrices et ne sont même pas définies. Si est une matrice de taille et de rang , montrer que est un inverse à droite. Il suffit de calculer le produit : . Si est une matrice de taille et de rang , montrer que est un inverse à gauche. Il suffit de calculer le produit : . "
},
{
  "id": "exercise-304",
  "level": "2",
  "url": "sec-4esp.html#exercise-304",
  "type": "Exercice",
  "number": "5.3.4.18",
  "title": "",
  "body": "Pour déterminer une base de l'espace colonne, la proposition dit qu'on doit prendre les colonnes de la matrice initiale qui correspondent aux positions pivots de sa forme échelonnée réduite. À l'exemple , on a utilisé la commande A.column_space().basis() pour obtenir une base de l'espace colonne de la matrice , mais ce n'est pas la base donnée par la proposition . On peut construire une fonction qui retourne cette base grâce à la fonction A.pivots() qui retourne la position des colonnes pivots (si l'on avait voulu les lignes pivots, on aurait utilisé la commande A.pivots_rows() ).  Construire une fonction colbase qui prend comme entrée une matrice et retourne la base de son espace colonne telle que donnée par la proposition . Tester avec les matrices de l'exercice .   La solution pour l'exercice   def colbase(A): L=A.pivots() B=[] for i in L: B.append(A.column(i)) return B   "
},
{
  "id": "exercise-305",
  "level": "2",
  "url": "sec-4esp.html#exercise-305",
  "type": "Exercice",
  "number": "5.3.4.19",
  "title": "",
  "body": "En utilisant les formules de l'exercice , déterminer un inverse à gauche ou un inverse à droite des matrices suivantes. Dans le cas d'une matrice carrée, calculer les deux inverses et vérifier qu'ils correspondent à l'inverse traditionnel. Toutes les matrices sont de rang maximal. Puisque , la matrice ne peut posséder qu'un inverse à droite.   Cette fois, et la matrice ne peut posséder qu'un inverse à gauche.   La matrice est carrée et, par hypothèse du problème de rang 2, donc inversible. On calcule les inverses à gauche, à droite et au sens usuel du terme et l'on vérifie que les trois sont égaux.     Puisque , la matrice ne peut posséder qu'un inverse à droite.   Puisque , la matrice ne peut posséder qu'un inverse à gauche.   "
},
{
  "id": "exercise-306",
  "level": "2",
  "url": "sec-4esp.html#exercise-306",
  "type": "Exercice",
  "number": "5.3.4.20",
  "title": "",
  "body": "Créer une fonction qui prend comme argument une matrice. La fonction retourne  Son inverse à gauche telle que donnée par la formule de l'exercice s'il existe, ainsi que la mention c'est un inverse à gauche ;  Son inverse à droite telle que donnée par la formule de l'exercice s'il existe, ainsi que la mention c'est un inverse à droite ;  Son inverse si la matrice est carrée et inversible;  La chaine de caractère La matrice ne possède pas d'inverse dans les autres cas.   Le code solution de l'exercice   def matinverse(A): m=len(A.rows()) n=len(A.columns()) r=A.rank() if r!=min(m,n): print(\"La matrice ne possède pas d'inverse\") elif m==n: print(\"La matrice est inversible\") return A.inverse() elif m<n: print(\"C'est un inverse à droite\") AT=A.transpose() AATinv=(A*AT).inverse() return AT*AATinv elif n<m: print(\"C'est un inverse à gauche\") AT=A.transpose() ATAinv=(AT*A).inverse() return ATAinv*AT   "
},
{
  "id": "sec-espaces",
  "level": "1",
  "url": "sec-espaces.html",
  "type": "Section",
  "number": "5.4",
  "title": "Espaces vectoriels",
  "body": "  Espaces vectoriels    Aller aux exercices de la section.  Dans ce chapitre, on a vu que chaque sous-espace vectoriel de dimension dans se comporte de manière équivalente à une copie de . Ainsi, un plan, peu importe l'espace dans lequel il se trouve, se comporte essentiellement comme . La structure d'addition et de multiplication par un scalaire obéit à des règles précises qui font en sorte que des éléments d'un sous-espace demeurent dans le sous-espace lorsqu'ils sont combinés par ces opérations. On s'intéresse maintenant à généraliser cette structure et l'on cherche à voir si ces règles s'appliquent en dehors du contexte des vecteurs et des nombres. On peut penser aux fonctions, qui demeurent des fonctions lorsqu'additionnées ou multipliées par des nombres réels, ou encore plus simplement aux polynômes. Si l'on pouvait montrer une forme d'équivalence entre ce que l'on a fait avec et ses sous-espaces et d'autres objets mathématiques ayant des opérations similaires, on pourrait utiliser plusieurs des résultats démontrés précédemment et les appliquer dans ces nouveaux contextes.  Dans cette section, on introduit la notion d'espace vectoriel et l'on généralise certaines notions pour des espaces plus abstraits. On donne aussi quelques exemples et leurs applications.    Espace vectoriel  Les espaces dans lesquels vivent les vecteurs étudiés jusqu'ici sont tous similaires. Ils sont composés de nombres réels, d'une opération addition et d'une opération multiplication. Ces opérations satisfont certaines propriétés naturelles et classiques. On cherche maintenant à généraliser ce concept. Dans un premier temps, on peut changer les objets, ce qui constitue les vecteurs. On peut également changer les opérations d'addition et de multiplication. Ces deux changements, individuellement ou ensemble, apportent un nouveau regard sur les notions de sous-espaces, base, etc. On commence par la définition d'un espace vectoriel.   Espace vectoriel   Un espace vectoriel sur les réels est un ensemble munis de deux opérations, une opération d'addition, notée , et une opération de multiplication par un scalaire réel, notée , qui satisfont les propriétés suivantes. Pour chaque et pour tout , on a   Condition à respecter pour être un espace vectoriel   (fermeture par rapport à l'addition);  (commutativité de l'addition vectorielle);  (associativité de l'addition vectorielle);  (neutre additif);  (inverse additif);  (fermeture par rapport à la multiplication par un scalaire);  (associativité de la multiplication par un scalaire);  (distributivité sur l'addition vectorielle);  (distributivité de l'addition des scalaires);  (neutre multiplicatif).      En passant  En fait, la véritable définition d'un espace vectoriel est plus générale que celle que l'on a donnée. Les scalaires ne sont pas nécessairement des nombres réels. La seule chose importante est que ceux-ci forment ce qu'on appelle en mathématique un .  Pour toute valeur de , l'espace muni des opérations usuelles d'addition et de multiplication est un espace vectoriel. On regarde des exemples un peu moins standards.   Des espaces vectoriels  Les espaces suivants sont des espaces vectoriels:  L'ensemble des matrices de taille , noté , et muni de l'addition matricielle et de la multiplication par un scalaire, toutes les deux dans leur forme usuelle.  L'ensemble , constitué des polynômes de degré inférieur ou égal à à coefficients réels, muni de l'addition et de la multiplication usuelle.  L'ensemble des suites infinies de nombres réels, muni de l'addition et de la multiplication usuelle. Un élément de est de la forme . L'addition et la multiplication se font composante par composante.  L'ensemble muni de l'addition et de la multiplication par un scalaire décrites ci-dessous. Pour et , .    C'était l'objet de l'exercice . Il ne manque qu'à justifier que l'addition de deux matrices de taille est aussi une matrice de taille , et de même pour la multiplication par un scalaire. Comme ces opérations se font composante par composante, c'est bien le cas.  Un polynôme de degré inférieur ou égal à peut s'écrire sous la forme où . On considère un deuxième polynôme de cette forme et des scalaires réels . On démontre certaines des propriétés, laissant les autres à l'exercice .  Dans un premier temps, si l'on additionne les polynômes et , on obtient . Puisque , l'addition de deux polynômes de degré inférieur ou égal à est encore un polynôme de degré inférieur ou égal à .  On montre ensuite la commutativité de l'addition. Puisqu'on peut écrire et que ceci correspond à l'addition , on obtient la commutativité.  Finalement, on montre la distributivité sur l'addition vectorielle. On a .   Cet espace est très similaire à , mais il y a une infinité de composantes aux vecteurs. Puisque l'addition et la multiplication se font composante par composante, l'espace est fermé sous les opérations d'addition et de multiplication par un scalaire. Une simple modification de la solution à l'exercice démontre les autres propriétés.   Cet exemple est particulier puisque c'est la première apparition d'opérations non usuelles. Puisque tous les nombres sont réels, est fermé sous les opérations d'addition et de multiplication par un scalaire. En effet, , puisque . De même, , puisque .  Pour les autres propriétés, on doit vérifier. On commence avec la commutativité. .  Pour l'associativité: .  Les choses se compliquent un peu lorsqu'on arrive à la propriété du neutre additif. Si l'on essaie naïvement d'additionner le vecteur au vecteur , on obtient . Cela ne veut toutefois pas dire que la propriété n'est pas respectée. Celle-ci dit qu'il doit exister un vecteur qui ne change rien lors de l'addition, et non pas que ce vecteur doit être . En observant la structure de l'opération , on voit qu'il faut être en mesure d'annuler les contributions du dans la première composante et dans la seconde. On essaie alors avec le vecteur : . Ainsi, dans cet espace, on a .  Pour l'existence d'un inverse additif, il faut se rappeler, dans un premier temps, que l'on cherche à obtenir le vecteur nul de cet espace, soit . Ainsi, si l'on essaie , on aura . Il faut donc repenser encore à l'opération pour trouver le bon inverse. On doit annuler la contribution du vecteur et modifier la constante ajoutée afin qu'elle donne à la première composante et à la seconde. En posant , on aura .  On termine avec la distributivité de la multiplication par le scalaire sur l'addition. Les propriétés restantes seront faites à l'exercice . Donc, pour et , on a . À ce stade-ci, il semble complexe de voir comment se rendre à l'objectif . Une stratégie courante dans ce cas consiste à commencer avec l'autre côté et de développer. On obtient . Comme cette dernière ligne est égale à la dernière ligne du développement précédent, on conclut que .    Évidemment, le dernier exemple avec les opérations spéciales est un peu arbitraire et l'on s'explique mal pourquoi on proposerait une telle définition. La prochaine sous-section donnera un exemple un peu plus concret d'un espace vectoriel muni d'opérations spéciales. Les notions de sous-espaces, dimension, base, etc. sont aussi des concepts qui s'appliquent aux sous-espaces plus abstraits. On revoit les définitions dans leur contexte plus général afin d'avoir un portrait global des espaces vectoriels.   Sous-espace vectoriel   Soit , un espace vectoriel. On dit que est un sous-espace vectoriel de si les vecteurs dans satisfont les propriétés suivantes:   Sous-espace vectoriel   Si deux vecteurs sont dans , alors leur somme est aussi dans , c'est-à-dire si , alors .  Si un vecteur est dans et qu'on le multiplie par un scalaire, alors le multiple est aussi dans , c'est-à-dire si , alors .     Cette définition n'est qu'une reformulation de la définition où l'on a remplacé toute allusion à par un espace vectoriel quelconque . Un sous-espace hérite des propriétés de l'espace vectoriel, puisque, par défaut, il est inclus dans ce dernier. Les propriétés des opérations sont automatiquement satisfaites à l'intérieur d'un sous-espace vectoriel. En plus, par définition, un sous-espace vectoriel est fermé par rapport à ces opérations, ce qui fait qu'un sous-espace vectoriel est aussi un espace vectoriel. Il y a toutefois un point plus contentieux, qui pourra être résolu grâce à la proposition suivante.   Vecteur nul et inverse additif  Soit , un espace vectoriel sur , soit et . Alors, on a les propriétés suivantes:   Propriétés des espaces vectoriels   Le vecteur nul est unique, c'est-à-dire si et , alors ;  ;  ;  Si alors ou ;     On considère deux vecteurs qui ont la propriété d'être un neutre additif. On a alors . Le vecteur nul est donc unique.    On débute avec un scalaire quelconque et un vecteur arbitraire. Pour montrer que , on peut montrer que . En vertu de l'unicité du vecteur nul, ceci montrera que . On a . Ainsi, .   De manière similaire à la propriété précédente, on veut montrer que en montrant que ce vecteur possède la propriété de neutre additif. L'unicité permettra de conclure que c'est le vecteur nul de l'espace. En utilisant une idée similaire, on a . Ainsi .   Pour démontrer cette affirmation, on fait une hypothèse additionnelle sur . En effet, soit , soit . Dans le cas où , la preuve est terminée puisque c'est ce qu'on voulait montrer. Maintenant, si , on doit montrer que . On a . Ainsi, si , le vecteur doit être nul.  Voir l'exercice .   La proposition précédente peut sembler anodine, mais on doit se souvenir que les opérations peuvent être définies de manière un peu arbitraire. On a aussi pu voir à l'exemple que le vecteur nul et l'inverse additif n'étaient pas toujours aussi naturels qu'on aurait pu le croire. Il est donc utile de savoir que l'on peut déterminer ces éléments uniquement en utilisant la multiplication.   Retour sur l'espace vectoriel avec opérations spéciales  On considère à nouveau l'espace muni de l'addition et de la multiplication .  On cherche à déterminer le vecteur nul et l'inverse additif en utilisant la proposition .   Soit , un vecteur quelconque de . En vertu de la propriété , on a , ce qui correspond au vecteur nul trouvé à l'exemple .  De même, en vertu de la propriété , on a , correspondant aussi à l'inverse trouvé à l'exemple .    Un sous-espace vectoriel est aussi un espace vectoriel  Soit , un espace vectoriel et un sous-espace vectoriel. Alors est aussi un espace vectoriel.   Les deux propriétés de fermeture découlent directement de la définition d'un sous-espace vectoriel . Pour les propriétés plus algébriques, elles sont satisfaites en vertu du fait que, pour des vecteurs dans , ces vecteurs sont aussi dans et devaient donc naturellement satisfaire aux propriétés de la définition .  Le seul point à vérifier est que le vecteur nul appartient au sous-espace et que l'inverse additif d'un vecteur du sous-espace est aussi dans le sous-espace, car à priori, rien ne garantit cela.  Pour le vecteur nul, il suffit de constater qu'en prenant n'importe quel vecteur de , la propriété de fermeture par rapport à la multiplication par un scalaire combiné avec la multiplication par le scalaire font en sorte que est dans le sous-espace. La propriété montre que .  Pour l'inverse additif, la même idée s'applique, puisque selon la propriété . Comme c'est un multiple d'un vecteur dans le sous-espace, il est aussi dans le sous-espace. Tout ceci entraine qu'un sous-espace possède toutes les propriétés d'un espace et peut donc être vu aussi comme un espace vectoriel.    La stratégie pour montrer qu'un ensemble est un sous-espace d'un espace demeure la même que celle qui est utilisée à la section . Les objets ont changé, mais les idées sont les mêmes.   Des sous-espaces vectoriels  Les ensembles suivants sont des sous-espaces vectoriels des espaces vectoriels indiqués.  L'ensemble des matrices dont toutes les entrées sont sauf sur la diagonale principale est un sous-espace vectoriel de l'espace des matrices de taille muni des opérations usuelles.  L'ensemble des polynômes de degré inférieur ou égal à tels que est un sous-espace vectoriel de l'espace des polynômes de degré inférieur ou égal à , .  L'ensemble des suites infinies qui sont éventuellement est un sous-espace de muni des opérations usuelles.   Soit et , deux matrices diagonales et , un scalaire. Parce que l'addition matricielle se fait entrée par entrée et que les entrées autres que celles qui sont sur la diagonale sont nulles, la somme des matrices et n'a aussi des zéros que sur les entrées différentes de la diagonale. Elle est donc également une matrice diagonale, ce qui montre que l'ensemble est fermé par rapport à l'addition.  De même, en multipliant par , il n'y a que les entrées sur la diagonale qui sont potentiellement modifiées, les autres étant nulles. Le produit est aussi une matrice diagonale, ce qui montre que l'ensemble est fermé par rapport à la multiplication par un scalaire. L'ensemble est donc un sous-espace vectoriel de l'espace des matrices carrées.  On considère deux polynômes de degré inférieur ou égal à ayant la propriété que . On pose . Alors . Cet ensemble est donc fermé par rapport à l'addition. De même , montrant que l'ensemble est aussi fermé par rapport à la multiplication par un scalaire.  Soit et , deux suites qui sont éventuellement nulles passé un certain indice. Lorsqu'on les additionne, les entrées seront toujours nulles au-delà de l'indice . L'ensemble est donc fermé par rapport à l'addition.  De même, si l'on multiplie les éléments de par un scalaire quelconque, toutes les entrées au-delà de l'indice sont encore nulles. L'ensemble est donc aussi fermé par rapport à la multiplication par un scalaire. C'est un sous-espace vectoriel de .    On écrit maintenant la définition de plusieurs concepts déjà connus, mais reformulés dans les termes plus généraux d'un espace vectoriel quelconque.   Span, indépendance linéaire, base et dimension  Soit , un espace vectoriel et soit , des éléments de . On définit l'espace engendré par ces vecteurs comme l'ensemble de leurs combinaisons linéaires: .  On dit que l'ensemble est linéairement indépendant si uniquement lorsque . Dans le cas contraire, on dit que l'ensemble est dépendant.  On dit que l'ensemble est une base de si  Les vecteurs génèrent , c'est-à-dire si  et si les vecteurs sont linéairement indépendants.     Encore une fois, les techniques et stratégies utilisées dans le cas des espaces vectoriels quelconques sont similaires à celles qui sont utilisées avec les espaces .   Base d'un espace de polynômes  On considère à nouveau l'espace des polynômes de degré inférieur ou égal à et l'on considère les polynômes et . On souhaite montrer que  l'ensemble est linéairement indépendant et  engendre l'espace ,  faisant de cet ensemble une base pour .   On commence avec une combinaison linéaire des polynômes donnant le vecteur nul: . Deux stratégies sont possibles ici. L'équation précédente peut être développée et réécrite en regroupant les puissances de : . Ceci donne un système à trois équations et trois inconnues que l'on peut résoudre avec les techniques usuelles.   On voit donc qu'il faut que chaque coefficient soit nul pour satisfaire l'équation. Les polynômes sont donc indépendants.  Une autre stratégie consiste à réaliser que l'équation doit être satisfaite pour toutes les valeurs de . En prenant des valeurs spécifiques de , on peut se créer un autre système d'équations à résoudre. Par exemple, en prenant respectivement , on obtient les équations . Les deux dernières équations demandent à avoir et , ce qui n'est possible que lorsque . La première équation complète finalement la preuve avec .  Selon le contexte, ces deux méthodes peuvent s'avérer efficaces, parfois l'une plus que l'autre.   Pour montrer que les trois polynômes engendrent , il faut prendre un élément quelconque de l'espace et montrer qu'il peut s'écrire comme une combinaison linéaire des trois polynômes. On obtient donc . Encore une fois, on peut développer ou utiliser des valeurs spécifiques de . On propose de reprendre le calcul Sage fait précédemment, mais de résoudre l'équation en fonction du vecteur plutôt que du vecteur nul.   Puisqu'il est possible d'écrire tout polynôme comme une combinaison linéaire de , combinés au fait qu'ils sont linéairement indépendants, ces trois polynômes forment une base de .    Les résultats des sections précédentes de ce chapitre s'appliquent et s'obtiennent presque tous sans changement. Tout ce qui a trait à l'existence d'une base ( ), à la dimension, au complément orthogonal et ses résultats associés reste valide. On propose ici une nouvelle définition de dimension s'inspirant de celle qui concerne les espaces , avec une remarque qui apportera peut-être davantage de questions que de réponses.   La dimension d'un espace vectoriel  Soit , un espace vectoriel. S'il existe et des vecteurs qui engendrent , on dit que est de dimension finie et sa dimension est . Dans le cas contraire, on dit que est de dimension infinie.   Comme dans beaucoup de domaines mathématiques, l'infini apporte son lot de particularités et qui dépassent le niveau souhaité ici. On aura un aperçu de ces particularités dans la section .   Quelques espaces et leur dimension  On cherche à caractériser la dimension des espaces suivants:  L'espace des polynomes de degré inférieur ou égal à ;  L'espace des matrices carrées de taille ;  L'espace des suites infinies.     Puisqu'on a trouvé une base de cet espace à l'exemple , la dimension de cet espace correspond au nombre de vecteurs dans la base, soit .   Une matrice carrée est de la forme . Pour engendrer cet espace, on peut utiliser les matrices . On voit en effet que toute matrice peut s'écrire comme .  De plus, la seule manière d'avoir la matrice nulle, correspondant au neutre additif de cet espace, est de prendre . Ces matrices forment donc une base et la dimension est .   Le nom de l'espace suggère fortement que la dimension de cet espace sera infinie. Il faut montrer qu'il est impossible d'engendrer cette espace avec un nombre fini de vecteurs. Pour montrer que cela est impossible, on procède par contradiction.  On suppose qu'il existe suites engendrant . On considère le sous-espace vectoriel composé des suites dont les éléments valent lorsque l'indice est plus grand que . Ce sous-espace est, tout compte fait, équivalent à puisqu'on peut ignorer les composantes nulles à partir de l'indice . Or on sait que la dimension de est , ce qui signifie qu'il faut vecteurs pour engendrer ce sous-espace. Ceci entraine que les vecteurs en hypothèse ne peuvent engendrer le sous-espace vectoriel, mais comme celui-ci est inclus dans l'espace , cela contredit le fait que les suites existent.  Comme il ne peut y avoir d'ensemble de taille finie qui engendre cet espace, il est de dimension infinie.      Quelques espaces importants  Au-delà des espaces , il existe plusieurs autres espaces vectoriels qui sont d'un intérêt particulier. Même les fonctions usuelles peuvent être vues comme des espaces vectoriels, bien que ces espaces soient de dimension infinie et donc plus complexe que les espaces et autres espaces de dimension finie.   Les espaces de fontions  On considère un intervalle , possiblement en entier. On note par  l'ensemble des fonctions réelles définies sur ;  l'ensemble des fonctions réelles et continues sur ;  l'ensemble des fonctions réelles et continues dont les dérivées sont aussi continues sur ;  l'ensemble des fonctions réelles et continues dont les premières dérivées sont aussi continues sur ;  l'ensemble des fonctions réelles et continues infiniment dérivables de manière continue sur .    On munit ces espaces de l'addition usuelle des fonctions ainsi que de la multiplication usuelle par un scalaire. Ces espaces sont tous des espaces vectoriels. La preuve utilise le résultat bien connu en calcul différentiel qui stipule que la somme de deux fonctions continues est continue, tout comme le résultat de la multiplication d'une fonction continue par une constante.   À partir de ces espaces, on peut s'intéresser à leurs sous-espaces vectoriels et conclure certains résultats classiques en calcul différentiel et intégral en utilisant les résultats d'algèbre linéaire.  Un sous-espace familier  On considère l'espace vectoriel et le sous-espace . Ce sous-espace représente l'ensemble des fonctions qui sont égales à leur dérivée première. On montre dans un premier temps que c'est bel et bien un sous-espace vectoriel et l'on détermine une base de ce sous-espace.   Puisque est un membre de l'ensemble , il y a au moins un élément dans l'ensemble. On considère deux éléments quelconque de ainsi qu'un scalaire réel . Pour la somme, on a , la somme fait donc partie de . De même, on a en vertu de la règle sur la dérivée d'un multiple d'une fonction. est donc un sous-espace vectoriel.  En plus de la fonction nulle, une fonction bien connue qui est égale à sa dérivée est . Cette fonction constitue, en fait, une base pour ce sous-espace vectoriel, qui est donc de dimension . Puisqu'il n'y a qu'un seul élément, il suffit de montrer que celui-ci génère . On considère un élément quelconque du sous-espace et l'on considère la fonction . En dérivant cette fonction, on trouve . Si la fonction a pour dérivée , c'est donc qu'elle est constante et ainsi , ce qui entraine que . Toutes les fonctions dans peuvent alors s'écrire comme un multiple de la fonction , ce qui signifie qu'elle génère le sous-espace.    Il y a beaucoup d'autres liens et d'autres applications à faire entre les espaces vectoriels (ou l'algèbre linéaire en général) et les équations différentielles. On en explore quelques-unes au chapitre .  Le deuxième exemple est en fait l'espace , mais muni d'une addition et d'une multiplication spéciales. En physique newtonienne, on calcule la vitesse à laquelle deux objets s'approchent l'un de l'autre en additionnant les vitesses de chacun des objets. Lorsqu'on considère de très grandes vitesses (près de la vitesse de la lumière), cette addition n'a plus de sens étant donné que rien ne peut dépasser la vitesse de la lumière. Il se trouve que la véritable manière d'additionner les vitesses en physique repose sur une modification du concept d'addition, qui respecte toutefois les mêmes propriétés que l'addition usuelle. Ceci fait en sorte qu'on peut définir un espace vectoriel.   Addition de vitesses en relativité   L'ensemble muni des opérations suivantes, pour  et est un espace vectoriel sur les réels. Ici, les variables représentent des fractions de la vitesse de la lumière, les signes positif ou négatif indiquant la direction.  On montre que les propriétés d'un espace vectoriel sont respectées avec ces opérations.    Soit et . On veut montrer que la somme de deux éléments dans reste dans , c'est-à-dire reste dans l'intervalle . Puisque , on a avec , on a et donc . L'argument pour montrer que est similaire et sera explicité à l'exercice . On a donc fermeture pour l'addition, car on a montré que .   La commutativité de l'addition usuelle ainsi que de la multiplication usuelle montre que .   L'associativité sera démontrée à l'exercice .   Selon la propriété , on peut obtenir le vecteur nul en multipliant un vecteur quelconque par le scalaire . On a donc . Le vecteur nul est donc simplement . Évidemment, on aurait aussi pu deviner et vérifier que .   Voir l'exercice .  Voir l'exercice .  Soit et . On cherche à montrer que . Dans un premier temps, on a . Pour l'autre côté, on commence par calculer : . On fait ensuite , ce qui donne .  On calcule séparément et . Pour , on a alors que pour , on obtient   On pose et l'on revient à . On a . On a donc égalité entre et .   Encore un gros exercice de manipulation algébriques. On veut montrer que . Dans un premier temps, on a .  On pose et . Pour l'autre côté, on a . Puisque . D'une manière similaire, on trouve et donc . La propriété est donc respectée.   Voir l'exercice .  On a .        Les points importants de cette section sont:  La définition d'un espace vectoriel et les dix propriétés à respecter;  Les propriétés propres à tous les espaces vectoriels.       Exercices   L'ensemble des nombres complexes est défini comme l'ensemble et est lui-même un nombre complexe ayant la propriété que . On munit cet espace de l'addition et de la multiplication par un scalaire réel .  Montrer que cet ensemble muni de ces opérations est un espace vectoriel.   Soit et , des nombres complexes et , des réels.  Pour la propriété , on doit montrer que la somme de deux nombres complexes est encore un nombre complexe, c'est-à-dire qu'elle peut s'écrire sous la forme un réel plus un réel fois . On a en vertu de l'addition sur les complexes. Comme de même que , la somme de nombres complexes est encore un nombre complexe.  La commutativité et l'associativité découlent directement des propriétés de l'addition sur les réels, puisque et que .  Le neutre additif est aussi dans cet espace, puisque et l'inverse additif est simplement , puisque .  Pour les propriétés avec la multiplication, elles découlent aussi des propriétés de l'addition et de la multiplication avec les nombres réels. Puisque et , on obtient la fermeture par rapport à la multiplication. L'associativité s'obtient du fait que .  De plus, et . Finalement, et donc, toutes les propriétés sont respectées. C'est un espace vectoriel.    On considère l'ensemble des nombres réels muni de l'addition et de la multiplication par un scalaire usuelle. Cet ensemble n'est pas un espace vectoriel. Déterminer quelle(s) propriété(s) n'est (ne sont) pas satisfaite(s).   Les propriétés Voir l'explication dans la solution ne sont pas respectées.  Puisque la somme de nombres réels est aussi un nombre réel et que , la première propriété est respectée. Par contre, la deuxième propriété ne l'est pas. En effet, en général on n'a pas . En prenant , on a , mais . De même, l'associativité n'est pas respectée étant donné que le terme à droite a une particularité qui lui est propre. En effet , alors que . Dans le premier cas, est pris deux fois dans un côté droit de l'opération , il apparait donc avec une puissance quatre, mais dans le second cas, il est seulement affecté d'un exposant deux, conséquence du fait qu'il n'est à droite de l'opération qu'une seule fois.  D'un point de vue technique, l'élément neutre existe, puisque . Comme cette addition n'est pas commutative, il faudrait aussi vérifier à gauche aussi. Dans ce cas, on a , ce qui, en général, ne donnera pas . On pourrait donc dire qu'il y a un neutre additif à gauche, mais qu'il n'y en a pas à droite. De même, pour l'inverse additif, on peut prendre et avoir , qui correspond au neutre à gauche, mais si , aucune valeur de ne fera que .  Comme la multiplication est celle qui est usuelle, la propriété est respectée, de même que la propriété et la propriété du neutre multiplicatif. Pour les propriétés qui combinent multiplication et addition, elles ne sont pas respectées. En effet, alors que . De même, on a , mais . Ces propriétés ne sont donc pas respectées.    On considère les nombres réels strictement positifs munis des opérations suivantes: Est-ce que ceci forme un espace vectoriel? Oui. On note , l'ensemble des nombres réels strictement positifs. Muni de ces opérations, c'est en effet un espace vectoriel. On montre chacune des propriétés. Soit et . Puisque le produit de deux nombres strictement positifs est encore positif, il s'ensuit que est dans . La propriété est satisfaite. De la même manière, puisque la multiplication usuelle de nombres réels est commutative, on a et la propriété est satisfaite. La propriété découle aussi des propriétés de la multiplication usuelle, notamment l'associativité. Ainsi, .  On doit faire attention au neutre et à l'inverse additif. On peut les deviner ou encore utiliser les propriétés de la proposition . Dans le cas du neutre additif, est le vecteur nul, puisque . Du côté de l'inverse additif, c'est qui fonctionne ( ) étant donné que .  Pour les propriétés de la multiplication par un scalaire, on remarque que cette multiplication est en fait le processus d'exponentiation de nombres réels. Puisque l'exponentiation réelle donne toujours un nombre strictement plus grand que zéro, il s'ensuit que . De plus, en vertu des propriétés des exposants, on a . La propriété est donc satisfaite.  Pour la propriété , on a , ce qui confirme que cette propriété est satisfaite. La propriété est similaire, puisque . Finalement, la propriété s'obtient grâce au fait que .  Toutes les propriétés étant respectées, l'ensemble est un espace vectoriel.   Déterminer si chacun des ensembles suivants est linéairement indépendant. Tous les espaces sous-jacents sont munis des opérations d'addition et de multiplication usuelles. vu comme un ensemble de . Oui On regarde deux manières de faire le problème. Dans un premier temps, la définition demande de trouver des coefficients tels que . Si la seule solution à ce système est celle où , alors l'ensemble est linéairement indépendant. On obtient alors un système à quatre équations et trois inconnues, en regardant composante par composante les entrées des matrices: . On voit rapidement qu'on doit avoir et, avec la deuxième équation, on trouve , tous les coefficients doivent donc être nuls.  Dans un second temps, on a établi, à l'exemple , que la dimension de l'espace était en trouvant une base qui générait cet espace. On peut donc écrire chacune des matrices de l'ensemble en fonction de la base ordonnée . Ainsi, on a . La question dans le contexte matriciel est équivalente à la même question, mais du point de vue vectoriel. On place les vecteurs dans les lignes d'une matrice et l'on regarde la dimension de l'espace ligne afin de déterminer s'ils sont indépendants.   Comme la dimension de l'espace ligne correspond au nombre de vecteurs, ils sont indépendants.  vu comme un ensemble de l'espace des polynômes de degré inférieur ou égal à . Non Encore une fois, il y a plusieurs manières de répondre à cette question. À l'exemple , on a montré que la dimension de est égale à . En suivant un raisonnement similaire, on peut montrer que la dimension de est . Puisqu'il y a trois vecteurs dans l'ensemble et que l'espace est de dimension , les vecteurs sont forcément dépendants. vu comme un ensemble dans l'espace . Non Ici, il est plus difficile de procéder avec une base de l'espace, celui-ci étant de dimension infinie. On sait toutefois que , qui se traduit en réécrivant par . On a ainsi une combinaison linéaire non triviale qui donne le vecteur nul de l'espace. Les vecteurs sont donc dépendants.  On considère l'espace des matrices muni des opérations usuelles. Déterminer si chacun des ensembles suivants est un sous-espace vectoriel. Le cas échéant, déterminer une base du sous-espace et dans le cas contraire, justifier. L'ensemble des matrices de rang . Non Puisque le vecteur nul doit faire partie de chaque sous-espace et que la matrice est de rang , l'ensemble n'est pas un sous-espace vectoriel. L'ensemble des matrices de rang inférieur ou égal à . Non On ne peut plus utiliser l'argument précédent puisqu'ici, la matrice fait partie de l'ensemble. On essaie de réfléchir à ce qui se produit avec le rang lorsqu'on additionne des matrices ou lorsqu'on multiplie par un scalaire. Comme le rang correspond au nombre de lignes non nulles de la forme échelonnée réduite d'une matrice, le fait de multiplier par une constante non nulle ne devrait pas changer le rang. La deuxième propriété est donc respectée.  On se demande alors si la somme de deux matrices peut ajouter des lignes non nulles. En prenant et , deux matrices de rang , on voit bien que la somme donne la matrice identité, de rang . En ce sens, ce n'est pas un sous-espace vectoriel.  L'ensemble des matrices qui contiennent le vecteur dans leur espace nul. Oui. Cela découle du fait que si et , alors et . C'est donc un sous-espace vectoriel.  On cherche maintenant une base de ce sous-espace. Dans si l'espace nul contient le vecteur , alors l'espace nul est de dimension ou . Cela signifie que l'espace ligne de la matrice est de dimension ou . De plus, l'espace ligne doit être perpendiculaire à l'espace nul. Ainsi, si l'espace nul est simplement , alors l'espace ligne est engendré par . Les matrices possédant cet espace ligne sont toutes de la forme pour . Si toutefois l'espace nul est au complet, alors l'espace nul ne contient que le vecteur nul. Il n'y a que la matrice nulle qui est ainsi. On peut donc dire que toutes les matrices ayant le vecteur dans leur espace nul s'écrivent comme , sans restriction sur . Le sous-espace est de dimension et la matrice est une base.  L'ensemble des matrices qui contiennent le vecteur dans leur espace colonne. Non. Comme la matrice nulle doit faire partie de l'ensemble pour être un sous-espace vectoriel et que l'espace colonne de la matrice nul ne contient que le vecteur , cet ensemble n'est pas un sous-espace. L'ensemble des matrices qui sont symétriques. (Rappel: une matrice est symétrique si .) Oui.  C'est une conséquence directe des propriétés de la proposition que ce sous-ensemble est fermé sous l'addition et la multiplication par un scalaire. En effet et .  Pour trouver une base, on remarque que les matrices symétriques de taille sont de la forme . On peut donc l'engendrer par les matrices indépendantes .   À la proposition , on a montré que le vecteur nul d'un espace vectoriel est unique . Montrer que l'inverse additif est aussi unique. Soit , des vecteurs tels que et . On veut montrer que . On a . Ainsi, l'inverse additif est unique.  On considère l'ensemble des polynômes de degré inférieur ou égal à tels que .  Montrer que cet ensemble est un sous-espace vectoriel de l'espace des polynômes de degré inférieur ou égal à . Soit , des polynômes de degré inférieur ou égal à avec . On a alors , la somme est donc aussi dans l'ensemble. De plus, si , il s'ensuit que et que cet ensemble est un sous-espace vectoriel. Déterminer une base de ce sous-espace. Quelle est sa dimension? La dimension est deux. Une base possible est .  Soit , un polynôme de degré avec . On a alors , ce qui entraine que . Comme les polynômes et sont indépendants et que tout polynôme de cet espace peut être obtenu par une combinaison linéaire de ces deux polynômes, la dimension est et ils forment une base.   Montrer la propriété de la proposition .  On a . Ainsi, le vecteur est l'inverse additif, puisqu'en vertu de l'exercice , celui-ci est unique.   Dans la preuve de la propriété , on a fait l'hypothèse que soit , soit et l'on a démontré l'implication sous cette dichotomie supplémentaire. Faire une preuve alternative où l'hypothèse supplémentaire est plutôt ou . Débuter avec et conclure qu'on doit avoir ou .  Pour démontrer l'affirmation, on fait une hypothèse additionnelle sur . En effet, soit , soit . Dans le cas où , la preuve est terminée puisque c'est ce qu'on voulait montrer. Maintenant, si , on doit montrer que . Soit , un vecteur quelconque. On a . Ceci implique que ou . Puisque, par hypothèse, , on conclut qu'on doit avoir .   Soit , une matrice carrée quelconque. On considère l'ensemble des matrices qui commutent avec : . Montrer que est un sous-espace vectoriel de muni des opérations usuelles.  Soit et . Pour que soit dans , il faut que . On a . Ainsi, .  Pour que , il faut que . On a . L'ensemble est donc un sous-espace vectoriel de    Voici une preuve alternative de la propriété . Justifier chacune des étapes. .   Voici la preuve justifiée: .    Voici une preuve alternative de la propriété s'inspirant de l'exercice précédent. Compléter et justifier chacune des étapes. .   Voici la preuve complétée et justifiée: .    À l'exemple , on a montré que l'ensemble des nombres réels muni des opérations spéciales et était un espace vectoriel, mais certaines propriétés n'ont pas été démontrées dans l'exemple.   Montrer que .   On a    Montrer que, pour chaque , il existe un nombre tel que .   Si l'on prend , on a .   Montrer que .  Puisque , on a . Ainsi .  De même, et donc . Ceci signifie que .  Montrer que .   On voit que .  On pose et . Pour l'autre côté, on a . Puisque . D'une manière similaire, on trouve et donc . La propriété est donc respectée.  Est-ce que l'ensemble est un sous-espace vectoriel de ? Non. Essayer de trouver deux nombres dont la somme sort de l'intervalle. Si l'on prend et , alors . Donc, ce n'est pas fermé sous l'addition.  Comment en vient-on à trouver ces nombres? On peut y aller de manière méthodique avec l'addition. Par exemple, si l'on veut que la somme soit inférieure à , alors on cherche des conditions sur pour que ce soit valide. . La fonction est décroissante et tend vers lorsque tend vers .   La fonction   Un graphique illustrant la fonction un moins deux y sur deux moins y. On voit que la fonction est décroissante et tend vers zéro lorsque y s'approche de une demie.     On prend donc une valeur arbitraire de , par exemple . L'équation ci-haut force alors à être inférieur à . On sait toutefois que dans , le nombre peut aller jusqu'à . En prenant quelque chose de plus grand que , mais toujours sous , la somme sortira de .    Le produit scalaire   Dans cette partie, on cherche à généraliser la notion de produit scalaire à différents espaces. Dans le chapitre , le produit scalaire est apparu naturellement comme une opération algébrique dans le contexte du calcul d'angle. On a par la suite généralisé aux espaces . Dans le contexte des espaces algébriques quelconques, il faut réfléchir à ce que représente le produit scalaire afin de le définir, un peu comme on a défini le déterminant au chapitre .  Il s'avère que les propriétés de la proposition sont suffisantes pour généraliser, avec une légère adaptation de la dernière.  Le produit scalaire  Soit , un espace vectoriel sur les réels. On dit que a un produit scalaire si pour chaque paire il existe un nombre réel noté , appelé le produit scalaire, tel que  ;  ;  ;  avec seulement lorsque .   La quatrième propriété permet de définir la norme dans ce contexte, en ayant .    Soit , l'espace des polynômes de degré inférieur ou égal à et , des points distincts. Soit , des polynômes. On définit un produit scalaire sur de la manière suivante: . Montrer que ceci définit bel et bien un produit scalaire. On prend trois polynômes quelconques et un scalaire . Il faut vérifier chacune des quatre propriétés. Pour la première, cela découle directement de la commutativité de la multiplication. . De manière similaire, la deuxième propriété découle des propriétés de l'addition et de la multiplication: alors que la propriété trois est similaire elle aussi .  La dernière propriété est celle qui demande un peu plus de réflexion. La première partie est relativement simple, si . Si , alors . Comme est un polynôme de degré ou moins, il ne peut avoir plus de deux zéros. Les points et étant distincts, il s'ensuit que le seul polynôme pour lequel est possible est .   Soit , l'ensemble des fonctions continues sur . Soit . On considère le produit scalaire définit par . Montrer que ceci définit bel et bien un produit scalaire. Les trois premières propriétés découlent aussi des propriétés de l'addition, de la multiplication et également des propriétés de l'intégrale:   Pour la dernière propriété, il découle aussi des propriétés de l'intégrale (ou de l'interprétation en ce qui concerne l'aire sous la courbe) que . De même, si , puisque la fonction est continue, on doit avoir que , sinon il y aurait aire sous la courbe.   La trace d'une matrice On définit la trace d'une matrice carrée, notée comme la somme des éléments sur sa diagonale principale: . Montrer que . Puisque l'addition de matrice se fait entrée par entrée, il s'ensuit que la diagonale de est formée des valeurs . La trace est donc . Montrer que . De même, la multiplication par un scalaire se fait aussi en multipliant chaque entrée par le scalaire. Il s'ensuit que la diagonale est composée des valeurs . On a donc Montrer que . Comme les entrées sur la diagonale principale ne changent pas lors du passage à la transposée, la trace est la même. Montrer que . Montrer qu'un élément sur la diagonale de est de la forme et qu'un élément sur la diagonale de est de la forme . Les entrées sur la diagonale de la matrice s'obtiennent en effectuant le produit scalaire de la ligne de avec la colonne de . Donc, pour l'entrée en position du produit, on a . La trace est donnée par la somme des . En écrivant chaque entrée sur une ligne, la trace est donnée par la somme de tous les produits ci-dessous: .  Pour la matrice , on a plutôt . La trace est la somme de ces valeurs. Dans la liste de tous les , cela correspond à faire la somme sur les colonnes en premier plutôt que sur les lignes. Par exemple se retrouve dans le tableau des dans la première colonne. Comme l'addition est commutative, faire la somme sur de toutes les lignes ou faire la somme de toutes les colonnes revient à la même chose. On a alors .  On définit sur l'espace des matrices le produit scalaire suivant: Montrer que le produit scalaire en est bel et bien un en vérifiant les quatre propriétés.  Dans un premier temps, on veut montrer que , c'est-à-dire que Puisque , il s'ensuit de l'exercice que ce produit scalaire est commutatif.  Il découle des propriétés de la multiplication matricielle que puisque .  Selon les propriétés de l'addition matricielle, de la transposée et de la trace, on a .  Finalement, pour montrer que , on remarque que l'entrée sur la diagonale en position de correspond à , puisque les colonnes de sont les lignes de . Il s'ensuit donc que, pour que la somme soit nulle, tous les doivent aussi être nuls et donc, .  Montrer que, si est une matrice symétrique et si est une matrice antisymétrique ( , alors . Selon les propriétés de la trace et de la transposée, on a . Comme le seul nombre pour lequel est zéro, le résultat suit.  Avec la notion de produit scalaire, on peut définir le concept d'angle dans un espace vectoriel quelconque, plus principalement la notion d'orthogonalité. Ainsi, les fonctions et sont orthogonales sous le produit scalaire défini par l'intégrale en prenant , puisque . Ceci est une propriété importante dans l'espace qui permet de créer une base à partir des fonctions trigonométriques. Cela mène ensuite aux séries de Fourier. Les matrices symétriques et antisymétriques sont aussi orthogonales sous le produit scalaire défini à l'aide de la trace.     "
},
{
  "id": "def-espacevectoriel",
  "level": "2",
  "url": "sec-espaces.html#def-espacevectoriel",
  "type": "Définition",
  "number": "5.4.1",
  "title": "Espace vectoriel.",
  "body": " Espace vectoriel   Un espace vectoriel sur les réels est un ensemble munis de deux opérations, une opération d'addition, notée , et une opération de multiplication par un scalaire réel, notée , qui satisfont les propriétés suivantes. Pour chaque et pour tout , on a   Condition à respecter pour être un espace vectoriel   (fermeture par rapport à l'addition);  (commutativité de l'addition vectorielle);  (associativité de l'addition vectorielle);  (neutre additif);  (inverse additif);  (fermeture par rapport à la multiplication par un scalaire);  (associativité de la multiplication par un scalaire);  (distributivité sur l'addition vectorielle);  (distributivité de l'addition des scalaires);  (neutre multiplicatif).     "
},
{
  "id": "ex-espacesvectoriels",
  "level": "2",
  "url": "sec-espaces.html#ex-espacesvectoriels",
  "type": "Exemple",
  "number": "5.4.3",
  "title": "Des espaces vectoriels.",
  "body": " Des espaces vectoriels  Les espaces suivants sont des espaces vectoriels:  L'ensemble des matrices de taille , noté , et muni de l'addition matricielle et de la multiplication par un scalaire, toutes les deux dans leur forme usuelle.  L'ensemble , constitué des polynômes de degré inférieur ou égal à à coefficients réels, muni de l'addition et de la multiplication usuelle.  L'ensemble des suites infinies de nombres réels, muni de l'addition et de la multiplication usuelle. Un élément de est de la forme . L'addition et la multiplication se font composante par composante.  L'ensemble muni de l'addition et de la multiplication par un scalaire décrites ci-dessous. Pour et , .    C'était l'objet de l'exercice . Il ne manque qu'à justifier que l'addition de deux matrices de taille est aussi une matrice de taille , et de même pour la multiplication par un scalaire. Comme ces opérations se font composante par composante, c'est bien le cas.  Un polynôme de degré inférieur ou égal à peut s'écrire sous la forme où . On considère un deuxième polynôme de cette forme et des scalaires réels . On démontre certaines des propriétés, laissant les autres à l'exercice .  Dans un premier temps, si l'on additionne les polynômes et , on obtient . Puisque , l'addition de deux polynômes de degré inférieur ou égal à est encore un polynôme de degré inférieur ou égal à .  On montre ensuite la commutativité de l'addition. Puisqu'on peut écrire et que ceci correspond à l'addition , on obtient la commutativité.  Finalement, on montre la distributivité sur l'addition vectorielle. On a .   Cet espace est très similaire à , mais il y a une infinité de composantes aux vecteurs. Puisque l'addition et la multiplication se font composante par composante, l'espace est fermé sous les opérations d'addition et de multiplication par un scalaire. Une simple modification de la solution à l'exercice démontre les autres propriétés.   Cet exemple est particulier puisque c'est la première apparition d'opérations non usuelles. Puisque tous les nombres sont réels, est fermé sous les opérations d'addition et de multiplication par un scalaire. En effet, , puisque . De même, , puisque .  Pour les autres propriétés, on doit vérifier. On commence avec la commutativité. .  Pour l'associativité: .  Les choses se compliquent un peu lorsqu'on arrive à la propriété du neutre additif. Si l'on essaie naïvement d'additionner le vecteur au vecteur , on obtient . Cela ne veut toutefois pas dire que la propriété n'est pas respectée. Celle-ci dit qu'il doit exister un vecteur qui ne change rien lors de l'addition, et non pas que ce vecteur doit être . En observant la structure de l'opération , on voit qu'il faut être en mesure d'annuler les contributions du dans la première composante et dans la seconde. On essaie alors avec le vecteur : . Ainsi, dans cet espace, on a .  Pour l'existence d'un inverse additif, il faut se rappeler, dans un premier temps, que l'on cherche à obtenir le vecteur nul de cet espace, soit . Ainsi, si l'on essaie , on aura . Il faut donc repenser encore à l'opération pour trouver le bon inverse. On doit annuler la contribution du vecteur et modifier la constante ajoutée afin qu'elle donne à la première composante et à la seconde. En posant , on aura .  On termine avec la distributivité de la multiplication par le scalaire sur l'addition. Les propriétés restantes seront faites à l'exercice . Donc, pour et , on a . À ce stade-ci, il semble complexe de voir comment se rendre à l'objectif . Une stratégie courante dans ce cas consiste à commencer avec l'autre côté et de développer. On obtient . Comme cette dernière ligne est égale à la dernière ligne du développement précédent, on conclut que .   "
},
{
  "id": "def-ssesp2",
  "level": "2",
  "url": "sec-espaces.html#def-ssesp2",
  "type": "Définition",
  "number": "5.4.4",
  "title": "Sous-espace vectoriel.",
  "body": " Sous-espace vectoriel   Soit , un espace vectoriel. On dit que est un sous-espace vectoriel de si les vecteurs dans satisfont les propriétés suivantes:   Sous-espace vectoriel   Si deux vecteurs sont dans , alors leur somme est aussi dans , c'est-à-dire si , alors .  Si un vecteur est dans et qu'on le multiplie par un scalaire, alors le multiple est aussi dans , c'est-à-dire si , alors .    "
},
{
  "id": "prop-propespaces",
  "level": "2",
  "url": "sec-espaces.html#prop-propespaces",
  "type": "Proposition",
  "number": "5.4.6",
  "title": "Vecteur nul et inverse additif.",
  "body": " Vecteur nul et inverse additif  Soit , un espace vectoriel sur , soit et . Alors, on a les propriétés suivantes:   Propriétés des espaces vectoriels   Le vecteur nul est unique, c'est-à-dire si et , alors ;  ;  ;  Si alors ou ;     On considère deux vecteurs qui ont la propriété d'être un neutre additif. On a alors . Le vecteur nul est donc unique.    On débute avec un scalaire quelconque et un vecteur arbitraire. Pour montrer que , on peut montrer que . En vertu de l'unicité du vecteur nul, ceci montrera que . On a . Ainsi, .   De manière similaire à la propriété précédente, on veut montrer que en montrant que ce vecteur possède la propriété de neutre additif. L'unicité permettra de conclure que c'est le vecteur nul de l'espace. En utilisant une idée similaire, on a . Ainsi .   Pour démontrer cette affirmation, on fait une hypothèse additionnelle sur . En effet, soit , soit . Dans le cas où , la preuve est terminée puisque c'est ce qu'on voulait montrer. Maintenant, si , on doit montrer que . On a . Ainsi, si , le vecteur doit être nul.  Voir l'exercice .  "
},
{
  "id": "example-112",
  "level": "2",
  "url": "sec-espaces.html#example-112",
  "type": "Exemple",
  "number": "5.4.8",
  "title": "Retour sur l’espace vectoriel avec opérations spéciales.",
  "body": " Retour sur l'espace vectoriel avec opérations spéciales  On considère à nouveau l'espace muni de l'addition et de la multiplication .  On cherche à déterminer le vecteur nul et l'inverse additif en utilisant la proposition .   Soit , un vecteur quelconque de . En vertu de la propriété , on a , ce qui correspond au vecteur nul trouvé à l'exemple .  De même, en vertu de la propriété , on a , correspondant aussi à l'inverse trouvé à l'exemple .  "
},
{
  "id": "prop-ssespestespace",
  "level": "2",
  "url": "sec-espaces.html#prop-ssespestespace",
  "type": "Proposition",
  "number": "5.4.9",
  "title": "Un sous-espace vectoriel est aussi un espace vectoriel.",
  "body": " Un sous-espace vectoriel est aussi un espace vectoriel  Soit , un espace vectoriel et un sous-espace vectoriel. Alors est aussi un espace vectoriel.   Les deux propriétés de fermeture découlent directement de la définition d'un sous-espace vectoriel . Pour les propriétés plus algébriques, elles sont satisfaites en vertu du fait que, pour des vecteurs dans , ces vecteurs sont aussi dans et devaient donc naturellement satisfaire aux propriétés de la définition .  Le seul point à vérifier est que le vecteur nul appartient au sous-espace et que l'inverse additif d'un vecteur du sous-espace est aussi dans le sous-espace, car à priori, rien ne garantit cela.  Pour le vecteur nul, il suffit de constater qu'en prenant n'importe quel vecteur de , la propriété de fermeture par rapport à la multiplication par un scalaire combiné avec la multiplication par le scalaire font en sorte que est dans le sous-espace. La propriété montre que .  Pour l'inverse additif, la même idée s'applique, puisque selon la propriété . Comme c'est un multiple d'un vecteur dans le sous-espace, il est aussi dans le sous-espace. Tout ceci entraine qu'un sous-espace possède toutes les propriétés d'un espace et peut donc être vu aussi comme un espace vectoriel.   "
},
{
  "id": "example-113",
  "level": "2",
  "url": "sec-espaces.html#example-113",
  "type": "Exemple",
  "number": "5.4.10",
  "title": "Des sous-espaces vectoriels.",
  "body": " Des sous-espaces vectoriels  Les ensembles suivants sont des sous-espaces vectoriels des espaces vectoriels indiqués.  L'ensemble des matrices dont toutes les entrées sont sauf sur la diagonale principale est un sous-espace vectoriel de l'espace des matrices de taille muni des opérations usuelles.  L'ensemble des polynômes de degré inférieur ou égal à tels que est un sous-espace vectoriel de l'espace des polynômes de degré inférieur ou égal à , .  L'ensemble des suites infinies qui sont éventuellement est un sous-espace de muni des opérations usuelles.   Soit et , deux matrices diagonales et , un scalaire. Parce que l'addition matricielle se fait entrée par entrée et que les entrées autres que celles qui sont sur la diagonale sont nulles, la somme des matrices et n'a aussi des zéros que sur les entrées différentes de la diagonale. Elle est donc également une matrice diagonale, ce qui montre que l'ensemble est fermé par rapport à l'addition.  De même, en multipliant par , il n'y a que les entrées sur la diagonale qui sont potentiellement modifiées, les autres étant nulles. Le produit est aussi une matrice diagonale, ce qui montre que l'ensemble est fermé par rapport à la multiplication par un scalaire. L'ensemble est donc un sous-espace vectoriel de l'espace des matrices carrées.  On considère deux polynômes de degré inférieur ou égal à ayant la propriété que . On pose . Alors . Cet ensemble est donc fermé par rapport à l'addition. De même , montrant que l'ensemble est aussi fermé par rapport à la multiplication par un scalaire.  Soit et , deux suites qui sont éventuellement nulles passé un certain indice. Lorsqu'on les additionne, les entrées seront toujours nulles au-delà de l'indice . L'ensemble est donc fermé par rapport à l'addition.  De même, si l'on multiplie les éléments de par un scalaire quelconque, toutes les entrées au-delà de l'indice sont encore nulles. L'ensemble est donc aussi fermé par rapport à la multiplication par un scalaire. C'est un sous-espace vectoriel de .   "
},
{
  "id": "definition-49",
  "level": "2",
  "url": "sec-espaces.html#definition-49",
  "type": "Définition",
  "number": "5.4.11",
  "title": "Span, indépendance linéaire, base et dimension.",
  "body": " Span, indépendance linéaire, base et dimension  Soit , un espace vectoriel et soit , des éléments de . On définit l'espace engendré par ces vecteurs comme l'ensemble de leurs combinaisons linéaires: .  On dit que l'ensemble est linéairement indépendant si uniquement lorsque . Dans le cas contraire, on dit que l'ensemble est dépendant.  On dit que l'ensemble est une base de si  Les vecteurs génèrent , c'est-à-dire si  et si les vecteurs sont linéairement indépendants.    "
},
{
  "id": "ex-basepoly2",
  "level": "2",
  "url": "sec-espaces.html#ex-basepoly2",
  "type": "Exemple",
  "number": "5.4.12",
  "title": "Base d’un espace de polynômes.",
  "body": " Base d'un espace de polynômes  On considère à nouveau l'espace des polynômes de degré inférieur ou égal à et l'on considère les polynômes et . On souhaite montrer que  l'ensemble est linéairement indépendant et  engendre l'espace ,  faisant de cet ensemble une base pour .   On commence avec une combinaison linéaire des polynômes donnant le vecteur nul: . Deux stratégies sont possibles ici. L'équation précédente peut être développée et réécrite en regroupant les puissances de : . Ceci donne un système à trois équations et trois inconnues que l'on peut résoudre avec les techniques usuelles.   On voit donc qu'il faut que chaque coefficient soit nul pour satisfaire l'équation. Les polynômes sont donc indépendants.  Une autre stratégie consiste à réaliser que l'équation doit être satisfaite pour toutes les valeurs de . En prenant des valeurs spécifiques de , on peut se créer un autre système d'équations à résoudre. Par exemple, en prenant respectivement , on obtient les équations . Les deux dernières équations demandent à avoir et , ce qui n'est possible que lorsque . La première équation complète finalement la preuve avec .  Selon le contexte, ces deux méthodes peuvent s'avérer efficaces, parfois l'une plus que l'autre.   Pour montrer que les trois polynômes engendrent , il faut prendre un élément quelconque de l'espace et montrer qu'il peut s'écrire comme une combinaison linéaire des trois polynômes. On obtient donc . Encore une fois, on peut développer ou utiliser des valeurs spécifiques de . On propose de reprendre le calcul Sage fait précédemment, mais de résoudre l'équation en fonction du vecteur plutôt que du vecteur nul.   Puisqu'il est possible d'écrire tout polynôme comme une combinaison linéaire de , combinés au fait qu'ils sont linéairement indépendants, ces trois polynômes forment une base de .   "
},
{
  "id": "definition-50",
  "level": "2",
  "url": "sec-espaces.html#definition-50",
  "type": "Définition",
  "number": "5.4.13",
  "title": "La dimension d’un espace vectoriel.",
  "body": " La dimension d'un espace vectoriel  Soit , un espace vectoriel. S'il existe et des vecteurs qui engendrent , on dit que est de dimension finie et sa dimension est . Dans le cas contraire, on dit que est de dimension infinie.  "
},
{
  "id": "ex-espacesetdimension",
  "level": "2",
  "url": "sec-espaces.html#ex-espacesetdimension",
  "type": "Exemple",
  "number": "5.4.14",
  "title": "Quelques espaces et leur dimension.",
  "body": " Quelques espaces et leur dimension  On cherche à caractériser la dimension des espaces suivants:  L'espace des polynomes de degré inférieur ou égal à ;  L'espace des matrices carrées de taille ;  L'espace des suites infinies.     Puisqu'on a trouvé une base de cet espace à l'exemple , la dimension de cet espace correspond au nombre de vecteurs dans la base, soit .   Une matrice carrée est de la forme . Pour engendrer cet espace, on peut utiliser les matrices . On voit en effet que toute matrice peut s'écrire comme .  De plus, la seule manière d'avoir la matrice nulle, correspondant au neutre additif de cet espace, est de prendre . Ces matrices forment donc une base et la dimension est .   Le nom de l'espace suggère fortement que la dimension de cet espace sera infinie. Il faut montrer qu'il est impossible d'engendrer cette espace avec un nombre fini de vecteurs. Pour montrer que cela est impossible, on procède par contradiction.  On suppose qu'il existe suites engendrant . On considère le sous-espace vectoriel composé des suites dont les éléments valent lorsque l'indice est plus grand que . Ce sous-espace est, tout compte fait, équivalent à puisqu'on peut ignorer les composantes nulles à partir de l'indice . Or on sait que la dimension de est , ce qui signifie qu'il faut vecteurs pour engendrer ce sous-espace. Ceci entraine que les vecteurs en hypothèse ne peuvent engendrer le sous-espace vectoriel, mais comme celui-ci est inclus dans l'espace , cela contredit le fait que les suites existent.  Comme il ne peut y avoir d'ensemble de taille finie qui engendre cet espace, il est de dimension infinie.   "
},
{
  "id": "example-116",
  "level": "2",
  "url": "sec-espaces.html#example-116",
  "type": "Exemple",
  "number": "5.4.15",
  "title": "Les espaces de fontions.",
  "body": " Les espaces de fontions  On considère un intervalle , possiblement en entier. On note par  l'ensemble des fonctions réelles définies sur ;  l'ensemble des fonctions réelles et continues sur ;  l'ensemble des fonctions réelles et continues dont les dérivées sont aussi continues sur ;  l'ensemble des fonctions réelles et continues dont les premières dérivées sont aussi continues sur ;  l'ensemble des fonctions réelles et continues infiniment dérivables de manière continue sur .    On munit ces espaces de l'addition usuelle des fonctions ainsi que de la multiplication usuelle par un scalaire. Ces espaces sont tous des espaces vectoriels. La preuve utilise le résultat bien connu en calcul différentiel qui stipule que la somme de deux fonctions continues est continue, tout comme le résultat de la multiplication d'une fonction continue par une constante.  "
},
{
  "id": "example-117",
  "level": "2",
  "url": "sec-espaces.html#example-117",
  "type": "Exemple",
  "number": "5.4.16",
  "title": "Un sous-espace familier.",
  "body": "Un sous-espace familier  On considère l'espace vectoriel et le sous-espace . Ce sous-espace représente l'ensemble des fonctions qui sont égales à leur dérivée première. On montre dans un premier temps que c'est bel et bien un sous-espace vectoriel et l'on détermine une base de ce sous-espace.   Puisque est un membre de l'ensemble , il y a au moins un élément dans l'ensemble. On considère deux éléments quelconque de ainsi qu'un scalaire réel . Pour la somme, on a , la somme fait donc partie de . De même, on a en vertu de la règle sur la dérivée d'un multiple d'une fonction. est donc un sous-espace vectoriel.  En plus de la fonction nulle, une fonction bien connue qui est égale à sa dérivée est . Cette fonction constitue, en fait, une base pour ce sous-espace vectoriel, qui est donc de dimension . Puisqu'il n'y a qu'un seul élément, il suffit de montrer que celui-ci génère . On considère un élément quelconque du sous-espace et l'on considère la fonction . En dérivant cette fonction, on trouve . Si la fonction a pour dérivée , c'est donc qu'elle est constante et ainsi , ce qui entraine que . Toutes les fonctions dans peuvent alors s'écrire comme un multiple de la fonction , ce qui signifie qu'elle génère le sous-espace.   "
},
{
  "id": "ex-relativite",
  "level": "2",
  "url": "sec-espaces.html#ex-relativite",
  "type": "Exemple",
  "number": "5.4.17",
  "title": "Addition de vitesses en relativité.",
  "body": " Addition de vitesses en relativité   L'ensemble muni des opérations suivantes, pour  et est un espace vectoriel sur les réels. Ici, les variables représentent des fractions de la vitesse de la lumière, les signes positif ou négatif indiquant la direction.  On montre que les propriétés d'un espace vectoriel sont respectées avec ces opérations.    Soit et . On veut montrer que la somme de deux éléments dans reste dans , c'est-à-dire reste dans l'intervalle . Puisque , on a avec , on a et donc . L'argument pour montrer que est similaire et sera explicité à l'exercice . On a donc fermeture pour l'addition, car on a montré que .   La commutativité de l'addition usuelle ainsi que de la multiplication usuelle montre que .   L'associativité sera démontrée à l'exercice .   Selon la propriété , on peut obtenir le vecteur nul en multipliant un vecteur quelconque par le scalaire . On a donc . Le vecteur nul est donc simplement . Évidemment, on aurait aussi pu deviner et vérifier que .   Voir l'exercice .  Voir l'exercice .  Soit et . On cherche à montrer que . Dans un premier temps, on a . Pour l'autre côté, on commence par calculer : . On fait ensuite , ce qui donne .  On calcule séparément et . Pour , on a alors que pour , on obtient   On pose et l'on revient à . On a . On a donc égalité entre et .   Encore un gros exercice de manipulation algébriques. On veut montrer que . Dans un premier temps, on a .  On pose et . Pour l'autre côté, on a . Puisque . D'une manière similaire, on trouve et donc . La propriété est donc respectée.   Voir l'exercice .  On a .   "
},
{
  "id": "exercise-307",
  "level": "2",
  "url": "sec-espaces.html#exercise-307",
  "type": "Exercice",
  "number": "5.4.3.1",
  "title": "",
  "body": " L'ensemble des nombres complexes est défini comme l'ensemble et est lui-même un nombre complexe ayant la propriété que . On munit cet espace de l'addition et de la multiplication par un scalaire réel .  Montrer que cet ensemble muni de ces opérations est un espace vectoriel.   Soit et , des nombres complexes et , des réels.  Pour la propriété , on doit montrer que la somme de deux nombres complexes est encore un nombre complexe, c'est-à-dire qu'elle peut s'écrire sous la forme un réel plus un réel fois . On a en vertu de l'addition sur les complexes. Comme de même que , la somme de nombres complexes est encore un nombre complexe.  La commutativité et l'associativité découlent directement des propriétés de l'addition sur les réels, puisque et que .  Le neutre additif est aussi dans cet espace, puisque et l'inverse additif est simplement , puisque .  Pour les propriétés avec la multiplication, elles découlent aussi des propriétés de l'addition et de la multiplication avec les nombres réels. Puisque et , on obtient la fermeture par rapport à la multiplication. L'associativité s'obtient du fait que .  De plus, et . Finalement, et donc, toutes les propriétés sont respectées. C'est un espace vectoriel.  "
},
{
  "id": "exercise-308",
  "level": "2",
  "url": "sec-espaces.html#exercise-308",
  "type": "Exercice",
  "number": "5.4.3.2",
  "title": "",
  "body": " On considère l'ensemble des nombres réels muni de l'addition et de la multiplication par un scalaire usuelle. Cet ensemble n'est pas un espace vectoriel. Déterminer quelle(s) propriété(s) n'est (ne sont) pas satisfaite(s).   Les propriétés Voir l'explication dans la solution ne sont pas respectées.  Puisque la somme de nombres réels est aussi un nombre réel et que , la première propriété est respectée. Par contre, la deuxième propriété ne l'est pas. En effet, en général on n'a pas . En prenant , on a , mais . De même, l'associativité n'est pas respectée étant donné que le terme à droite a une particularité qui lui est propre. En effet , alors que . Dans le premier cas, est pris deux fois dans un côté droit de l'opération , il apparait donc avec une puissance quatre, mais dans le second cas, il est seulement affecté d'un exposant deux, conséquence du fait qu'il n'est à droite de l'opération qu'une seule fois.  D'un point de vue technique, l'élément neutre existe, puisque . Comme cette addition n'est pas commutative, il faudrait aussi vérifier à gauche aussi. Dans ce cas, on a , ce qui, en général, ne donnera pas . On pourrait donc dire qu'il y a un neutre additif à gauche, mais qu'il n'y en a pas à droite. De même, pour l'inverse additif, on peut prendre et avoir , qui correspond au neutre à gauche, mais si , aucune valeur de ne fera que .  Comme la multiplication est celle qui est usuelle, la propriété est respectée, de même que la propriété et la propriété du neutre multiplicatif. Pour les propriétés qui combinent multiplication et addition, elles ne sont pas respectées. En effet, alors que . De même, on a , mais . Ces propriétés ne sont donc pas respectées.  "
},
{
  "id": "exercise-309",
  "level": "2",
  "url": "sec-espaces.html#exercise-309",
  "type": "Exercice",
  "number": "5.4.3.3",
  "title": "",
  "body": " On considère les nombres réels strictement positifs munis des opérations suivantes: Est-ce que ceci forme un espace vectoriel? Oui. On note , l'ensemble des nombres réels strictement positifs. Muni de ces opérations, c'est en effet un espace vectoriel. On montre chacune des propriétés. Soit et . Puisque le produit de deux nombres strictement positifs est encore positif, il s'ensuit que est dans . La propriété est satisfaite. De la même manière, puisque la multiplication usuelle de nombres réels est commutative, on a et la propriété est satisfaite. La propriété découle aussi des propriétés de la multiplication usuelle, notamment l'associativité. Ainsi, .  On doit faire attention au neutre et à l'inverse additif. On peut les deviner ou encore utiliser les propriétés de la proposition . Dans le cas du neutre additif, est le vecteur nul, puisque . Du côté de l'inverse additif, c'est qui fonctionne ( ) étant donné que .  Pour les propriétés de la multiplication par un scalaire, on remarque que cette multiplication est en fait le processus d'exponentiation de nombres réels. Puisque l'exponentiation réelle donne toujours un nombre strictement plus grand que zéro, il s'ensuit que . De plus, en vertu des propriétés des exposants, on a . La propriété est donc satisfaite.  Pour la propriété , on a , ce qui confirme que cette propriété est satisfaite. La propriété est similaire, puisque . Finalement, la propriété s'obtient grâce au fait que .  Toutes les propriétés étant respectées, l'ensemble est un espace vectoriel.  "
},
{
  "id": "exercise-310",
  "level": "2",
  "url": "sec-espaces.html#exercise-310",
  "type": "Exercice",
  "number": "5.4.3.4",
  "title": "",
  "body": "Déterminer si chacun des ensembles suivants est linéairement indépendant. Tous les espaces sous-jacents sont munis des opérations d'addition et de multiplication usuelles. vu comme un ensemble de . Oui On regarde deux manières de faire le problème. Dans un premier temps, la définition demande de trouver des coefficients tels que . Si la seule solution à ce système est celle où , alors l'ensemble est linéairement indépendant. On obtient alors un système à quatre équations et trois inconnues, en regardant composante par composante les entrées des matrices: . On voit rapidement qu'on doit avoir et, avec la deuxième équation, on trouve , tous les coefficients doivent donc être nuls.  Dans un second temps, on a établi, à l'exemple , que la dimension de l'espace était en trouvant une base qui générait cet espace. On peut donc écrire chacune des matrices de l'ensemble en fonction de la base ordonnée . Ainsi, on a . La question dans le contexte matriciel est équivalente à la même question, mais du point de vue vectoriel. On place les vecteurs dans les lignes d'une matrice et l'on regarde la dimension de l'espace ligne afin de déterminer s'ils sont indépendants.   Comme la dimension de l'espace ligne correspond au nombre de vecteurs, ils sont indépendants.  vu comme un ensemble de l'espace des polynômes de degré inférieur ou égal à . Non Encore une fois, il y a plusieurs manières de répondre à cette question. À l'exemple , on a montré que la dimension de est égale à . En suivant un raisonnement similaire, on peut montrer que la dimension de est . Puisqu'il y a trois vecteurs dans l'ensemble et que l'espace est de dimension , les vecteurs sont forcément dépendants. vu comme un ensemble dans l'espace . Non Ici, il est plus difficile de procéder avec une base de l'espace, celui-ci étant de dimension infinie. On sait toutefois que , qui se traduit en réécrivant par . On a ainsi une combinaison linéaire non triviale qui donne le vecteur nul de l'espace. Les vecteurs sont donc dépendants. "
},
{
  "id": "exercise-311",
  "level": "2",
  "url": "sec-espaces.html#exercise-311",
  "type": "Exercice",
  "number": "5.4.3.5",
  "title": "",
  "body": "On considère l'espace des matrices muni des opérations usuelles. Déterminer si chacun des ensembles suivants est un sous-espace vectoriel. Le cas échéant, déterminer une base du sous-espace et dans le cas contraire, justifier. L'ensemble des matrices de rang . Non Puisque le vecteur nul doit faire partie de chaque sous-espace et que la matrice est de rang , l'ensemble n'est pas un sous-espace vectoriel. L'ensemble des matrices de rang inférieur ou égal à . Non On ne peut plus utiliser l'argument précédent puisqu'ici, la matrice fait partie de l'ensemble. On essaie de réfléchir à ce qui se produit avec le rang lorsqu'on additionne des matrices ou lorsqu'on multiplie par un scalaire. Comme le rang correspond au nombre de lignes non nulles de la forme échelonnée réduite d'une matrice, le fait de multiplier par une constante non nulle ne devrait pas changer le rang. La deuxième propriété est donc respectée.  On se demande alors si la somme de deux matrices peut ajouter des lignes non nulles. En prenant et , deux matrices de rang , on voit bien que la somme donne la matrice identité, de rang . En ce sens, ce n'est pas un sous-espace vectoriel.  L'ensemble des matrices qui contiennent le vecteur dans leur espace nul. Oui. Cela découle du fait que si et , alors et . C'est donc un sous-espace vectoriel.  On cherche maintenant une base de ce sous-espace. Dans si l'espace nul contient le vecteur , alors l'espace nul est de dimension ou . Cela signifie que l'espace ligne de la matrice est de dimension ou . De plus, l'espace ligne doit être perpendiculaire à l'espace nul. Ainsi, si l'espace nul est simplement , alors l'espace ligne est engendré par . Les matrices possédant cet espace ligne sont toutes de la forme pour . Si toutefois l'espace nul est au complet, alors l'espace nul ne contient que le vecteur nul. Il n'y a que la matrice nulle qui est ainsi. On peut donc dire que toutes les matrices ayant le vecteur dans leur espace nul s'écrivent comme , sans restriction sur . Le sous-espace est de dimension et la matrice est une base.  L'ensemble des matrices qui contiennent le vecteur dans leur espace colonne. Non. Comme la matrice nulle doit faire partie de l'ensemble pour être un sous-espace vectoriel et que l'espace colonne de la matrice nul ne contient que le vecteur , cet ensemble n'est pas un sous-espace. L'ensemble des matrices qui sont symétriques. (Rappel: une matrice est symétrique si .) Oui.  C'est une conséquence directe des propriétés de la proposition que ce sous-ensemble est fermé sous l'addition et la multiplication par un scalaire. En effet et .  Pour trouver une base, on remarque que les matrices symétriques de taille sont de la forme . On peut donc l'engendrer par les matrices indépendantes .  "
},
{
  "id": "exo-inverseunique",
  "level": "2",
  "url": "sec-espaces.html#exo-inverseunique",
  "type": "Exercice",
  "number": "5.4.3.6",
  "title": "",
  "body": "À la proposition , on a montré que le vecteur nul d'un espace vectoriel est unique . Montrer que l'inverse additif est aussi unique. Soit , des vecteurs tels que et . On veut montrer que . On a . Ainsi, l'inverse additif est unique. "
},
{
  "id": "exercise-313",
  "level": "2",
  "url": "sec-espaces.html#exercise-313",
  "type": "Exercice",
  "number": "5.4.3.7",
  "title": "",
  "body": "On considère l'ensemble des polynômes de degré inférieur ou égal à tels que .  Montrer que cet ensemble est un sous-espace vectoriel de l'espace des polynômes de degré inférieur ou égal à . Soit , des polynômes de degré inférieur ou égal à avec . On a alors , la somme est donc aussi dans l'ensemble. De plus, si , il s'ensuit que et que cet ensemble est un sous-espace vectoriel. Déterminer une base de ce sous-espace. Quelle est sa dimension? La dimension est deux. Une base possible est .  Soit , un polynôme de degré avec . On a alors , ce qui entraine que . Comme les polynômes et sont indépendants et que tout polynôme de cet espace peut être obtenu par une combinaison linéaire de ces deux polynômes, la dimension est et ils forment une base.  "
},
{
  "id": "exo-neutremultiplicatif",
  "level": "2",
  "url": "sec-espaces.html#exo-neutremultiplicatif",
  "type": "Exercice",
  "number": "5.4.3.8",
  "title": "",
  "body": "Montrer la propriété de la proposition .  On a . Ainsi, le vecteur est l'inverse additif, puisqu'en vertu de l'exercice , celui-ci est unique.  "
},
{
  "id": "exercise-315",
  "level": "2",
  "url": "sec-espaces.html#exercise-315",
  "type": "Exercice",
  "number": "5.4.3.9",
  "title": "",
  "body": "Dans la preuve de la propriété , on a fait l'hypothèse que soit , soit et l'on a démontré l'implication sous cette dichotomie supplémentaire. Faire une preuve alternative où l'hypothèse supplémentaire est plutôt ou . Débuter avec et conclure qu'on doit avoir ou .  Pour démontrer l'affirmation, on fait une hypothèse additionnelle sur . En effet, soit , soit . Dans le cas où , la preuve est terminée puisque c'est ce qu'on voulait montrer. Maintenant, si , on doit montrer que . Soit , un vecteur quelconque. On a . Ceci implique que ou . Puisque, par hypothèse, , on conclut qu'on doit avoir .  "
},
{
  "id": "exercise-316",
  "level": "2",
  "url": "sec-espaces.html#exercise-316",
  "type": "Exercice",
  "number": "5.4.3.10",
  "title": "",
  "body": "Soit , une matrice carrée quelconque. On considère l'ensemble des matrices qui commutent avec : . Montrer que est un sous-espace vectoriel de muni des opérations usuelles.  Soit et . Pour que soit dans , il faut que . On a . Ainsi, .  Pour que , il faut que . On a . L'ensemble est donc un sous-espace vectoriel de  "
},
{
  "id": "exercise-317",
  "level": "2",
  "url": "sec-espaces.html#exercise-317",
  "type": "Exercice",
  "number": "5.4.3.11",
  "title": "",
  "body": " Voici une preuve alternative de la propriété . Justifier chacune des étapes. .   Voici la preuve justifiée: .  "
},
{
  "id": "exercise-318",
  "level": "2",
  "url": "sec-espaces.html#exercise-318",
  "type": "Exercice",
  "number": "5.4.3.12",
  "title": "",
  "body": " Voici une preuve alternative de la propriété s'inspirant de l'exercice précédent. Compléter et justifier chacune des étapes. .   Voici la preuve complétée et justifiée: .  "
},
{
  "id": "exo-proprelativite",
  "level": "2",
  "url": "sec-espaces.html#exo-proprelativite",
  "type": "Exercice",
  "number": "5.4.3.13",
  "title": "",
  "body": " À l'exemple , on a montré que l'ensemble des nombres réels muni des opérations spéciales et était un espace vectoriel, mais certaines propriétés n'ont pas été démontrées dans l'exemple.   Montrer que .   On a    Montrer que, pour chaque , il existe un nombre tel que .   Si l'on prend , on a .   Montrer que .  Puisque , on a . Ainsi .  De même, et donc . Ceci signifie que .  Montrer que .   On voit que .  On pose et . Pour l'autre côté, on a . Puisque . D'une manière similaire, on trouve et donc . La propriété est donc respectée.  Est-ce que l'ensemble est un sous-espace vectoriel de ? Non. Essayer de trouver deux nombres dont la somme sort de l'intervalle. Si l'on prend et , alors . Donc, ce n'est pas fermé sous l'addition.  Comment en vient-on à trouver ces nombres? On peut y aller de manière méthodique avec l'addition. Par exemple, si l'on veut que la somme soit inférieure à , alors on cherche des conditions sur pour que ce soit valide. . La fonction est décroissante et tend vers lorsque tend vers .   La fonction   Un graphique illustrant la fonction un moins deux y sur deux moins y. On voit que la fonction est décroissante et tend vers zéro lorsque y s'approche de une demie.     On prend donc une valeur arbitraire de , par exemple . L'équation ci-haut force alors à être inférieur à . On sait toutefois que dans , le nombre peut aller jusqu'à . En prenant quelque chose de plus grand que , mais toujours sous , la somme sortira de .  "
},
{
  "id": "exercise-320",
  "level": "2",
  "url": "sec-espaces.html#exercise-320",
  "type": "Exercice",
  "number": "5.4.3.14",
  "title": "",
  "body": "Soit , l'espace des polynômes de degré inférieur ou égal à et , des points distincts. Soit , des polynômes. On définit un produit scalaire sur de la manière suivante: . Montrer que ceci définit bel et bien un produit scalaire. On prend trois polynômes quelconques et un scalaire . Il faut vérifier chacune des quatre propriétés. Pour la première, cela découle directement de la commutativité de la multiplication. . De manière similaire, la deuxième propriété découle des propriétés de l'addition et de la multiplication: alors que la propriété trois est similaire elle aussi .  La dernière propriété est celle qui demande un peu plus de réflexion. La première partie est relativement simple, si . Si , alors . Comme est un polynôme de degré ou moins, il ne peut avoir plus de deux zéros. Les points et étant distincts, il s'ensuit que le seul polynôme pour lequel est possible est .  "
},
{
  "id": "exercise-321",
  "level": "2",
  "url": "sec-espaces.html#exercise-321",
  "type": "Exercice",
  "number": "5.4.3.15",
  "title": "",
  "body": "Soit , l'ensemble des fonctions continues sur . Soit . On considère le produit scalaire définit par . Montrer que ceci définit bel et bien un produit scalaire. Les trois premières propriétés découlent aussi des propriétés de l'addition, de la multiplication et également des propriétés de l'intégrale:   Pour la dernière propriété, il découle aussi des propriétés de l'intégrale (ou de l'interprétation en ce qui concerne l'aire sous la courbe) que . De même, si , puisque la fonction est continue, on doit avoir que , sinon il y aurait aire sous la courbe.  "
},
{
  "id": "exo-trace",
  "level": "2",
  "url": "sec-espaces.html#exo-trace",
  "type": "Exercice",
  "number": "5.4.3.16",
  "title": "La trace d’une matrice.",
  "body": "La trace d'une matrice On définit la trace d'une matrice carrée, notée comme la somme des éléments sur sa diagonale principale: . Montrer que . Puisque l'addition de matrice se fait entrée par entrée, il s'ensuit que la diagonale de est formée des valeurs . La trace est donc . Montrer que . De même, la multiplication par un scalaire se fait aussi en multipliant chaque entrée par le scalaire. Il s'ensuit que la diagonale est composée des valeurs . On a donc Montrer que . Comme les entrées sur la diagonale principale ne changent pas lors du passage à la transposée, la trace est la même. Montrer que . Montrer qu'un élément sur la diagonale de est de la forme et qu'un élément sur la diagonale de est de la forme . Les entrées sur la diagonale de la matrice s'obtiennent en effectuant le produit scalaire de la ligne de avec la colonne de . Donc, pour l'entrée en position du produit, on a . La trace est donnée par la somme des . En écrivant chaque entrée sur une ligne, la trace est donnée par la somme de tous les produits ci-dessous: .  Pour la matrice , on a plutôt . La trace est la somme de ces valeurs. Dans la liste de tous les , cela correspond à faire la somme sur les colonnes en premier plutôt que sur les lignes. Par exemple se retrouve dans le tableau des dans la première colonne. Comme l'addition est commutative, faire la somme sur de toutes les lignes ou faire la somme de toutes les colonnes revient à la même chose. On a alors .  On définit sur l'espace des matrices le produit scalaire suivant: Montrer que le produit scalaire en est bel et bien un en vérifiant les quatre propriétés.  Dans un premier temps, on veut montrer que , c'est-à-dire que Puisque , il s'ensuit de l'exercice que ce produit scalaire est commutatif.  Il découle des propriétés de la multiplication matricielle que puisque .  Selon les propriétés de l'addition matricielle, de la transposée et de la trace, on a .  Finalement, pour montrer que , on remarque que l'entrée sur la diagonale en position de correspond à , puisque les colonnes de sont les lignes de . Il s'ensuit donc que, pour que la somme soit nulle, tous les doivent aussi être nuls et donc, .  Montrer que, si est une matrice symétrique et si est une matrice antisymétrique ( , alors . Selon les propriétés de la trace et de la transposée, on a . Comme le seul nombre pour lequel est zéro, le résultat suit. "
},
{
  "id": "sec-espaceslabos",
  "level": "1",
  "url": "sec-espaceslabos.html",
  "type": "Section",
  "number": "5.5",
  "title": "Activités et laboratoires",
  "body": "  Activités et laboratoires    Dans cette section, on regarde des activités et des laboratoires en lien avec des concepts présentés dans le chapitre.    Le jeu Lights out   Lights Out est un jeu électronique mis en marché en 1995. Il consiste en une grille de taille dans laquelle on retrouve de petites lumières qui peuvent être allumées ou éteintes. Lorsqu'on touche un élément de la grille, celui-ci, ainsi que ses quatre voisins, changent d'état, passant d'allumé à éteint ou d'éteint à allumé. Le but du jeu est, étant donnée une configuration initiale, d'éteindre toutes les lumières. Voici une image tirée de Wikipedia Image par Life of Riley, libre de droits, tirée de . qui montre le fonctionnement du jeu.   Le jeu Lights Out .   Cinq grille de taille cinq de taille cinq par cinq sont illustrées. Les grilles sont de couleur vert foncé avec certains carrés plus brillant, simulant une lumière ouverte. Dans celle à l'extrémité gauche, il n'y a que le carré au coin supérieur gauche qui est en position ouvert. Une flèche amenant à la seconde grille dans laquelle on voit une main appuyé sur le carré inférieur droit. Dans la troisième grille, les trois carrés formant un L inversé dans le coin inférieur droit sont maintenant allumés. La quatrième grille voit une main appuyer sur le carré dans la quatrième ligne et quatrième colonne. Celui-ci passe de éteint à allumé dans la cinquième grille tout comme celui à sa gauche et au-dessus. Les carrés à sa droite et en dessous eux passent d'allumés à éteints.    On considère, dans un premier temps, une version simplifiée du jeu où la grille est de taille . On peut représenter une grille de jeu par une matrice où les entrées sont si la lumière est allumée et si la lumière est éteinte. La figure illustre un exemple associé à la matrice .   Un exemple   Une grille de taille trois par trois est illustrée avec les carrés colorées en vert. Les carrés en position un,un; un,trois; deux,deux et trois,deux sont d'un vert plus brillant, signifiant qu'ils sont allumés. Les autres carrés sont d'un vert plus terne, signifiant qu'ils sont éteints.    Pour le cas , il s'avère qu'il existe une solution peu importe la configuration initiale. L'image interactive ci-dessous permet de jouer avec une configuration aléatoire et montre aussi la solution optimale dans chaque cas.   Lights Out en version interactive     L'espace dans lequel on travaillera pour résoudre ce problème est l'espace des matrices dont les entrées ne sont que des ou des . On définit sur les nombres les opérations suivantes: et pour , on définit et alors que pour , on définit et toujours .  Montrer que l'ensemble des nombres muni de ces opérations est un espace vectoriel.  Ceci entraine que l'espace des matrices muni de l'addition entrée par entrée avec ces opérations est aussi un espace vectoriel.  Sur Sage, il est possible de travailler avec l'addition définie plus haut. Cela correspond à travailler en modulo . Pour cela, on ajoute un argument GF(2) dans la définition des matrices et des vecteurs, indiquant à Sage qu'on ne travaille qu'avec les nombres et . Sage connait déjà les règles arithmétiques de cet espace.   On peut associer à chaque case une matrice donnant son effet lorsqu'on clique sur la case. L'effet d'un clic revient donc à additionner à une matrice représentant une grille de Lights Out la matrice du clic, selon les règles de l'addition définies plus haut. Par exemple, un clic sur la case en position correspond à la matrice . Son effet sur la grille de la figure peut donc être obtenu en ajoutant à la matrice la matrice (suivant les règles d'additions définies plus haut): . Le résultat est illustré ci-dessous.   L'exemple après un clic   Une grille de taille trois par trois est illustrée avec les carrés colorées en vert. Les carrés en position un,trois; deux,un; trois,un et trois,deux sont d'un vert plus brillant, signifiant qu'ils sont allumés. Les autres carrés sont d'un vert plus terne, signifiant qu'ils sont éteints.    Sur Sage:   Définir les neuf matrices de clic.   Vérifier que et est donc une solution à la grille de la figure .   Justifier le fait que, pour une solution, l'ordre dans lequel on clique sur les carrés n'est pas important. Montrer que chaque matrice est son propre inverse dans cet espace.   On s'intéresse maintenant à obtenir une solution pour une configuration de départ spécifique . On cherche une suite de matrice telles que . Puisque chaque matrice est son propre inverse, on peut réécrire l'équation sous la forme . Expliquer pourquoi, dans une solution optimale (nombre minimal de clic), chaque matrice apparait au plus une fois. En vertu de l'exercice précédent, on peut alors dire que pour avoir une solution, il faut que la matrice soit dans le des matrices , c'est-à-dire , avec les . Comme l'espace des matrices de taille est de dimension et qu'une base de cet espace est donnée par les neuf matrices qui ne contiennent qu'une entrée non nulle égale à (voir l'exemple ), on peut écrire l'équation sous la forme matricielle où correspond à l'écriture vectorielle de la matrice dans la base des matrices ne contenant qu'un seul . La représentation vectorielle de la matrice l'équation est donnée par . On considère donc que la base ordonnée de cet espace est . La première colonne de cette matrice vient donc du fait que .  Montrer que la solution pour la matrice est bel et bien celle qui est donnée à l'équation en résolvant ce système d'équations.   Les questions suivantes s'intéressent au nombre de solutions et à l'existence de solutions pour la grille . Montrer que la solution est unique.  Est-ce que toute configuration initiale possède une solution?  On explore maintenant quelques variantes. La première variante considère tout simplement la grille carrée de taille . Montrer que la configuration de départ où seulement la case au coin supérieur gauche est allumée ne possède pas de solutions.  Montrer que la grille où toutes les cases sont initialement allumées possède plusieurs solutions et donner l'une de celles-ci. Rien n'empêche la grille d'être carrée, on pourrait tout aussi bien avoir une grille rectangulaire. Il existe configurations initiales pour une grille de taille . Combien possèdent une solution? Déterminer si possible une solution pour la grille suivante:   Une grille de Lights Out de taille   Une grille de taille quatre par trois est illustrée. Les carrés sur la premières lignes sont allumés, ceux sur la deuxième ligne de même que celui sur en position trois;deux sont éteints et les autres sont également allumés.     Explorer une autre variante, existante ou inventée. Répondre aux questions suivantes:  Est-ce qu'il y a toujours une solution peu importe la configuration initiale?  S'il y en a une, donner une solution pour une grille complètement allumée et sinon, montrer qu'il n'y en a pas.    Voici quelques inspirations:  Un jeu où il y a trois états pour une case, par exemple rouge, vert et éteint. Un clic change la case et ses voisins selon l'ordre rouge à vert, vert à éteint et éteint à rouge. Considérer une grille et partir de l'état où tout est rouge.  Un jeu où les bords sont reliés, chaque clic affecte cinq cellules. Donc la cellule dans le coin supérieur gauche change aussi l'état de la cellule dans le coin supérieur droit et dans le coin inférieur gauche. Considérer une grille .  Un jeu où chaque clic affecte la ligne entière et la colonne entière. Considérer une grille .   Dans le cas d'une variante inventée, bien clarifier les règles du jeu.    "
},
{
  "id": "project-5",
  "level": "2",
  "url": "sec-espaceslabos.html#project-5",
  "type": "Projet",
  "number": "5.5.1",
  "title": "Le jeu “Lights out”.",
  "body": " Le jeu Lights out   Lights Out est un jeu électronique mis en marché en 1995. Il consiste en une grille de taille dans laquelle on retrouve de petites lumières qui peuvent être allumées ou éteintes. Lorsqu'on touche un élément de la grille, celui-ci, ainsi que ses quatre voisins, changent d'état, passant d'allumé à éteint ou d'éteint à allumé. Le but du jeu est, étant donnée une configuration initiale, d'éteindre toutes les lumières. Voici une image tirée de Wikipedia Image par Life of Riley, libre de droits, tirée de . qui montre le fonctionnement du jeu.   Le jeu Lights Out .   Cinq grille de taille cinq de taille cinq par cinq sont illustrées. Les grilles sont de couleur vert foncé avec certains carrés plus brillant, simulant une lumière ouverte. Dans celle à l'extrémité gauche, il n'y a que le carré au coin supérieur gauche qui est en position ouvert. Une flèche amenant à la seconde grille dans laquelle on voit une main appuyé sur le carré inférieur droit. Dans la troisième grille, les trois carrés formant un L inversé dans le coin inférieur droit sont maintenant allumés. La quatrième grille voit une main appuyer sur le carré dans la quatrième ligne et quatrième colonne. Celui-ci passe de éteint à allumé dans la cinquième grille tout comme celui à sa gauche et au-dessus. Les carrés à sa droite et en dessous eux passent d'allumés à éteints.    On considère, dans un premier temps, une version simplifiée du jeu où la grille est de taille . On peut représenter une grille de jeu par une matrice où les entrées sont si la lumière est allumée et si la lumière est éteinte. La figure illustre un exemple associé à la matrice .   Un exemple   Une grille de taille trois par trois est illustrée avec les carrés colorées en vert. Les carrés en position un,un; un,trois; deux,deux et trois,deux sont d'un vert plus brillant, signifiant qu'ils sont allumés. Les autres carrés sont d'un vert plus terne, signifiant qu'ils sont éteints.    Pour le cas , il s'avère qu'il existe une solution peu importe la configuration initiale. L'image interactive ci-dessous permet de jouer avec une configuration aléatoire et montre aussi la solution optimale dans chaque cas.   Lights Out en version interactive     L'espace dans lequel on travaillera pour résoudre ce problème est l'espace des matrices dont les entrées ne sont que des ou des . On définit sur les nombres les opérations suivantes: et pour , on définit et alors que pour , on définit et toujours .  Montrer que l'ensemble des nombres muni de ces opérations est un espace vectoriel.  Ceci entraine que l'espace des matrices muni de l'addition entrée par entrée avec ces opérations est aussi un espace vectoriel.  Sur Sage, il est possible de travailler avec l'addition définie plus haut. Cela correspond à travailler en modulo . Pour cela, on ajoute un argument GF(2) dans la définition des matrices et des vecteurs, indiquant à Sage qu'on ne travaille qu'avec les nombres et . Sage connait déjà les règles arithmétiques de cet espace.   On peut associer à chaque case une matrice donnant son effet lorsqu'on clique sur la case. L'effet d'un clic revient donc à additionner à une matrice représentant une grille de Lights Out la matrice du clic, selon les règles de l'addition définies plus haut. Par exemple, un clic sur la case en position correspond à la matrice . Son effet sur la grille de la figure peut donc être obtenu en ajoutant à la matrice la matrice (suivant les règles d'additions définies plus haut): . Le résultat est illustré ci-dessous.   L'exemple après un clic   Une grille de taille trois par trois est illustrée avec les carrés colorées en vert. Les carrés en position un,trois; deux,un; trois,un et trois,deux sont d'un vert plus brillant, signifiant qu'ils sont allumés. Les autres carrés sont d'un vert plus terne, signifiant qu'ils sont éteints.    Sur Sage:   Définir les neuf matrices de clic.   Vérifier que et est donc une solution à la grille de la figure .   Justifier le fait que, pour une solution, l'ordre dans lequel on clique sur les carrés n'est pas important. Montrer que chaque matrice est son propre inverse dans cet espace.   On s'intéresse maintenant à obtenir une solution pour une configuration de départ spécifique . On cherche une suite de matrice telles que . Puisque chaque matrice est son propre inverse, on peut réécrire l'équation sous la forme . Expliquer pourquoi, dans une solution optimale (nombre minimal de clic), chaque matrice apparait au plus une fois. En vertu de l'exercice précédent, on peut alors dire que pour avoir une solution, il faut que la matrice soit dans le des matrices , c'est-à-dire , avec les . Comme l'espace des matrices de taille est de dimension et qu'une base de cet espace est donnée par les neuf matrices qui ne contiennent qu'une entrée non nulle égale à (voir l'exemple ), on peut écrire l'équation sous la forme matricielle où correspond à l'écriture vectorielle de la matrice dans la base des matrices ne contenant qu'un seul . La représentation vectorielle de la matrice l'équation est donnée par . On considère donc que la base ordonnée de cet espace est . La première colonne de cette matrice vient donc du fait que .  Montrer que la solution pour la matrice est bel et bien celle qui est donnée à l'équation en résolvant ce système d'équations.   Les questions suivantes s'intéressent au nombre de solutions et à l'existence de solutions pour la grille . Montrer que la solution est unique.  Est-ce que toute configuration initiale possède une solution?  On explore maintenant quelques variantes. La première variante considère tout simplement la grille carrée de taille . Montrer que la configuration de départ où seulement la case au coin supérieur gauche est allumée ne possède pas de solutions.  Montrer que la grille où toutes les cases sont initialement allumées possède plusieurs solutions et donner l'une de celles-ci. Rien n'empêche la grille d'être carrée, on pourrait tout aussi bien avoir une grille rectangulaire. Il existe configurations initiales pour une grille de taille . Combien possèdent une solution? Déterminer si possible une solution pour la grille suivante:   Une grille de Lights Out de taille   Une grille de taille quatre par trois est illustrée. Les carrés sur la premières lignes sont allumés, ceux sur la deuxième ligne de même que celui sur en position trois;deux sont éteints et les autres sont également allumés.     Explorer une autre variante, existante ou inventée. Répondre aux questions suivantes:  Est-ce qu'il y a toujours une solution peu importe la configuration initiale?  S'il y en a une, donner une solution pour une grille complètement allumée et sinon, montrer qu'il n'y en a pas.    Voici quelques inspirations:  Un jeu où il y a trois états pour une case, par exemple rouge, vert et éteint. Un clic change la case et ses voisins selon l'ordre rouge à vert, vert à éteint et éteint à rouge. Considérer une grille et partir de l'état où tout est rouge.  Un jeu où les bords sont reliés, chaque clic affecte cinq cellules. Donc la cellule dans le coin supérieur gauche change aussi l'état de la cellule dans le coin supérieur droit et dans le coin inférieur gauche. Considérer une grille .  Un jeu où chaque clic affecte la ligne entière et la colonne entière. Considérer une grille .   Dans le cas d'une variante inventée, bien clarifier les règles du jeu.   "
},
{
  "id": "sec-propre",
  "level": "1",
  "url": "sec-propre.html",
  "type": "Section",
  "number": "6.1",
  "title": "Vecteurs et valeurs propres",
  "body": "  Vecteurs et valeurs propres    Aller aux exercices de la section.  On considère la matrice . On peut observer l'effet géométrique de cette transformation sur le carré unité à la figure . À priori, il n'est pas évident de voir comment décrire la transformation dans des termes géométriques. Est-ce une rotation, une réflexion, un étirement, un cisaillement ou même une combinaison de tout cela? Par contre, si l'on regarde son effet sur le parallélogramme engendré par les vecteurs , son effet devient clair. La figure permet de voir cet effet.    Une transformation difficile à cerner       La même transformation sous un autre angle       Il semble que la matrice représente un étirement d'un certain facteur dans la direction et un étirement d'un autre facteur dans la direction . En principe, on dévie légèrement de la définition donnée à l'exercice , mais cela ne cause pas de problème en pratique.  Dans cette section, on verra comment trouver les bonnes directions pour comprendre la géométrie d'une transformation linéaire. Ces directions sont appelées les vecteurs propres et possèdent des nombres associés appelés valeurs propres. On définit la notion de multiplicité algébrique et multiplicité géométrique.    Vecteurs et valeurs propres  On considère les matrices carrées de format . Inspiré par la matrice de l'introduction, on se demande s'il existe des vecteurs dont l'image est un multiple du vecteur initial. Mathématiquement, on cherche des vecteurs et des nombres réels tels que , où est une matrice quelconque. On regarde l'exemple d'introduction afin de déterminer les nombres à partir des directions invariantes. La prochaine sous-section expliquera comment obtenir à la fois les et les directions invariantes.   Un premier calcul avec les directions invariantes  On cherche les deux nombres associés aux directions invariantes de la matrice .  Ces directions sont et .   Parce que les directions sont données, il suffit de calculer l'image de chacune de ces directions et de déduire le facteur associé. Pour la direction , on a et pour la direction , on a .  La matrice représente alors un étirement de facteur dans la direction du vecteur et un étirement de facteur dans la direction .    Parce que les matrices peuvent aussi représenter des transformations linéaires d'espaces vectoriels quelconques, on définit les directions invariantes (et leur facteur associé) par un terme qui s'éloigne un peu de la géométrie.   Vecteurs et valeurs propres  Soit , une matrice carrée représentant une transformation linéaire d'un espace vers ce même espace. On dit que est un vecteur propre si et s'il existe un scalaire pour lequel . Le scalaire est alors appelé la valeur propre associée à .   Si l'on regarde l'équation du point de vue d'un système d'équations, on se retrouve avec inconnues pour le vecteur et une supplémentaire provenant de la valeur propre . Le fait que cette valeur propre multiplie les composantes du vecteur fait en sorte que ce système d'équations n'est même pas linéaire. Heureusement, les notions du et du fournissent une méthode efficace pour trouver les vecteurs et les valeurs propres. Dans un premier temps par contre, on considère certaines questions et l'on tente d'y répondre en s'appuyant sur des arguments géométriques.  Une première remarque est qu'un vecteur propre ne peut pas être nul, par définition. Puisque le vecteur nul n'a pas de direction et que les vecteurs propres correspondent géométriquement aux directions invariantes de la transformation linéaire, ce choix prend son sens. D'un autre point de vue, puisque n'importe quelle valeur de rendrait l'équation si , on n'aurait plus l'unicité de la valeur propre. Par contre, rien n'empêche d'être nul. Géométriquement, cela signifie qu'une direction est envoyée sur le vecteur nul. Si l'on pense à une projection orthogonale dans sur un vecteur , on sait que et . Cela donne donc directement deux vecteurs propres, et leur valeur propre associée, .  Est-ce qu'une transformation linéaire a toujours des directions invariantes? En regardant l'effet d'une rotation et le fait que le vecteur nul ne peut pas être un vecteur propre, on comprend qu'il est possible qu'il n'y ait pas de vecteurs propres pour une transformation donnée. (Si l'on se permet de sortir du cadre des nombres réels, cela sera alors possible. On explore cette particularité dans l'annexe .) Y a-t-il un nombre maximum de directions invariantes? Si l'on pense à la matrice identité, toutes les directions sont invariantes. Dans le cas des vecteurs propres, dès qu'il y en a un, il y a une infinité de vecteurs propres.   Vecteurs propres et direction invariante  Soit , un vecteur propre d'une matrice . Alors pour tout réel, le vecteur est aussi un vecteur propre.  Pour une direction invariante, il y a donc une infinité de vecteurs propres.    Voir l'exercice .    La figure interactive suivante permet d'explorer différentes transformations géométriques et demande de déterminer les vecteurs et valeurs propres associés.   Vecteurs et valeurs propres géométriques    On termine avec des commandes Sage en lien avec la sous-section.   Vecteurs et valeurs propres sur Sage  En anglais, les mots pour vecteur propre et valeur propre sont respectivement eigenvector et eigenvalue , qui sont eux-mêmes dérivés du mot allemand eigen , qui signifie propre , caractéristique ou encore particulier . Sans surprise donc, la commande sur Sage pour trouver les valeurs propres est A.eigenvalues() . Pour les vecteurs propres, Sage doit aussi savoir si l'on veut un vecteur propre à droite (ce que l'on veut) ou à gauche (car il pourrait aussi exister un vecteur et un scalaire tels que ). La commande est donc A.eigenvectors_right() . Sage retourne alors un triplet composé, dans l'ordre, de la valeur propre, d'un vecteur propre associé à celle-ci et d'un troisième nombre, appelé la multiplicité, qui sera considéré dans la sous-section suivante. Voici les valeurs et vecteurs propres de la matrice de l'introduction.   On vérifie que, pour une matrice de réflexion quelconque, on a toujours et comme valeurs propres et que les vecteurs propres associés sont la direction de l'axe de réflexion et son perpendiculaire.   En multipliant le second vecteur par et le premier par , on retrouve les directions voulues.  Une particularité que l'on peut remarquer tient au fait que, dans la commande du vecteur propre, celui-ci est donné dans une liste qui ne contient que ce vecteur. En fait, pour une valeur explicite de , il est possible d'avoir plus d'une direction invariante associée à cette valeur. Il s'avère que l'espace engendré par les vecteurs propres associés à un scalaire est un sous-espace vectoriel. On peut donc parler d'espace invariant ou espace propre. Ce concept sera exploré dans la sous-section suivante. En attendant, voici les vecteurs et valeurs propres d'une réflexion dans .   On remarque que la valeur propre apparait deux fois dans l'exécution de la commande eigenvalues et que le vecteur propre qui lui est associé est en fait deux vecteurs. On remarque aussi que le troisième élément de la liste est , qu'il y a deux vecteurs et que la valeur propre apparaissait deux fois. Coïncidence?     Polynôme caractéristique et espace propre  L'objectif principal de cette sous-section est de déterminer une manière d'obtenir les valeurs et les vecteurs propres. On a expliqué plus haut que le système d'équations découlant de l'équation matricielle n'est pas linéaire par rapport à la variable , ce qui peut poser problème, spécifiquement en pensant aux méthodes du . On regarde donc à nouveau cette équation. On peut réécrire . De cette nouvelle équation, on peut conclure qu'un vecteur propre doit être dans l'espace nul de la matrice . De plus, puisque la définition d'un vecteur propre exige que le vecteur soit non nul, il faut que l'espace nul de cette matrice soit de dimension plus grande ou égale à . Les valeurs propres possibles pour une matrice sont donc les valeurs de qui font en sorte que l'espace nul de la matrice n'est pas réduit à . Selon le , ceci se produit lorsque la matrice n'est pas inversible.  La manière classique de déterminer les valeurs propres d'une matrice est de considérer les valeurs de qui font que le déterminant de la matrice est nul. Le déterminant de cette matrice est un polynôme en , dont les zéros sont précisément les valeurs propres.   Polynôme caractéristique d'une matrice   Soit , une matrice carrée. On appelle le polynôme caractéristique de la matrice le polynôme résultant du calcul de .    En réunissant les informations ci-dessus, on obtient la proposition suivante.   Polynôme caractéristique et valeurs propres  Soit , une matrice carrée. Les valeurs propres de correspondent aux zéros de son polynôme caractéristique.   Pour que soit une valeur propre de la matrice , il faut qu'il existe un vecteur non nul tel que . Soit , un zéro du polynôme caractéristique. Puisque , l'espace nul de cette matrice est de dimension supérieure ou égale à . Soit , un vecteur non nul de cet espace nul. On a alors .  Ainsi, est une valeur propre de la matrice .     Calcul des valeurs propres de la matrice d'introduction   On calcule les valeurs propres de la matrice . À l'exemple , on a déjà calculé ces valeurs propres, mais c'était en connaissant les vecteurs propres qui leur étaient associés.    On calcule le polynôme caractéristique de la matrice en calculant le déterminant de : .  Ce polynôme se factorise en , ce qui donne les valeurs propres connues et .    On se tourne vers les transformations linéaires géométriques de l'exemple . On peut déduire les valeurs propres de plusieurs de ces transformations en s'appuyant seulement sur le contexte géométrique, mais le calcul du polynôme caractéristique permettra de voir si l'on en oublie.   Valeurs propres des transformations géométriques de .  Pour chacune des transformations de la liste , déterminer les valeurs propres réelles. (Rappel: les matrices de ces transformations linéaires ont été trouvées à l'exemple .)   La transformation identité garde tous les vecteurs en place. On a donc pour tous vecteurs de . Il s'ensuit que est une valeur propre. Le polynôme caractéristique de la matrice est . Ce polynôme s'annule seulement lorsque , c'est donc la seule valeur propre possible.   La réflexion par rapport à l'axe des laisse tout vecteur parallèle à inchangé et tout vecteur perpendiculaire à est envoyé sur son opposé. Les valeurs propres devraient donc être et . En effet, le polynôme caractéristique donne . Comme ce polynôme s'annule uniquement en et , ce sont les seules valeurs propres possibles.  Une rotation ne laisse aucun vecteur en place, sauf le vecteur nul qui ne peut pas être un vecteur propre. Il ne devrait donc pas y avoir de valeurs propres. Le polynôme caractéristique est . Ce polynôme n'a en effet pas de solution dans les réels.  Les étirements ont dans leur définition une direction qui est inchangée. Une valeur propre est très certainement le facteur d'étirement . Dans l'exercice , on a toutefois mentionné qu'un vecteur dont la direction est perpendiculaire à la direction étirée ne changeait pas. La valeur semble donc aussi être une valeur propre. Dans le cas de l'étirement horizontal, on a , qui s'annule bel et bien en et .  Une homothétie étant un étirement dans les deux directions, il semble plausible de considérer que le facteur sera la seule valeur propre. En effet, on a , qui s'annule seulement lorsque .  Il est peut-être difficile de voir quelles seront les valeurs propres en pensant seulement à la permutation des composantes. On peut toutefois remarquer que la permutation dans est aussi une réflexion de direction . On peut probablement conclure que les valeurs propres seront et , comme pour les valeurs propres d'une réflexion selon l'axe des abscisses. En effet, s'annule lorsque et . Ce sont donc les valeurs propres.  Pour une projection orthogonale, le vecteur sur lequel on projette demeure inchangé et le vecteur perpendiculaire s'écrase à . On peut donc penser que les valeurs propres seront et . On a, . On voit que peu importe les composantes du vecteur , les valeurs propres seront toujours et .   Pour ensuite trouver les vecteurs propres d'une matrice , on peut regarder l'espace nul de pour chaque valeur de faisant en sorte que le polynôme caractéristique s'annule. Bien qu'ils soient relativement facile de les déterminer géométriquement, on l'a, en quelque sorte, fait à l'exemple , l'exercice déterminera les vecteurs propres des transformations linéaires de la liste , en regardant l'espace propre approprié. Pour le moment, on va regarder les vecteurs propres de la matrice d'introduction.   Calcul des vecteurs propres de la matrice d'introduction   On calcule les vecteurs propres de la matrice . On sait que ces vecteurs propres devraient être , selon la figure .    À l'exemple , on a réussi à trouver que les valeurs propres de la matrice sont et . En caractérisant l'espace propre des matrices et , on pourra trouver des vecteurs propres associés à chacune des valeurs propres.  Dans un premier temps, on a . On peut lire une base de l'espace nul de cette matrice de sa forme échelonnée réduite qui est . En multipliant par ce vecteur, on retrouve le vecteur de l'énoncé.  De même, avec la seconde valeur propre, on a . On peut lire une base de l'espace nul de cette matrice de sa forme échelonnée réduite qui est . En multipliant par ce vecteur, on retrouve le vecteur de l'énoncé.    On constate que, pour trouver un vecteur propre, il faut regarder l'espace nul de la matrice et que n'importe quel vecteur de ce sous-espace pourra jouer le rôle de vecteur propre. En particulier, une base de cet espace peut entièrement décrire l'espace des vecteurs propres associés à une valeur propre spécifique d'une matrice . On appelle  l'espace propre de la matrice associé à .  On regarde d'autres exemples de calculs de valeurs et vecteurs propres. À partir de ceux-ci, on fera quelques observations qui guideront la suite.   Des calculs de vecteurs et valeurs propres  On cherche les valeurs et vecteurs propres des matrices suivantes: .   On commence par trouver les valeurs propres en calculant le déterminant de . On obtient . Les valeurs propres sont les valeurs de qui annulent ce déterminant, soit et .  On trouve le premier vecteur propre en regardant l'espace nul de . En effectuant l'opération élémentaire et ensuite l'opération élémentaire , on obtient la matrice échelonnée réduite . Celle-ci donne le vecteur propre , ou son multiple . Un calcul rapide montre qu'on a bel et bien .  Pour le second vecteur propre, on procède de manière similaire. On regarde l'espace propre associé à . On a alors . Une base de cet espace, donc un vecteur propre, est le vecteur . Encore une fois, un calcul rapide permet d'observer que .   On procède de la même manière. On a . On ne trouve ici qu'une seule valeur propre égale à . Pour l'espace propre, on regarde l'espace nul de la matrice , dont la forme échelonnée réduite est . Un vecteur propre est donc . Encore une fois, un calcul permet de vérifier que .  On calcule le déterminant de la matrice afin de déterminer les valeurs propres. On a . Les valeurs propres sont donc et .  Pour la recherche des vecteurs propres associés, il faut regarder les espaces nuls des matrices pour chaque valeur trouvée. Pour , on trouve . Il n'y a qu'une seule variable libre, la deuxième. Une base de l'espace nul est donc , qui constitue un vecteur propre. Plus simplement, on peut le multiplier par pour avoir . Un calcul simple montre que l'on a bel et bien .  Pour le deuxième vecteur propre associé à la valeur propre , on procède de la même manière. On a . Encore une fois, on ne retrouve qu'une variable libre, cette fois en , qui amène comme vecteur propre le vecteur . On vérifie à nouveau que l'on a bien par un calcul de produit matrice vecteur.  Finalement, avec la dernière valeur propre , on a . Le dernier vecteur propre est .   On se permet de faire les calculs sur Sage pour les deux prochaines matrices. On n'utilisera pas les fonctions eigenvalues et eigenvectors_right , car on veut pour l'instant être en mesure de comprendre comment obtenir les valeurs et vecteurs propres à partir des définitions et résultats, mais on laisse Sage faire les calculs de ces déterminants et l'échelonnage des matrices. Pour les valeurs propres:   Cette fois, les valeurs propres sont et . On remarque qu'il n'y a encore une fois que deux valeurs propres.  Un premier vecteur propre est obtenu en regardant l'espace propre associé à .   Le vecteur propre est . Pour la seconde valeur propre :   Le second vecteur propre est .  On remarque dans ce cas-ci que chaque valeur propre n'a qu'une direction propre associée.   On répète la démarche précédente avec la matrice et Sage.  D'abord, pour les valeurs propres, on calcule le déterminant de la matrice et l'on demande à Sage de factoriser le tout pour pouvoir y lire facilement les zéros. À noter qu'on utilise plutôt que , car le mot lambda est protégé en python.   Il n'y a que deux valeurs propres distinctes, et . Pour trouver les vecteurs propres, on trouve une base pour les espaces nuls des deux matrices et .   Un vecteur propre associé à est donc . On vérifie facilement que , puisque ce produit donne la première colonne de la matrice . Pour , on regarde ce que Sage donne comme espace propre.   On constate qu'il y a ici deux vecteurs propres associés à la valeur propre . Le vecteur (après multiplication par ) et le vecteur , dont on peut dire que .    L'exemple précédent montre que plusieurs situations peuvent survenir lors du calcul des valeurs et vecteurs propres. Est-ce que le déterminant d'une matrice , où est une matrice , est toujours un polynôme de degré ? Cela semble évident, mais il faudrait le démontrer (voir l'exercice ). Parfois, pour une valeur propre, il peut y avoir plus d'une direction invariante et donc, plus d'un vecteur propre indépendant. En fait, la véritable question est de savoir quelle peut être la dimension de l'espace propre associée à une valeur propre? La matrice de l'exemple précédent avait deux valeurs propres, l'une dont l'espace propre était de dimension et l'autre de dimension . La matrice , quant à elle, avait aussi deux valeurs propres, mais avec chacun leur espace propre respectif de dimension . Ceci conduit à la définition suivante.   Multiplicité algébrique et géométrique  Soit , une matrice, , une valeur propre de cette matrice et , la plus grande valeur telle que le facteur divise le polynôme caractéristique. On dit que est la multiplicité algébrique de la valeur propre.  Soit , la dimension de l'espace nul de la matrice . On dit que est la multiplicité géométrique de la valeur propre.    La valeur propre pour la matrice de l'exemple a une multiplicité algébrique de puisque le déterminant de est . Puisque l'espace propre associé à cette valeur propre était donné par . Ces vecteurs étant indépendants, la dimension du sous-espace est , qui est donc la dimension géométrique de . Par contre, avec la matrice , toujours avec la valeur propre valant , on avait encore une dimension algébrique égale à , mais comme l'espace nul de est engendré par , la dimension géométrique est de . Sur Sage, lorsqu'on utilise la commande eigenvectors_right , le troisième argument d'un triplet de réponse représente la multiplicité algébrique de la valeur propre. La multiplicité géométrique doit être déduite du nombre de vecteurs propres retournés.  On termine avec des commandes Sage en lien avec la sous-section.   Polynôme caractéristique et Sage  Bien que Sage soit capable de calculer directement les vecteurs et les valeurs propres, il peut aussi simplement donner le polynôme caractéristique d'une matrice . Il suffit d'utiliser la commande characteristic_polynomial() ou son équivalent plus court charpoly() . À noter que Sage utilise une version légèrement différente du polynôme caractéristique. Il considère plutôt le déterminant de . Le polynôme retourné par Sage sera le même que celui de la définition lorsque est une matrice de taille où est pair et diffèrera d'un facteur lorsque est impair.   On peut ensuite demander à Sage de factoriser ce polynôme caractéristique, mais pour qu'il puisse accomplir le travail, il faudra peut-être préciser l'espace sous-jacent aux entrées de la matrice. (Par défaut, Sage considère qu'une matrice dont toutes les entrées sont des entiers comme une matrice dans un espace d'entiers, et va factoriser en conséquence.)   En terminant, un retour sur la commande eigenvectors_right en lien avec les multiplicités.   Cette matrice correspond à la matrice de l'exemple , où l'on avait trouvé que la valeur propre n'avait qu'un vecteur propre. Elle apparait toutefois avec une multiplicité algébrique de .     Quelques résultats  Dans cette section, on obtient quelques résultats théoriques en lien avec les valeurs et vecteurs propres. Plus particulièrement, on obtiendra la sixième version du théorème de la matrice inverse en ajoutant une équivalence sur les valeurs propres. Que peut-on dire d'une matrice inversible et de ses valeurs propres? Puisque les valeurs et vecteurs propres satisfont l'équation et qu'un vecteur propre ne peut pas être le vecteur nul, quelque chose de particulierse produit si la valeur propre est nulle. Cela entraine qu'il y a des vecteurs non nuls dans l'espace nul de la matrice. Une telle matrice ne peut donc pas être inversible.   Théorème de la matrice inverse, sixième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité;  Aucune ligne n'est une combinaison linéaire des autres lignes;  Aucune colonne n'est une combinaison linéaire des autres colonnes;  Le déterminant de la matrice est non nul;  L'espace colonne est de dimension ;  L'espace ligne est de dimension ;  L'espace nul est de dimension ;  L'espace nul gauche est de dimension ;  Toutes les valeurs propres de sont non nulles.    Il faut seulement démontrer l'équivalence entre le dernier énoncé et l'un des autres. Dans un premier temps, si est inversible, alors son espace nul est de dimension . Il n'existe donc pas d'autres vecteurs que tels que . Il en découle que ne peut être une valeur propre.  À l'inverse, si est une matrice dont toutes les valeurs propres sont différentes de zéro, cela implique qu'aucun vecteur non nul ne possède la propriété que . Donc, le seul élément dans l'espace nul de est le vecteur nul, ce qui signifie que l'espace nul est de dimension . Ainsi, une matrice est inversible si et seulement si aucune de ses valeurs propres n'est nulle.    Le prochain résultat sera utile dans la section suivante. Il porte sur les vecteurs propres et leur indépendance.   Vecteurs propres et indépendance   Soit , des valeurs propres distinctes d'une matrice et , des vecteurs propre associés à chacune de ces valeurs propres. Alors, l'ensemble est linéairement indépendant.    Si , il n'y a qu'un seul vecteur propre. Celui-ci étant non nul, il est par défaut indépendant. S'il y a plus de deux vecteurs, on procède par contradiction. On suppose que l'ensemble de ces vecteurs propres est dépendant. On peut alors affirmer qu'il existe un entier tel que est un ensemble indépendant, mais que est dépendant. Bien entendu, puisqu'on suppose que l'ensemble de tous ces vecteurs est dépendant. On cherche donc le premier vecteur qui, combiné aux précédents vecteurs indépendants, rend l'ensemble dépendant. Si est dépendant, il existe une combinaison linéaire des premiers vecteurs qui donne le vecteur : . On multiplie les deux côtés de cette équation par . On obtient alors . D'un autre côté, on multiplie l'équation par pour obtenir . On obtient qui se réécrit sous la forme . Comme les vecteurs sont linéairement indépendants, il faut que les coefficients de cette combinaison linéaire soient nuls, mais on a également que les valeurs propres sont distinctes. Cela entraine que . Par contre, si cela était vrai, l'équation impliquerait que , ce qui est impossible. On ne peut en conséquence trouver une valeur de telle que l'ensemble est indépendant, mais l'ensemble est dépendant. On conclut que est forcément indépendant, ce qui termine la preuve.    Le prochain résultat est en lien avec les valeurs propres d'une matrice et les valeurs propres de matrices obtenues à partir d'opérations algébriques et matricielles comme la multiplication par un scalaire ou l'inverse de .   L'effet de certaines opérations sur les valeurs propres  Soit , une matrice carrée et , une valeur propre. Alors  le scalaire est une valeur propre de la matrice ;  le scalaire est une valeur propre de la matrice ;  lorsque est inversible, est une valeur propre de la matrice ;  la valeur propre est aussi une valeur propre de transposée .    Soit , un vecteur propre associé à pour la matrice . On a . Ainsi, puisque , une valeur propre de est . De plus, le vecteur demeure un vecteur propre.  Voir l'exercice  Si est une matrice inversible, alors selon le , la valeur propre n'est pas nulle. Soit , un vecteur propre associé à . On peut alors écrire . Le scalaire est donc bel et bien une valeur propre de .  Voir l'exercice   Il n'était pas question du produit de deux matrices dans la proposition précédente. Qu'en est-il des valeurs propres d'une matrice ? À première vue, on pourrait penser que si était une valeur propre de et une valeur propre de , alors serait une valeur propre du produit puisque , mais il y a un problème avec ce raisonnement. Rien ne garantit que et ont les mêmes vecteurs propres. Si c'est toutefois le cas, c'est-à-dire si est un vecteur propre de associé à la valeur propre et un vecteur propre de associé à la valeur propre , alors est un vecteur propre de associé à la valeur propre . En fait, on a même davantage, puisque est aussi un vecteur propre de la matrice , aussi associé à la valeur propre . La question du partage des vecteurs propres entre deux matrices sera étudiée plus spécifiquement à la prochaine section.  Un type de matrice pour lequel il est facile de trouver les valeurs propres est lorsque la matrice est triangulaire . Dans ce cas, les valeurs propres se trouvent toujours sur la diagonale.   Les valeurs propres de matrices triangulaires  Soit , une matrice triangulaire inférieure et , une matrice triangulaire supérieure. Alors, les valeurs propres de sont sur leur diagonale respective.   C'est une conséquence directe du fait que les matrices et sont triangulaires et de la proposition qui stipule que le déterminant d'une matrice triangulaire est le produit des entrées sur la diagonale principale. On voit que le polynôme caractéristique est déjà factorisé et s'annule précisément aux entrées de la diagonale de ou .        Les points importants de cette section sont:  La définition des vecteurs et valeurs propres ;  La définition du polynôme caractéristique ;  Le fait que les zéros du polynôme caractéristique sont les valeurs propres;  Les deux multiplicités associées à une valeur propre;  Le fait qu'une matrice est inversible si et seulement si aucune de ses valeurs propres est zéro, ce qui s'ajoute au théorème de la matrice inverse ;  Les propriétés des valeurs propres en lien avec différentes opérations algébriques.   De plus, avec Sage, on a vu les commandes eigenvalues , eigenvectors_right et characteristic_polynomial (ou charpoly ) permettant respectivement de déterminer les valeurs propres, vecteurs propres et le polynôme caractéristique d'une matrice.      Exercices   Déterminer les vecteurs propres de chacune des transformations linéaires de la liste en considérant l'espace propre associé à chaque valeur propre. On rappelle que les valeurs propres ont été trouvées à l'exemple .  Dans la plupart des cas, on donne une base de l'espace propre associé à chaque valeur propre.  Tous les vecteurs de sont des vecteurs propres pour la matrice identité.  Le vecteur est un vecteur propre pour la valeur propre et le vecteur est un vecteur propre associé à la valeur propre .  Aucun vecteur propre réel.  Pour l'étirement horizontal, le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .  Pour un étirement vertical, les rôles sont renversés. Le vecteur est un vecteur propre associé à et le vecteur un vecteur propre pour .  Tous les vecteurs de sont des vecteurs propres.  Le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .  Le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .   Pour chaque transformation, on regarde l'espace propre associé à chacune des valeurs propres trouvées à l'exemple .  Pour la seule valeur propre , on a , la matrice nulle. Tous les vecteurs sont dans l'espace nul de cette matrice. N'importe quel vecteur de est donc un vecteur propre.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace nul de cette matrice est engendré par le vecteur . N'importe quel multiple de ce vecteur est donc un vecteur propre.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace nul de cette matrice est engendré par le vecteur . N'importe quel multiple de ce vecteur est donc un vecteur propre.   Comme il n'y avait pas de valeurs propres réelles, il ne peut pas y avoir de vecteurs propres réels non plus.  D'abord, l'étirement horizontal: Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente;  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.  Pour ce qui est de l'étirement vertical, la même démarche s'applique, mais les rôles sont inversés. Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.    De manière semblable à la transformation identité, la matrice donne la matrice nulle. Tous les vecteurs de sont des vecteurs propres.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace propre de cette matrice est engendré par , ce qui fait de tout multiple de ce vecteur un vecteur propre de la matrice associé à .  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace propre de cette matrice est engendré par , ce qui fait de tout multiple de ce vecteur un vecteur propre de la matrice associé à .   Pour la valeur propre , la matrice à analyser est . On fait d'abord l'hypothèse que . Par conséquent, la matrice est équivalente après réduction à . Dans ce cas, l'espace nul est engendré par , ou encore . Toutefois, si , alors, puisqu'on ne peut projeter sur le vecteur nul, on doit avoir . La matrice est alors équivalente à après réduction, et a pour générateur de son espace nul le vecteur , ou encore son multiple . Dans tous les cas, une base de l'espace propre peut s'écrire comme .  Pour la valeur propre , la matrice à analyser est . Sous l'hypothèse cette fois que , on peut montrer que cette matrice est équivalente après réduction à la matrice Dans ce cas, l'espace nul est engendré par ou son multiple . Toutefois, si , alors comme précédemment, on ne peut avoir aussi , ce qui fait que la matrice après réduction est équivalente à . L'espace nul est engendré par le vecteur , ou encore son multiple . Dans tous les cas, une base de l'espace propre peut s'écrire comme .     Pour chacune des matrices suivantes, déterminer les valeurs propres et une base de l'espace propre associé à chaque valeur propre. avec et Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne une seule valeur propre, .  On regarde l'espace propre associé à cette valeur propre. La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on commence par calculer le déterminant de : , qui s'annule lorsque et .  Pour le premier espace propre, on regarde la matrice et l'on détermine une base de son espace nul. On utilise Sage pour effectuer la réduction.   On remarque que la troisième variable est libre. Une base de l'espace nul serait le vecteur , parallèle au vecteur .  De même, pour le second espace propre, on obtient avec Sage un système ayant lui aussi une seule variable libre, dont une base est donnée par le vecteur , parallèle au vecteur .   et avec , et . On commence par déterminer les valeurs propres en considérant le déterminant de : , ce qui donne comme valeur propre et .  On détermine les espaces propres en échelonnant les matrices appropriées avec Sage.   Pour l'espace propre associé à , on voit une variable libre en . Une base de cet espace propre est donnée par . Pour le deuxième espace propre, on a aussi une seule direction invariante donnée par , parallèle à . Enfin, pour le dernier espace propre, on trouve le vecteur après ajustement.  avec , . Encore une fois, on commence par les valeurs propres. On a , qui offre comme valeurs propres et .  Pour les espaces propres, on se tourne une fois de plus vers Sage afin d'échelonner la matrice.   Pour la première valeur propre, on trouve un vecteur propre associé qui est . Pour la seconde valeur propre, il y a deux variables libres et donc, deux directions invariantes associées à cette valeur propre. On trouve , parallèle à et .   Soit , une matrice carrée, , une valeur propre et , un vecteur propre associé à . Montrer que pour tout non nul, le vecteur est aussi un vecteur propre associé à . Cela découle directement du fait que les vecteurs propres sont des directions invariantes et que et ont la même direction. Un calcul montre que . Le vecteur est donc bel et bien un vecteur propre.  Compléter la preuve de la proposition en démontrant que le scalaire est une valeur propre de la matrice et que la valeur propre est aussi une valeur propre de la transposée .  On commence par le nombre et l'on montre que c'est une valeur propre de . Il semble plausible que si est un vecteur propre de , ce soit aussi un vecteur propre de . On s'en assure en effectuant le calcul. . On trouve qu'en effet, est aussi un vecteur propre de et l'on obtient en même temps la valeur propre .  Pour le fait que est aussi une valeur propre de , on ne peut pas procéder de la même manière, car rien ne garantit que le vecteur sera aussi un vecteur propre de la matrice . De toute évidence, on ne connait pas l'effet de sur . On se tourne donc vers la définition. .  Puisque le déterminant de est le même que celui de , il s'ensuit que les valeurs propres seront les mêmes.    Déterminer les valeurs propres de la matrice en fonction de celles de la matrice .  On peut procéder de deux manières. Pour l'une d'elles, peut-on deviner un vecteur propre de ? On calcule le déterminant approprié. On utilise comme variable du polynôme caractéristique, laissant pour les valeurs propres de . . On sait que le membre de droite de cette dernière équation a des solutions lorsque correspond aux valeurs propres de . En posant et en isolant , on découvre que les valeurs propres de sont un de plus que les valeurs propres de .  On aurait aussi pu déduire les valeurs propres en essayant de voir si un vecteur propre de est aussi un vecteur propre de . On aurait alors eu . On ne peut, par contre, pas toujours se fier au fait que les vecteurs propres seront les mêmes après une opération sur la matrice (comme la transposée), c'est pourquoi il est bon de trouver des preuves qui ne les utilisent pas.   Soit , des matrices carrées et , une de leurs valeurs propres respectives. On tente de généraliser l'exercice précédent. Pour chaque énoncé suivant, démontrer s'il est vrai et donner un contrexemple s'il est faux. Le scalaire est une valeur propre de a matrice . C'est vrai. C'est vrai, il suffit de refaire l'une des preuves de l'exercice précédent. Par exemple, en supposant qu'un vecteur propre de devrait encore être un vecteur propre de , on trouve . Le scalaire est une valeur propre de la matrice . C'est faux En général, ce sera faux, car on ne sait pas si le même vecteur propre est associé à et . À titre d'exemple, la matrice a pour valeur propre , la matrice a pour valeur propre , mais la matrice a pour valeurs deux nombres irrationnels. En effet , mais , qui s'annule lorsque . Les valeurs propres de la somme ne sont donc pas la somme des valeurs propres. Si est tel que et , alors est une valeur propre de . C'est vrai Cette fois, un vecteur propre est partagé. On peut penser que ce vecteur propre sera aussi un vecteur propre de la matrice . En effet, on a . On obtient un vecteur propre associé à .  Montrer que si est une matrice carrée telle que et et que , alors . En d'autres mots, les vecteurs propres d'une matrice et ceux de sa transposée sont perpendiculaires s'ils ne sont pas associés à la même valeur propre. L'exercice pourrait être utile. Montrer que et . Conclure que, puisque , on doit avoir . On considère le produit scalaire . Puisque est un vecteur propre de la matrice , on a alors .  D'un autre côté, avec l'exercice , on a que , qui, parce que est vecteur propre de , devient .  On a donc et puisque , on doit avoir .   Soit , une matrice de taille possédant des valeurs propres . Montrer que et où est la trace de la matrice définie à l'exercice comme la somme des éléments sur la diagonale de la matrice . On pose . On calcule le polynôme caractéristique et l'on trouve une correspondance entre les valeurs propres et celui-ci. . D'un autre côté, si sont les valeurs propres, alors le polynôme caractéristique peut s'écrire comme . En comparant les deux manières d'écrire le polynôme, on trouve que le facteur et que et .  Soit , une matrice carrée dont toutes les entrées sont supérieures ou égales à avec la propriété additionnelle que la somme des entrées de chaque ligne donne . Déterminer un vecteur et une valeur propre de . On cherche une solution à l'équation . Le produit a, dans chaque entrée, le produit scalaire des lignes de avec le vecteur . Afin d'utiliser l'information sur la somme des lignes, on pose . On obtient , un vecteur propre dont la valeur propre est .  Soit , des matrices . Dans cet exercice, on s'intéresse aux valeurs propres des produits et . Montrer que est une valeur propre de si et seulement si c'est aussi une valeur propre de . Si , alors . Si est une valeur propre de , alors . Or comme , l'implication est vraie d'un côté. En échangeant le rôle de dans la preuve ci-dessus, on montre que si est une valeur propre de , c'est aussi une valeur propre de . Montrer que si et que est un vecteur propre de associé à , alors le vecteur est non nul. Expliquer pourquoi il est nécessaire de supposer que . On procède par contradiction en supposant que . Puisque est un vecteur propre de , on doit avoir . On se retrouve dans la situation où . En vertu de la propriété sur les espaces vectoriels , on doit avoir ou . La première possibilité est impossible par hypothèse du problème et la seconde est impossible par définition d'un vecteur propre. Il est donc impossible d'avoir le vecteur .  Il était nécessaire d'avoir l'hypothèse pour forcer la contradiction sur le vecteur propre qui est nul. Ainsi, dans une situation où la valeur propre est , il est possible que .  Montrer que si est une valeur propre de et que est un vecteur propre associé, alors est un vecteur propre de . Conclure que est aussi une valeur propre de . Soit , un vecteur propre de associé à la valeur propre . On prétend que est un vecteur propre de . On vérifie en calculant . Ainsi, le vecteur est un vecteur propre, si celui-ci est non nul. La partie précédente a montré que dans le cas , le vecteur est bel et bien non nul. Montrer que si et que sont des vecteurs formant une base de (donc des vecteurs propres de ), alors les vecteurs sont indépendants. Expliquer pourquoi il est nécessaire de supposer que .  Soit , des nombres tels que . En multipliant par cette équation, on a . Puisque est non nul, il faut que le vecteur le soit, or, comme les vecteurs sont indépendants, on doit avoir , ce qui montre que les vecteurs sont aussi indépendants.  Si avait pu être nul, on n'aurait pas été en mesure de conclure qui de ou du vecteur aurait contribué à faire du produit le vecteur nul.  Conclure de la partie précédente que et que la multiplicité géométrique de pour est inférieure ou égale à celle pour . La dimension de l'espace correspond au nombre de vecteurs dans une base. Ces vecteurs seront indépendants. Puisque les vecteurs sont eux-mêmes indépendants, la dimension doit être au moins égale à , car si elle était inférieure, cela contredirait la proposition . Comme il y a vecteurs dans une base de , on a  Montrer que . Que peut-on conclure? Il suffit d'interchanger les rôles de et dans les parties précédentes. En inversant le rôle de et de , l'exercice permet aussi de conclure que est non nul si est un vecteur propre de . De plus, la partie permet de conclure que est un vecteur propre de associé à . On peut ensuite utiliser le reste de l'exercice pour montrer que .  En combinant les deux inégalités, on montre que et que les multiplicités géométriques sont égales.  Ceci montre que les matrices et ont les mêmes valeurs propres, mais on ne sait rien sur leur multiplicité algébrique respective. Il est possible, mais plus difficile, de montrer qu'en fait, les matrices et ont le même polynôme caractéristique et que leurs valeurs propres ont les mêmes multiplicités algébriques. On a toutefois montré que les multiplicités géométriques sont les mêmes.  On s'intéresse aux vecteurs et valeurs propres d'un cisaillement défini à l'exercice . Déterminer les valeurs propres d'un cisaillement ainsi qu'une base de l'espace propre pour chaque valeur propre trouvée.  Autant dans le cas horizontal que dans le cas vertical, la seule valeur propre est . Pour le cisaillement horizontal, l'espace propre est engendré par le vecteur et pour le cisaillement vertical, c'est plutôt par le vecteur  Comme les matrices de cisaillement horizontal et vertical sont triangulaires, on peut utiliser la proposition afin de trouver que, dans les deux cas, la seule valeur propre est . Pour l'espace propre d'un étirement horizontal, on trouve . Si , la transformation est l'identité et tous les vecteurs sont invariants. Dans le cas contraire, on peut diviser par la dernière ligne de la matrice et obtenir que l'espace propre est engendré par le vecteur . Dans le cas du cisaillement vertical, on a plutôt , qui, sous la même condition que , a comme générateur de son espace nul le vecteur .   Répondre aux questions suivantes sans déterminer la matrice . Trouver si et que et sont des vecteurs propres de associés respectivement aux valeurs propres et .  On écrit le vecteur comme une combinaison linéaire des vecteurs propres. On doit donc résoudre le système . On trouve et en utilisant n'importe quelle méthode. Pour trouver , on a alors .  Trouver si et si et sont des vecteurs propres de associés respectivement aux valeurs propres et . Selon la proposition , les vecteurs propres d'une matrice inverse sont les mêmes que la matrice originale, avec les valeurs propres inversées. En trouvant une combinaison linéaire des vecteurs propres donnant , on aura toutes les informations nécessaires pour trouver . On doit donc trouver tels que . La solution de ce système est , . On a ainsi pour le vecteur  .  Soit , une matrice et deux vecteurs non nuls tels que . Montrer qu'une des valeurs propres de est nécessairement ou . Considérer .  On cherche un vecteur tel que avec . Puisque , et que est une transformation linéaire, on peut prendre la somme de ces deux équations pour obtenir . On a donc trouvé un vecteur pour lequel . Si ce vecteur est non nul, c'est un vecteur propre associé à la valeur propre .  Toutefois, si , alors ce ne peut pas être un vecteur propre. Mais dans ce cas, et l'équation montre que est un vecteur propre associé à .   Montrer que si sont des vecteurs propres tels que est aussi un vecteur propre, alors sont associés à la même valeur propre.  Si et sont parallèles, ils ont nécessairement la même valeur propre, selon l'exercice . Soit , les valeurs propres associées respectivement à . Puisque est un vecteur propre, il existe un pour lequel . En développant les deux côtés, on trouve . Puisque les vecteurs sont non parallèles, ils sont indépendants. On doit donc avoir et , entrainant que .   Considérer la matrice triangulaire suivante: . Décrire les dimensions possibles pour en fonction de . (Pourquoi sait-on que est une valeur propre?)  On échelonne la matrice afin de déterminer une base de l'espace propre. On a alors . Comme prévu, l'espace nul est au moins à dimension avec la première variable libre. La deuxième et la quatrième sont toujours pivots, indépendamment de la valeur de . Pour la troisième variable, elle sera pivot si et libre dans les autres cas. L'espace propre est donc à deux dimensions si et à une dimension autrement.   Une matrice est dite nilpotente s'il existe un entier pour lequel . La plus petite valeur de pour laquelle est appelé l'indice de nilpotence. On dit aussi que est nilpotente d'ordre . Montrer que est nilpotente et donner l'indice. L'indice de nilpotence est . On commence par calculer les puissances de la matrice , afin de voir si l'on obtient la matrice nulle. Puisque , la matrice est nilpotente et l'indice de nilpotence est . Montrer que est nilpotente d'ordre . On calcule la troisième puissance de la matrice. On utilise Sage.   La matrice est bien nilpotente d'ordre 3. Montrer que est nilpotente d'ordre . On calcule la deuxième puissance de la matrice. On utilise Sage.   La matrice est bien nilpotente d'ordre 2. Montrer que si est nilpotente, la seule valeur propre de est . Soit , une valeur propre de et , l'indice de nilpotence. Selon la proposition , le nombre est une valeur propre de . Comme est nilpotente d'ordre , la matrice et toutes ses valeurs propres sont nulles. On a donc , ce qui implique que .  Soit , une matrice telle que . Déterminer les valeurs et vecteurs propres. Montrer que est un vecteur propre de et déterminer la valeur propre associée. On calcule le produit matrice vecteur: . Le vecteur est donc effectivement un vecteur propre et la valeur propre associée est . Trouver l'autre valeur propre et un vecteur propre lui étant associé. Selon l'exercice , la somme des valeurs propres doit être égale à la trace de la matrice, soit la somme des éléments sur la diagonale principale ( ). On a donc . Avec la seconde valeur propre, on peut trouver un vecteur propre associé en regardant l'espace nul de la matrice : . Un vecteur propre est donc si et si et . Dans l'éventualité où , on doit alors avoir par hypothèse , la matrice est un multiple de la matrice identité et tous les vecteurs sont des directions invariantes.  Soit et , tel que défini à l'exercice . Montrer que est un vecteur propre de la matrice . Quelle est la valeur propre associée? On a .  Le vecteur est donc un vecteur propre associé à la valeur propre . Dans le cas où les vecteurs sont dans , déterminer une autre valeur propre de . Quel est le rang de ?  Puisque est de rang selon l'exercice , la matrice n'est pas inversible selon le théorème de la matrice inverse. Toujours selon ce théorème , l'une des valeurs propres de doit être nulle.  Cela se vérifié également en utilisant l'exercice . On pose et . On a alors Si et que l'on doit avoir , on voit qu'on doit avoir .  Fibonacci La suite de Fibonacci est bien connue en mathématiques. C'est une suite définie par et . Les premiers nombres peuvent être obtenus par Sage à l'aide de la fonction suivante.   L'objectif de cet exercice est d'apporter une perspective d'algèbre linéaire à cette suite et de déterminer une formule pour sans avoir à calculer les nombres précédents.  On pose pour et . Déterminer une matrice qui permet d'avoir .  On aurait pu commencer par le vecteur , qui aurait contenu les deux premiers termes de la suite. On peut toutefois argumenter que en travaillant avec l'équation à l'envers. C'est un choix arbitraire qui fera l'affaire pour la suite.  Le vecteur contient et . On peut poser pour avoir un système à deux équations et deux inconnues. On peut réécrire sous la forme . La matrice est donc Calculer , et . Donner une formule en fonction de et pour . , , . En général, est la première composante de . Trouver à l'aide de cette matrice et de Sage. Vérifier la réponse à l'aide de la fonction fibo définie dans l'introduction.  Le code de la solution   A=matrix([[1,1],[1,0]]) x0=vector([0,1]) show(A^100*x0[0])   Pour la suite, il pourra être pratique d'utiliser le fait que si , alors et donc . Démontrer ce fait Il suffit de calculer  . Trouver les valeurs propres de la matrice et le vecteur propre de chacune. La première valeur propre est avec son vecteur propre et la deuxième valeur propre est avec son vecteur propre .  On a . Ce polynôme s'annule lorsque et . On remarque que ces deux valeurs sont les nombres de la partie . Pour les espaces propres, on a d'abord pour  . On trouve donc un vecteur propre .  De la même manière, on trouve , donnant le vecteur associé à .  Écrire le vecteur comme une combinaison linéaire des vecteurs propres de .  Il faut trouver tels que . Sous forme matricielle, on cherche à résoudre la matrice augmentée . On a .  Un peu de simplification est de mise. On peut montrer que et que . On a donc .  Décrire comment obtenir sans calculer les précédents et sans calculer de produit matrice vecteur. On sait que . En utilisant la décomposition en fonction des vecteurs propres, on trouve . Le nombre se retrouve dans la première composante de ce vecteur et donc .  Utiliser Sage pour calculer .   En utilisant la formule trouvée, on trouve avec Sage que cette limite vaut .   Le nombre est appelé le nombre d'or. On le note souvent par et il apparait à de nombreux endroits.   Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.  Pour chaque matrice, utiliser les commandes Sage eigenvalues ou eigenvectors_right pour caractériser les valeurs et vecteurs propres. Donner aussi les multiplicités des valeurs propres.   Les valeurs propres et les vecteurs propres associés à chacune sont . Il y a deux valeurs propres de multiplicité algébrique et géométrique égales à et une valeur propre de multiplicité algébrique et géométrique égales à . Le code de la solution   A=matrix([[21, 18, 35, -1], [-16, -13, -29, 1], [-41, -39, -74, 2], [-1381, -1311, -2552, 72]]) show(A.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . Toutes les valeurs propres ont les multiplicités algébrique et géométrique égales à . Le code de la solution   B=matrix([[4, -6, 6, 6], [-6, -4, 6, 2], [-2, -14, 16, 12], [-4, 12, -12, -12]]) show(B.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . La valeur propre est de multiplicité algébrique et géométrique . La valeur propre a pour multiplicité algébrique , mais seulement comme multiplicité géométrique. Le code de la solution   C=matrix([[-14, -1, 6, -5], [-9, 0, 4, -3], [-27, -1, 11, -9], [12, 2, -6, 5],]) show(C.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . Les deux valeurs propres ont comme multiplicité algébrique , mais une multiplicité géométrique seulement égale à . Le code de la solution   D=matrix([[3, -5, 15, 14], [1, -3, 14, 13], [-6, 5, -58, -54], [6, -5, 60, 56]]) show(D.eigenvectors_right())    Cet exercice est un exemple semblable à l'exercice qui introduit une autre suite fameuse en mathématiques. Les nombres de Lucas sont définis par la suite et . C'est donc la même suite que Fibonacci, mais avec des termes initiaux différents. Voici les dix premiers termes de cette suite.   La matrice qui sera utilisée pour ce problème est la même que celle de l'exercice . Utiliser la matrice inverse pour déterminer le vecteur initial à partir du vecteur . .   Le code solution   A=matrix([[1,1],[1,0]]) Ainv=A.inverse() x1=vector([1,2]) x0=Ainv*x1 show(x0)   Déterminer une combinaison linéaire des vecteurs propres et exprimant . . où Le code solution   l1=(1-sqrt(5))\/2 l2=(1+sqrt(5))\/2 T=column_matrix([[l1,1],[l2,1]]) x0=vector([2,-1]) rep=T.solve_right(x0) show(rep) #### Ce que c'est n'est pas tout à fait clair, mais on peut forcer Sage à simplifier### maxima_calculus('algebraic: true;') rep[0].simplify_rational() rep[1].simplify_rational()   Montrer que .    "
},
{
  "id": "fig-vecpropre1",
  "level": "2",
  "url": "sec-propre.html#fig-vecpropre1",
  "type": "Figure",
  "number": "6.1.1",
  "title": "",
  "body": " Une transformation difficile à cerner     "
},
{
  "id": "fig-vecpropre2",
  "level": "2",
  "url": "sec-propre.html#fig-vecpropre2",
  "type": "Figure",
  "number": "6.1.2",
  "title": "",
  "body": " La même transformation sous un autre angle     "
},
{
  "id": "ex-valpropresA1",
  "level": "2",
  "url": "sec-propre.html#ex-valpropresA1",
  "type": "Exemple",
  "number": "6.1.3",
  "title": "Un premier calcul avec les directions invariantes.",
  "body": " Un premier calcul avec les directions invariantes  On cherche les deux nombres associés aux directions invariantes de la matrice .  Ces directions sont et .   Parce que les directions sont données, il suffit de calculer l'image de chacune de ces directions et de déduire le facteur associé. Pour la direction , on a et pour la direction , on a .  La matrice représente alors un étirement de facteur dans la direction du vecteur et un étirement de facteur dans la direction .   "
},
{
  "id": "def-propres",
  "level": "2",
  "url": "sec-propre.html#def-propres",
  "type": "Définition",
  "number": "6.1.4",
  "title": "Vecteurs et valeurs propres.",
  "body": " Vecteurs et valeurs propres  Soit , une matrice carrée représentant une transformation linéaire d'un espace vers ce même espace. On dit que est un vecteur propre si et s'il existe un scalaire pour lequel . Le scalaire est alors appelé la valeur propre associée à .  "
},
{
  "id": "proposition-69",
  "level": "2",
  "url": "sec-propre.html#proposition-69",
  "type": "Proposition",
  "number": "6.1.5",
  "title": "Vecteurs propres et direction invariante.",
  "body": " Vecteurs propres et direction invariante  Soit , un vecteur propre d'une matrice . Alors pour tout réel, le vecteur est aussi un vecteur propre.  Pour une direction invariante, il y a donc une infinité de vecteurs propres.    Voir l'exercice .   "
},
{
  "id": "fig-propresgeo",
  "level": "2",
  "url": "sec-propre.html#fig-propresgeo",
  "type": "Figure",
  "number": "6.1.6",
  "title": "",
  "body": " Vecteurs et valeurs propres géométriques   "
},
{
  "id": "computation-37",
  "level": "2",
  "url": "sec-propre.html#computation-37",
  "type": "Calcul",
  "number": "6.1.7",
  "title": "Vecteurs et valeurs propres sur Sage.",
  "body": " Vecteurs et valeurs propres sur Sage  En anglais, les mots pour vecteur propre et valeur propre sont respectivement eigenvector et eigenvalue , qui sont eux-mêmes dérivés du mot allemand eigen , qui signifie propre , caractéristique ou encore particulier . Sans surprise donc, la commande sur Sage pour trouver les valeurs propres est A.eigenvalues() . Pour les vecteurs propres, Sage doit aussi savoir si l'on veut un vecteur propre à droite (ce que l'on veut) ou à gauche (car il pourrait aussi exister un vecteur et un scalaire tels que ). La commande est donc A.eigenvectors_right() . Sage retourne alors un triplet composé, dans l'ordre, de la valeur propre, d'un vecteur propre associé à celle-ci et d'un troisième nombre, appelé la multiplicité, qui sera considéré dans la sous-section suivante. Voici les valeurs et vecteurs propres de la matrice de l'introduction.   On vérifie que, pour une matrice de réflexion quelconque, on a toujours et comme valeurs propres et que les vecteurs propres associés sont la direction de l'axe de réflexion et son perpendiculaire.   En multipliant le second vecteur par et le premier par , on retrouve les directions voulues.  Une particularité que l'on peut remarquer tient au fait que, dans la commande du vecteur propre, celui-ci est donné dans une liste qui ne contient que ce vecteur. En fait, pour une valeur explicite de , il est possible d'avoir plus d'une direction invariante associée à cette valeur. Il s'avère que l'espace engendré par les vecteurs propres associés à un scalaire est un sous-espace vectoriel. On peut donc parler d'espace invariant ou espace propre. Ce concept sera exploré dans la sous-section suivante. En attendant, voici les vecteurs et valeurs propres d'une réflexion dans .   On remarque que la valeur propre apparait deux fois dans l'exécution de la commande eigenvalues et que le vecteur propre qui lui est associé est en fait deux vecteurs. On remarque aussi que le troisième élément de la liste est , qu'il y a deux vecteurs et que la valeur propre apparaissait deux fois. Coïncidence?  "
},
{
  "id": "def-polynomecaracteristique",
  "level": "2",
  "url": "sec-propre.html#def-polynomecaracteristique",
  "type": "Définition",
  "number": "6.1.8",
  "title": "Polynôme caractéristique d’une matrice.",
  "body": " Polynôme caractéristique d'une matrice   Soit , une matrice carrée. On appelle le polynôme caractéristique de la matrice le polynôme résultant du calcul de .   "
},
{
  "id": "prop-valproprepoly",
  "level": "2",
  "url": "sec-propre.html#prop-valproprepoly",
  "type": "Proposition",
  "number": "6.1.9",
  "title": "Polynôme caractéristique et valeurs propres.",
  "body": " Polynôme caractéristique et valeurs propres  Soit , une matrice carrée. Les valeurs propres de correspondent aux zéros de son polynôme caractéristique.   Pour que soit une valeur propre de la matrice , il faut qu'il existe un vecteur non nul tel que . Soit , un zéro du polynôme caractéristique. Puisque , l'espace nul de cette matrice est de dimension supérieure ou égale à . Soit , un vecteur non nul de cet espace nul. On a alors .  Ainsi, est une valeur propre de la matrice .   "
},
{
  "id": "ex-valpropre1",
  "level": "2",
  "url": "sec-propre.html#ex-valpropre1",
  "type": "Exemple",
  "number": "6.1.10",
  "title": "Calcul des valeurs propres de la matrice d’introduction.",
  "body": " Calcul des valeurs propres de la matrice d'introduction   On calcule les valeurs propres de la matrice . À l'exemple , on a déjà calculé ces valeurs propres, mais c'était en connaissant les vecteurs propres qui leur étaient associés.    On calcule le polynôme caractéristique de la matrice en calculant le déterminant de : .  Ce polynôme se factorise en , ce qui donne les valeurs propres connues et .   "
},
{
  "id": "ex-transfor2valpropres",
  "level": "2",
  "url": "sec-propre.html#ex-transfor2valpropres",
  "type": "Exemple",
  "number": "6.1.11",
  "title": "Valeurs propres des transformations géométriques de <span class=\"process-math\">\\(\\mathbb{R}^2\\text{.}\\)<\/span>.",
  "body": " Valeurs propres des transformations géométriques de .  Pour chacune des transformations de la liste , déterminer les valeurs propres réelles. (Rappel: les matrices de ces transformations linéaires ont été trouvées à l'exemple .)   La transformation identité garde tous les vecteurs en place. On a donc pour tous vecteurs de . Il s'ensuit que est une valeur propre. Le polynôme caractéristique de la matrice est . Ce polynôme s'annule seulement lorsque , c'est donc la seule valeur propre possible.   La réflexion par rapport à l'axe des laisse tout vecteur parallèle à inchangé et tout vecteur perpendiculaire à est envoyé sur son opposé. Les valeurs propres devraient donc être et . En effet, le polynôme caractéristique donne . Comme ce polynôme s'annule uniquement en et , ce sont les seules valeurs propres possibles.  Une rotation ne laisse aucun vecteur en place, sauf le vecteur nul qui ne peut pas être un vecteur propre. Il ne devrait donc pas y avoir de valeurs propres. Le polynôme caractéristique est . Ce polynôme n'a en effet pas de solution dans les réels.  Les étirements ont dans leur définition une direction qui est inchangée. Une valeur propre est très certainement le facteur d'étirement . Dans l'exercice , on a toutefois mentionné qu'un vecteur dont la direction est perpendiculaire à la direction étirée ne changeait pas. La valeur semble donc aussi être une valeur propre. Dans le cas de l'étirement horizontal, on a , qui s'annule bel et bien en et .  Une homothétie étant un étirement dans les deux directions, il semble plausible de considérer que le facteur sera la seule valeur propre. En effet, on a , qui s'annule seulement lorsque .  Il est peut-être difficile de voir quelles seront les valeurs propres en pensant seulement à la permutation des composantes. On peut toutefois remarquer que la permutation dans est aussi une réflexion de direction . On peut probablement conclure que les valeurs propres seront et , comme pour les valeurs propres d'une réflexion selon l'axe des abscisses. En effet, s'annule lorsque et . Ce sont donc les valeurs propres.  Pour une projection orthogonale, le vecteur sur lequel on projette demeure inchangé et le vecteur perpendiculaire s'écrase à . On peut donc penser que les valeurs propres seront et . On a, . On voit que peu importe les composantes du vecteur , les valeurs propres seront toujours et .  "
},
{
  "id": "example-122",
  "level": "2",
  "url": "sec-propre.html#example-122",
  "type": "Exemple",
  "number": "6.1.12",
  "title": "Calcul des vecteurs propres de la matrice d’introduction.",
  "body": " Calcul des vecteurs propres de la matrice d'introduction   On calcule les vecteurs propres de la matrice . On sait que ces vecteurs propres devraient être , selon la figure .    À l'exemple , on a réussi à trouver que les valeurs propres de la matrice sont et . En caractérisant l'espace propre des matrices et , on pourra trouver des vecteurs propres associés à chacune des valeurs propres.  Dans un premier temps, on a . On peut lire une base de l'espace nul de cette matrice de sa forme échelonnée réduite qui est . En multipliant par ce vecteur, on retrouve le vecteur de l'énoncé.  De même, avec la seconde valeur propre, on a . On peut lire une base de l'espace nul de cette matrice de sa forme échelonnée réduite qui est . En multipliant par ce vecteur, on retrouve le vecteur de l'énoncé.   "
},
{
  "id": "ex-vecvalpropres",
  "level": "2",
  "url": "sec-propre.html#ex-vecvalpropres",
  "type": "Exemple",
  "number": "6.1.13",
  "title": "Des calculs de vecteurs et valeurs propres.",
  "body": " Des calculs de vecteurs et valeurs propres  On cherche les valeurs et vecteurs propres des matrices suivantes: .   On commence par trouver les valeurs propres en calculant le déterminant de . On obtient . Les valeurs propres sont les valeurs de qui annulent ce déterminant, soit et .  On trouve le premier vecteur propre en regardant l'espace nul de . En effectuant l'opération élémentaire et ensuite l'opération élémentaire , on obtient la matrice échelonnée réduite . Celle-ci donne le vecteur propre , ou son multiple . Un calcul rapide montre qu'on a bel et bien .  Pour le second vecteur propre, on procède de manière similaire. On regarde l'espace propre associé à . On a alors . Une base de cet espace, donc un vecteur propre, est le vecteur . Encore une fois, un calcul rapide permet d'observer que .   On procède de la même manière. On a . On ne trouve ici qu'une seule valeur propre égale à . Pour l'espace propre, on regarde l'espace nul de la matrice , dont la forme échelonnée réduite est . Un vecteur propre est donc . Encore une fois, un calcul permet de vérifier que .  On calcule le déterminant de la matrice afin de déterminer les valeurs propres. On a . Les valeurs propres sont donc et .  Pour la recherche des vecteurs propres associés, il faut regarder les espaces nuls des matrices pour chaque valeur trouvée. Pour , on trouve . Il n'y a qu'une seule variable libre, la deuxième. Une base de l'espace nul est donc , qui constitue un vecteur propre. Plus simplement, on peut le multiplier par pour avoir . Un calcul simple montre que l'on a bel et bien .  Pour le deuxième vecteur propre associé à la valeur propre , on procède de la même manière. On a . Encore une fois, on ne retrouve qu'une variable libre, cette fois en , qui amène comme vecteur propre le vecteur . On vérifie à nouveau que l'on a bien par un calcul de produit matrice vecteur.  Finalement, avec la dernière valeur propre , on a . Le dernier vecteur propre est .   On se permet de faire les calculs sur Sage pour les deux prochaines matrices. On n'utilisera pas les fonctions eigenvalues et eigenvectors_right , car on veut pour l'instant être en mesure de comprendre comment obtenir les valeurs et vecteurs propres à partir des définitions et résultats, mais on laisse Sage faire les calculs de ces déterminants et l'échelonnage des matrices. Pour les valeurs propres:   Cette fois, les valeurs propres sont et . On remarque qu'il n'y a encore une fois que deux valeurs propres.  Un premier vecteur propre est obtenu en regardant l'espace propre associé à .   Le vecteur propre est . Pour la seconde valeur propre :   Le second vecteur propre est .  On remarque dans ce cas-ci que chaque valeur propre n'a qu'une direction propre associée.   On répète la démarche précédente avec la matrice et Sage.  D'abord, pour les valeurs propres, on calcule le déterminant de la matrice et l'on demande à Sage de factoriser le tout pour pouvoir y lire facilement les zéros. À noter qu'on utilise plutôt que , car le mot lambda est protégé en python.   Il n'y a que deux valeurs propres distinctes, et . Pour trouver les vecteurs propres, on trouve une base pour les espaces nuls des deux matrices et .   Un vecteur propre associé à est donc . On vérifie facilement que , puisque ce produit donne la première colonne de la matrice . Pour , on regarde ce que Sage donne comme espace propre.   On constate qu'il y a ici deux vecteurs propres associés à la valeur propre . Le vecteur (après multiplication par ) et le vecteur , dont on peut dire que .   "
},
{
  "id": "def-multalggeo",
  "level": "2",
  "url": "sec-propre.html#def-multalggeo",
  "type": "Définition",
  "number": "6.1.14",
  "title": "Multiplicité algébrique et géométrique.",
  "body": " Multiplicité algébrique et géométrique  Soit , une matrice, , une valeur propre de cette matrice et , la plus grande valeur telle que le facteur divise le polynôme caractéristique. On dit que est la multiplicité algébrique de la valeur propre.  Soit , la dimension de l'espace nul de la matrice . On dit que est la multiplicité géométrique de la valeur propre.   "
},
{
  "id": "computation-38",
  "level": "2",
  "url": "sec-propre.html#computation-38",
  "type": "Calcul",
  "number": "6.1.15",
  "title": "Polynôme caractéristique et Sage.",
  "body": " Polynôme caractéristique et Sage  Bien que Sage soit capable de calculer directement les vecteurs et les valeurs propres, il peut aussi simplement donner le polynôme caractéristique d'une matrice . Il suffit d'utiliser la commande characteristic_polynomial() ou son équivalent plus court charpoly() . À noter que Sage utilise une version légèrement différente du polynôme caractéristique. Il considère plutôt le déterminant de . Le polynôme retourné par Sage sera le même que celui de la définition lorsque est une matrice de taille où est pair et diffèrera d'un facteur lorsque est impair.   On peut ensuite demander à Sage de factoriser ce polynôme caractéristique, mais pour qu'il puisse accomplir le travail, il faudra peut-être préciser l'espace sous-jacent aux entrées de la matrice. (Par défaut, Sage considère qu'une matrice dont toutes les entrées sont des entiers comme une matrice dans un espace d'entiers, et va factoriser en conséquence.)   En terminant, un retour sur la commande eigenvectors_right en lien avec les multiplicités.   Cette matrice correspond à la matrice de l'exemple , où l'on avait trouvé que la valeur propre n'avait qu'un vecteur propre. Elle apparait toutefois avec une multiplicité algébrique de .  "
},
{
  "id": "thm-delamatriceinversev6",
  "level": "2",
  "url": "sec-propre.html#thm-delamatriceinversev6",
  "type": "Théorème",
  "number": "6.1.16",
  "title": "Théorème de la matrice inverse, sixième version.",
  "body": " Théorème de la matrice inverse, sixième version   Soit , une matrice carrée d'ordre . Les énoncés suivants sont équivalents:  La matrice est inversible;  Pour chaque vecteur , il existe un seul vecteur tel que ;  Le rang de la matrice est égal à ;  La matrice possède pivots.  La forme échelonnée réduite de est la matrice identité;  Aucune ligne n'est une combinaison linéaire des autres lignes;  Aucune colonne n'est une combinaison linéaire des autres colonnes;  Le déterminant de la matrice est non nul;  L'espace colonne est de dimension ;  L'espace ligne est de dimension ;  L'espace nul est de dimension ;  L'espace nul gauche est de dimension ;  Toutes les valeurs propres de sont non nulles.    Il faut seulement démontrer l'équivalence entre le dernier énoncé et l'un des autres. Dans un premier temps, si est inversible, alors son espace nul est de dimension . Il n'existe donc pas d'autres vecteurs que tels que . Il en découle que ne peut être une valeur propre.  À l'inverse, si est une matrice dont toutes les valeurs propres sont différentes de zéro, cela implique qu'aucun vecteur non nul ne possède la propriété que . Donc, le seul élément dans l'espace nul de est le vecteur nul, ce qui signifie que l'espace nul est de dimension . Ainsi, une matrice est inversible si et seulement si aucune de ses valeurs propres n'est nulle.   "
},
{
  "id": "prop-propresindep",
  "level": "2",
  "url": "sec-propre.html#prop-propresindep",
  "type": "Proposition",
  "number": "6.1.17",
  "title": "Vecteurs propres et indépendance.",
  "body": " Vecteurs propres et indépendance   Soit , des valeurs propres distinctes d'une matrice et , des vecteurs propre associés à chacune de ces valeurs propres. Alors, l'ensemble est linéairement indépendant.    Si , il n'y a qu'un seul vecteur propre. Celui-ci étant non nul, il est par défaut indépendant. S'il y a plus de deux vecteurs, on procède par contradiction. On suppose que l'ensemble de ces vecteurs propres est dépendant. On peut alors affirmer qu'il existe un entier tel que est un ensemble indépendant, mais que est dépendant. Bien entendu, puisqu'on suppose que l'ensemble de tous ces vecteurs est dépendant. On cherche donc le premier vecteur qui, combiné aux précédents vecteurs indépendants, rend l'ensemble dépendant. Si est dépendant, il existe une combinaison linéaire des premiers vecteurs qui donne le vecteur : . On multiplie les deux côtés de cette équation par . On obtient alors . D'un autre côté, on multiplie l'équation par pour obtenir . On obtient qui se réécrit sous la forme . Comme les vecteurs sont linéairement indépendants, il faut que les coefficients de cette combinaison linéaire soient nuls, mais on a également que les valeurs propres sont distinctes. Cela entraine que . Par contre, si cela était vrai, l'équation impliquerait que , ce qui est impossible. On ne peut en conséquence trouver une valeur de telle que l'ensemble est indépendant, mais l'ensemble est dépendant. On conclut que est forcément indépendant, ce qui termine la preuve.   "
},
{
  "id": "prop-effetvalpropre",
  "level": "2",
  "url": "sec-propre.html#prop-effetvalpropre",
  "type": "Proposition",
  "number": "6.1.18",
  "title": "L’effet de certaines opérations sur les valeurs propres.",
  "body": " L'effet de certaines opérations sur les valeurs propres  Soit , une matrice carrée et , une valeur propre. Alors  le scalaire est une valeur propre de la matrice ;  le scalaire est une valeur propre de la matrice ;  lorsque est inversible, est une valeur propre de la matrice ;  la valeur propre est aussi une valeur propre de transposée .    Soit , un vecteur propre associé à pour la matrice . On a . Ainsi, puisque , une valeur propre de est . De plus, le vecteur demeure un vecteur propre.  Voir l'exercice  Si est une matrice inversible, alors selon le , la valeur propre n'est pas nulle. Soit , un vecteur propre associé à . On peut alors écrire . Le scalaire est donc bel et bien une valeur propre de .  Voir l'exercice  "
},
{
  "id": "prop-valpropretriangulaire",
  "level": "2",
  "url": "sec-propre.html#prop-valpropretriangulaire",
  "type": "Proposition",
  "number": "6.1.19",
  "title": "Les valeurs propres de matrices triangulaires.",
  "body": " Les valeurs propres de matrices triangulaires  Soit , une matrice triangulaire inférieure et , une matrice triangulaire supérieure. Alors, les valeurs propres de sont sur leur diagonale respective.   C'est une conséquence directe du fait que les matrices et sont triangulaires et de la proposition qui stipule que le déterminant d'une matrice triangulaire est le produit des entrées sur la diagonale principale. On voit que le polynôme caractéristique est déjà factorisé et s'annule précisément aux entrées de la diagonale de ou .   "
},
{
  "id": "exo-transfor2vecpropres",
  "level": "2",
  "url": "sec-propre.html#exo-transfor2vecpropres",
  "type": "Exercice",
  "number": "6.1.4.1",
  "title": "",
  "body": "Déterminer les vecteurs propres de chacune des transformations linéaires de la liste en considérant l'espace propre associé à chaque valeur propre. On rappelle que les valeurs propres ont été trouvées à l'exemple .  Dans la plupart des cas, on donne une base de l'espace propre associé à chaque valeur propre.  Tous les vecteurs de sont des vecteurs propres pour la matrice identité.  Le vecteur est un vecteur propre pour la valeur propre et le vecteur est un vecteur propre associé à la valeur propre .  Aucun vecteur propre réel.  Pour l'étirement horizontal, le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .  Pour un étirement vertical, les rôles sont renversés. Le vecteur est un vecteur propre associé à et le vecteur un vecteur propre pour .  Tous les vecteurs de sont des vecteurs propres.  Le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .  Le vecteur est un vecteur propre associé à et le vecteur est un vecteur propre associé à .   Pour chaque transformation, on regarde l'espace propre associé à chacune des valeurs propres trouvées à l'exemple .  Pour la seule valeur propre , on a , la matrice nulle. Tous les vecteurs sont dans l'espace nul de cette matrice. N'importe quel vecteur de est donc un vecteur propre.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace nul de cette matrice est engendré par le vecteur . N'importe quel multiple de ce vecteur est donc un vecteur propre.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace nul de cette matrice est engendré par le vecteur . N'importe quel multiple de ce vecteur est donc un vecteur propre.   Comme il n'y avait pas de valeurs propres réelles, il ne peut pas y avoir de vecteurs propres réels non plus.  D'abord, l'étirement horizontal: Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente;  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.  Pour ce qui est de l'étirement vertical, la même démarche s'applique, mais les rôles sont inversés. Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction (si . L'espace nul de cette matrice est engendré par . Toutefois, si l'on avait , alors la transformation serait en fait l'identité. On réfère à la partie précédente.    De manière semblable à la transformation identité, la matrice donne la matrice nulle. Tous les vecteurs de sont des vecteurs propres.  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace propre de cette matrice est engendré par , ce qui fait de tout multiple de ce vecteur un vecteur propre de la matrice associé à .  Pour la valeur propre , la matrice devient , qui est équivalente à la matrice après réduction. L'espace propre de cette matrice est engendré par , ce qui fait de tout multiple de ce vecteur un vecteur propre de la matrice associé à .   Pour la valeur propre , la matrice à analyser est . On fait d'abord l'hypothèse que . Par conséquent, la matrice est équivalente après réduction à . Dans ce cas, l'espace nul est engendré par , ou encore . Toutefois, si , alors, puisqu'on ne peut projeter sur le vecteur nul, on doit avoir . La matrice est alors équivalente à après réduction, et a pour générateur de son espace nul le vecteur , ou encore son multiple . Dans tous les cas, une base de l'espace propre peut s'écrire comme .  Pour la valeur propre , la matrice à analyser est . Sous l'hypothèse cette fois que , on peut montrer que cette matrice est équivalente après réduction à la matrice Dans ce cas, l'espace nul est engendré par ou son multiple . Toutefois, si , alors comme précédemment, on ne peut avoir aussi , ce qui fait que la matrice après réduction est équivalente à . L'espace nul est engendré par le vecteur , ou encore son multiple . Dans tous les cas, une base de l'espace propre peut s'écrire comme .    "
},
{
  "id": "exo-valvecpropres",
  "level": "2",
  "url": "sec-propre.html#exo-valvecpropres",
  "type": "Exercice",
  "number": "6.1.4.2",
  "title": "",
  "body": "Pour chacune des matrices suivantes, déterminer les valeurs propres et une base de l'espace propre associé à chaque valeur propre. avec et Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne deux valeurs propres, la première et la seconde .  On regarde l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur .  On regarde ensuite l'espace propre associé à . La matrice devient , qui a comme base de son espace propre le vecteur , parallèle à .  et . Pour les valeurs propres, on calcule d'abord le déterminant de : . Ceci donne une seule valeur propre, .  On regarde l'espace propre associé à cette valeur propre. La matrice devient , qui a comme base de son espace propre le vecteur .  avec et . Pour les valeurs propres, on commence par calculer le déterminant de : , qui s'annule lorsque et .  Pour le premier espace propre, on regarde la matrice et l'on détermine une base de son espace nul. On utilise Sage pour effectuer la réduction.   On remarque que la troisième variable est libre. Une base de l'espace nul serait le vecteur , parallèle au vecteur .  De même, pour le second espace propre, on obtient avec Sage un système ayant lui aussi une seule variable libre, dont une base est donnée par le vecteur , parallèle au vecteur .   et avec , et . On commence par déterminer les valeurs propres en considérant le déterminant de : , ce qui donne comme valeur propre et .  On détermine les espaces propres en échelonnant les matrices appropriées avec Sage.   Pour l'espace propre associé à , on voit une variable libre en . Une base de cet espace propre est donnée par . Pour le deuxième espace propre, on a aussi une seule direction invariante donnée par , parallèle à . Enfin, pour le dernier espace propre, on trouve le vecteur après ajustement.  avec , . Encore une fois, on commence par les valeurs propres. On a , qui offre comme valeurs propres et .  Pour les espaces propres, on se tourne une fois de plus vers Sage afin d'échelonner la matrice.   Pour la première valeur propre, on trouve un vecteur propre associé qui est . Pour la seconde valeur propre, il y a deux variables libres et donc, deux directions invariantes associées à cette valeur propre. On trouve , parallèle à et .  "
},
{
  "id": "exo-direcinvariante",
  "level": "2",
  "url": "sec-propre.html#exo-direcinvariante",
  "type": "Exercice",
  "number": "6.1.4.3",
  "title": "",
  "body": "Soit , une matrice carrée, , une valeur propre et , un vecteur propre associé à . Montrer que pour tout non nul, le vecteur est aussi un vecteur propre associé à . Cela découle directement du fait que les vecteurs propres sont des directions invariantes et que et ont la même direction. Un calcul montre que . Le vecteur est donc bel et bien un vecteur propre. "
},
{
  "id": "exo-effetvalpropre",
  "level": "2",
  "url": "sec-propre.html#exo-effetvalpropre",
  "type": "Exercice",
  "number": "6.1.4.4",
  "title": "",
  "body": "Compléter la preuve de la proposition en démontrant que le scalaire est une valeur propre de la matrice et que la valeur propre est aussi une valeur propre de la transposée .  On commence par le nombre et l'on montre que c'est une valeur propre de . Il semble plausible que si est un vecteur propre de , ce soit aussi un vecteur propre de . On s'en assure en effectuant le calcul. . On trouve qu'en effet, est aussi un vecteur propre de et l'on obtient en même temps la valeur propre .  Pour le fait que est aussi une valeur propre de , on ne peut pas procéder de la même manière, car rien ne garantit que le vecteur sera aussi un vecteur propre de la matrice . De toute évidence, on ne connait pas l'effet de sur . On se tourne donc vers la définition. .  Puisque le déterminant de est le même que celui de , il s'ensuit que les valeurs propres seront les mêmes.  "
},
{
  "id": "exercise-327",
  "level": "2",
  "url": "sec-propre.html#exercise-327",
  "type": "Exercice",
  "number": "6.1.4.5",
  "title": "",
  "body": " Déterminer les valeurs propres de la matrice en fonction de celles de la matrice .  On peut procéder de deux manières. Pour l'une d'elles, peut-on deviner un vecteur propre de ? On calcule le déterminant approprié. On utilise comme variable du polynôme caractéristique, laissant pour les valeurs propres de . . On sait que le membre de droite de cette dernière équation a des solutions lorsque correspond aux valeurs propres de . En posant et en isolant , on découvre que les valeurs propres de sont un de plus que les valeurs propres de .  On aurait aussi pu déduire les valeurs propres en essayant de voir si un vecteur propre de est aussi un vecteur propre de . On aurait alors eu . On ne peut, par contre, pas toujours se fier au fait que les vecteurs propres seront les mêmes après une opération sur la matrice (comme la transposée), c'est pourquoi il est bon de trouver des preuves qui ne les utilisent pas.  "
},
{
  "id": "exercise-328",
  "level": "2",
  "url": "sec-propre.html#exercise-328",
  "type": "Exercice",
  "number": "6.1.4.6",
  "title": "",
  "body": "Soit , des matrices carrées et , une de leurs valeurs propres respectives. On tente de généraliser l'exercice précédent. Pour chaque énoncé suivant, démontrer s'il est vrai et donner un contrexemple s'il est faux. Le scalaire est une valeur propre de a matrice . C'est vrai. C'est vrai, il suffit de refaire l'une des preuves de l'exercice précédent. Par exemple, en supposant qu'un vecteur propre de devrait encore être un vecteur propre de , on trouve . Le scalaire est une valeur propre de la matrice . C'est faux En général, ce sera faux, car on ne sait pas si le même vecteur propre est associé à et . À titre d'exemple, la matrice a pour valeur propre , la matrice a pour valeur propre , mais la matrice a pour valeurs deux nombres irrationnels. En effet , mais , qui s'annule lorsque . Les valeurs propres de la somme ne sont donc pas la somme des valeurs propres. Si est tel que et , alors est une valeur propre de . C'est vrai Cette fois, un vecteur propre est partagé. On peut penser que ce vecteur propre sera aussi un vecteur propre de la matrice . En effet, on a . On obtient un vecteur propre associé à . "
},
{
  "id": "exercise-329",
  "level": "2",
  "url": "sec-propre.html#exercise-329",
  "type": "Exercice",
  "number": "6.1.4.7",
  "title": "",
  "body": "Montrer que si est une matrice carrée telle que et et que , alors . En d'autres mots, les vecteurs propres d'une matrice et ceux de sa transposée sont perpendiculaires s'ils ne sont pas associés à la même valeur propre. L'exercice pourrait être utile. Montrer que et . Conclure que, puisque , on doit avoir . On considère le produit scalaire . Puisque est un vecteur propre de la matrice , on a alors .  D'un autre côté, avec l'exercice , on a que , qui, parce que est vecteur propre de , devient .  On a donc et puisque , on doit avoir .  "
},
{
  "id": "exo-dettracevalpropre",
  "level": "2",
  "url": "sec-propre.html#exo-dettracevalpropre",
  "type": "Exercice",
  "number": "6.1.4.8",
  "title": "",
  "body": "Soit , une matrice de taille possédant des valeurs propres . Montrer que et où est la trace de la matrice définie à l'exercice comme la somme des éléments sur la diagonale de la matrice . On pose . On calcule le polynôme caractéristique et l'on trouve une correspondance entre les valeurs propres et celui-ci. . D'un autre côté, si sont les valeurs propres, alors le polynôme caractéristique peut s'écrire comme . En comparant les deux manières d'écrire le polynôme, on trouve que le facteur et que et . "
},
{
  "id": "exercise-331",
  "level": "2",
  "url": "sec-propre.html#exercise-331",
  "type": "Exercice",
  "number": "6.1.4.9",
  "title": "",
  "body": "Soit , une matrice carrée dont toutes les entrées sont supérieures ou égales à avec la propriété additionnelle que la somme des entrées de chaque ligne donne . Déterminer un vecteur et une valeur propre de . On cherche une solution à l'équation . Le produit a, dans chaque entrée, le produit scalaire des lignes de avec le vecteur . Afin d'utiliser l'information sur la somme des lignes, on pose . On obtient , un vecteur propre dont la valeur propre est . "
},
{
  "id": "exercise-332",
  "level": "2",
  "url": "sec-propre.html#exercise-332",
  "type": "Exercice",
  "number": "6.1.4.10",
  "title": "",
  "body": "Soit , des matrices . Dans cet exercice, on s'intéresse aux valeurs propres des produits et . Montrer que est une valeur propre de si et seulement si c'est aussi une valeur propre de . Si , alors . Si est une valeur propre de , alors . Or comme , l'implication est vraie d'un côté. En échangeant le rôle de dans la preuve ci-dessus, on montre que si est une valeur propre de , c'est aussi une valeur propre de . Montrer que si et que est un vecteur propre de associé à , alors le vecteur est non nul. Expliquer pourquoi il est nécessaire de supposer que . On procède par contradiction en supposant que . Puisque est un vecteur propre de , on doit avoir . On se retrouve dans la situation où . En vertu de la propriété sur les espaces vectoriels , on doit avoir ou . La première possibilité est impossible par hypothèse du problème et la seconde est impossible par définition d'un vecteur propre. Il est donc impossible d'avoir le vecteur .  Il était nécessaire d'avoir l'hypothèse pour forcer la contradiction sur le vecteur propre qui est nul. Ainsi, dans une situation où la valeur propre est , il est possible que .  Montrer que si est une valeur propre de et que est un vecteur propre associé, alors est un vecteur propre de . Conclure que est aussi une valeur propre de . Soit , un vecteur propre de associé à la valeur propre . On prétend que est un vecteur propre de . On vérifie en calculant . Ainsi, le vecteur est un vecteur propre, si celui-ci est non nul. La partie précédente a montré que dans le cas , le vecteur est bel et bien non nul. Montrer que si et que sont des vecteurs formant une base de (donc des vecteurs propres de ), alors les vecteurs sont indépendants. Expliquer pourquoi il est nécessaire de supposer que .  Soit , des nombres tels que . En multipliant par cette équation, on a . Puisque est non nul, il faut que le vecteur le soit, or, comme les vecteurs sont indépendants, on doit avoir , ce qui montre que les vecteurs sont aussi indépendants.  Si avait pu être nul, on n'aurait pas été en mesure de conclure qui de ou du vecteur aurait contribué à faire du produit le vecteur nul.  Conclure de la partie précédente que et que la multiplicité géométrique de pour est inférieure ou égale à celle pour . La dimension de l'espace correspond au nombre de vecteurs dans une base. Ces vecteurs seront indépendants. Puisque les vecteurs sont eux-mêmes indépendants, la dimension doit être au moins égale à , car si elle était inférieure, cela contredirait la proposition . Comme il y a vecteurs dans une base de , on a  Montrer que . Que peut-on conclure? Il suffit d'interchanger les rôles de et dans les parties précédentes. En inversant le rôle de et de , l'exercice permet aussi de conclure que est non nul si est un vecteur propre de . De plus, la partie permet de conclure que est un vecteur propre de associé à . On peut ensuite utiliser le reste de l'exercice pour montrer que .  En combinant les deux inégalités, on montre que et que les multiplicités géométriques sont égales.  Ceci montre que les matrices et ont les mêmes valeurs propres, mais on ne sait rien sur leur multiplicité algébrique respective. Il est possible, mais plus difficile, de montrer qu'en fait, les matrices et ont le même polynôme caractéristique et que leurs valeurs propres ont les mêmes multiplicités algébriques. On a toutefois montré que les multiplicités géométriques sont les mêmes. "
},
{
  "id": "exercise-333",
  "level": "2",
  "url": "sec-propre.html#exercise-333",
  "type": "Exercice",
  "number": "6.1.4.11",
  "title": "",
  "body": "On s'intéresse aux vecteurs et valeurs propres d'un cisaillement défini à l'exercice . Déterminer les valeurs propres d'un cisaillement ainsi qu'une base de l'espace propre pour chaque valeur propre trouvée.  Autant dans le cas horizontal que dans le cas vertical, la seule valeur propre est . Pour le cisaillement horizontal, l'espace propre est engendré par le vecteur et pour le cisaillement vertical, c'est plutôt par le vecteur  Comme les matrices de cisaillement horizontal et vertical sont triangulaires, on peut utiliser la proposition afin de trouver que, dans les deux cas, la seule valeur propre est . Pour l'espace propre d'un étirement horizontal, on trouve . Si , la transformation est l'identité et tous les vecteurs sont invariants. Dans le cas contraire, on peut diviser par la dernière ligne de la matrice et obtenir que l'espace propre est engendré par le vecteur . Dans le cas du cisaillement vertical, on a plutôt , qui, sous la même condition que , a comme générateur de son espace nul le vecteur . "
},
{
  "id": "exercise-334",
  "level": "2",
  "url": "sec-propre.html#exercise-334",
  "type": "Exercice",
  "number": "6.1.4.12",
  "title": "",
  "body": " Répondre aux questions suivantes sans déterminer la matrice . Trouver si et que et sont des vecteurs propres de associés respectivement aux valeurs propres et .  On écrit le vecteur comme une combinaison linéaire des vecteurs propres. On doit donc résoudre le système . On trouve et en utilisant n'importe quelle méthode. Pour trouver , on a alors .  Trouver si et si et sont des vecteurs propres de associés respectivement aux valeurs propres et . Selon la proposition , les vecteurs propres d'une matrice inverse sont les mêmes que la matrice originale, avec les valeurs propres inversées. En trouvant une combinaison linéaire des vecteurs propres donnant , on aura toutes les informations nécessaires pour trouver . On doit donc trouver tels que . La solution de ce système est , . On a ainsi pour le vecteur  . "
},
{
  "id": "exercise-335",
  "level": "2",
  "url": "sec-propre.html#exercise-335",
  "type": "Exercice",
  "number": "6.1.4.13",
  "title": "",
  "body": "Soit , une matrice et deux vecteurs non nuls tels que . Montrer qu'une des valeurs propres de est nécessairement ou . Considérer .  On cherche un vecteur tel que avec . Puisque , et que est une transformation linéaire, on peut prendre la somme de ces deux équations pour obtenir . On a donc trouvé un vecteur pour lequel . Si ce vecteur est non nul, c'est un vecteur propre associé à la valeur propre .  Toutefois, si , alors ce ne peut pas être un vecteur propre. Mais dans ce cas, et l'équation montre que est un vecteur propre associé à .  "
},
{
  "id": "exercise-336",
  "level": "2",
  "url": "sec-propre.html#exercise-336",
  "type": "Exercice",
  "number": "6.1.4.14",
  "title": "",
  "body": "Montrer que si sont des vecteurs propres tels que est aussi un vecteur propre, alors sont associés à la même valeur propre.  Si et sont parallèles, ils ont nécessairement la même valeur propre, selon l'exercice . Soit , les valeurs propres associées respectivement à . Puisque est un vecteur propre, il existe un pour lequel . En développant les deux côtés, on trouve . Puisque les vecteurs sont non parallèles, ils sont indépendants. On doit donc avoir et , entrainant que .  "
},
{
  "id": "exercise-337",
  "level": "2",
  "url": "sec-propre.html#exercise-337",
  "type": "Exercice",
  "number": "6.1.4.15",
  "title": "",
  "body": "Considérer la matrice triangulaire suivante: . Décrire les dimensions possibles pour en fonction de . (Pourquoi sait-on que est une valeur propre?)  On échelonne la matrice afin de déterminer une base de l'espace propre. On a alors . Comme prévu, l'espace nul est au moins à dimension avec la première variable libre. La deuxième et la quatrième sont toujours pivots, indépendamment de la valeur de . Pour la troisième variable, elle sera pivot si et libre dans les autres cas. L'espace propre est donc à deux dimensions si et à une dimension autrement.  "
},
{
  "id": "exercise-338",
  "level": "2",
  "url": "sec-propre.html#exercise-338",
  "type": "Exercice",
  "number": "6.1.4.16",
  "title": "",
  "body": "Une matrice est dite nilpotente s'il existe un entier pour lequel . La plus petite valeur de pour laquelle est appelé l'indice de nilpotence. On dit aussi que est nilpotente d'ordre . Montrer que est nilpotente et donner l'indice. L'indice de nilpotence est . On commence par calculer les puissances de la matrice , afin de voir si l'on obtient la matrice nulle. Puisque , la matrice est nilpotente et l'indice de nilpotence est . Montrer que est nilpotente d'ordre . On calcule la troisième puissance de la matrice. On utilise Sage.   La matrice est bien nilpotente d'ordre 3. Montrer que est nilpotente d'ordre . On calcule la deuxième puissance de la matrice. On utilise Sage.   La matrice est bien nilpotente d'ordre 2. Montrer que si est nilpotente, la seule valeur propre de est . Soit , une valeur propre de et , l'indice de nilpotence. Selon la proposition , le nombre est une valeur propre de . Comme est nilpotente d'ordre , la matrice et toutes ses valeurs propres sont nulles. On a donc , ce qui implique que . "
},
{
  "id": "exercise-339",
  "level": "2",
  "url": "sec-propre.html#exercise-339",
  "type": "Exercice",
  "number": "6.1.4.17",
  "title": "",
  "body": "Soit , une matrice telle que . Déterminer les valeurs et vecteurs propres. Montrer que est un vecteur propre de et déterminer la valeur propre associée. On calcule le produit matrice vecteur: . Le vecteur est donc effectivement un vecteur propre et la valeur propre associée est . Trouver l'autre valeur propre et un vecteur propre lui étant associé. Selon l'exercice , la somme des valeurs propres doit être égale à la trace de la matrice, soit la somme des éléments sur la diagonale principale ( ). On a donc . Avec la seconde valeur propre, on peut trouver un vecteur propre associé en regardant l'espace nul de la matrice : . Un vecteur propre est donc si et si et . Dans l'éventualité où , on doit alors avoir par hypothèse , la matrice est un multiple de la matrice identité et tous les vecteurs sont des directions invariantes. "
},
{
  "id": "exercise-340",
  "level": "2",
  "url": "sec-propre.html#exercise-340",
  "type": "Exercice",
  "number": "6.1.4.18",
  "title": "",
  "body": "Soit et , tel que défini à l'exercice . Montrer que est un vecteur propre de la matrice . Quelle est la valeur propre associée? On a .  Le vecteur est donc un vecteur propre associé à la valeur propre . Dans le cas où les vecteurs sont dans , déterminer une autre valeur propre de . Quel est le rang de ?  Puisque est de rang selon l'exercice , la matrice n'est pas inversible selon le théorème de la matrice inverse. Toujours selon ce théorème , l'une des valeurs propres de doit être nulle.  Cela se vérifié également en utilisant l'exercice . On pose et . On a alors Si et que l'on doit avoir , on voit qu'on doit avoir . "
},
{
  "id": "exo-fibo",
  "level": "2",
  "url": "sec-propre.html#exo-fibo",
  "type": "Exercice",
  "number": "6.1.4.19",
  "title": "Fibonacci.",
  "body": "Fibonacci La suite de Fibonacci est bien connue en mathématiques. C'est une suite définie par et . Les premiers nombres peuvent être obtenus par Sage à l'aide de la fonction suivante.   L'objectif de cet exercice est d'apporter une perspective d'algèbre linéaire à cette suite et de déterminer une formule pour sans avoir à calculer les nombres précédents.  On pose pour et . Déterminer une matrice qui permet d'avoir .  On aurait pu commencer par le vecteur , qui aurait contenu les deux premiers termes de la suite. On peut toutefois argumenter que en travaillant avec l'équation à l'envers. C'est un choix arbitraire qui fera l'affaire pour la suite.  Le vecteur contient et . On peut poser pour avoir un système à deux équations et deux inconnues. On peut réécrire sous la forme . La matrice est donc Calculer , et . Donner une formule en fonction de et pour . , , . En général, est la première composante de . Trouver à l'aide de cette matrice et de Sage. Vérifier la réponse à l'aide de la fonction fibo définie dans l'introduction.  Le code de la solution   A=matrix([[1,1],[1,0]]) x0=vector([0,1]) show(A^100*x0[0])   Pour la suite, il pourra être pratique d'utiliser le fait que si , alors et donc . Démontrer ce fait Il suffit de calculer  . Trouver les valeurs propres de la matrice et le vecteur propre de chacune. La première valeur propre est avec son vecteur propre et la deuxième valeur propre est avec son vecteur propre .  On a . Ce polynôme s'annule lorsque et . On remarque que ces deux valeurs sont les nombres de la partie . Pour les espaces propres, on a d'abord pour  . On trouve donc un vecteur propre .  De la même manière, on trouve , donnant le vecteur associé à .  Écrire le vecteur comme une combinaison linéaire des vecteurs propres de .  Il faut trouver tels que . Sous forme matricielle, on cherche à résoudre la matrice augmentée . On a .  Un peu de simplification est de mise. On peut montrer que et que . On a donc .  Décrire comment obtenir sans calculer les précédents et sans calculer de produit matrice vecteur. On sait que . En utilisant la décomposition en fonction des vecteurs propres, on trouve . Le nombre se retrouve dans la première composante de ce vecteur et donc .  Utiliser Sage pour calculer .   En utilisant la formule trouvée, on trouve avec Sage que cette limite vaut .   Le nombre est appelé le nombre d'or. On le note souvent par et il apparait à de nombreux endroits. "
},
{
  "id": "exercise-342",
  "level": "2",
  "url": "sec-propre.html#exercise-342",
  "type": "Exercice",
  "number": "6.1.4.20",
  "title": "",
  "body": "Pour chaque matrice, utiliser les commandes Sage eigenvalues ou eigenvectors_right pour caractériser les valeurs et vecteurs propres. Donner aussi les multiplicités des valeurs propres.   Les valeurs propres et les vecteurs propres associés à chacune sont . Il y a deux valeurs propres de multiplicité algébrique et géométrique égales à et une valeur propre de multiplicité algébrique et géométrique égales à . Le code de la solution   A=matrix([[21, 18, 35, -1], [-16, -13, -29, 1], [-41, -39, -74, 2], [-1381, -1311, -2552, 72]]) show(A.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . Toutes les valeurs propres ont les multiplicités algébrique et géométrique égales à . Le code de la solution   B=matrix([[4, -6, 6, 6], [-6, -4, 6, 2], [-2, -14, 16, 12], [-4, 12, -12, -12]]) show(B.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . La valeur propre est de multiplicité algébrique et géométrique . La valeur propre a pour multiplicité algébrique , mais seulement comme multiplicité géométrique. Le code de la solution   C=matrix([[-14, -1, 6, -5], [-9, 0, 4, -3], [-27, -1, 11, -9], [12, 2, -6, 5],]) show(C.eigenvectors_right())    Les valeurs propres et les vecteurs propres associés sont . Les deux valeurs propres ont comme multiplicité algébrique , mais une multiplicité géométrique seulement égale à . Le code de la solution   D=matrix([[3, -5, 15, 14], [1, -3, 14, 13], [-6, 5, -58, -54], [6, -5, 60, 56]]) show(D.eigenvectors_right())  "
},
{
  "id": "exercise-343",
  "level": "2",
  "url": "sec-propre.html#exercise-343",
  "type": "Exercice",
  "number": "6.1.4.21",
  "title": "",
  "body": " Cet exercice est un exemple semblable à l'exercice qui introduit une autre suite fameuse en mathématiques. Les nombres de Lucas sont définis par la suite et . C'est donc la même suite que Fibonacci, mais avec des termes initiaux différents. Voici les dix premiers termes de cette suite.   La matrice qui sera utilisée pour ce problème est la même que celle de l'exercice . Utiliser la matrice inverse pour déterminer le vecteur initial à partir du vecteur . .   Le code solution   A=matrix([[1,1],[1,0]]) Ainv=A.inverse() x1=vector([1,2]) x0=Ainv*x1 show(x0)   Déterminer une combinaison linéaire des vecteurs propres et exprimant . . où Le code solution   l1=(1-sqrt(5))\/2 l2=(1+sqrt(5))\/2 T=column_matrix([[l1,1],[l2,1]]) x0=vector([2,-1]) rep=T.solve_right(x0) show(rep) #### Ce que c'est n'est pas tout à fait clair, mais on peut forcer Sage à simplifier### maxima_calculus('algebraic: true;') rep[0].simplify_rational() rep[1].simplify_rational()   Montrer que . "
},
{
  "id": "sec-diagonalisation",
  "level": "1",
  "url": "sec-diagonalisation.html",
  "type": "Section",
  "number": "6.2",
  "title": "Diagonalisation",
  "body": "  Diagonalisation    Aller aux exercices de la section.  Dans la section précédente, on a vu que certaines matrices ont des directions invariantes associées à des valeurs propres. Si les bonnes conditions sont respectées, il y a suffisamment de vecteurs propres pour obtenir une base de l'espace. Dans ce cas, ces vecteurs permettront d'offrir une perspective géométrique intéressante sur la transformation linéaire associée à la matrice. Il y aura aussi d'importantes conséquences algébriques qui découleront de cette perspective.  Dans cette section, on introduit la diagonalisation d'une matrice et la notion de changement de base.   Diagonalisation  À la section , on a défini le concept de base ordonnée à partir d'un ensemble de vecteurs et des composantes d'un vecteur selon cette base. Ainsi, le vecteur , tel que représenté dans la base standard, s'écrit plutôt dans la base puisque . De plus, selon les notions de la sous-section , une matrice contient dans chaque colonne l'image des vecteurs . Spontanément, on peut se demander s'il est possible d'exprimer une matrice dans une autre base. À titre d'exemple, la matrice de l'équation , à l'introduction de la section précédente, peut aussi s'écrire selon la base comme , puisque l'exemple a montré que c'était un étirement de facteur dans la direction du vecteur et un étirement de facteur dans la direction du vecteur .  Il y a un lien intéressant entre la matrice et la matrice . En regardant seulement ses entrées, il semble que ce soit la même matrice, mais comme est exprimée dans une autre base, les deux transformations représentent des transformations différentes. La matrice est un étirement de facteur dans la direction du vecteur et un étirement de facteur dans la direction du vecteur , alors que est un étirement horizontal et vertical de ces mêmes facteurs. On note la matrice contenant les vecteurs propres en colonne. Justement, parce que ce sont des vecteurs propres, l'effet de sur est .  En particulier, on peut isoler pour obtenir . La proposition garantit ici que la matrice est inversible puisque ses colonnes sont indépendantes. En général, ce pourrait ne pas être le cas. On introduit le concept de matrice diagonalisable.   Matrice diagonalisable  Soit , une matrice carrée. Si la matrice possède vecteurs propres indépendants, alors il existe des matrices avec une matrice diagonale telles que . On dit alors que est diagonalisable.  La matrice contient dans ses colonnes les vecteurs propres et la matrice a pour éléments de sa diagonale les valeurs propres associées aux vecteurs propres, dans le même ordre que ceux-ci apparaissent dans .   La matrice est diagonalisable avec et comme l'a montré le calcul ci-dessus. On regarde d'autres exemples.   Diagonalisation de matrices  On reprend les matrices de l'exemple . Parmi celles-ci, les matrices avaient un nombre suffisant de vecteurs propres pour former une base. On s'intéresse donc à diagonaliser ces matrices.  La matrice a pour valeurs propres et et comme vecteurs propres associés à ces valeurs propres et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.     La matrice a pour valeurs propres et et comme vecteurs propres associés à ces valeurs propres , et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.     La matrice a pour valeurs propres et . Pour la valeur propre , on a trouvé , alors que pour la valeur propre , on a trouvé deux vecteurs propres indépendants en et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.     La diagonalisation permet de voir la matrice sous un autre œil en permettant de la décrire par des transformations simples comme les étirements et les réflexions. Par exemple, la matrice de l'exemple semble être un étirement de facteur dans la direction avec une direction inchangée en . La figure suivante illustre un parallélogramme engendré par ces vecteurs et son image.   La transformation   Un parallélogramme engendré par les deux vecteurs propres de la matrices A est illustré avec son image, qui est un étirement de facteur deux dans la direction de l'un des vecteurs propres, l'autre direction étant inchangée.     De même, la matrice peut être vue comme un étirement de facteur dans la direction , un étirement aussi de facteur , ainsi qu'une réflexion dans la direction . Il y a aussi une projection sur le plan engendré par ces deux premiers vecteurs, mais c'est plus difficile à décrire puisque les projections générales n'ont pas encore été abordées. On les verra à la section . On peut toutefois en observer l'effet sur la figure suivante.   La transformation   Un parallélépipède engendré par les vecteurs propres de la matrices C est illustré avec son image par cette matrice. Dans ce cas, l'image est en fait un parallélograme dont les côtés sont parallèles aux deux premiers vecteurs propres.     Finalement, la matrice peut être vue comme une réflexion selon le plan perpendiculaire à laissant les directions et fixes. La figure ci-dessous illustre la transformation sur le parallélépipède engendré par ces trois directions.   La transformation   Un parallélépipède engendré par les vecteurs propres de la matrices F est illustré avec son image par cette matrice. L'image est un parallélépipiède se trouvant à être la réflexion du parallélépipède initial selon le premier vecteur.     L'un des principaux avantages de la diagonalisation est de calculer rapidement les puissances d'une matrice . En général, calculer pour une grande valeur de peut être un exercice laborieux ou encore un procédé couteux pour un ordinateur, mais si est diagonalisable, alors on peut écrire . Lorsqu'une matrice est diagonale, le calcul de ses puissances est beaucoup plus simple, il suffit en effet de mettre chaque entrée sur la diagonale à la puissance . Pour obtenir , il suffit donc de multiplier à gauche par et à droite par .   Puissances de matrices   Pour chacune des matrices diagonalisables de l'exemple , on souhaite calculer la dixième puissance. On rappelle que la diagonalisation a été trouvée à l'exemple .   Pour première matrice, on a et donc   Pour la deuxième matrice, on a où l'inverse a été calculé par Sage. On a alors .  Enfin, pour la dernière matrice, on a où l'inverse a été calculé par Sage. On a alors . En réfléchissant sur la nature géométrique de la matrice , on aurait pu trouver encore plus facilement la dixième puissance. En effet, puisqu'elle consiste en une réflexion selon le plan perpendiculaire à et laisse les directions et fixes, les puissances de devraient alterner entre et l'identité .   On termine avec des commandes Sage en lien avec la sous-section.   La diagonalisation sur Sage  Sage a une commande appelée eigenmatrix_right qui retourne une paire de matrices, les matrices et , lorsque la matrice est diagonalisable. On peut aussi vérifier si une matrice est diagonalisable avec la commande , qui fonctionne si l'on ajoute l'option QQ à la matrice (ou RR , RDF ). On regarde les matrices de l'exemple et lorsque diagonalisable, on fait sortir les deux matrices afin de comparer avec celles que l'on a obtenues à l'exemple .        On remarque que lorsque la matrice n'est pas diagonalisable, la commande eigenmatrix_right retourne quand même la matrice des valeurs propres et une matrice contenant des vecteurs propres indépendants et des colonnes de zéros pour la compléter.    Changement de base  L'écriture d'une matrice n'est pas réservée au cas où la matrice est diagonale. En fait, deux matrices qui sont reliées par une telle correspondance sont dites semblables.  Matrices semblables  Soit et , deux matrices pour lesquelles il existe une matrice inversible telle que . On dit que et sont semblables.    Déterminer si des matrices sont semblables  On cherche à savoir si la matrice est semblable à l'une des matrices ou .  Pour la matrice , on cherche une matrice inversible telle que . On pose et l'on réécrit . On trouve, à partir de cette égalité matricielle, un système à quatre équations et quatre inconnues: . On résout ce système avec Sage.   Ce système contient deux variables libres en . Il y a donc une infinité de solutions. On doit seulement s'assurer que est inversible, alors il faut que . En prenant , on trouve , qui est effectivement inversible et donc, et sont semblables.    Pour la matrice , on cherche aussi une matrice inversible telle que . On pose et l'on réécrit . On trouve, à partir de cette égalité matricielle, un système à quatre équations et quatre inconnues: . On résout ce système avec Sage.   Il n'y a qu'une solution à ce système, soit lorsque . Cette solution ne peut toutefois pas être valide puisque la matrice ne serait pas inversible. Les matrices ne sont donc pas semblables.    Une interprétation de cette définition est possible dans le contexte du changement de base pour l'écriture d'une matrice. En effet, si représente une matrice dans la base usuelle et sa représentation dans la base ordonnée , alors les deux matrices sont semblables. Ceci n'est peut-être pas surprenant, mais c'est néanmoins pratique d'un point de vue calculatoire. La proposition suivante résume ce propos.   Formule de changement de base  Soit , une matrice et , sa représentation dans une base ordonnée et soit , la matrice contenant les vecteurs de dans ses colonnes. Alors .  Puisque est une base, la matrice est inversible, on obtient alors des formules pour les représentations de : . La matrice est appelée la matrice de changement de base ou encore la matrice de passage .   On analyse les colonnes de chacun des produits et . Pour , chaque colonne est donnée par le produit de la matrice avec les vecteurs de la base , soit les colonnes de . Ces colonnes sont donc les images des vecteurs de la base par représentées dans la base usuelle. On peut certainement convertir ces vecteurs dans la base , c'est-à-dire qu'il existe tels que .  D'un autre côté, la colonne de la matrice est précisément l'image du vecteur et est donc (cette fois dans la base usuelle). On a alors . Ainsi, les colonnes de sont les mêmes que les colonnes de .   On regarde des exemples artificiels de changement de base avant de considérer un exemple plus concret.   De la base standard à une base  On veut convertir la matrice dans la base .  On pose . Selon la proposition , la formule pour écrire dans la base est . On utilise Sage pour les calculs.   On a donc . Les colonnes de correspondent à l'écriture des vecteurs dans la base .    D'une base à la base standard  Soit , où . On cherche la représentation de ces vecteurs dans la base standard.  On procède comme dans l'exemple précédent, avec une matrice et une matrice de passage . Selon la proposition , la formule pour obtenir la matrice est . On utilise Sage pour les calculs.   La matrice dans la base usuelle est donc .    On revient maintenant sur l'un des exemples du chapitre , dans lequel on avait trouvé la matrice d'une rotation autour d'un axe quelconque dans . À ce moment, on avait déplacé l'axe de rotation sur l'axe des afin d'utiliser la matrice de rotation connue . On peut maintenant procéder autrement avec la formule de changement de base. On aura besoin de la proposition suivante.   Matrice de rotation dans une base orthonormée  Soit , une base de telle que . On dit que la base est orthonormée, c'est-à-dire que les vecteurs sont orthogonaux deux à deux et ont une norme égale à , et qu'elle est orientée positivement. Dans ce cas, la matrice de rotation autour de dans la base est .  Puisque est l'axe de rotation, on doit avoir pour que et donc, la troisième colonne de la matrice est déterminée.  Le même dessin que celui de la figure peut être utilisé pour voir que le vecteur sera déplacé à et que sera envoyé sur . On obtient alors les deux premières colonnes.    Il est mentionné que la base formée des vecteurs doit être orientée positivement pour que la formule soit correcte. En effet, puisqu'une rotation est par défaut dans le sens antihoraire, il faut que dans le repère, on puisse aller de vers avec une rotation antihoraire de . Il est aussi important que et soient perpendiculaire afin que corresponde avec l'angle et le rapport d'un quart de tour. Finalement, on demande la norme égale à , puisque les vecteurs et sont unitaires. L'importance des bases orthonormées sera précisée dans la section .  Matrice de rotation dans  On revient sur l'exemple dans lequel on a trouvé la matrice représentant une rotation autour de l'axe de . On veut utiliser une matrice de changement de base afin de retrouve l'expression de cette transformation (dans la base standard).  On doit trouver une base qui va satisfaire les conditions de la proposition . On prend , l'axe de rotation. Pour avoir un vecteur perpendiculaire, il suffit de prendre un vecteur qui satisfait l'équation . On opte pour . Pour le second vecteur, on doit s'assurer qu'il sera perpendiculaire à et à et que le repère sera orienté positivement. On sait que serait orienté positivement selon l'exercice . On aurait donc que le repère serait orienté négativement et finalement, que . On pose donc .   En fait, ces vecteurs ne sont pas de norme , alors on doit les normaliser avant de pouvoir utiliser la formule . On utilise ensuite la matrice de passage formé des vecteurs unitaires pour déterminer la matrice dans la base usuelle.     Dans certains cas, il pourrait être utile de trouver la représentation d'une matrice dans une base à partir de sa représentation dans une base . Puisqu'on sait comment passer d'une base quelconque à la base standard et de la base standard à une base usuelle, on devrait pouvoir trouver une manière de passer directement entre les bases non standards.   Formule générale pour le changement de base  Soit , deux bases ordonnées et soit , les matrices contenant les vecteurs de ces bases dans leurs colonnes. Soit une matrice, , sa représentation dans la base et , celle dans la base . Alors .  où est la matrice de changement de base de à et est la matrice de changement de base de à .   Voir l'exercice .    Changement de base générale  Soit et , deux bases de et la matrice d'une transformation linéaire représentée en base . On cherche la représentation de en base .  On pose et . On a alors , Ce qui donne comme matrice de passage . L'inverse de cette matrice est . En utilisant la formule de changement de base de la proposition , on obtient finalement .   On pourrait aussi parler de changement de bases pour des matrices rectangulaires, et même entre des espaces vectoriels plus généraux. On verra quelques exemples dans les exercices.    Quelques résultats  On termine cette section avec quelques résultats plus théoriques sur la diagonalisation et le changement de base. Lorsque deux matrices sont semblables, elles ont le même polynôme caractéristique. En particulier, elles ont les mêmes valeurs propres.   Les matrices semblables ont les mêmes valeurs propres   Si et sont semblables, elles ont le même polynôme caractéristique. En particulier, elles ont les mêmes valeurs propres.   Voir l'exercice .   Comme deuxième résultat, une condition suffisante, mais non nécessaire pour qu'une matrice carrée soit diagonalisable.   Une matrice possédant valeurs propres est diagonalisable  Soit , une matrice qui possède valeurs propres distinctes. Alors est diagonalisable.  Selon la proposition , les vecteurs propres associés à des valeurs propres distinctes sont indépendants. Dans ce cas, la matrice existe et est inversible. Dans la base des vecteurs propres, la matrice est égale à une matrice diagonale où les entrées sont les valeurs propres. On a donc selon la formule du changement de base.   Bien sûr, il existe des matrices diagonalisables qui n'ont pas valeurs propres distinctes, c'est la raison pour laquelle on affirme que la condition est suffisante (au sens où cette condition est suffisante pour garantir), mais non nécessaire (on peut être diagonalisable sans avoir les valeurs propres distinctes). En fait, une condition qui est nécessaire et suffisante concerne la relation entre la multiplicité algébrique et la multiplicité géométrique des valeurs propres. On se souvient que, pour être diagonalisable, il faut que la matrice possède vecteurs propres indépendants. Pour chaque valeur propre, on veut donc produire suffisamment de vecteurs propres pour que le nombre total donne . On aura besoin des deux résultats suivants pour démontrer la condition.   La multiplicité géométrique est plus petite ou égale à la multiplicité algébrique   Soit , une matrice carrée et , une valeur propre de multiplicité géométrique et de multiplicité algébrique . Alors .   Par définition, la multiplicité géométrique est la dimension de l'espace propre et celui-ci contient au moins un vecteur non nul, donc . Soit , une base de cet espace propre. Il est toujours possible d'étendre cette base en ajoutant des vecteurs indépendants pour former une base de . Soit , une base possible. À quoi ressemble la matrice dans la base ?  Les premières colonnes correspondent aux vecteurs propres associés à , qui sont les premiers vecteurs de la base. En base , l'écriture d'un vecteur est équivalente à celle du vecteur si et , signifiant que la première partie de est équivalente à la première partie de . Pour le reste, on ne sait pas en quoi consiste la matrice, mais on peut l'écrire de la manière suivante , où est une matrice quelconque, la matrice nulle est de taille et est une matrice carrée . Selon la proposition , les matrices et ont le même polynôme caractéristique puisqu'elles sont semblables. En développant avec les cofacteurs la matrice , on trouve .  On voit donc que la multiplicité algébrique de est d'au moins , puisque le facteur apparait dans le polynôme caractéristique. On a donc .     Une combinaison spéciale de vecteurs  Soit , une matrice et des valeurs propres distinctes. Soit , des vecteurs dans les espaces propres respectifs des valeurs propres. Si , alors .  On suppose qu'il y a des vecteurs non nuls. On peut simplement éliminer tous les vecteurs nuls de l'équation et obtenir une équation similaire, alors on suppose simplement qu'on a un ensemble de vecteurs non nuls où chaque vecteur est un des vecteurs dans . Si ces vecteurs sont non nuls et dans un espace propre, ce sont donc des vecteurs propres. Selon la proposition , on ne peut pas avoir une combinaison linéaire de vecteurs propres associés à des valeurs propres différentes qui donne le vecteur nul, car ces vecteurs devraient être indépendants. Les vecteurs ne peuvent donc pas être non nuls. On conclut alors que tous les vecteurs sont en effet nuls.   Avec ces résultats, on est en mesure de démontrer qu'une matrice est diagonalisable si et seulement si les multiplicités algébriques et géométriques sont égales.   Une matrice dont les multiplicités géométriques sont les mêmes que les multiplicités algébriques est diagonalisable  Soit , une matrice et soit , ses valeurs propres distinctes. Alors est diagonalisable si et seulement si les multiplicités géométriques des valeurs propres sont les mêmes que les multiplicités algébriques et somment à .  La condition que les multiplicités somment à pourra être enlevée en considérant les nombres complexes.    On suppose, dans un premier temps, que pour toutes les valeurs propres et que la somme de ces multiplicités donne . Pour chaque valeur propre, il existe une base de vecteurs propres indépendants. On considère l'ensemble . Cet ensemble contient vecteurs propres.  On suppose qu'on a une combinaison linéaire de tous ces vecteurs qui donne le vecteur nul. On peut écrire cette combinaison de la manière suivante: . Pour chaque , on pose . Chacun de ces vecteurs appartient à l'espace propre de . La combinaison linéaire des vecteurs dans devient donc . En vertu du lemme , on doit avoir pour tous les . Ceci entraine à son tour que tous les coefficients sont nuls car les vecteurs forment une base. Ainsi, l'ensemble est indépendant et, puisqu'il est composé de vecteurs dans un espace de dimension , il forme une base. En posant la matrice contenant ces vecteurs dans ses colonnes et la matrice des valeurs propres associées, dans le même ordre d'apparition que les vecteurs dans , on a bel et bien . Ainsi, est diagonalisable.  Dans un deuxième temps, on suppose que est diagonalisable. On veut montrer que les multiplicités géométriques et algébriques concordent et somment à .  Soit , une base de vecteurs propres pour l'espace vectoriel. On note l'intersection de cette base avec l'espace propre associé à . Soit , le nombre de vecteurs dans . On a alors puisque est de dimension et que les vecteurs dans sont indépendants (on ne peut avoir plus de vecteurs indépendants que la dimension du sous-espace, selon la proposition ). De plus, selon le lemme , on a . Comme il y a vecteurs dans et que est diagonalisable, il faut que . De même, on peut écrire le polynôme caractéristique de comme . De plus, comme ce polynôme doit être de degré , on obtient que . En combinant le tout, on a . Ainsi, . En particulier, on a et comme chacun de ces termes est plus grand que , on conclut que pour tout et que les multiplicités concordent.  * Bruit de soupir *    En se rappelant les matrices de l'exemple , on constate que la valeur propre avait comme multiplicité algébrique , mais une multiplicité géométrique de pour la matrice , alors que dans le cas de la matrice , on avait les multiplicités algébrique et géométrique égales à pour . On peut donc conclure que est diagonalisable, mais pas .   On constate en effet que la matrice donnée par Sage n'est pas inversible et donc que n'est pas diagonalisable.      Les points importants de cette section sont:  La notion de matrice diagonalisable ;  La formule de changement de base ;  La représentation matricielle d'une rotation dans une base orthonormée;  Les différentes propositions sur les valeurs propres d'une matrice, notamment celle qui portent sur les multiplicités des valeurs propres.   De plus, avec Sage, on a vu la commande eigenmatrix_right permettant de diagonaliser une matrice lorsque c'est possible.      Exercices   Pour chaque matrice de l'exercice , dire si la matrice est diagonalisable. Le cas échéant, calculer la cinquième puissance de la matrice.  La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .  La matrice n'est pas diagonalisable. La matrice n'est pas diagonalisable.  La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   Pour chaque matrice ci-dessous (donnée dans la base standard), déterminer l'écriture dans la base donnée. avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura .  Pour chaque matrice ci-dessous (donnée dans la base ), déterminer l'écriture dans la base standard. avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura .   On considère un cube dont les sommets sont situés aux points de coordonnées , comme celui de la figure . Donner la matrice dans la base standard pour chacune des transformations suivantes.   Des symétries du cube.   Une rotation de autour de l'axe des . C'est la matrice de rotation usuelle . Une rotation de autour de l'axe . On veut utiliser la matrice de la proposition et la formule de changement de base. Pour cela, on doit trouver une base orthonormée. On commence par trouver un ensemble de vecteurs perpendiculaires dont l'orientation est positive. On normalise ensuite les vecteurs. En se basant sur l'exemple , on prend n'importe quel vecteur dans le plan , par exemple . Afin d'orienter positivement le repère, on pose . On normalise ensuite le repère pour avoir la base ordonnée . La matrice de cette rotation dans la base est celle de l'équation .  On utilise ensuite la matrice de changement de base afin d'obtenir la représentation dans la base standard en posant et lf'on obtient .  Une rotation de autour de l'axe . De la même manière, on veut construire une base orthonormée orientée positivement et utiliser la formule du changement de base. Pour le plan perpendiculaire à la rotation, on cherche donc des vecteurs sur . On pose et . On normalise pour avoir la base ordonnée .  On utilise ensuite la matrice de changement de base afin d'obtenir la représentation dans la base standard en posant et l'on obtient .   On considère le sous-espace vectoriel de correspondant au plan ainsi que son complément orthogonal . On note par et , des bases de ces deux sous-espaces, et , une base de provenant de ces deux bases. On s'intéresse à la projection orthogonale sur la droite correspondant à . Quelle est l'écriture de la matrice correspondant à cette projection dans la base ? Puisque et sont perpendiculaires à la droite, leur projection est nulle, De plus, puisque le vecteur est sur la droite, sa projection est . On a donc . Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base, on a . On pose . Vérifier que et que , la projection orthogonale d'un vecteur sur . Puisque correspond à la somme des colonnes, on a bien que . Dans le cas général, on a . On veut maintenant déterminer la matrice de la projection orthogonale sur le plan correspondant au sous-espace . Quelle est l'écriture de la matrice correspondant à cette projection dans la base ? Puisque et sont dans le plan, leur projection respective est eux-mêmes, De plus, puisque le vecteur est sur la droite perpendiculaire au plan, sa projection est nulle. On a donc Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base on a . Finalement, on s'intéresse à la réflexion par rapport au plan. Quelle est l'écriture de la matrice correspondant à cette réflexion dans la base ?  Puisque et sont dans le plan, leur réflexion respective est eux-mêmes, De plus, puisque le vecteur est sur la droite perpendiculaire au plan, sa réflexion correspond à . On a donc  Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base on a .  On considère la matrice . C'est une matrice de rotation dans . On cherche à déterminer son axe de rotation ainsi que l'angle de la rotation. Déterminer un vecteur tel que . C'est l'axe de rotation. On pose . Pour trouver , on peut procéder de deux manières.  De l'équation , on tire . On doit donc avoir et . En prenant , on obtient un vecteur .  L'équation signifie que le vecteur cherché est un vecteur propre associé à la valeur propre . On peut donc le trouver en regardant l'espace nul de . On obtient . De ceci, on tire comme vecteur propre .  Trouver une base orthonormée de orientée positivement dont le troisième vecteur est et donner la matrice de rotation dans cette base. Une base possible est où et . Dans cette base, la matrice s'écrit On doit trouver deux vecteurs, perpendiculaires entre eux et perpendiculaires avec . La norme des vecteurs doit être égale à et le repère doit être orienté positivement. Le premier vecteur choisi est , que l'on normalisera plus tard. Celui-ci est perpendiculaire à . Pour le deuxième vecteur, on pose . On pose , la matrice contenant les vecteurs et l'on trouve son inverse avec Sage. On trouve ensuite l'écriture de dans la base .   On obtient donc, après simplification des radicaux  Déterminer l'angle de la rotation. Selon la proposition , on doit avoir et . Le seul point sur le cercle trigonométrique qui possède ces propriétés se trouve en .  On s'intéresse à nouveau à la matrice de l'exemple . Comme cette matrice possède une seule valeur propre de multiplicité géométrique égale à , elle n'est pas diagonalisable. Calculer . On a . Cette matrice est donc nilpotente d'ordre . À l'exercice , on a montré que l'espace colonne de la matrice est inclus dans l'espace nul de la matrice si le produit . En appliquant cet exercice au produit , on peut affirmer que . Plus particulièrement, l'équation possède des solutions si est un vecteur propre de . Trouver un vecteur qui satisfait cette équation pour , le vecteur propre trouvé à l'exemple . On a . Une solution à ce système est . Donner l'écriture de dans la base . On pose . On a alors et La matrice obtenue dans la dernière partie de cet exercice est appelée la forme de Jordan de . C'est une forme de généralisation des matrices diagonales lorsque le nombre de vecteurs propres est insuffisant pour diagonaliser la matrice.  Démontrer les formules de changement de base dans le cas général de la proposition .  Soit , la matrice de changement de base contenant les vecteurs de et la matrice de changement de base contenant les vecteurs de . Selon la proposition , on obtient la représentation de dans la base standard à l'aide de l'équation . De plus, toujours selon la propriété , on peut obtenir à partir de à l'aide de la formule . On pose . On remarque que et donc que . Puisque , on isole dans l'équation pour trouver .   Dans cet exercice, on veut démontrer la proposition Montrer que si est semblable à , alors . Soit , deux matrices semblables. Il existe donc une matrice inversible pour laquelle on a . On a . Montrer que si est semblable à , alors est semblable à . Utiliser le fait que pour factoriser .  Soit , deux matrices semblables. Il existe donc une matrice inversible pour laquelle on a . On peut factoriser comme suit: . Les matrices sont donc semblables.  Démontrer la proposition . Puisque est semblable à lorsque est semblable à , on conclut de la première partie de cet exercice que . Ainsi, le polynôme caractéristique de est le même que celui de et les valeurs propres seront les mêmes.  Déterminer si les énoncés suivants sont vrais ou faux. Lorsque vrais, donner une démonstration et lorsque faux, donner un contrexemple. Si est semblable à , alors est semblable à . Vrai Si est semblable à , il existe une matrice inversible pour laquelle . On a alors . Les matrices sont donc semblables avec la même matrice . Si est semblable à , alors est semblable à . La proposition dit que deux matrices semblables ont les mêmes valeurs propres. La proposition dit que est une valeur propre de si est une valeur propre de . Est-il possible de trouver des matrices telles que les valeurs propres de sont les mêmes, mais pas celles de ? Faux Inspiré par l'indice, on tente de trouver des matrices avec des valeurs propres différentes, mais qui ont les mêmes valeurs propres lorsque prises à la puissance deux. Puisque sera une valeur propre de , on peut penser à trouver une matrice dont l'une des valeurs propres est négative et une matrice qui a comme valeur propre la valeur absolue de cette valeur propre et telles que le carré de ces matrices donne la même matrice. On peut penser à une réflexion et une rotation de . Pour la réflexion, on aura deux valeurs propres, et et, pour la rotation, il n'y a qu'une valeur propre double valant . Dans les deux cas, le carré de ces matrices donne l'identité. Ces puissances sont donc semblables. Plus précisément, on pose et où la réflexion est par rapport à la droite . Comme , les carrés de ces matrices sont semblables. Soit , une matrice inversible. Si est semblable à , on doit avoir . De cette égalité, on tire que et . La matrice est donc . Cette matrice ne peut toutefois pas être inversible, son déterminant étant négatif. Par conséquent, et ne sont pas semblables. Si est inversible et semblable à , alors est inversible. Vrai Puisque est semblable à , on peut écrire . Comme sont inversibles, la proposition garantit que est inversible.  Soit , une matrice telle que . Montrer que les seules valeurs propres possibles pour sont ou . On sait, par la proposition , que si est une valeur propre de , alors est une valeur propre de . Puisque ces deux matrices sont égales, on doit avoir pour toutes les valeurs propres, ce qui entraine que et que les seules valeurs possibles sont ou . Montrer que est diagonalisable. Utiliser l'exercice . À l'exercice , on a montré que si , alors . Ceci correspond donc au vecteur propre associé à la valeur propre . De plus, l'espace nul, caractérisé par les vecteurs tels que , est composé des vecteurs propres associés à la valeur propre . Finalement, toujours à l'exercice , on a montré que . Cela signifie qu'il y a vecteurs propres indépendants et que est diagonalisable.  Soit , des matrices de tailles . On suppose que et sont diagonalisables et qu'elles possèdent les mêmes vecteurs propres. Montrer que les matrices commutent, c'est-à-dire que . Deux matrices diagonales commutent toujours. Puisque est diagonalisable, il existe une matrice telle que où est la matrice contenant les vecteurs propres de (et ) dans ses colonnes. De même, il existe une matrice pour laquelle . On a alors . On suppose maintenant que possède valeurs propres réelles distinctes et que . Montrer que est diagonalisable. Montrer que tous les vecteurs propres de sont des vecteurs propres de . Utiliser le fait que les espaces propres de sont de dimension . Soit , un vecteur propre de . D'un côté, on a , ce qui signifie que est un vecteur propre de associé à . Puisque possède valeurs propres distinctes, les espaces propres associés à chaque valeur propre sont alors de dimension . Il découle de ce fait que doit être un multiple de et que , faisant de un vecteur propre de .  Comme était arbitraire, on conclut que tous les vecteurs propres de sont des vecteurs propres de . Comme il y en a , on peut alors affirmer qu'il y a suffisamment de vecteurs propres pour diagonaliser .   Soit , une matrice inversible (de vecteurs propres). On pose l'ensemble des matrices diagonalisable par . Montrer que cet ensemble est un sous-espace vectoriel. Soit et . D'un côté, on a . Le sous-ensemble est donc fermé sous l'addition. De plus, . Comme la matrice est aussi diagonale, le sous-ensemble est fermé pour la multiplication par un scalaire. On a donc un sous-espace vectoriel.   Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.  Fibonacci, prise 2 On poursuit l'exploration entamée à l'exercice de la suite de Fibonacci en regardant comment la diagonalisation peut aider à comprendre cette suite.  À la partie , on a proposé une manière de calculer en décomposant le vecteur initial comme une combinaison linéaire des vecteurs propres. Ceci avait été fait dans le but d'éviter d'avoir à calculer les grandes puissances de la matrice . Par contre, avec la diagonalisation, le calcul des puissances n'est plus très difficile. Calculer et à partir de celle-ci, . Vérifier que .     Le code de la solution   l1=(1-sqrt(5))\/2 l2=(1+sqrt(5))\/2 v1=vector([l1,1]) v2=vector([l2,1]) x0=vector([0,1]) P=column_matrix(RDF,[v1,v2]) Pinv=P.inverse() D=matrix(RDF,[[l1,0],[0,l2]]) show(D^100) show(P*D^100*Pinv) show(P*D^100*Pinv*x0)        "
},
{
  "id": "def-diagonalisable",
  "level": "2",
  "url": "sec-diagonalisation.html#def-diagonalisable",
  "type": "Définition",
  "number": "6.2.1",
  "title": "Matrice diagonalisable.",
  "body": " Matrice diagonalisable  Soit , une matrice carrée. Si la matrice possède vecteurs propres indépendants, alors il existe des matrices avec une matrice diagonale telles que . On dit alors que est diagonalisable.  La matrice contient dans ses colonnes les vecteurs propres et la matrice a pour éléments de sa diagonale les valeurs propres associées aux vecteurs propres, dans le même ordre que ceux-ci apparaissent dans .  "
},
{
  "id": "ex-vecvalpropresdiago",
  "level": "2",
  "url": "sec-diagonalisation.html#ex-vecvalpropresdiago",
  "type": "Exemple",
  "number": "6.2.2",
  "title": "Diagonalisation de matrices.",
  "body": " Diagonalisation de matrices  On reprend les matrices de l'exemple . Parmi celles-ci, les matrices avaient un nombre suffisant de vecteurs propres pour former une base. On s'intéresse donc à diagonaliser ces matrices.  La matrice a pour valeurs propres et et comme vecteurs propres associés à ces valeurs propres et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.     La matrice a pour valeurs propres et et comme vecteurs propres associés à ces valeurs propres , et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.     La matrice a pour valeurs propres et . Pour la valeur propre , on a trouvé , alors que pour la valeur propre , on a trouvé deux vecteurs propres indépendants en et . On pose donc et . De cela, on devrait obtenir . On vérifie avec Sage.    "
},
{
  "id": "fig-vecpropre3",
  "level": "2",
  "url": "sec-diagonalisation.html#fig-vecpropre3",
  "type": "Figure",
  "number": "6.2.3",
  "title": "",
  "body": " La transformation   Un parallélogramme engendré par les deux vecteurs propres de la matrices A est illustré avec son image, qui est un étirement de facteur deux dans la direction de l'un des vecteurs propres, l'autre direction étant inchangée.    "
},
{
  "id": "fig-vecpropre4",
  "level": "2",
  "url": "sec-diagonalisation.html#fig-vecpropre4",
  "type": "Figure",
  "number": "6.2.4",
  "title": "",
  "body": " La transformation   Un parallélépipède engendré par les vecteurs propres de la matrices C est illustré avec son image par cette matrice. Dans ce cas, l'image est en fait un parallélograme dont les côtés sont parallèles aux deux premiers vecteurs propres.    "
},
{
  "id": "fig-vecpropre5",
  "level": "2",
  "url": "sec-diagonalisation.html#fig-vecpropre5",
  "type": "Figure",
  "number": "6.2.5",
  "title": "",
  "body": " La transformation   Un parallélépipède engendré par les vecteurs propres de la matrices F est illustré avec son image par cette matrice. L'image est un parallélépipiède se trouvant à être la réflexion du parallélépipède initial selon le premier vecteur.    "
},
{
  "id": "example-125",
  "level": "2",
  "url": "sec-diagonalisation.html#example-125",
  "type": "Exemple",
  "number": "6.2.6",
  "title": "Puissances de matrices.",
  "body": " Puissances de matrices   Pour chacune des matrices diagonalisables de l'exemple , on souhaite calculer la dixième puissance. On rappelle que la diagonalisation a été trouvée à l'exemple .   Pour première matrice, on a et donc   Pour la deuxième matrice, on a où l'inverse a été calculé par Sage. On a alors .  Enfin, pour la dernière matrice, on a où l'inverse a été calculé par Sage. On a alors . En réfléchissant sur la nature géométrique de la matrice , on aurait pu trouver encore plus facilement la dixième puissance. En effet, puisqu'elle consiste en une réflexion selon le plan perpendiculaire à et laisse les directions et fixes, les puissances de devraient alterner entre et l'identité .  "
},
{
  "id": "computation-39",
  "level": "2",
  "url": "sec-diagonalisation.html#computation-39",
  "type": "Calcul",
  "number": "6.2.7",
  "title": "La diagonalisation sur Sage.",
  "body": " La diagonalisation sur Sage  Sage a une commande appelée eigenmatrix_right qui retourne une paire de matrices, les matrices et , lorsque la matrice est diagonalisable. On peut aussi vérifier si une matrice est diagonalisable avec la commande , qui fonctionne si l'on ajoute l'option QQ à la matrice (ou RR , RDF ). On regarde les matrices de l'exemple et lorsque diagonalisable, on fait sortir les deux matrices afin de comparer avec celles que l'on a obtenues à l'exemple .        On remarque que lorsque la matrice n'est pas diagonalisable, la commande eigenmatrix_right retourne quand même la matrice des valeurs propres et une matrice contenant des vecteurs propres indépendants et des colonnes de zéros pour la compléter.  "
},
{
  "id": "definition-55",
  "level": "2",
  "url": "sec-diagonalisation.html#definition-55",
  "type": "Définition",
  "number": "6.2.8",
  "title": "Matrices semblables.",
  "body": "Matrices semblables  Soit et , deux matrices pour lesquelles il existe une matrice inversible telle que . On dit que et sont semblables.  "
},
{
  "id": "example-126",
  "level": "2",
  "url": "sec-diagonalisation.html#example-126",
  "type": "Exemple",
  "number": "6.2.9",
  "title": "Déterminer si des matrices sont semblables.",
  "body": " Déterminer si des matrices sont semblables  On cherche à savoir si la matrice est semblable à l'une des matrices ou .  Pour la matrice , on cherche une matrice inversible telle que . On pose et l'on réécrit . On trouve, à partir de cette égalité matricielle, un système à quatre équations et quatre inconnues: . On résout ce système avec Sage.   Ce système contient deux variables libres en . Il y a donc une infinité de solutions. On doit seulement s'assurer que est inversible, alors il faut que . En prenant , on trouve , qui est effectivement inversible et donc, et sont semblables.    Pour la matrice , on cherche aussi une matrice inversible telle que . On pose et l'on réécrit . On trouve, à partir de cette égalité matricielle, un système à quatre équations et quatre inconnues: . On résout ce système avec Sage.   Il n'y a qu'une solution à ce système, soit lorsque . Cette solution ne peut toutefois pas être valide puisque la matrice ne serait pas inversible. Les matrices ne sont donc pas semblables.   "
},
{
  "id": "prop-changementdebase",
  "level": "2",
  "url": "sec-diagonalisation.html#prop-changementdebase",
  "type": "Proposition",
  "number": "6.2.10",
  "title": "Formule de changement de base.",
  "body": " Formule de changement de base  Soit , une matrice et , sa représentation dans une base ordonnée et soit , la matrice contenant les vecteurs de dans ses colonnes. Alors .  Puisque est une base, la matrice est inversible, on obtient alors des formules pour les représentations de : . La matrice est appelée la matrice de changement de base ou encore la matrice de passage .   On analyse les colonnes de chacun des produits et . Pour , chaque colonne est donnée par le produit de la matrice avec les vecteurs de la base , soit les colonnes de . Ces colonnes sont donc les images des vecteurs de la base par représentées dans la base usuelle. On peut certainement convertir ces vecteurs dans la base , c'est-à-dire qu'il existe tels que .  D'un autre côté, la colonne de la matrice est précisément l'image du vecteur et est donc (cette fois dans la base usuelle). On a alors . Ainsi, les colonnes de sont les mêmes que les colonnes de .  "
},
{
  "id": "example-127",
  "level": "2",
  "url": "sec-diagonalisation.html#example-127",
  "type": "Exemple",
  "number": "6.2.11",
  "title": "De la base standard à une base <span class=\"process-math\">\\(\\mathcal{B}\\)<\/span>.",
  "body": " De la base standard à une base  On veut convertir la matrice dans la base .  On pose . Selon la proposition , la formule pour écrire dans la base est . On utilise Sage pour les calculs.   On a donc . Les colonnes de correspondent à l'écriture des vecteurs dans la base .   "
},
{
  "id": "example-128",
  "level": "2",
  "url": "sec-diagonalisation.html#example-128",
  "type": "Exemple",
  "number": "6.2.12",
  "title": "D’une base <span class=\"process-math\">\\(\\mathcal{B}\\)<\/span> à la base standard.",
  "body": "D'une base à la base standard  Soit , où . On cherche la représentation de ces vecteurs dans la base standard.  On procède comme dans l'exemple précédent, avec une matrice et une matrice de passage . Selon la proposition , la formule pour obtenir la matrice est . On utilise Sage pour les calculs.   La matrice dans la base usuelle est donc .   "
},
{
  "id": "prop-rotR3B",
  "level": "2",
  "url": "sec-diagonalisation.html#prop-rotR3B",
  "type": "Proposition",
  "number": "6.2.13",
  "title": "Matrice de rotation dans une base orthonormée.",
  "body": " Matrice de rotation dans une base orthonormée  Soit , une base de telle que . On dit que la base est orthonormée, c'est-à-dire que les vecteurs sont orthogonaux deux à deux et ont une norme égale à , et qu'elle est orientée positivement. Dans ce cas, la matrice de rotation autour de dans la base est .  Puisque est l'axe de rotation, on doit avoir pour que et donc, la troisième colonne de la matrice est déterminée.  Le même dessin que celui de la figure peut être utilisé pour voir que le vecteur sera déplacé à et que sera envoyé sur . On obtient alors les deux premières colonnes.   "
},
{
  "id": "ex-rotR3B",
  "level": "2",
  "url": "sec-diagonalisation.html#ex-rotR3B",
  "type": "Exemple",
  "number": "6.2.14",
  "title": "Matrice de rotation dans <span class=\"process-math\">\\(\\mathbb{R}^3\\)<\/span>.",
  "body": "Matrice de rotation dans  On revient sur l'exemple dans lequel on a trouvé la matrice représentant une rotation autour de l'axe de . On veut utiliser une matrice de changement de base afin de retrouve l'expression de cette transformation (dans la base standard).  On doit trouver une base qui va satisfaire les conditions de la proposition . On prend , l'axe de rotation. Pour avoir un vecteur perpendiculaire, il suffit de prendre un vecteur qui satisfait l'équation . On opte pour . Pour le second vecteur, on doit s'assurer qu'il sera perpendiculaire à et à et que le repère sera orienté positivement. On sait que serait orienté positivement selon l'exercice . On aurait donc que le repère serait orienté négativement et finalement, que . On pose donc .   En fait, ces vecteurs ne sont pas de norme , alors on doit les normaliser avant de pouvoir utiliser la formule . On utilise ensuite la matrice de passage formé des vecteurs unitaires pour déterminer la matrice dans la base usuelle.    "
},
{
  "id": "prop-changementdebasegeneral",
  "level": "2",
  "url": "sec-diagonalisation.html#prop-changementdebasegeneral",
  "type": "Proposition",
  "number": "6.2.15",
  "title": "Formule générale pour le changement de base.",
  "body": " Formule générale pour le changement de base  Soit , deux bases ordonnées et soit , les matrices contenant les vecteurs de ces bases dans leurs colonnes. Soit une matrice, , sa représentation dans la base et , celle dans la base . Alors .  où est la matrice de changement de base de à et est la matrice de changement de base de à .   Voir l'exercice .  "
},
{
  "id": "example-130",
  "level": "2",
  "url": "sec-diagonalisation.html#example-130",
  "type": "Exemple",
  "number": "6.2.16",
  "title": "Changement de base générale.",
  "body": " Changement de base générale  Soit et , deux bases de et la matrice d'une transformation linéaire représentée en base . On cherche la représentation de en base .  On pose et . On a alors , Ce qui donne comme matrice de passage . L'inverse de cette matrice est . En utilisant la formule de changement de base de la proposition , on obtient finalement .  "
},
{
  "id": "prop-similvalpropres",
  "level": "2",
  "url": "sec-diagonalisation.html#prop-similvalpropres",
  "type": "Proposition",
  "number": "6.2.17",
  "title": "Les matrices semblables ont les mêmes valeurs propres.",
  "body": " Les matrices semblables ont les mêmes valeurs propres   Si et sont semblables, elles ont le même polynôme caractéristique. En particulier, elles ont les mêmes valeurs propres.   Voir l'exercice .  "
},
{
  "id": "proposition-78",
  "level": "2",
  "url": "sec-diagonalisation.html#proposition-78",
  "type": "Proposition",
  "number": "6.2.18",
  "title": "Une matrice possédant <span class=\"process-math\">\\(n\\)<\/span> valeurs propres est diagonalisable.",
  "body": " Une matrice possédant valeurs propres est diagonalisable  Soit , une matrice qui possède valeurs propres distinctes. Alors est diagonalisable.  Selon la proposition , les vecteurs propres associés à des valeurs propres distinctes sont indépendants. Dans ce cas, la matrice existe et est inversible. Dans la base des vecteurs propres, la matrice est égale à une matrice diagonale où les entrées sont les valeurs propres. On a donc selon la formule du changement de base.  "
},
{
  "id": "lem-multgeoalg",
  "level": "2",
  "url": "sec-diagonalisation.html#lem-multgeoalg",
  "type": "Lemme",
  "number": "6.2.19",
  "title": "La multiplicité géométrique est plus petite ou égale à la multiplicité algébrique.",
  "body": " La multiplicité géométrique est plus petite ou égale à la multiplicité algébrique   Soit , une matrice carrée et , une valeur propre de multiplicité géométrique et de multiplicité algébrique . Alors .   Par définition, la multiplicité géométrique est la dimension de l'espace propre et celui-ci contient au moins un vecteur non nul, donc . Soit , une base de cet espace propre. Il est toujours possible d'étendre cette base en ajoutant des vecteurs indépendants pour former une base de . Soit , une base possible. À quoi ressemble la matrice dans la base ?  Les premières colonnes correspondent aux vecteurs propres associés à , qui sont les premiers vecteurs de la base. En base , l'écriture d'un vecteur est équivalente à celle du vecteur si et , signifiant que la première partie de est équivalente à la première partie de . Pour le reste, on ne sait pas en quoi consiste la matrice, mais on peut l'écrire de la manière suivante , où est une matrice quelconque, la matrice nulle est de taille et est une matrice carrée . Selon la proposition , les matrices et ont le même polynôme caractéristique puisqu'elles sont semblables. En développant avec les cofacteurs la matrice , on trouve .  On voit donc que la multiplicité algébrique de est d'au moins , puisque le facteur apparait dans le polynôme caractéristique. On a donc .   "
},
{
  "id": "lem-sommepropre",
  "level": "2",
  "url": "sec-diagonalisation.html#lem-sommepropre",
  "type": "Lemme",
  "number": "6.2.20",
  "title": "Une combinaison spéciale de vecteurs.",
  "body": " Une combinaison spéciale de vecteurs  Soit , une matrice et des valeurs propres distinctes. Soit , des vecteurs dans les espaces propres respectifs des valeurs propres. Si , alors .  On suppose qu'il y a des vecteurs non nuls. On peut simplement éliminer tous les vecteurs nuls de l'équation et obtenir une équation similaire, alors on suppose simplement qu'on a un ensemble de vecteurs non nuls où chaque vecteur est un des vecteurs dans . Si ces vecteurs sont non nuls et dans un espace propre, ce sont donc des vecteurs propres. Selon la proposition , on ne peut pas avoir une combinaison linéaire de vecteurs propres associés à des valeurs propres différentes qui donne le vecteur nul, car ces vecteurs devraient être indépendants. Les vecteurs ne peuvent donc pas être non nuls. On conclut alors que tous les vecteurs sont en effet nuls.  "
},
{
  "id": "prop-matdiagomult",
  "level": "2",
  "url": "sec-diagonalisation.html#prop-matdiagomult",
  "type": "Proposition",
  "number": "6.2.21",
  "title": "Une matrice dont les multiplicités géométriques sont les mêmes que les multiplicités algébriques est diagonalisable.",
  "body": " Une matrice dont les multiplicités géométriques sont les mêmes que les multiplicités algébriques est diagonalisable  Soit , une matrice et soit , ses valeurs propres distinctes. Alors est diagonalisable si et seulement si les multiplicités géométriques des valeurs propres sont les mêmes que les multiplicités algébriques et somment à .  La condition que les multiplicités somment à pourra être enlevée en considérant les nombres complexes.    On suppose, dans un premier temps, que pour toutes les valeurs propres et que la somme de ces multiplicités donne . Pour chaque valeur propre, il existe une base de vecteurs propres indépendants. On considère l'ensemble . Cet ensemble contient vecteurs propres.  On suppose qu'on a une combinaison linéaire de tous ces vecteurs qui donne le vecteur nul. On peut écrire cette combinaison de la manière suivante: . Pour chaque , on pose . Chacun de ces vecteurs appartient à l'espace propre de . La combinaison linéaire des vecteurs dans devient donc . En vertu du lemme , on doit avoir pour tous les . Ceci entraine à son tour que tous les coefficients sont nuls car les vecteurs forment une base. Ainsi, l'ensemble est indépendant et, puisqu'il est composé de vecteurs dans un espace de dimension , il forme une base. En posant la matrice contenant ces vecteurs dans ses colonnes et la matrice des valeurs propres associées, dans le même ordre d'apparition que les vecteurs dans , on a bel et bien . Ainsi, est diagonalisable.  Dans un deuxième temps, on suppose que est diagonalisable. On veut montrer que les multiplicités géométriques et algébriques concordent et somment à .  Soit , une base de vecteurs propres pour l'espace vectoriel. On note l'intersection de cette base avec l'espace propre associé à . Soit , le nombre de vecteurs dans . On a alors puisque est de dimension et que les vecteurs dans sont indépendants (on ne peut avoir plus de vecteurs indépendants que la dimension du sous-espace, selon la proposition ). De plus, selon le lemme , on a . Comme il y a vecteurs dans et que est diagonalisable, il faut que . De même, on peut écrire le polynôme caractéristique de comme . De plus, comme ce polynôme doit être de degré , on obtient que . En combinant le tout, on a . Ainsi, . En particulier, on a et comme chacun de ces termes est plus grand que , on conclut que pour tout et que les multiplicités concordent.  * Bruit de soupir *   "
},
{
  "id": "exercise-344",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-344",
  "type": "Exercice",
  "number": "6.2.4.1",
  "title": "",
  "body": "Pour chaque matrice de l'exercice , dire si la matrice est diagonalisable. Le cas échéant, calculer la cinquième puissance de la matrice.  La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .  La matrice n'est pas diagonalisable. La matrice n'est pas diagonalisable.  La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .   La matrice est diagonalisable avec . Pour la cinquième puissance, on trouve .  "
},
{
  "id": "exercise-345",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-345",
  "type": "Exercice",
  "number": "6.2.4.2",
  "title": "",
  "body": "Pour chaque matrice ci-dessous (donnée dans la base standard), déterminer l'écriture dans la base donnée. avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . "
},
{
  "id": "exercise-346",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-346",
  "type": "Exercice",
  "number": "6.2.4.3",
  "title": "",
  "body": "Pour chaque matrice ci-dessous (donnée dans la base ), déterminer l'écriture dans la base standard. avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . avec On pose . On a alors . Selon la formule de changement de base, on aura . "
},
{
  "id": "exercise-347",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-347",
  "type": "Exercice",
  "number": "6.2.4.4",
  "title": "",
  "body": " On considère un cube dont les sommets sont situés aux points de coordonnées , comme celui de la figure . Donner la matrice dans la base standard pour chacune des transformations suivantes.   Des symétries du cube.   Une rotation de autour de l'axe des . C'est la matrice de rotation usuelle . Une rotation de autour de l'axe . On veut utiliser la matrice de la proposition et la formule de changement de base. Pour cela, on doit trouver une base orthonormée. On commence par trouver un ensemble de vecteurs perpendiculaires dont l'orientation est positive. On normalise ensuite les vecteurs. En se basant sur l'exemple , on prend n'importe quel vecteur dans le plan , par exemple . Afin d'orienter positivement le repère, on pose . On normalise ensuite le repère pour avoir la base ordonnée . La matrice de cette rotation dans la base est celle de l'équation .  On utilise ensuite la matrice de changement de base afin d'obtenir la représentation dans la base standard en posant et lf'on obtient .  Une rotation de autour de l'axe . De la même manière, on veut construire une base orthonormée orientée positivement et utiliser la formule du changement de base. Pour le plan perpendiculaire à la rotation, on cherche donc des vecteurs sur . On pose et . On normalise pour avoir la base ordonnée .  On utilise ensuite la matrice de changement de base afin d'obtenir la représentation dans la base standard en posant et l'on obtient .  "
},
{
  "id": "exercise-348",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-348",
  "type": "Exercice",
  "number": "6.2.4.5",
  "title": "",
  "body": "On considère le sous-espace vectoriel de correspondant au plan ainsi que son complément orthogonal . On note par et , des bases de ces deux sous-espaces, et , une base de provenant de ces deux bases. On s'intéresse à la projection orthogonale sur la droite correspondant à . Quelle est l'écriture de la matrice correspondant à cette projection dans la base ? Puisque et sont perpendiculaires à la droite, leur projection est nulle, De plus, puisque le vecteur est sur la droite, sa projection est . On a donc . Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base, on a . On pose . Vérifier que et que , la projection orthogonale d'un vecteur sur . Puisque correspond à la somme des colonnes, on a bien que . Dans le cas général, on a . On veut maintenant déterminer la matrice de la projection orthogonale sur le plan correspondant au sous-espace . Quelle est l'écriture de la matrice correspondant à cette projection dans la base ? Puisque et sont dans le plan, leur projection respective est eux-mêmes, De plus, puisque le vecteur est sur la droite perpendiculaire au plan, sa projection est nulle. On a donc Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base on a . Finalement, on s'intéresse à la réflexion par rapport au plan. Quelle est l'écriture de la matrice correspondant à cette réflexion dans la base ?  Puisque et sont dans le plan, leur réflexion respective est eux-mêmes, De plus, puisque le vecteur est sur la droite perpendiculaire au plan, sa réflexion correspond à . On a donc  Donner la représentation de dans la base standard. On pose . Selon la formule de changement de base on a . "
},
{
  "id": "exo-rotR3axeangle",
  "level": "2",
  "url": "sec-diagonalisation.html#exo-rotR3axeangle",
  "type": "Exercice",
  "number": "6.2.4.6",
  "title": "",
  "body": "On considère la matrice . C'est une matrice de rotation dans . On cherche à déterminer son axe de rotation ainsi que l'angle de la rotation. Déterminer un vecteur tel que . C'est l'axe de rotation. On pose . Pour trouver , on peut procéder de deux manières.  De l'équation , on tire . On doit donc avoir et . En prenant , on obtient un vecteur .  L'équation signifie que le vecteur cherché est un vecteur propre associé à la valeur propre . On peut donc le trouver en regardant l'espace nul de . On obtient . De ceci, on tire comme vecteur propre .  Trouver une base orthonormée de orientée positivement dont le troisième vecteur est et donner la matrice de rotation dans cette base. Une base possible est où et . Dans cette base, la matrice s'écrit On doit trouver deux vecteurs, perpendiculaires entre eux et perpendiculaires avec . La norme des vecteurs doit être égale à et le repère doit être orienté positivement. Le premier vecteur choisi est , que l'on normalisera plus tard. Celui-ci est perpendiculaire à . Pour le deuxième vecteur, on pose . On pose , la matrice contenant les vecteurs et l'on trouve son inverse avec Sage. On trouve ensuite l'écriture de dans la base .   On obtient donc, après simplification des radicaux  Déterminer l'angle de la rotation. Selon la proposition , on doit avoir et . Le seul point sur le cercle trigonométrique qui possède ces propriétés se trouve en . "
},
{
  "id": "exercise-350",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-350",
  "type": "Exercice",
  "number": "6.2.4.7",
  "title": "",
  "body": "On s'intéresse à nouveau à la matrice de l'exemple . Comme cette matrice possède une seule valeur propre de multiplicité géométrique égale à , elle n'est pas diagonalisable. Calculer . On a . Cette matrice est donc nilpotente d'ordre . À l'exercice , on a montré que l'espace colonne de la matrice est inclus dans l'espace nul de la matrice si le produit . En appliquant cet exercice au produit , on peut affirmer que . Plus particulièrement, l'équation possède des solutions si est un vecteur propre de . Trouver un vecteur qui satisfait cette équation pour , le vecteur propre trouvé à l'exemple . On a . Une solution à ce système est . Donner l'écriture de dans la base . On pose . On a alors et La matrice obtenue dans la dernière partie de cet exercice est appelée la forme de Jordan de . C'est une forme de généralisation des matrices diagonales lorsque le nombre de vecteurs propres est insuffisant pour diagonaliser la matrice. "
},
{
  "id": "exo-changementgeneral",
  "level": "2",
  "url": "sec-diagonalisation.html#exo-changementgeneral",
  "type": "Exercice",
  "number": "6.2.4.8",
  "title": "",
  "body": "Démontrer les formules de changement de base dans le cas général de la proposition .  Soit , la matrice de changement de base contenant les vecteurs de et la matrice de changement de base contenant les vecteurs de . Selon la proposition , on obtient la représentation de dans la base standard à l'aide de l'équation . De plus, toujours selon la propriété , on peut obtenir à partir de à l'aide de la formule . On pose . On remarque que et donc que . Puisque , on isole dans l'équation pour trouver .  "
},
{
  "id": "exo-similvalpropres",
  "level": "2",
  "url": "sec-diagonalisation.html#exo-similvalpropres",
  "type": "Exercice",
  "number": "6.2.4.9",
  "title": "",
  "body": "Dans cet exercice, on veut démontrer la proposition Montrer que si est semblable à , alors . Soit , deux matrices semblables. Il existe donc une matrice inversible pour laquelle on a . On a . Montrer que si est semblable à , alors est semblable à . Utiliser le fait que pour factoriser .  Soit , deux matrices semblables. Il existe donc une matrice inversible pour laquelle on a . On peut factoriser comme suit: . Les matrices sont donc semblables.  Démontrer la proposition . Puisque est semblable à lorsque est semblable à , on conclut de la première partie de cet exercice que . Ainsi, le polynôme caractéristique de est le même que celui de et les valeurs propres seront les mêmes. "
},
{
  "id": "exercise-353",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-353",
  "type": "Exercice",
  "number": "6.2.4.10",
  "title": "",
  "body": "Déterminer si les énoncés suivants sont vrais ou faux. Lorsque vrais, donner une démonstration et lorsque faux, donner un contrexemple. Si est semblable à , alors est semblable à . Vrai Si est semblable à , il existe une matrice inversible pour laquelle . On a alors . Les matrices sont donc semblables avec la même matrice . Si est semblable à , alors est semblable à . La proposition dit que deux matrices semblables ont les mêmes valeurs propres. La proposition dit que est une valeur propre de si est une valeur propre de . Est-il possible de trouver des matrices telles que les valeurs propres de sont les mêmes, mais pas celles de ? Faux Inspiré par l'indice, on tente de trouver des matrices avec des valeurs propres différentes, mais qui ont les mêmes valeurs propres lorsque prises à la puissance deux. Puisque sera une valeur propre de , on peut penser à trouver une matrice dont l'une des valeurs propres est négative et une matrice qui a comme valeur propre la valeur absolue de cette valeur propre et telles que le carré de ces matrices donne la même matrice. On peut penser à une réflexion et une rotation de . Pour la réflexion, on aura deux valeurs propres, et et, pour la rotation, il n'y a qu'une valeur propre double valant . Dans les deux cas, le carré de ces matrices donne l'identité. Ces puissances sont donc semblables. Plus précisément, on pose et où la réflexion est par rapport à la droite . Comme , les carrés de ces matrices sont semblables. Soit , une matrice inversible. Si est semblable à , on doit avoir . De cette égalité, on tire que et . La matrice est donc . Cette matrice ne peut toutefois pas être inversible, son déterminant étant négatif. Par conséquent, et ne sont pas semblables. Si est inversible et semblable à , alors est inversible. Vrai Puisque est semblable à , on peut écrire . Comme sont inversibles, la proposition garantit que est inversible. "
},
{
  "id": "exercise-354",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-354",
  "type": "Exercice",
  "number": "6.2.4.11",
  "title": "",
  "body": "Soit , une matrice telle que . Montrer que les seules valeurs propres possibles pour sont ou . On sait, par la proposition , que si est une valeur propre de , alors est une valeur propre de . Puisque ces deux matrices sont égales, on doit avoir pour toutes les valeurs propres, ce qui entraine que et que les seules valeurs possibles sont ou . Montrer que est diagonalisable. Utiliser l'exercice . À l'exercice , on a montré que si , alors . Ceci correspond donc au vecteur propre associé à la valeur propre . De plus, l'espace nul, caractérisé par les vecteurs tels que , est composé des vecteurs propres associés à la valeur propre . Finalement, toujours à l'exercice , on a montré que . Cela signifie qu'il y a vecteurs propres indépendants et que est diagonalisable. "
},
{
  "id": "exercise-355",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-355",
  "type": "Exercice",
  "number": "6.2.4.12",
  "title": "",
  "body": "Soit , des matrices de tailles . On suppose que et sont diagonalisables et qu'elles possèdent les mêmes vecteurs propres. Montrer que les matrices commutent, c'est-à-dire que . Deux matrices diagonales commutent toujours. Puisque est diagonalisable, il existe une matrice telle que où est la matrice contenant les vecteurs propres de (et ) dans ses colonnes. De même, il existe une matrice pour laquelle . On a alors . On suppose maintenant que possède valeurs propres réelles distinctes et que . Montrer que est diagonalisable. Montrer que tous les vecteurs propres de sont des vecteurs propres de . Utiliser le fait que les espaces propres de sont de dimension . Soit , un vecteur propre de . D'un côté, on a , ce qui signifie que est un vecteur propre de associé à . Puisque possède valeurs propres distinctes, les espaces propres associés à chaque valeur propre sont alors de dimension . Il découle de ce fait que doit être un multiple de et que , faisant de un vecteur propre de .  Comme était arbitraire, on conclut que tous les vecteurs propres de sont des vecteurs propres de . Comme il y en a , on peut alors affirmer qu'il y a suffisamment de vecteurs propres pour diagonaliser .  "
},
{
  "id": "exercise-356",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-356",
  "type": "Exercice",
  "number": "6.2.4.13",
  "title": "",
  "body": "Soit , une matrice inversible (de vecteurs propres). On pose l'ensemble des matrices diagonalisable par . Montrer que cet ensemble est un sous-espace vectoriel. Soit et . D'un côté, on a . Le sous-ensemble est donc fermé sous l'addition. De plus, . Comme la matrice est aussi diagonale, le sous-ensemble est fermé pour la multiplication par un scalaire. On a donc un sous-espace vectoriel. "
},
{
  "id": "exercise-357",
  "level": "2",
  "url": "sec-diagonalisation.html#exercise-357",
  "type": "Exercice",
  "number": "6.2.4.14",
  "title": "Fibonacci, prise 2.",
  "body": "Fibonacci, prise 2 On poursuit l'exploration entamée à l'exercice de la suite de Fibonacci en regardant comment la diagonalisation peut aider à comprendre cette suite.  À la partie , on a proposé une manière de calculer en décomposant le vecteur initial comme une combinaison linéaire des vecteurs propres. Ceci avait été fait dans le but d'éviter d'avoir à calculer les grandes puissances de la matrice . Par contre, avec la diagonalisation, le calcul des puissances n'est plus très difficile. Calculer et à partir de celle-ci, . Vérifier que .     Le code de la solution   l1=(1-sqrt(5))\/2 l2=(1+sqrt(5))\/2 v1=vector([l1,1]) v2=vector([l2,1]) x0=vector([0,1]) P=column_matrix(RDF,[v1,v2]) Pinv=P.inverse() D=matrix(RDF,[[l1,0],[0,l2]]) show(D^100) show(P*D^100*Pinv) show(P*D^100*Pinv*x0)    "
},
{
  "id": "sec-propreslabos",
  "level": "1",
  "url": "sec-propreslabos.html",
  "type": "Section",
  "number": "6.3",
  "title": "Activités et laboratoires",
  "body": "  Activités et laboratoires    Dans cette section, on regarde des activités et des laboratoires en lien avec des concepts présentés dans le chapitre.    L'algorithme PageRank   En 1998, Sergey Brin et Larry Page ont révolutionné le monde de la recherche sur le web en développant un algorithme appelé PageRank, qui mena à la création de la compagnie Google. Le fonctionnement est simple, l'algorithme retourne la probabilité qu'un utilisateur qui se promène au hasard sur le web clique sur une certaine page.  On considère un modèle simplifié d'internet. La figure illustre un graphe dont les sommets peuvent être vus comme étant des pages web et les arêtes comme des liens d'une page vers un autre. Ce web simplifié contient donc trois pages, nommées respectivement et . À partir de la page , on peut aller vers la page ou la page , à partir de la page , on peut aller vers la page ou la page , mais à partir de la page , on ne peut qu'aller vers la page .   Une version simplifiée du web   Un graphe à trois sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un et deux, le sommet un pointe vers les sommets zéro et deux et le sommet deux ne pointe que vers le sommet un.     Pour chaque page, on associe la valeur de la page en considérant la proportion de liens pointant vers cette page en provenance de chaque sommet. Par exemple, pour la page , la valeur associée est puisque le seul lien pointant vers provient de et que cette dernière possède deux liens sortants. La valeur de est et celle de est .  Le vecteur PageRank est le vecteur .   On regarde maintenant comment les valeurs sont calculées. On reconnait à partir des trois équations pour qu'on peut former un système d'équations linéaires. Trouver une matrice telle que . On appelle cette matrice la matrice Google. Par construction, cette matrice a pour valeur propre . La direction invariante associée à cette valeur propre est importante. C'est le vecteur des valeurs recherchées. Puisqu'on veut que ce vecteur soit une proportion, on ajoute la condition additionnelle que . Trouver le vecteur des valeurs pour le web hypothétique décrit par la figure .   Quelle page parmi les trois a la plus grande valeur? C'est cette page qui sortirait en premier lors d'une recherche Google sur ce petit web.  Trouver la page ayant la plus grande valeur dans le web hypothétique décrit par la figure .   Un graphe à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un et deux, le sommet un pointe vers les sommets zéro, trois et cinq, le sommet deux pointe vers les sommets trois et cinq, le sommet trois pointe vers les sommets zéro et deux, le sommet quatre pointe vers les sommets zéro et trois et le sommet cinq pointe vers le sommet zéro et quatre.       Dans la réalité, il serait très couteux de calculer le vecteur propre de la matrice de Google, puisque le véritable web contient près de deux-milliards de sites web En date de 2022 , qui contiennent chacun plusieurs pages. Échelonner une telle matrice est impensable. On s'intéresse à la position d'un utilisateur après clics qui cliquerait sur les liens de manières aléatoires. Par exemple, dans le web hypothétique de la figure , avec la page de départ , si l'on pose , alors les chances de se retrouver sur les pages après un clic sont données par les entrées du vecteur . En général, les chances après clics sont données par .  Calculer les probabilités de se retrouver sur les pages après clics.   Calculer les probabilités de se retrouver sur les pages après clics pour le web hypothétique de la figure .  Calculer pour les deux matrices de Google des webs hypothétiques. Que peut-on remarquer?  En général, Google va calculer une grande puissance de sa matrice pour retourner les pages avec le plus de valeurs, car cela est moins couteux que de trouver le vecteur propre. On peut montrer que sous certaines conditions sur , les colonnes de convergent toujours vers le vecteur propre recherché lorsque tend vers l'infini.  Considérer maintenant le web hypothétique illustré par la figure . Quelle prédiction peut être faite pour les pages et ?   Un autre graphe à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un, deux et trois, le sommet un pointe vers les sommets deux et trois, le sommet deux pointe vers les sommets zéro, un, trois et quatre, le sommet trois pointe vers le sommet quatre, le sommet quatre pointe vers les sommets trois et cinq et le sommet cinq pointe vers le sommet trois et quatre.      Vérifier l'hypothèse en calculant le vecteur propre de la matrice de Google et en le normalisant pour que les entrées somment à .  Calculer et vérifier à nouveau ce qui a été observé à la partie .  Une matrice comme celle du web hypothétique de la figure est problématique car, à partir d'une certaine puissance, des entrées de la matrice sont toujours nulles et il est impossible de retourner à ces pages. En regardant plus attentivement le graphe, on constate que lorsqu'on entre dans l'une des pages , il est impossible d'en ressortir.  Google contourne ce problème en modifiant légèrement sa matrice . En fait, il utilise une matrice définie à partir de la matrice et d'une matrice qui, pour un web à pages serait égale à . Dans cette matrice, toutes les pages ont la même chance d'être visitées, à partir de n'importe quelle autre page, incluant la page sur laquelle on se trouve déjà. L'équation pour la matrice est où . La valeur de utilisée par Google n'est pas connue. Pour la suite, on utilisera .  En prenant à nouveau la situation de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?  Répéter avec le web hypothétique de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?  Répéter avec le web hypothétique de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?   On peut généraliser le concept où, à partir de certaines pages, il est plus probable d'aller vers une page qu'une autre. Graphiquement, ceci est représenté en donnant un poids aux arêtes reliant les sommets du graphe. On s'assure que la somme des poids sortant d'un sommet donne . En quelque sorte, le poids pourrait représenter la proportion des liens sortant du sommet et allant vers le sommet . Analyser le graphe de la figure , représentant une modification du web hypothétique de la figure .   Une version pondérée d'un web hypothétique à trois sommets   Un graphe à trois sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids un sur cinq et vers le sommet deux avec poids quatre sur cinq. Le sommet un pointe vers le sommet zéro avec poids un sur trois et vers le sommet deux avec poids deux sur trois. Le sommet deux ne pointe que vers le sommet un, avec poids un.      Répéter avec la modifification du web hypothétique de la figure , illustrée à la figure suivante.   Une version pondérée d'un web hypothétique à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids un sur trois et vers le sommet deux avec poids deux sur trois. Le sommet un pointe vers le sommet zéro avec poids un sur quatre, vers le sommet trois avec poids un sur deux et vers le sommet cinq avec poids un sur quatre. Le sommet deux pointe vers le sommet trois avec poids trois sur quatre et vers le sommet cinq avec poids 1\/4. Le sommet trois pointe vers le sommet zéro avec poids trois sur cinq et vers le sommet deux avec poids deux sur cinq. Le sommet quatre pointe vers le sommet zéro avec poids un sur trois et vers le sommet trois avec poids deux sur trois. Le sommet cinq pointe vers le sommet zéro et quatre, chacun avec poids un sur deux.      Répéter avec la modification du web hypothétique de la figure , illustrée à la figure suivante.   Une modification d'un autre web hypothétique à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids une demi, vers le sommet deux avec poids un tiers et vers le sommet trois avec poids un sur six. Le sommet un pointe vers le sommet deux avec poids trois sur sept et vers le sommet trois avec poirds quatre sur sept. Le sommet deux pointe vers le sommet zéro avec poids deux sur cinq, vers le sommet un avec poids un sur quatre, vers le sommet trois avec poids un sur trois et vers le sommet quatre avec poids un sur soixante. Le sommet trois pointe vers le sommet quatre avec poids 1, le sommet quatre pointe vers le sommet trois avec poids un sur six et vers le sommet cinq avec poids cinq sur six. Finalement, le sommet cinq pointe vers le sommet trois avec poids sept sur neuf et vers le sommet quatre avec poids deux sur neuf.       "
},
{
  "id": "project-6",
  "level": "2",
  "url": "sec-propreslabos.html#project-6",
  "type": "Projet",
  "number": "6.3.1",
  "title": "L’algorithme PageRank.",
  "body": " L'algorithme PageRank   En 1998, Sergey Brin et Larry Page ont révolutionné le monde de la recherche sur le web en développant un algorithme appelé PageRank, qui mena à la création de la compagnie Google. Le fonctionnement est simple, l'algorithme retourne la probabilité qu'un utilisateur qui se promène au hasard sur le web clique sur une certaine page.  On considère un modèle simplifié d'internet. La figure illustre un graphe dont les sommets peuvent être vus comme étant des pages web et les arêtes comme des liens d'une page vers un autre. Ce web simplifié contient donc trois pages, nommées respectivement et . À partir de la page , on peut aller vers la page ou la page , à partir de la page , on peut aller vers la page ou la page , mais à partir de la page , on ne peut qu'aller vers la page .   Une version simplifiée du web   Un graphe à trois sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un et deux, le sommet un pointe vers les sommets zéro et deux et le sommet deux ne pointe que vers le sommet un.     Pour chaque page, on associe la valeur de la page en considérant la proportion de liens pointant vers cette page en provenance de chaque sommet. Par exemple, pour la page , la valeur associée est puisque le seul lien pointant vers provient de et que cette dernière possède deux liens sortants. La valeur de est et celle de est .  Le vecteur PageRank est le vecteur .   On regarde maintenant comment les valeurs sont calculées. On reconnait à partir des trois équations pour qu'on peut former un système d'équations linéaires. Trouver une matrice telle que . On appelle cette matrice la matrice Google. Par construction, cette matrice a pour valeur propre . La direction invariante associée à cette valeur propre est importante. C'est le vecteur des valeurs recherchées. Puisqu'on veut que ce vecteur soit une proportion, on ajoute la condition additionnelle que . Trouver le vecteur des valeurs pour le web hypothétique décrit par la figure .   Quelle page parmi les trois a la plus grande valeur? C'est cette page qui sortirait en premier lors d'une recherche Google sur ce petit web.  Trouver la page ayant la plus grande valeur dans le web hypothétique décrit par la figure .   Un graphe à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un et deux, le sommet un pointe vers les sommets zéro, trois et cinq, le sommet deux pointe vers les sommets trois et cinq, le sommet trois pointe vers les sommets zéro et deux, le sommet quatre pointe vers les sommets zéro et trois et le sommet cinq pointe vers le sommet zéro et quatre.       Dans la réalité, il serait très couteux de calculer le vecteur propre de la matrice de Google, puisque le véritable web contient près de deux-milliards de sites web En date de 2022 , qui contiennent chacun plusieurs pages. Échelonner une telle matrice est impensable. On s'intéresse à la position d'un utilisateur après clics qui cliquerait sur les liens de manières aléatoires. Par exemple, dans le web hypothétique de la figure , avec la page de départ , si l'on pose , alors les chances de se retrouver sur les pages après un clic sont données par les entrées du vecteur . En général, les chances après clics sont données par .  Calculer les probabilités de se retrouver sur les pages après clics.   Calculer les probabilités de se retrouver sur les pages après clics pour le web hypothétique de la figure .  Calculer pour les deux matrices de Google des webs hypothétiques. Que peut-on remarquer?  En général, Google va calculer une grande puissance de sa matrice pour retourner les pages avec le plus de valeurs, car cela est moins couteux que de trouver le vecteur propre. On peut montrer que sous certaines conditions sur , les colonnes de convergent toujours vers le vecteur propre recherché lorsque tend vers l'infini.  Considérer maintenant le web hypothétique illustré par la figure . Quelle prédiction peut être faite pour les pages et ?   Un autre graphe à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers les sommets un, deux et trois, le sommet un pointe vers les sommets deux et trois, le sommet deux pointe vers les sommets zéro, un, trois et quatre, le sommet trois pointe vers le sommet quatre, le sommet quatre pointe vers les sommets trois et cinq et le sommet cinq pointe vers le sommet trois et quatre.      Vérifier l'hypothèse en calculant le vecteur propre de la matrice de Google et en le normalisant pour que les entrées somment à .  Calculer et vérifier à nouveau ce qui a été observé à la partie .  Une matrice comme celle du web hypothétique de la figure est problématique car, à partir d'une certaine puissance, des entrées de la matrice sont toujours nulles et il est impossible de retourner à ces pages. En regardant plus attentivement le graphe, on constate que lorsqu'on entre dans l'une des pages , il est impossible d'en ressortir.  Google contourne ce problème en modifiant légèrement sa matrice . En fait, il utilise une matrice définie à partir de la matrice et d'une matrice qui, pour un web à pages serait égale à . Dans cette matrice, toutes les pages ont la même chance d'être visitées, à partir de n'importe quelle autre page, incluant la page sur laquelle on se trouve déjà. L'équation pour la matrice est où . La valeur de utilisée par Google n'est pas connue. Pour la suite, on utilisera .  En prenant à nouveau la situation de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?  Répéter avec le web hypothétique de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?  Répéter avec le web hypothétique de la figure , déterminer le vecteur propre de la matrice . Est-il différent de celui de la matrice ?   On peut généraliser le concept où, à partir de certaines pages, il est plus probable d'aller vers une page qu'une autre. Graphiquement, ceci est représenté en donnant un poids aux arêtes reliant les sommets du graphe. On s'assure que la somme des poids sortant d'un sommet donne . En quelque sorte, le poids pourrait représenter la proportion des liens sortant du sommet et allant vers le sommet . Analyser le graphe de la figure , représentant une modification du web hypothétique de la figure .   Une version pondérée d'un web hypothétique à trois sommets   Un graphe à trois sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids un sur cinq et vers le sommet deux avec poids quatre sur cinq. Le sommet un pointe vers le sommet zéro avec poids un sur trois et vers le sommet deux avec poids deux sur trois. Le sommet deux ne pointe que vers le sommet un, avec poids un.      Répéter avec la modifification du web hypothétique de la figure , illustrée à la figure suivante.   Une version pondérée d'un web hypothétique à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids un sur trois et vers le sommet deux avec poids deux sur trois. Le sommet un pointe vers le sommet zéro avec poids un sur quatre, vers le sommet trois avec poids un sur deux et vers le sommet cinq avec poids un sur quatre. Le sommet deux pointe vers le sommet trois avec poids trois sur quatre et vers le sommet cinq avec poids 1\/4. Le sommet trois pointe vers le sommet zéro avec poids trois sur cinq et vers le sommet deux avec poids deux sur cinq. Le sommet quatre pointe vers le sommet zéro avec poids un sur trois et vers le sommet trois avec poids deux sur trois. Le sommet cinq pointe vers le sommet zéro et quatre, chacun avec poids un sur deux.      Répéter avec la modification du web hypothétique de la figure , illustrée à la figure suivante.   Une modification d'un autre web hypothétique à six sommets   Un graphe à six sommets est illustré. Les sommets sont reliés par des flèches. Le sommet zéro pointe vers le sommet un avec poids une demi, vers le sommet deux avec poids un tiers et vers le sommet trois avec poids un sur six. Le sommet un pointe vers le sommet deux avec poids trois sur sept et vers le sommet trois avec poirds quatre sur sept. Le sommet deux pointe vers le sommet zéro avec poids deux sur cinq, vers le sommet un avec poids un sur quatre, vers le sommet trois avec poids un sur trois et vers le sommet quatre avec poids un sur soixante. Le sommet trois pointe vers le sommet quatre avec poids 1, le sommet quatre pointe vers le sommet trois avec poids un sur six et vers le sommet cinq avec poids cinq sur six. Finalement, le sommet cinq pointe vers le sommet trois avec poids sept sur neuf et vers le sommet quatre avec poids deux sur neuf.      "
},
{
  "id": "sec-Markov",
  "level": "1",
  "url": "sec-Markov.html",
  "type": "Section",
  "number": "7.1",
  "title": "Chaines de Markov",
  "body": "  Chaines de Markov    Aller aux exercices de la section.  En général, le contenu du chapitre et celui du chapitre devraient suffire pour comprendre cette section. Quelques résultats et notions du chapitre sont utilisés. Il peut être utile de revoir la théorie générale du chapitre 6, mais ce n'est pas absolument nécessaire. Quelques éléments de probabilités et statistiques sont aussi mis à profit.  On suppose que la météo d'une journée peut se manifester selon un seul des trois scénarios suivants: il pleut, c'est nuageux, il fait soleil. De plus, on suppose que le scénario qui sera en vigueur le lendemain ne dépend que du scénario en vigueur aujourd'hui. Ainsi, s'il a plu les cinq derniers jours, seul le fait qu'il pleuve aujourd'hui influence le temps qu'il fera demain. Lorsqu'on applique des probabilités à chaque transition possible entre les différents scénarios, on obtient une chaine de Markov. L'objectif de cette section est de définir cet objet mathématique et d'en découvrir les applications.  Dans cette section, on présente la notion de chaine de Markov, quelques propriétés et plusieurs applications.   Définition et exemples  Pour parler de chaine de Markov, on doit commencer par restreindre les vecteurs et les matrices avec lesquels on travaille. Un vecteur de probabilité est un vecteur dont toutes les entrées sont supérieures ou égales à zéro et dont la somme est égale à un. Une matrice stochastique est une matrice carrée telle que toutes ses colonnes sont des vecteurs de probabilité. Par exemple, les vecteurs sont des vecteurs de probabilité, contrairement aux vecteurs .  De même, la matrice est une matrice stochastique, ce qui n'est pas le cas de la matrice .  À noter qu'on dit parfois un vecteur de distribution, ou simplement distribution, pour parler d'un vecteur de probabilité. On dit aussi matrice de transition pour une matrice stochastique, pour des raisons qui deviendront évidentes sous peu.   Chaine de Markov  Une chaine de Markov est une suite infinie de vecteurs de probabilité ainsi qu'une matrice telle que .  Le vecteur est appelé l'état initial de la chaine de Markov.    Historiquement, les vecteurs de probabilité d'une chaine de Markov sont notés par une lettre majuscule, souvent , sans la flèche au-dessus. Afin de respecter la tradition, on utilise aussi cette notation. Il est également possible qu'un vecteur de probabilité possède une infinité de composantes. Dans ce cas, la matrice serait également infinie. L'étude de ces chaines de Markov est plus complexe, bien que certains résultats peuvent tout de même être obtenus sans trop de difficultés. Dans ce qui suit, on considère seulement les chaines de Markov finies.  On peut penser qu'en vertu de la définition , il faille connaitre toute la chaine des vecteurs de probabilité afin de vérifier si l'on a bel et bien une chaine de Markov, mais en réalité, on obtient souvent une telle chaine à partir de la description d'une situation ou d'un phénomène.   Une première chaine de Markov  Dans un pays hypothétique, on retrouve uniquement deux compagnies de téléphone cellulaire. Une étude de marché a démontré qu'un client de la compagnie allait, dans des cas, demeurer avec la même compagnie au moment du renouvèlement. Il allait donc changer de compagnie de téléphonie dans 20% des cas. Dans le cas d'un client de la compagnie , cette même étude a montré qu'il allait lui rester fidèle du temps, mais qu'il allait changer pour dans les autres cas.  L'étude a également établi qu'en date de publication, la compagnie accaparait des parts de marché contre pour la compagnie .  On montre que l'évolution des parts de marché de ces deux compagnies obéit à une chaine de Markov.   On pose et . Soit , un vecteur de probabilité quelconque. On peut interpréter ce vecteur comme les parts de marché des compagnies et . Le produit représente alors les nouvelles proportions, après une première transition de la population d'une compagnie à l'autre. En effet, si l'on note les parts de marché de la compagnie et celles de , le produit matrice vecteur correspond à . Ceci est cohérent avec le modèle de l'énoncé qui dit que des clients chez y restent et que des clients de migrent vers . Un raisonnement semblable démontre le même effet pour la deuxième compagnie.  De cette observation, on déduit que les parts de marché après un an seront de . Le reste de la suite s'obtient itérativement.    On reprend maintenant l'exemple de la météo présenté à l'introduction.  Modèle markovien pour la météo  On suppose que la matrice suivante modélise adéquatement les transitions entre les scénarios météorologiques décrits à l'introduction de cette section . On identifie la première colonne par le scénario pluie , la deuxième par le scénario nuageux et la troisième par le scénario ensoleillé . Puisque l'image d'une matrice va des colonnes vers les lignes, l'entrée représente la probabilité de passer d'une journée nuageuse à une journée pluvieuse.  Sachant que le temps est ensoleillé aujourd'hui, une famille veut connaitre les chances qu'il y ait de la pluie lors de leur annuel BBQ familial, qui est dans deux jours.   On pose , puisqu'on est certain, selon les informations de la famille, que le temps est ensoleillé aujourd'hui. La réponse à la question se trouve dans la première composante du vecteur . On commence par calculer les probabilités de chacun des scénarios pour le lendemain. On a . Pour calculer , on poursuit avec l'image du vecteur par la matrice , ce qui donne . La probabilité que la pluie vienne ruiner cette fête est donc légèrement supérieure à .   Parfois, il peut être utile de représenter les transitions d'une chaine de Markov par un graphe. On retrouvera dans ce graphe les sommets, qui représentent les états possibles de la chaine, les arêtes, qui relient les sommets pour lesquels la transition de l'un vers l'autre est possible en une étape. Ces arêtes sont parfois dirigées, c'est-à-dire qu'elles ont une flèche indiquant le sens de la transition et elles peuvent être pondérées, pour donner la probabilité de cette transition. Lorsque toutes les transitions ont la même probabilité, on omet généralement les pondérations. L'exemple ci-dessous illustre l'habitat d'une souris domestique, composé de quatre pièces reliées par des portes.   L'habitat d'une souris domestique  L'habitat d'une souris domestique est composé de quatre pièces, dont certaines sont reliées par des portes. Le graphe de la figure suivante illustre les parcours possibles pour cette souris.   Graphe représentant les transitions de la chaine de Markov associée au déplacement d'une souris domestique dans son habitat   Un graphe à quatre sommet est illustré.     Lorsqu'elle est dans son habitat, la souris se promène de pièce en pièce en choisissant au hasard, chaque fois, l'une des portes disponibles au hasard. On prend cette souris et on la place au hasard dans l'une des quatre pièces, sans préférence pour une pièce particulière. On se demande où la souris a le moins de chance de se trouver après trois transitions.   À partir du graphe de la figure , on peut créer la matrice de transition associée à la chaine de Markov. On constate, par exemple, qu'à partir de la première pièce, il est possible d'aller dans la deuxième ou dans la quatrième, de façon équiprobable. En raisonnant ainsi pour les trois autres pièces, on arrive à la matrice .  On pose ensuite . Pour calculer la pièce qui a le moins de chance d'être occupée par la souris après trois déplacements, on utilise Sage.   Deux pièces ont en fait le moins de chance d'être occupées, les pièces et avec chacune.    Le prochain exemple est un cas classique en probabilité. Souvent appelé la ruine du parieur . La mention la plus vieille retracée remonte à Blaise Pascal, en 1656, dans une lettre à Pierre de Fermat. Pascal est considéré comme l'un des pionniers de la théorie des probabilités.   La ruine du parieur  On considère un parieur qui possède $. Il joue au jeu suivant. Il lance une pièce de monnaie. Dans le cas où la pièce tombe sur pile , il gagne un dollar et dans le cas où la pièce tombe sur face , il perd plutôt un dollar. Afin de considérer une chaine de Markov finie, on suppose que le jeu s'arrête lorsqu'il n'a plus d'argent ou bien qu'il réussit à atteindre $. La figure suivante illustre le parcours de dix joueurs ayant participé à ce jeu.   La ruine du parieur illustrée      Quelles sont les probabilités qu'il soit encore en train de jouer après cinq lancers de sa pièce?   À tout moment, le joueur peut avoir en sa possession ou dollars. Pour les montants allant de à , on peut se déplacer vers chacun des nombres voisins avec probabilité . Pour tenir compte de la fin du jeu, on fait en sorte qu'il est impossible de sortir des états représentat les montants et dollars en donnant comme seule possibilité à partir de ces états le fait de rester en place. La matrice suivante illustre ces transitions . On pose puisque le joueur commence avec $. La réponse à la question se trouve dans . Il faut faire la somme de toutes les entrées de ce vecteur qui ne sont pas les extrémités. On aura alors la probabilité qu'après cinq lancers, le joueur ait en sa possession ou dollars. La cellule suivante définit une fonction Sage qui permettra de créer rapidement la matrice. Il faut l'exécuter, mais rien ne sera affiché. Cette fonction sera étudiée et modifiée à l'exercice .   On crée dans la cellule suivante la matrice T et l'on calcule .   On remarque qu'après cinq lancers, le joueur peut se retrouver avec ou dollars. La probabilité cherchée est , soit légèrement en-dessous d'une chance sur deux.    L'exemple de la ruine du parieur est un cas particulier d'un modèle plus général appelé la marche aléatoire. On en donne une définition simplifiée ci-dessous.   La marche aléatoire à une dimension  Soit , des entiers. Une marche aléatoire sur est un processus aléatoire où une particule à une position intermédiaire se déplace vers la droite avec probabilité et vers la gauche avec probabilité .  Si la marche est absorbante, alors la particule demeure toujours aux extrémités lorsqu'elle les atteint, et si la marche est réfléchissante, alors la particule retourne toujours vers la bande centrale lorsqu'elle atteint une position extrême. La figure ci-dessous illustre graphiquement une marche aléatoire absorbante.   Une marche aléatoire absorbante sur les entiers .    On peut même généraliser les marches aléatoires à tous les entiers ou à un sous-ensemble, fini ou non, de ceux-ci.    Le modèle d'Ehrenfest est une application intéressante d'une marche aléatoire. Le phénomène peut servir de modélisation pour la diffusion des particules d'un gaz entre deux milieux.   Le modèle d'Enrenfest  On considère deux contenants , l'un contenant objets identiques et l'autre étant vide. À chaque étape, on choisit l'un des objets au hasard et on le change de contenant. On propose d'étudier le cas où l'urne possède initialement quatre objets. Quelle peut être la situation après dix transitions?  En considérant uniquement le nombre d'objets dans le premier contenant, on peut voir ce processus comme une marche aléatoire réfléchissante sur dont les probabilités changent selon l'état actuel. En effet, si tous les objets sont dans un contenant, il est certain qu'à la prochaine transition, l'autre contenant en recevra une. Pour les états intermédiaires, si le contenant possède objets, alors il en possèdera avec probabilité et avec probabilité . On peut illustrer cela par la matrice de transition . On pose comme vecteur initial . Avec Sage, on obtient représentant le portrait après dix transitions.     On termine cette sous-section avec un exemple Sage qui permet de simuler une chaine de Markov.   Chaine de Markov et Sage  On va créer une fonction Sage qui prend comme argument une matrice de transition , un vecteur de probabilité et un entier facultatif qui retournera . Si l'entier n'est pas fourni, on retournera par défaut .   On peut vérifier les exemples de la sous-section en utilisant la fonction. Par exemple, pour la chaine de Markov de l'exemple , la cellule suivante montre l'évolution des parts de marché pour les dix premières transitions.      Le comportement limite  Dans la sous-section précédente, on a calculé les vecteurs de probabilité pour des valeurs relativement petites de . Dans ce qui suit, on cherche à trouver une manière efficace de calculer . On s'intéresse aussi au comportement à long terme de la chaine de Markov, soit au comportement de lorsque tend vers l'infini. La réponse à cette question permet de dire, par exemple, quelles seront les parts de marché auxquelles peuvent s'attendre les compagnies dans l'exemple , ou encore, quelle est la probabilité que le joueur se ruine avant d'atteindre son but dans l'exemple . Pour commencer, une proposition qui ne devrait pas surprendre sur le calcul de .   Calcul de  Soit , la matrice d'une chaine de Markov et , l'état initial. Alors .   Il suffit de remarquer qu'en calculant par itération, on finit par arriver à : .    Un état stable d'une matrice stochastique est un vecteur de probabilité tel que . Dans le chapitre , on étudie ces vecteurs, appelés vecteurs propres . Toutefois, on peut trouver ces vecteurs en n'utilisant que les notions des premiers chapitres.   L'état stable des compagnies téléphoniques  On reprend la chaine de Markov de l'exemple . On cherche à déterminer s'il existe un état stable.   On pose , pour . Le vecteur est un vecteur de probabilité. En effectuant le produit , on obtient un système d'équation à deux équations et une seule inconnue. On a , ce qui donne les deux équations , qui sont, en fait, à un multiple près, la même équation. La solution est . L'état stable de cette chaine de Markov existe et est .    Il est intéressant de noter que, sous certaines conditions, toute chaine de Markov va converger vers l'état stable. La proposition suivante donne un critère garantissant l'existence et la convergence vers l'état stable. Elle ne sera pas démontrée, puisqu'elle découle davantage d'un cours de probabilités avancé que de l'algèbre linéaire.   L'état stable et la convergence de la chaine de Markov  Soit , une matrice stochastique finie telle que toutes les entrées de sont strictement plus grandes que zéro pour un certain . Alors, possède un unique état stable . De plus, pour tout vecteur de probabilité , on a .  Également, les puissances de la matrice convergent vers une matrice dont toutes les colonnes correspondent au vecteur de l'état stable.    Avec Sage, on peut vérifier numériquement la convergence vers l'état stable dans la situation des compagnies téléphoniques, puisque dès le départ, la matrice ne contient aucune valeur nulle.   En commençant par une distribution différente, on converge toujours vers l'état stable. Même dans le cas où l'une des compagnies commence en ayant toutes les parts de marché.   La convergence est plus lente, comme le montre la différence après transitions, mais à transitions et à la précision utilisée, on ne peut voir de différence.  Comme la matrice de l'exemple sur le modèle météorologique ne contient pas de zéros, on peut aussi trouver son état stable.   On cherche l'état stable de la matrice de l'exemple . On peut procéder en résolvant un système d'équations linéaires, comme on l'a fait à l'exemple , mais puisqu'on sait que l'état stable existe et que toute distribution va converger vers celui-ci, on peut procéder numériquement en calculant une grande valeur de .  On procède par un calcul numérique, qu'on validera ensuite avec une démarche théorique.   On tente maintenant de trouver cette solution par une démarche algébrique. On pose pour . On a . On en déduit les trois équations . Ce système possède une solution unique, que l'on calcule à l'aide de Sage.     Dans le cas de l'habitat de la souris, il faut se rendre à la cinquième puissance avant de trouver une matrice qui ne contient pas de zéros. La proposition garantit alors qu'un état stable existe. Celui-ci sera déterminé à l'exercice . Pour ce qui est de la ruine du joueur, la proposition ne s'applique pas. Les puissances de la matrice de transition ont toujours des valeurs nulles. On ne peut quitter la position correspondant à zéro ou cinq dollars, la première et la dernière colonne possèdent toujours des zéros. Toutefois, cela ne signifie pas qu'un état stable est impossible.   État stable pour la ruine de joueur   On cherche à savoir si un état stable existe pour la matrice de l'exemple . En fait, on peut déjà apercevoir qu'il y aura plus d'un état stable. Le vecteur est stable , puisque celui-ci redonne la première colonne de la matrice qui est aussi ce vecteur. De même, le vecteur fait la même chose avec la dernière colonne. En poursuivant la réflexion, on pourra déduire que tout vecteur de la forme sera un état sable. Pour savoir si la chaine de Markov, pour un état initial donné, converge vers un état stable, on se tourne vers le calcul d'une grande puissance.    On recopie dans la cellule ci-dessous le code nécessaire pour fabriquer la matrice.   Avec le vecteur , on obtient, en calculant une grande puissance de la chaine, que l'état stable est environ . Ceci signifie que le joueur de l'exemple a environ de chance de perdre tout son argent, contre de chance d'atteindre son objectif. Certains et certaines auront peut-être réalisé que l'état stable dépend forcément de l'état initial, contrairement aux autres exemples. Si l'on considère un joueur dont la mise initiale n'est que d'un dollar, dans des cas, le joueur se retrouve déjà ruiné et dans les autres cas, il se retrouve avec deux dollars. On sait alors qu'il possède, à partir de deux dollars, des chances de se ruiner. Les règles de probabilités établissent donc les chances de se ruiner à partir d'un montant initial égal à un dollar à . Ce calcul est un exemple de ce que l'on appelle les probabilités conditionnelles en théorie des probabilités. On vérifie le tout numériquement. La cellule ci-dessous donne l'état stable pour les chaines de Markov commençant à deux dollars et à un dollar.   On note que chacun de ces états stables est de la forme .      Un peu plus loin  Dans cette courte sous-section, on donne quelques éléments concernant les chaines de Markov permettant à la lectire et au lecteur intéressés d'en apprendre un peu plus.  Les calculs des grandes puissances d'une matrice ainsi que de l'état stable d'une chaine de Markov peuvent être grandement facilités par l'utilisation des valeurs et vecteurs propres, étudiés au chapitre . En effet, on peut montrer que est toujours une valeur propre pour une matrice stochastique et, par définition d'un vecteur propre, que les vecteurs propres représentent les états stables de la chaine.  L'existence d'un état stable n'est pas garantie. Une autre condition que celle donnée à la proposition est que les autres valeurs propres soient, en valeur absolue, inférieures à . C'est un critère algébrique. Du côté de la théorie des probabilités, on veut être en mesure d'atteindre n'importe quel état à partir de tous les autres en un nombre fini de transitions, on veut que la chaine ne contienne pas de cycle, c'est-à-dire que tous les états peuvent être visités à tout moment, et non seulement aux transitions paires par exemple. De plus, on veut que la chaine soit récurrente positive, c'est-à-dire que l'on peut retourner à un l'état initial en un nombre fini de transitions.  Les chaines de Markov infinies sont également intéressantes. Une étude davantage axée sur les probabilités que sur l'algèbre linéaire arrive à montrer qu'il existe des résultats semblables à ceux obtenus dans cette section, bien que leurs conditions d'application puissent être différentes. Un exemple intéressant, qui a d'abord été abordé par Francis Galton, étudie les probabilités qu'une lignée s'éteigne. Étant donnée une personne, on cherche à savoir si sa descendance sera perpétuelle. Pour cela, on suppose qu'à chaque génération, les héritiers ont un nombre aléatoire d'enfants qui pourront poursuivre la lignée. Galton a montré que si le nombre d'enfants moyen est inférieur ou égal à un, l'extinction de la lignée est certaine et que, dans le cas où la moyenne est supérieure à un, il a quantifié la probabilité de perpétuité de la lignée en fonction de cette moyenne.  Dans la section , on présente ce qui est sans doute la plus connue des chaines de Markov: celle qui est à l'origine du moteur de recherche Google!  Les chaines de Markov sont un exemple de ce qu'on appelle plus généralement les processus stochastiques, ou processus aléatoires. Le plus important de ceux-ci est sans aucun doute le mouvement brownien.     Les points importants de cette section sont:  Les notions de vecteurs de probabilité et de matrice stochastique ou de transition;  La définition d'un chaine de Markov ;  La proposition pour le calcul de l'état stable dans le cas d'une matrice possédant une puissance sans entrées nulles.        Exercices   Considérer une chaine de Markov dont la matrice de transition est donnée par . Si l'état initial est donné par le vecteur , déterminer l'état après transitions. Il suffit de calculer Quel sera l'état à long terme de cette chaine? On cherche un vecteur état qui sera stationnaire et donc inchangé par la matrice de transition. On pose , cet état. Ainsi, . On obtient les équations suivantes: On résout pour trouver , le vecteur stable est donc .  On considère la chaine de Markov se déroulant sur le graphe de la figure suivante.   Le graphe de l'exercice   Une graphe à quatre sommet est illustré avec des arêtes reliant certains sommets.     Déterminer la matrice de transition associée à une chaice de Markov sur ce graphe. Si un objet est placé au sommet du graphe et se déplace selon les règles, quel est l'endroit le plus probable où il peut se retrouver après deux transitions? Sur le sommet . Il faut calculer où est le vecteur de l'état initial. . On peut donc voir que la position la plus probable après deux transitions est la position . L'objet est oublié et continue ses déplacements pendant un bon moment. Une personne finit par l'apercevoir et note la position de l'objet. Quelles sont les probabilités qu'à ce moment, l'objet se trouve sur le sommet ? Environ . Sans connaitre l'état initial et le nombre de transitions effectuées jusqu'à maintenant, on ne peut répondre de manière exacte à cette question. Dans ce cas, la probabilité associée à l'état stable fournit la meilleure estimation. On pose , le vecteur stable recherché. Ainsi, . À partir de cette égalité vectorielle, on obtient le système d'équations linéaires . Une fois réduit (on a multiplié par pour éliminer les fractions), le système est équivalent à . On résout avec Gauss-Jordan: On obtient donc , et et ainsi, On conclut que la position est fréquentée du temps à l'état stable. C'est la meilleure estimation à donner pour la probabilité cherchée.  On s'intéresse aux chaines de Markov à deux états dont la matrice de transition est avec . Déterminer l'état stationnaire d'une telle chaine. On cherche un vecteur de probabilité qui sera stationnaire et donc inchangé par la matrice de transition. On pose , cet état. On a , d'où l'on tire les équations suivantes . On obtient en résolvant , l'état stable est donc  Calculer l'état stable de la chaine de Markov représentant le déplacement de la souris dans l'exemple .  La matrice de transition est donnée par . Un calcul montre que n'a pas d'entrée égale à zéro, il est donc possible de calculer une grande puissance de pour trouver l'état stable. Avec Sage, on trouve .    On considère la figure qui représente l'habitat d'une souris.   Un habitat de souris.   Le plan d'un habitat de souris, formé de sept pièces reliées par des portes.    Quelle est la matrice de transition associée à la chaine de Markov représentant cette situation? Sachant que la souris est présentement dans la pièce , quelle sera sa position la plus probable dans trois transitions? C'est la pièce numéro 4 qui est la plus probable.  On peut procéder par itération à partir du vecteur . On a , puis et finalement, .  Déterminer la pièce ayant la plus grande probabilité d'abriter la souris à long terme. Est-ce que cela parait logique? Utiliser Sage pour faire les calculs. La pièce .   C'est la pièce qui a le plus de chances d'abriter la souris à long terme. Cela semble plausible étant donné que c'est la pièce qui a le plus de portes. La souris devrait donc y transiter plus souvent.    On reprend la situation du parieur de l'exemple . Tout casino qui se respecte n'offre pas des probabilités équitables dans ses jeux de hasard. Pour simplifier, on considère toujours un joueur qui joue à un jeu qui ne possède que deux résultats possibles. Avec probabilité , le joueur gagne dollar et avec probabilité , il perd dollar.  Déterminer les probabilités de chaque état après cinq tours si . Comparer avec les résultats obtenus à l'exemple . Il est possible de modifier la fonction ruinetransitionproba de l'exemple pour construire la matrice. On peut aussi la construire manuellement. La cellule suivante construit la matrice de transition associée à cette chaine de Markov.   On calcule ensuite avec Sage.   On constate que, dans cette situation, le joueur a maintenant plus de de chance d'être ruiné après cinq jeux, contrairement à dans le jeu avec probabilité de succès égale à .  Déterminer les probabilités de succès du joueur. Tout comme à l'exemple , il faut approximer par pour une grande valeur de , puisque l'état stable dépend de l'état initial. Avec Sage, on trouve que le joueur a maintenant moins de de chance d'atteindre les cinq dollars avant de se ruiner, comparativement à dans la situation équiprobable. Un changement dans la probabilité de gagner à chaque tour de entraine un changement dans la probabilité de succès net de plus du double.     Lors de l'envoi d'information par un système informatique, cette information est encodée dans une chaine binaire, formée de ou de . Il arrive parfois, que lors du transfert, la chaine se corrompe. (Heureusement, il existe des techniques pour valider une chaine et déterminer si elle a été corrompue.) Chaque nombre dans une chaine est appelé un bit . On suppose qu'à chaque transfert, un bit a probabilité de rester le même et probabilité d'être changé. Les bits sont indépendants, c'est-à-dire que le fait que l'un change ou non n'affecte pas les autres.  On considère des chaines à deux bits d'information. Les possibilités sont et . On suppose .  Puisque l'état de la chaine binaire après un transfert ne dépend que de son état avant transfert, c'est une chaine de Markov. Écrire la matrice de transition associée à la chaine. La probabilité que deux évènements indépendants surviennent est le produit des probabilités de chacun des événements. Pour toute chaine, la probabilité de demeurer inchangé est obtenue par . La probabilité que le premier bit change, mais pas le deuxième est , tout comme la probabilité que le premier soit inchangé, mais que le deuxième le soit, puisque . Finalement, la probabilité que les deux bits soient changés est . La matrice de transition est donc On transmet comme information. Cette chaine passe de l'ordinateur d'un utilisateur à un réseau central, elle est ensuite envoyée aux serveurs d'une compagnie et se retrouve finalement sur l'ordinateur d'une autre utilisateur, d'une autre utilisatrice. La chaine a donc subi trois transferts. Quelle est la probabilité que le message soit toujours lors de la lecture par le deuxième utilisateur? (On note que le message pourrait avoir été corrompu en chemin, mais s'être corrigé de lui-même.) On pose , l'état initial. On cherche la troisième composante de . Avec Sage, on trouve que cette probabilité est d'environ , soit .   Calculer , comme on l'a souvent fait afin de déterminer l'état stable. Est-ce que le résultat contredit la proposition ?   Il semble ici que l'état stable ne soit pas le même pour chacune des colonnes. Toutefois, cela ne contredit pas la proposition . Celle-ci dit que les puissances de la matrice convergent vers l'état stable. Cette convergence peut, par contre, être plus lente dans certains cas. Une puissance plus élevée permet de voir que la matrice converge bel et bien vers un état stable.    Au tennis, le système de points est tel qu'un joueur doit faire quatre points pour gagner un jeu. Toutefois, il doit y avoir un écart de deux points entre les joueurs. Une situation particulière se produit lorsque le pointage est (ce qui correspond à trois points pour chacun des joueurs). On entre alors dans un état appelé égalité (aussi appelé deuce en anglais). Le prochain joueur à faire un point est alors considéré en avantage . S'il gagne le prochain point, il remporte le jeu et s'il le perd, on retourne à l'égalité. On peut modéliser la partie égalité d'un jeu de tennis par une chaine de Markov à cinq états. On note pour égalité, pour avantage serveur, pour avantage retourneur, pour la victoire du serveur et pour la victoire du retourneur. Chez les professionnels, le serveur est presque toujours considéré comme favori pour remporter le point. On suppose, que pour chaque point, le serveur a probabilité de remporter l'échange. Écrire la matrice de transition modélisant un jeu à partir de l'égalité.   Si un serveur a une probabilité de succès de , quelle est la probabilité qu'à partir de l'égalité, le jeu ne soit pas terminé après échanges?  Pour obtenir la probabilité que le jeu ne soit pas terminé, on doit additionner les probabilités que l'on soit à égalité ou à l'un des avantages.   On trouve qu'il y a environ de chance que le jeu ne soit pas terminé.  Quelle est la probabilité que le serveur remporte le jeu? Environ . Il faut trouver l'état stable à partir de l'état égalité. Comme la matrice possède toujours des entrées nulles, il faut procéder par le calcul d'une grande valeur de la chaine de Markov. On peut voir que le serveur a environ de chance de remporter le jeu.     Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.  Il est possible d'analyser certains jeux de société grâce aux chaines de Markov, particulièrement les jeux où peu de décisions sont prises par les joueurs. Les jeux pour enfants, comme serpents et échelles ou Trouble , se prêtent bien à cette analyse.  On propose d'étudier le jeu serpents et échelles en regardant dans un premier temps une version simplifiée.  On considère une partie de serpents et échelles se déroulant sur le plateau présenté à la figure suivante.   Une version simplifiée de serpents et échelles.   Un plateau de huit cases est illustré, la première identifiée D et la dernière A. Celles centrales sont identifiées de un à six. Une flèche allant de cinq à deux et une autre allant de un à quatre sont présentes.    Dans ce jeu, il y a huit cases. D'abord, on va créer un vecteur de déplacement à huit composantes qui correspondent, pour une position , à la case sur laquelle on se retrouve lorsqu'on atterrit sur la case . Pour les besoins de la cause, on associe la case départ à la position et la case d'arrivée à la position .  Créer le vecteur décrit dans l'introduction.   Étant donné la petite taille de ce plateau, le jeu se déroule avec une pièce de monnaie. Lorsqu'elle tombe sur pile , le joueur avance d'une case et, lorsqu'elle tombe sur face, le joueur avance de deux cases.  Créer une fonction tour qui, étant donné une position de départ et le vecteur de déplacement, retourne la nouvelle position du joueur après le lancer d'une pièce. On rappelle que la fonction choice peut être utilisée pour simuler du hasard.    Le code de la solution.   def tour(d,p): #fonction qui simule un tour de jeu, selon le vecteur de déplacement d et la position de départ p t=choice([1,2]) if p==7: return 7 else: return d[p+t]   Créer une fonction serpech , qui simule une partie de serpents et échelle sur ce plateau. La fonction prend comme argument le vecteur de déplacement et retourne le parcours du joueur.     Le code de la solution.   def serpech(d): p=[0] while p[-1]!=d[-1]: p.append(tour(d,p[-1])) return p    Approximer le nombre de coups nécessaires pour atteindre l'arrivée en simulant parties. La commande pour calculer la moyenne d'une liste est numpy.mean .     Le code de la solution.   d=vector([0,4,2,3,4,5,2,7]) M=[] for i in range(1000): M.append(len(serpech(d))-1) numpy.mean(M)     Toujours en simulant parties, déterminer approximativement la proportion de parties nécessitant plus de tours.     Le code de la solution.   d=vector([0,4,2,3,4,5,2,7]) M=[] for i in range(1000): M.append(len(serpech(d))-1) M21=[m for m in M if m>20] (len(M21)\/1000).n()     Créer une fonction transition_serpech qui, pour une liste de déplacements et un entier , retourne la matrice de transition d'une chaine de Markov du jeu où il est possible d'avancer de cases chaque tour.     Le code de la solution.   def transition_serpech(d,n): #Retourne la matrice de transition selon un vecteur de déplacement d et un dé à n faces cols=[] for case in range(len(d)): #On crée les colonnes de la matrice col=vector(QQ,[0 for i in range(len(d))]) #On initialise la colonne au vecteur nul. À noter qu'on spécifie QQ pour que Sage accepte les rationnels if case==len(d)-1: #Si l'on est à l'arrivée col[-1]=1 cols.append(col) break valide=0 #On compte combien de lancers de dés sont valides, au sens où ils ne dépassent pas l'arrivée for poss in range(1,n+1): #On peut avancer de 1,2,...,n if case+poss<=len(d)-1: #Si le déplacement est valide valide+=1 for poss in range(1,valide+1): #Pour les déplacements valides col[d[case+poss]]+=1\/valide #On ajoute 1\/valide aux chances de se retrouver à cette position. Il est important de l'ajouter et de ne pas remplacer, au cas où, lors d'un même tour, on peut atteindre une case à la fois par un lancer de dé et par un serpent ou une échelle. cols.append(col) #On ajoute la colonne à la liste des colonnes T=column_matrix(cols) #La matrice de transition return T    Utiliser cette fonction pour créer la matrice de transition du jeu simplifié serpents et échelles .     Quel est le nombre minimal de tours nécessaires pour terminer une partie? Quelle est la probabilité qu'une partie se termine en aussi peu de tours?   Le nombre minimal de tours est et les chances sont de .  Le code de la solution.   T=transition_serpech(d,2) X0=vector([1,0,0,0,0,0,0,0]) X=X0 i=0 while X[-1]==0: i+=1 X=T*X print(\"Le nombre de tours minimal est \",i) print(\"Les chances sont \",X[-1])    À la partie , on a estimé le nombre de parties qui n'étaient pas terminées après tours. Déterminer la véritable valeur de ce nombre à l'aide de la matrice de transition.   Le code de la solution.   (1-(T^20*X0)[-1]).n()   On regarde maintenant la véritable version du jeu serpents et échelles . L'original se déroule sur un plateau contenant cases et possédant huit échelles et huit serpents. Plusieurs plateaux existent, selon la compagnie qui publie le jeu. Le dictionnaire python ci-dessous donne le début des serpents et des échelles ainsi que leur fin, pour la version accessible à l'auteur au moment de la rédaction.   Le vecteur de déplacement dans ce jeu est un vecteur à composantes, le départ étant toujours en position et l'arrivée en position . Créer une fonction qui prend comme argument la configuration des serpents et des échelles et qui retourne le vecteur de déplacement.   Initialiser un vecteur contenant les valeurs de à et changer les entrées correspondant aux serpents et aux échelles.   Le code de la solution.   def deplacement(config): d=vector(range(101)) for i in config.keys(): d[i]=config[i] return d deplacement(config)     Modifier la fonction tour de la partie afin que les déplacements possibles soient compris entre et plutôt qu'entre et . Il pourrait aussi être nécessaire de modifier d'autres parties de la fonction selon la manière dont elle a été construite. Utiliser la fonction serpech pour simuler une partie.     Le code de la solution.   def tour(d,p): #fonction qui simule un tour de jeu, selon le vecteur de déplacement d et la position de départ p t=choice([1,2,3,4,5,6]) if p==100: #On modifie l'arrivée return 100 else: return d[min(100,p+t)] #Une manière de s'assurer de ne pas dépasser 100 def serpech(d): p=[0] while p[-1]!=d[-1]: p.append(tour(d,p[-1])) return p def deplacement(config): d=vector(range(101)) for i in config.keys(): d[i]=config[i] return d d=deplacement(config) serpech(d)    Approximer le nombre de coups nécessaires pour atteindre l'arrivée en simulant parties. La commande pour calculer la moyenne d'une liste est numpy.mean .    Le code de la solution.   M=[] for i in range(1000): M.append(len(serpech(d))-1) numpy.mean(M)     Toujours en simulant parties, déterminer approximativement la proportion de parties nécessitant plus de tours.     Le code de la solution.   M=[] for i in range(1000): M.append(len(serpech(d))-1) M21=[m for m in M if m>20] (len(M21)\/1000).n()     Créer la matrice de transition de cette chaine de Markov. Quel est le nombre minimal de tours nécessaires pour terminer une partie? Quelle est la probabilité qu'une partie se termine en aussi peu de tours?   Le nombre minimal de tours est et les chances sont de .  Le code de la solution.   T=transition_serpech(d,2) X0=vector([1,0,0,0,0,0,0,0]) X=X0 X=X0 i=0 while X[-1]==0: i+=1 X=T*X print(\"Le nombre de tours minimal est \",i) print(\"Les chances sont \",X[-1])   À la partie , on a estimé le nombre de parties qui n'étaient pas terminées après tours. Déterminer la véritable valeur de ce nombre à l'aide de la matrice de transition.   Le code de la solution.   (1-(T^20*X0)[-1]).n()   Créer une liste contenant les chances que le jeu soit terminé au tour , pour allant de à . À l'aide des fonctions zip et point , tracer le graphique des probabilités que le jeu soit terminé en fonction du nombre de tours.   Le code de la solution.   fin=[((T^n*X0)[-1]).n() for n in range(200)] coordx=list(range(200)) point(list(zip(coordx,fin)))       "
},
{
  "id": "def-Markov",
  "level": "2",
  "url": "sec-Markov.html#def-Markov",
  "type": "Définition",
  "number": "7.1.1",
  "title": "Chaine de Markov.",
  "body": " Chaine de Markov  Une chaine de Markov est une suite infinie de vecteurs de probabilité ainsi qu'une matrice telle que .  Le vecteur est appelé l'état initial de la chaine de Markov.   "
},
{
  "id": "ex-BVMarkov",
  "level": "2",
  "url": "sec-Markov.html#ex-BVMarkov",
  "type": "Exemple",
  "number": "7.1.2",
  "title": "Une première chaine de Markov.",
  "body": " Une première chaine de Markov  Dans un pays hypothétique, on retrouve uniquement deux compagnies de téléphone cellulaire. Une étude de marché a démontré qu'un client de la compagnie allait, dans des cas, demeurer avec la même compagnie au moment du renouvèlement. Il allait donc changer de compagnie de téléphonie dans 20% des cas. Dans le cas d'un client de la compagnie , cette même étude a montré qu'il allait lui rester fidèle du temps, mais qu'il allait changer pour dans les autres cas.  L'étude a également établi qu'en date de publication, la compagnie accaparait des parts de marché contre pour la compagnie .  On montre que l'évolution des parts de marché de ces deux compagnies obéit à une chaine de Markov.   On pose et . Soit , un vecteur de probabilité quelconque. On peut interpréter ce vecteur comme les parts de marché des compagnies et . Le produit représente alors les nouvelles proportions, après une première transition de la population d'une compagnie à l'autre. En effet, si l'on note les parts de marché de la compagnie et celles de , le produit matrice vecteur correspond à . Ceci est cohérent avec le modèle de l'énoncé qui dit que des clients chez y restent et que des clients de migrent vers . Un raisonnement semblable démontre le même effet pour la deuxième compagnie.  De cette observation, on déduit que les parts de marché après un an seront de . Le reste de la suite s'obtient itérativement.   "
},
{
  "id": "ex-meteoMarkov",
  "level": "2",
  "url": "sec-Markov.html#ex-meteoMarkov",
  "type": "Exemple",
  "number": "7.1.3",
  "title": "Modèle markovien pour la météo.",
  "body": "Modèle markovien pour la météo  On suppose que la matrice suivante modélise adéquatement les transitions entre les scénarios météorologiques décrits à l'introduction de cette section . On identifie la première colonne par le scénario pluie , la deuxième par le scénario nuageux et la troisième par le scénario ensoleillé . Puisque l'image d'une matrice va des colonnes vers les lignes, l'entrée représente la probabilité de passer d'une journée nuageuse à une journée pluvieuse.  Sachant que le temps est ensoleillé aujourd'hui, une famille veut connaitre les chances qu'il y ait de la pluie lors de leur annuel BBQ familial, qui est dans deux jours.   On pose , puisqu'on est certain, selon les informations de la famille, que le temps est ensoleillé aujourd'hui. La réponse à la question se trouve dans la première composante du vecteur . On commence par calculer les probabilités de chacun des scénarios pour le lendemain. On a . Pour calculer , on poursuit avec l'image du vecteur par la matrice , ce qui donne . La probabilité que la pluie vienne ruiner cette fête est donc légèrement supérieure à .  "
},
{
  "id": "ex-sourisMarkov",
  "level": "2",
  "url": "sec-Markov.html#ex-sourisMarkov",
  "type": "Exemple",
  "number": "7.1.4",
  "title": "L’habitat d’une souris domestique.",
  "body": " L'habitat d'une souris domestique  L'habitat d'une souris domestique est composé de quatre pièces, dont certaines sont reliées par des portes. Le graphe de la figure suivante illustre les parcours possibles pour cette souris.   Graphe représentant les transitions de la chaine de Markov associée au déplacement d'une souris domestique dans son habitat   Un graphe à quatre sommet est illustré.     Lorsqu'elle est dans son habitat, la souris se promène de pièce en pièce en choisissant au hasard, chaque fois, l'une des portes disponibles au hasard. On prend cette souris et on la place au hasard dans l'une des quatre pièces, sans préférence pour une pièce particulière. On se demande où la souris a le moins de chance de se trouver après trois transitions.   À partir du graphe de la figure , on peut créer la matrice de transition associée à la chaine de Markov. On constate, par exemple, qu'à partir de la première pièce, il est possible d'aller dans la deuxième ou dans la quatrième, de façon équiprobable. En raisonnant ainsi pour les trois autres pièces, on arrive à la matrice .  On pose ensuite . Pour calculer la pièce qui a le moins de chance d'être occupée par la souris après trois déplacements, on utilise Sage.   Deux pièces ont en fait le moins de chance d'être occupées, les pièces et avec chacune.   "
},
{
  "id": "ex-ruine",
  "level": "2",
  "url": "sec-Markov.html#ex-ruine",
  "type": "Exemple",
  "number": "7.1.6",
  "title": "La ruine du parieur.",
  "body": " La ruine du parieur  On considère un parieur qui possède $. Il joue au jeu suivant. Il lance une pièce de monnaie. Dans le cas où la pièce tombe sur pile , il gagne un dollar et dans le cas où la pièce tombe sur face , il perd plutôt un dollar. Afin de considérer une chaine de Markov finie, on suppose que le jeu s'arrête lorsqu'il n'a plus d'argent ou bien qu'il réussit à atteindre $. La figure suivante illustre le parcours de dix joueurs ayant participé à ce jeu.   La ruine du parieur illustrée      Quelles sont les probabilités qu'il soit encore en train de jouer après cinq lancers de sa pièce?   À tout moment, le joueur peut avoir en sa possession ou dollars. Pour les montants allant de à , on peut se déplacer vers chacun des nombres voisins avec probabilité . Pour tenir compte de la fin du jeu, on fait en sorte qu'il est impossible de sortir des états représentat les montants et dollars en donnant comme seule possibilité à partir de ces états le fait de rester en place. La matrice suivante illustre ces transitions . On pose puisque le joueur commence avec $. La réponse à la question se trouve dans . Il faut faire la somme de toutes les entrées de ce vecteur qui ne sont pas les extrémités. On aura alors la probabilité qu'après cinq lancers, le joueur ait en sa possession ou dollars. La cellule suivante définit une fonction Sage qui permettra de créer rapidement la matrice. Il faut l'exécuter, mais rien ne sera affiché. Cette fonction sera étudiée et modifiée à l'exercice .   On crée dans la cellule suivante la matrice T et l'on calcule .   On remarque qu'après cinq lancers, le joueur peut se retrouver avec ou dollars. La probabilité cherchée est , soit légèrement en-dessous d'une chance sur deux.   "
},
{
  "id": "definition-57",
  "level": "2",
  "url": "sec-Markov.html#definition-57",
  "type": "Définition",
  "number": "7.1.8",
  "title": "La marche aléatoire à une dimension.",
  "body": " La marche aléatoire à une dimension  Soit , des entiers. Une marche aléatoire sur est un processus aléatoire où une particule à une position intermédiaire se déplace vers la droite avec probabilité et vers la gauche avec probabilité .  Si la marche est absorbante, alors la particule demeure toujours aux extrémités lorsqu'elle les atteint, et si la marche est réfléchissante, alors la particule retourne toujours vers la bande centrale lorsqu'elle atteint une position extrême. La figure ci-dessous illustre graphiquement une marche aléatoire absorbante.   Une marche aléatoire absorbante sur les entiers .    On peut même généraliser les marches aléatoires à tous les entiers ou à un sous-ensemble, fini ou non, de ceux-ci.   "
},
{
  "id": "ex-Ehrenfest",
  "level": "2",
  "url": "sec-Markov.html#ex-Ehrenfest",
  "type": "Exemple",
  "number": "7.1.10",
  "title": "Le modèle d’Enrenfest.",
  "body": " Le modèle d'Enrenfest  On considère deux contenants , l'un contenant objets identiques et l'autre étant vide. À chaque étape, on choisit l'un des objets au hasard et on le change de contenant. On propose d'étudier le cas où l'urne possède initialement quatre objets. Quelle peut être la situation après dix transitions?  En considérant uniquement le nombre d'objets dans le premier contenant, on peut voir ce processus comme une marche aléatoire réfléchissante sur dont les probabilités changent selon l'état actuel. En effet, si tous les objets sont dans un contenant, il est certain qu'à la prochaine transition, l'autre contenant en recevra une. Pour les états intermédiaires, si le contenant possède objets, alors il en possèdera avec probabilité et avec probabilité . On peut illustrer cela par la matrice de transition . On pose comme vecteur initial . Avec Sage, on obtient représentant le portrait après dix transitions.    "
},
{
  "id": "computation-40",
  "level": "2",
  "url": "sec-Markov.html#computation-40",
  "type": "Calcul",
  "number": "7.1.11",
  "title": "Chaine de Markov et Sage.",
  "body": " Chaine de Markov et Sage  On va créer une fonction Sage qui prend comme argument une matrice de transition , un vecteur de probabilité et un entier facultatif qui retournera . Si l'entier n'est pas fourni, on retournera par défaut .   On peut vérifier les exemples de la sous-section en utilisant la fonction. Par exemple, pour la chaine de Markov de l'exemple , la cellule suivante montre l'évolution des parts de marché pour les dix premières transitions.   "
},
{
  "id": "proposition-80",
  "level": "2",
  "url": "sec-Markov.html#proposition-80",
  "type": "Proposition",
  "number": "7.1.12",
  "title": "Calcul de <span class=\"process-math\">\\(X_n\\)<\/span>.",
  "body": " Calcul de  Soit , la matrice d'une chaine de Markov et , l'état initial. Alors .   Il suffit de remarquer qu'en calculant par itération, on finit par arriver à : .   "
},
{
  "id": "ex-BVMarkovstable",
  "level": "2",
  "url": "sec-Markov.html#ex-BVMarkovstable",
  "type": "Exemple",
  "number": "7.1.13",
  "title": "L’état stable des compagnies téléphoniques.",
  "body": " L'état stable des compagnies téléphoniques  On reprend la chaine de Markov de l'exemple . On cherche à déterminer s'il existe un état stable.   On pose , pour . Le vecteur est un vecteur de probabilité. En effectuant le produit , on obtient un système d'équation à deux équations et une seule inconnue. On a , ce qui donne les deux équations , qui sont, en fait, à un multiple près, la même équation. La solution est . L'état stable de cette chaine de Markov existe et est .   "
},
{
  "id": "prop-etatstable",
  "level": "2",
  "url": "sec-Markov.html#prop-etatstable",
  "type": "Proposition",
  "number": "7.1.14",
  "title": "L’état stable et la convergence de la chaine de Markov.",
  "body": " L'état stable et la convergence de la chaine de Markov  Soit , une matrice stochastique finie telle que toutes les entrées de sont strictement plus grandes que zéro pour un certain . Alors, possède un unique état stable . De plus, pour tout vecteur de probabilité , on a .  Également, les puissances de la matrice convergent vers une matrice dont toutes les colonnes correspondent au vecteur de l'état stable.   "
},
{
  "id": "ex-meteoMarkovstable",
  "level": "2",
  "url": "sec-Markov.html#ex-meteoMarkovstable",
  "type": "Exemple",
  "number": "7.1.15",
  "title": "",
  "body": " On cherche l'état stable de la matrice de l'exemple . On peut procéder en résolvant un système d'équations linéaires, comme on l'a fait à l'exemple , mais puisqu'on sait que l'état stable existe et que toute distribution va converger vers celui-ci, on peut procéder numériquement en calculant une grande valeur de .  On procède par un calcul numérique, qu'on validera ensuite avec une démarche théorique.   On tente maintenant de trouver cette solution par une démarche algébrique. On pose pour . On a . On en déduit les trois équations . Ce système possède une solution unique, que l'on calcule à l'aide de Sage.    "
},
{
  "id": "ex-ruinestable",
  "level": "2",
  "url": "sec-Markov.html#ex-ruinestable",
  "type": "Exemple",
  "number": "7.1.16",
  "title": "État stable pour la ruine de joueur.",
  "body": " État stable pour la ruine de joueur   On cherche à savoir si un état stable existe pour la matrice de l'exemple . En fait, on peut déjà apercevoir qu'il y aura plus d'un état stable. Le vecteur est stable , puisque celui-ci redonne la première colonne de la matrice qui est aussi ce vecteur. De même, le vecteur fait la même chose avec la dernière colonne. En poursuivant la réflexion, on pourra déduire que tout vecteur de la forme sera un état sable. Pour savoir si la chaine de Markov, pour un état initial donné, converge vers un état stable, on se tourne vers le calcul d'une grande puissance.    On recopie dans la cellule ci-dessous le code nécessaire pour fabriquer la matrice.   Avec le vecteur , on obtient, en calculant une grande puissance de la chaine, que l'état stable est environ . Ceci signifie que le joueur de l'exemple a environ de chance de perdre tout son argent, contre de chance d'atteindre son objectif. Certains et certaines auront peut-être réalisé que l'état stable dépend forcément de l'état initial, contrairement aux autres exemples. Si l'on considère un joueur dont la mise initiale n'est que d'un dollar, dans des cas, le joueur se retrouve déjà ruiné et dans les autres cas, il se retrouve avec deux dollars. On sait alors qu'il possède, à partir de deux dollars, des chances de se ruiner. Les règles de probabilités établissent donc les chances de se ruiner à partir d'un montant initial égal à un dollar à . Ce calcul est un exemple de ce que l'on appelle les probabilités conditionnelles en théorie des probabilités. On vérifie le tout numériquement. La cellule ci-dessous donne l'état stable pour les chaines de Markov commençant à deux dollars et à un dollar.   On note que chacun de ces états stables est de la forme .   "
},
{
  "id": "exercise-358",
  "level": "2",
  "url": "sec-Markov.html#exercise-358",
  "type": "Exercice",
  "number": "7.1.4.1",
  "title": "",
  "body": "Considérer une chaine de Markov dont la matrice de transition est donnée par . Si l'état initial est donné par le vecteur , déterminer l'état après transitions. Il suffit de calculer Quel sera l'état à long terme de cette chaine? On cherche un vecteur état qui sera stationnaire et donc inchangé par la matrice de transition. On pose , cet état. Ainsi, . On obtient les équations suivantes: On résout pour trouver , le vecteur stable est donc . "
},
{
  "id": "exercise-359",
  "level": "2",
  "url": "sec-Markov.html#exercise-359",
  "type": "Exercice",
  "number": "7.1.4.2",
  "title": "",
  "body": "On considère la chaine de Markov se déroulant sur le graphe de la figure suivante.   Le graphe de l'exercice   Une graphe à quatre sommet est illustré avec des arêtes reliant certains sommets.     Déterminer la matrice de transition associée à une chaice de Markov sur ce graphe. Si un objet est placé au sommet du graphe et se déplace selon les règles, quel est l'endroit le plus probable où il peut se retrouver après deux transitions? Sur le sommet . Il faut calculer où est le vecteur de l'état initial. . On peut donc voir que la position la plus probable après deux transitions est la position . L'objet est oublié et continue ses déplacements pendant un bon moment. Une personne finit par l'apercevoir et note la position de l'objet. Quelles sont les probabilités qu'à ce moment, l'objet se trouve sur le sommet ? Environ . Sans connaitre l'état initial et le nombre de transitions effectuées jusqu'à maintenant, on ne peut répondre de manière exacte à cette question. Dans ce cas, la probabilité associée à l'état stable fournit la meilleure estimation. On pose , le vecteur stable recherché. Ainsi, . À partir de cette égalité vectorielle, on obtient le système d'équations linéaires . Une fois réduit (on a multiplié par pour éliminer les fractions), le système est équivalent à . On résout avec Gauss-Jordan: On obtient donc , et et ainsi, On conclut que la position est fréquentée du temps à l'état stable. C'est la meilleure estimation à donner pour la probabilité cherchée. "
},
{
  "id": "exercise-360",
  "level": "2",
  "url": "sec-Markov.html#exercise-360",
  "type": "Exercice",
  "number": "7.1.4.3",
  "title": "",
  "body": "On s'intéresse aux chaines de Markov à deux états dont la matrice de transition est avec . Déterminer l'état stationnaire d'une telle chaine. On cherche un vecteur de probabilité qui sera stationnaire et donc inchangé par la matrice de transition. On pose , cet état. On a , d'où l'on tire les équations suivantes . On obtient en résolvant , l'état stable est donc "
},
{
  "id": "exo-etatstablesouris",
  "level": "2",
  "url": "sec-Markov.html#exo-etatstablesouris",
  "type": "Exercice",
  "number": "7.1.4.4",
  "title": "",
  "body": "Calculer l'état stable de la chaine de Markov représentant le déplacement de la souris dans l'exemple .  La matrice de transition est donnée par . Un calcul montre que n'a pas d'entrée égale à zéro, il est donc possible de calculer une grande puissance de pour trouver l'état stable. Avec Sage, on trouve .   "
},
{
  "id": "exercise-362",
  "level": "2",
  "url": "sec-Markov.html#exercise-362",
  "type": "Exercice",
  "number": "7.1.4.5",
  "title": "",
  "body": "On considère la figure qui représente l'habitat d'une souris.   Un habitat de souris.   Le plan d'un habitat de souris, formé de sept pièces reliées par des portes.    Quelle est la matrice de transition associée à la chaine de Markov représentant cette situation? Sachant que la souris est présentement dans la pièce , quelle sera sa position la plus probable dans trois transitions? C'est la pièce numéro 4 qui est la plus probable.  On peut procéder par itération à partir du vecteur . On a , puis et finalement, .  Déterminer la pièce ayant la plus grande probabilité d'abriter la souris à long terme. Est-ce que cela parait logique? Utiliser Sage pour faire les calculs. La pièce .   C'est la pièce qui a le plus de chances d'abriter la souris à long terme. Cela semble plausible étant donné que c'est la pièce qui a le plus de portes. La souris devrait donc y transiter plus souvent.  "
},
{
  "id": "exo-ruineparieurgen",
  "level": "2",
  "url": "sec-Markov.html#exo-ruineparieurgen",
  "type": "Exercice",
  "number": "7.1.4.6",
  "title": "",
  "body": " On reprend la situation du parieur de l'exemple . Tout casino qui se respecte n'offre pas des probabilités équitables dans ses jeux de hasard. Pour simplifier, on considère toujours un joueur qui joue à un jeu qui ne possède que deux résultats possibles. Avec probabilité , le joueur gagne dollar et avec probabilité , il perd dollar.  Déterminer les probabilités de chaque état après cinq tours si . Comparer avec les résultats obtenus à l'exemple . Il est possible de modifier la fonction ruinetransitionproba de l'exemple pour construire la matrice. On peut aussi la construire manuellement. La cellule suivante construit la matrice de transition associée à cette chaine de Markov.   On calcule ensuite avec Sage.   On constate que, dans cette situation, le joueur a maintenant plus de de chance d'être ruiné après cinq jeux, contrairement à dans le jeu avec probabilité de succès égale à .  Déterminer les probabilités de succès du joueur. Tout comme à l'exemple , il faut approximer par pour une grande valeur de , puisque l'état stable dépend de l'état initial. Avec Sage, on trouve que le joueur a maintenant moins de de chance d'atteindre les cinq dollars avant de se ruiner, comparativement à dans la situation équiprobable. Un changement dans la probabilité de gagner à chaque tour de entraine un changement dans la probabilité de succès net de plus du double.    "
},
{
  "id": "exercise-364",
  "level": "2",
  "url": "sec-Markov.html#exercise-364",
  "type": "Exercice",
  "number": "7.1.4.7",
  "title": "",
  "body": "Lors de l'envoi d'information par un système informatique, cette information est encodée dans une chaine binaire, formée de ou de . Il arrive parfois, que lors du transfert, la chaine se corrompe. (Heureusement, il existe des techniques pour valider une chaine et déterminer si elle a été corrompue.) Chaque nombre dans une chaine est appelé un bit . On suppose qu'à chaque transfert, un bit a probabilité de rester le même et probabilité d'être changé. Les bits sont indépendants, c'est-à-dire que le fait que l'un change ou non n'affecte pas les autres.  On considère des chaines à deux bits d'information. Les possibilités sont et . On suppose .  Puisque l'état de la chaine binaire après un transfert ne dépend que de son état avant transfert, c'est une chaine de Markov. Écrire la matrice de transition associée à la chaine. La probabilité que deux évènements indépendants surviennent est le produit des probabilités de chacun des événements. Pour toute chaine, la probabilité de demeurer inchangé est obtenue par . La probabilité que le premier bit change, mais pas le deuxième est , tout comme la probabilité que le premier soit inchangé, mais que le deuxième le soit, puisque . Finalement, la probabilité que les deux bits soient changés est . La matrice de transition est donc On transmet comme information. Cette chaine passe de l'ordinateur d'un utilisateur à un réseau central, elle est ensuite envoyée aux serveurs d'une compagnie et se retrouve finalement sur l'ordinateur d'une autre utilisateur, d'une autre utilisatrice. La chaine a donc subi trois transferts. Quelle est la probabilité que le message soit toujours lors de la lecture par le deuxième utilisateur? (On note que le message pourrait avoir été corrompu en chemin, mais s'être corrigé de lui-même.) On pose , l'état initial. On cherche la troisième composante de . Avec Sage, on trouve que cette probabilité est d'environ , soit .   Calculer , comme on l'a souvent fait afin de déterminer l'état stable. Est-ce que le résultat contredit la proposition ?   Il semble ici que l'état stable ne soit pas le même pour chacune des colonnes. Toutefois, cela ne contredit pas la proposition . Celle-ci dit que les puissances de la matrice convergent vers l'état stable. Cette convergence peut, par contre, être plus lente dans certains cas. Une puissance plus élevée permet de voir que la matrice converge bel et bien vers un état stable.   "
},
{
  "id": "exercise-365",
  "level": "2",
  "url": "sec-Markov.html#exercise-365",
  "type": "Exercice",
  "number": "7.1.4.8",
  "title": "",
  "body": "Au tennis, le système de points est tel qu'un joueur doit faire quatre points pour gagner un jeu. Toutefois, il doit y avoir un écart de deux points entre les joueurs. Une situation particulière se produit lorsque le pointage est (ce qui correspond à trois points pour chacun des joueurs). On entre alors dans un état appelé égalité (aussi appelé deuce en anglais). Le prochain joueur à faire un point est alors considéré en avantage . S'il gagne le prochain point, il remporte le jeu et s'il le perd, on retourne à l'égalité. On peut modéliser la partie égalité d'un jeu de tennis par une chaine de Markov à cinq états. On note pour égalité, pour avantage serveur, pour avantage retourneur, pour la victoire du serveur et pour la victoire du retourneur. Chez les professionnels, le serveur est presque toujours considéré comme favori pour remporter le point. On suppose, que pour chaque point, le serveur a probabilité de remporter l'échange. Écrire la matrice de transition modélisant un jeu à partir de l'égalité.   Si un serveur a une probabilité de succès de , quelle est la probabilité qu'à partir de l'égalité, le jeu ne soit pas terminé après échanges?  Pour obtenir la probabilité que le jeu ne soit pas terminé, on doit additionner les probabilités que l'on soit à égalité ou à l'un des avantages.   On trouve qu'il y a environ de chance que le jeu ne soit pas terminé.  Quelle est la probabilité que le serveur remporte le jeu? Environ . Il faut trouver l'état stable à partir de l'état égalité. Comme la matrice possède toujours des entrées nulles, il faut procéder par le calcul d'une grande valeur de la chaine de Markov. On peut voir que le serveur a environ de chance de remporter le jeu.   "
},
{
  "id": "exercise-366",
  "level": "2",
  "url": "sec-Markov.html#exercise-366",
  "type": "Exercice",
  "number": "7.1.4.9",
  "title": "",
  "body": "Il est possible d'analyser certains jeux de société grâce aux chaines de Markov, particulièrement les jeux où peu de décisions sont prises par les joueurs. Les jeux pour enfants, comme serpents et échelles ou Trouble , se prêtent bien à cette analyse.  On propose d'étudier le jeu serpents et échelles en regardant dans un premier temps une version simplifiée.  On considère une partie de serpents et échelles se déroulant sur le plateau présenté à la figure suivante.   Une version simplifiée de serpents et échelles.   Un plateau de huit cases est illustré, la première identifiée D et la dernière A. Celles centrales sont identifiées de un à six. Une flèche allant de cinq à deux et une autre allant de un à quatre sont présentes.    Dans ce jeu, il y a huit cases. D'abord, on va créer un vecteur de déplacement à huit composantes qui correspondent, pour une position , à la case sur laquelle on se retrouve lorsqu'on atterrit sur la case . Pour les besoins de la cause, on associe la case départ à la position et la case d'arrivée à la position .  Créer le vecteur décrit dans l'introduction.   Étant donné la petite taille de ce plateau, le jeu se déroule avec une pièce de monnaie. Lorsqu'elle tombe sur pile , le joueur avance d'une case et, lorsqu'elle tombe sur face, le joueur avance de deux cases.  Créer une fonction tour qui, étant donné une position de départ et le vecteur de déplacement, retourne la nouvelle position du joueur après le lancer d'une pièce. On rappelle que la fonction choice peut être utilisée pour simuler du hasard.    Le code de la solution.   def tour(d,p): #fonction qui simule un tour de jeu, selon le vecteur de déplacement d et la position de départ p t=choice([1,2]) if p==7: return 7 else: return d[p+t]   Créer une fonction serpech , qui simule une partie de serpents et échelle sur ce plateau. La fonction prend comme argument le vecteur de déplacement et retourne le parcours du joueur.     Le code de la solution.   def serpech(d): p=[0] while p[-1]!=d[-1]: p.append(tour(d,p[-1])) return p    Approximer le nombre de coups nécessaires pour atteindre l'arrivée en simulant parties. La commande pour calculer la moyenne d'une liste est numpy.mean .     Le code de la solution.   d=vector([0,4,2,3,4,5,2,7]) M=[] for i in range(1000): M.append(len(serpech(d))-1) numpy.mean(M)     Toujours en simulant parties, déterminer approximativement la proportion de parties nécessitant plus de tours.     Le code de la solution.   d=vector([0,4,2,3,4,5,2,7]) M=[] for i in range(1000): M.append(len(serpech(d))-1) M21=[m for m in M if m>20] (len(M21)\/1000).n()     Créer une fonction transition_serpech qui, pour une liste de déplacements et un entier , retourne la matrice de transition d'une chaine de Markov du jeu où il est possible d'avancer de cases chaque tour.     Le code de la solution.   def transition_serpech(d,n): #Retourne la matrice de transition selon un vecteur de déplacement d et un dé à n faces cols=[] for case in range(len(d)): #On crée les colonnes de la matrice col=vector(QQ,[0 for i in range(len(d))]) #On initialise la colonne au vecteur nul. À noter qu'on spécifie QQ pour que Sage accepte les rationnels if case==len(d)-1: #Si l'on est à l'arrivée col[-1]=1 cols.append(col) break valide=0 #On compte combien de lancers de dés sont valides, au sens où ils ne dépassent pas l'arrivée for poss in range(1,n+1): #On peut avancer de 1,2,...,n if case+poss<=len(d)-1: #Si le déplacement est valide valide+=1 for poss in range(1,valide+1): #Pour les déplacements valides col[d[case+poss]]+=1\/valide #On ajoute 1\/valide aux chances de se retrouver à cette position. Il est important de l'ajouter et de ne pas remplacer, au cas où, lors d'un même tour, on peut atteindre une case à la fois par un lancer de dé et par un serpent ou une échelle. cols.append(col) #On ajoute la colonne à la liste des colonnes T=column_matrix(cols) #La matrice de transition return T    Utiliser cette fonction pour créer la matrice de transition du jeu simplifié serpents et échelles .     Quel est le nombre minimal de tours nécessaires pour terminer une partie? Quelle est la probabilité qu'une partie se termine en aussi peu de tours?   Le nombre minimal de tours est et les chances sont de .  Le code de la solution.   T=transition_serpech(d,2) X0=vector([1,0,0,0,0,0,0,0]) X=X0 i=0 while X[-1]==0: i+=1 X=T*X print(\"Le nombre de tours minimal est \",i) print(\"Les chances sont \",X[-1])    À la partie , on a estimé le nombre de parties qui n'étaient pas terminées après tours. Déterminer la véritable valeur de ce nombre à l'aide de la matrice de transition.   Le code de la solution.   (1-(T^20*X0)[-1]).n()   On regarde maintenant la véritable version du jeu serpents et échelles . L'original se déroule sur un plateau contenant cases et possédant huit échelles et huit serpents. Plusieurs plateaux existent, selon la compagnie qui publie le jeu. Le dictionnaire python ci-dessous donne le début des serpents et des échelles ainsi que leur fin, pour la version accessible à l'auteur au moment de la rédaction.   Le vecteur de déplacement dans ce jeu est un vecteur à composantes, le départ étant toujours en position et l'arrivée en position . Créer une fonction qui prend comme argument la configuration des serpents et des échelles et qui retourne le vecteur de déplacement.   Initialiser un vecteur contenant les valeurs de à et changer les entrées correspondant aux serpents et aux échelles.   Le code de la solution.   def deplacement(config): d=vector(range(101)) for i in config.keys(): d[i]=config[i] return d deplacement(config)     Modifier la fonction tour de la partie afin que les déplacements possibles soient compris entre et plutôt qu'entre et . Il pourrait aussi être nécessaire de modifier d'autres parties de la fonction selon la manière dont elle a été construite. Utiliser la fonction serpech pour simuler une partie.     Le code de la solution.   def tour(d,p): #fonction qui simule un tour de jeu, selon le vecteur de déplacement d et la position de départ p t=choice([1,2,3,4,5,6]) if p==100: #On modifie l'arrivée return 100 else: return d[min(100,p+t)] #Une manière de s'assurer de ne pas dépasser 100 def serpech(d): p=[0] while p[-1]!=d[-1]: p.append(tour(d,p[-1])) return p def deplacement(config): d=vector(range(101)) for i in config.keys(): d[i]=config[i] return d d=deplacement(config) serpech(d)    Approximer le nombre de coups nécessaires pour atteindre l'arrivée en simulant parties. La commande pour calculer la moyenne d'une liste est numpy.mean .    Le code de la solution.   M=[] for i in range(1000): M.append(len(serpech(d))-1) numpy.mean(M)     Toujours en simulant parties, déterminer approximativement la proportion de parties nécessitant plus de tours.     Le code de la solution.   M=[] for i in range(1000): M.append(len(serpech(d))-1) M21=[m for m in M if m>20] (len(M21)\/1000).n()     Créer la matrice de transition de cette chaine de Markov. Quel est le nombre minimal de tours nécessaires pour terminer une partie? Quelle est la probabilité qu'une partie se termine en aussi peu de tours?   Le nombre minimal de tours est et les chances sont de .  Le code de la solution.   T=transition_serpech(d,2) X0=vector([1,0,0,0,0,0,0,0]) X=X0 X=X0 i=0 while X[-1]==0: i+=1 X=T*X print(\"Le nombre de tours minimal est \",i) print(\"Les chances sont \",X[-1])   À la partie , on a estimé le nombre de parties qui n'étaient pas terminées après tours. Déterminer la véritable valeur de ce nombre à l'aide de la matrice de transition.   Le code de la solution.   (1-(T^20*X0)[-1]).n()   Créer une liste contenant les chances que le jeu soit terminé au tour , pour allant de à . À l'aide des fonctions zip et point , tracer le graphique des probabilités que le jeu soit terminé en fonction du nombre de tours.   Le code de la solution.   fin=[((T^n*X0)[-1]).n() for n in range(200)] coordx=list(range(200)) point(list(zip(coordx,fin)))    "
},
{
  "id": "sec-simplexe",
  "level": "1",
  "url": "sec-simplexe.html",
  "type": "Section",
  "number": "7.2",
  "title": "La programmation linéaire",
  "body": "  La programmation linéaire    Aller aux exercices de la section.  Le chapitre devrait suffire pour comprendre ce chapitre.  Au chapitre , on a vu comment représenter des droites dans le plan et dans l'espace et comment déterminer l'intersection de droites. Au chapitre , il a été question de la méthode de Gauss-Jordan pour résoudre un système d'équations linéaires en échelonnant la matrice représentant ce système. L'analyse de cette forme échelonnée réduite a permis de décomposer les solutions en fonction de ce qu'on a appelé les solutions de base et la solution particulière , formant à elles deux la solution générale. Les notions de ces deux chapitres sont suffisantes pour comprendre cette section.  Dans cette section, on s'intéresse à la solution à des problèmes d'optimisation posés sous la forme d'un programme linéaire, c'est-à-dire comme un ensemble d'égalités et d'inégalités. L'objectif est de maximiser ou de minimiser une fonction tout en satisfaisant à plusieurs contraintes.  Historiquement, on retrouve les premières tentatives de résolution des problèmes que l'on étudiera dans cette section par le mathématicien russe Leonid Kantorovich et par l'économiste Wassily Leontief. Le premier souhaitait résoudre des problèmes de fabrication d'horaires, alors que le second se penchait sur des problèmes économiques divers. La nécessité de résoudre ces problèmes efficacement et rapidement fut ensuite accentuée par la Deuxième Guerre mondiale. La méthode du simplexe, que l'on étudiera, a été établie en 1947 par George Dantzig et perfectionnée au fil des ans. La méthode s'applique aux problèmes qui demandent d'optimiser une fonction de vers sujette à des contraintes d'inégalité.  Dans cette section, on présente le côté géométrique d'un problème de programmation linéaire lorsque le nombre de variables est relativement peu élevé. Par la suite, on présente l'algorithme du simplexe, qui permet de résoudre ces problèmes en utilisant les notions du chapitre . On aborde, entre autres, la notion de fonction objectif, la notion de contraintes technologiques, la notion de région admissible, le concept de variables d'écart, le concept de variable en base et de variable hors base, la notion de matrice initiale du simplexe et le concept de dualité en optimisation.    Approche graphique à un problème d'optimisation linéaire  On considère une fonction de deux variables . Sans contraintes, cette fonction peut être aussi grande que l'on veut, en prenant de grandes valeurs pour . Par contre, si l'on suppose que , et , alors les possibilités sont beaucoup plus restreintes. Il est possible d'illustrer chacune de ces contraintes dans le plan cartésien. Prisent ensemble, on obtient ce que l'on appelle la région admissible , soit l'ensemble des valeurs des variables qui satisfont aux contraintes. La figure ci-dessous illustre la région admissible de la situation décrite ci-haut. En anglais, la région admissible est appelée feasible region , d'où le au centre de la région admissible. On peut voir, dans la figure, chacune des contraintes ainsi que leur intersection; l'ensemble des valeurs qui satisfont simultanément toutes les contraintes.   Région admissible de la situation décrite.   La région admissible est montrée en gris.     Parmi toutes les valeurs de la région admissible, au moins un couple devrait donner le maximum de la fonction . Pour trouver où ce maximum est atteint, il est impossible de tester chacune des valeurs possibles. On peut cependant raisonner comme suit. Soit , un point à l'intérieur de la région admissible. Selon la nature de la fonction , la fonction est croissante selon la variable et selon la variable . Si le point se trouve à l'intérieur de la région, plutôt que sur sa frontière, alors, une variation vers la droite pour ou vers le haut pour entraine une augmentation de la valeur de . Pour ces raisons, le maximum devrait être atteint sur la frontière. Un argument semblable montre qu'en fait, le maximum se trouvera en un sommet du polygone formant la frontière de la région admissible.  On peut aussi arriver à cette conclusion en considérant les droites , pour des valeurs fixes de . Ces droites sont un exemple de ce qu'on appelle les courbes de niveau d'une fonction. Ces courbes de niveau sont très utiles pour visualiser les fonctions de plusieurs variables à valeur réelle. Chaque valeur de représente une valeur possible pour la fonction et l'intersection de la région admissible avec une telle droite donne les points de la région pour lesquels . En augmentant la valeur pour , on arrive à trouver la plus grande valeur qui fait en sorte que la droite possède toujours au moins une intersection avec la région admissible. Cette intersection contient nécessairement un sommet, mais pourrait aussi contenir tout un segment du polygone.  La figure interactive ci-dessous permet de manipuler un point dans le polygone et de voir son image par la fonction , ainsi que de visualiser les droites pour des valeurs positives de .   Optimisation sous forme dynamique    L'exemple ci-dessus comporte les caractéristiques essentielles d'un problème de programmation linéaire en deux dimensions. L'exemple suivant contextualise un problème différent et le résout en utilisant les observations faites ci-dessus. La justification de ses observations sera présentée ultérieurement.   Optimisation de l'allocation de ressources  On considère un fermier qui dispose d'une certaine superficie de terrain pour cultiver deux types de plantes : le maïs et le soja. Chaque culture nécessite un certain temps de travail et des ressources spécifiques pour atteindre un certain rendement. Le fermier dispose d'un nombre limité d'heures de travail par semaine et d'un nombre limité d'engrais.  Pour une semaine donnée, le fermier est prêt à allouer heures à la production des deux types de plantes et il possède kg d'engrais. Chaque tonne de maïs se vend $ au marché et chaque tonne de soja se vend $. De plus, la production d'une tonne de maïs nécessite kg d'engrais et heures de travail, tandis que la production d'une tonne de soja requiert kg d'engrais et heures de travail.  Quelle devrait être la quantité produite pour chacune de ces plantes afin de maximiser le profit durant cette semaine?    On pose pour représenter les tonnes de maïs et de soja qui seront produites. La fonction à maximiser est , qui est sujette aux contraintes et , qui constituent les contraintes logiques, ainsi que , qui constituent les contraintes de non-négativité. On trace la région admissible à la figure suivante.   Région admissible de la situation décrite.   La région admissible est montrée en gris.     La frontière possède quatre sommets dont l'un sera le maximum. Pour le trouver, on évalue la fonction à chacun des sommets. La plus grande valeur sera le maximum. Les sommets étant et , on trouve . Le maximum se trouve lorsque l'on produit dix tonnes de maïs et dix tonnes de soja.     Optimisation de la production de chaises et de tables   Une entreprise fabrique des meubles en bois. Elle produit deux types de meubles, des chaises et des tables. La production d'une chaise nécessite planches de bois, boites de vis et heure de travail, tandis que la production d'une table nécessite planches de bois, boites de vis et heures de travail. L'entreprise dispose de planches de bois, boites de vis et heures de travail pour la production. Une chaise est vendue à dollars et une table à dollars. L'entreprise cherche à maximiser son chiffre d'affaires.    On note par le nombre de chaises produites et le nombre de tables produites. La fonction à optimiser est . La figure suivante représente la région admissible provenant des contraintes .   Région admissible de la situation décrite.   La région admissible est montrée en gris.     La région admissible est formée d'un polygone à quatre sommets. En plus des axes, trois droites forment les côtés de ce polygone. On peut trouver les coordonnées des sommets qui ne se retrouvent pas sur les axes en déterminant les intersections de chaque paire de droites. Les équations des droites correspondent aux contraintes, en remplaçant l'inégalité par une égalité. On trouve et . L'image de chacun de ces points par la fonction est . On voit que la valeur maximale des ventes se trouve lorsque le nombre de chaises produites est égal à et le nombre de tables fabriquées est de .    Les exemples précédents montrent comment on peut maximiser une fonction linéaire soumise à des contraintes, mais la minimisation d'une telle fonction se résout avec la même méthode.   Minimisation du cout de nutriments  Pour un régime particulier, une personne a besoin d'obtenir une quantité précise de nutriments chaque semaine. Il lui est possible de se procurer la poudre , au cout de $ par grammes, et la poudre , au cout de $ par grammes. La quantité pour chacun des trois nutriments, ainsi que la quantité quotidienne requise, sont données dans la table ci-dessous.   Les nutriments nécessaires au régime.                 A (par 100g)  3  2  1    B (par 100g)  2  4  3    Besoins  28  30  20     La personne peut se permettre un budget maximal de $ par semaine pour ces produits.  On peut traduire ce problème en considérant la fonction qui est assujettie aux contraintes . La figure ci-dessous illustre la région admissible.   Région admissible de la situation décrite.   La région admissible est montrée en gris.     Les sommets de la région admissible se trouve en et . Le cout pour chacune de ces paires est de . Le cout minimal est donc, à deux décimales près, de $. À ce prix, la personne achètera, toujours à deux décimales près, grammes de la poudre et grammes de la poudre .    Une certaine structure se dégage des problèmes précédents. Une fonction linéaire doit être optimisé en fonction de contraintes, aussi linéaires, qui viennent restreindre les valeurs possibles de cette fonction. Comme tout est linéaire, il est plausible de penser que l'on peut encoder l'information pertinente à un tel problème dans une matrice ou un vecteur. La forme canonique d'un problème de programmation linéaire permet de faire l'encodage de cette manière. On donne dès maintenant la définition générale. La méthode pour résoudre un problème où un nombre trop grand de variables est présent pour le résoudre géométriquement sera présentée dans la sous-section suivante.   Forme canonique d'un problème de programmation linéaire  On considère une fonction linéaire et un ensemble de contraintes de la forme , appelées les contraintes d'inégalité , ainsi que les contraintes de non-négativité .  Si l'objectif est de maximiser la fonction sous les contraintes, on dit alors que le problème est un problème de programmation linéaire et qu'il est sous forme canonique . La fonction est appelée la fonction objectif . De manière naturelle, il en découle la réécriture suivante: . Dans cette formulation, il est sous-entendu qu'une inégalité entre deux vecteurs s'applique sur chacune des composantes correspondantes.  Un vecteur qui satisfait les deux contraintes est une solution admissible . L'ensemble des solutions admissible forme la région admissible  et le vecteur est la solution optimale .    Cette forme suppose que l'on cherche toujours un maximum de la fonction objectif. Pour résoudre un problème de minimisation sur une fonction , on peut remplacer par . Ainsi, lorsque atteint son maximum, la fonction , elle, atteint son minimum. Également, on peut transformer les contraintes de la forme en multipliant par pour obtenir . Si une contrainte d'égalité était présente, on pourrait la remplacer par deux contraintes d'inégalités. Ainsi, deviendrait .  Dans l'exemple qui suit, on réécrit les trois problèmes, présentés plus haut, sous leur forme canonique.   Forme canonique des trois problèmes  On considère à nouveau les problèmes des exemples , et . On veut écrire la forme canonique de chacun de ces problèmes.  On pose , , et . En tenant compte des contraintes de non-négativité, le problème est sous forme canonique. Les contraintes, de même que la fonction objectif, n'ont pas eu à être réécrites puisqu'elles étaient déjà sous la bonne forme.  On pose , , et . En tenant compte des contraintes de non-négativité, le problème est sous forme canonique. Les contraintes, de même que la fonction objectif, n'ont pas eu à être réécrites puisqu'elles étaient déjà sous la bonne forme.  Cette fois-ci, le problème, sous sa forme initiale, comprend des contraintes de la forme et porte sur la minimisation d'une fonction. On remplace la fonction par . On peut alors poser . On remplace les trois contraintes par qui, avec la contrainte sur le cout , donne le vecteur et la matrice . En tenant compte des contraintes de non-négativité, le problème est maintenant sous forme canonique.   Pour toute combinaison de fonction objectif et d'ensemble de contraintes sous forme canonique, il n'y a que trois choses qui peuvent survenir. Les contraintes peuvent être incompatibles, ce qui fait que le problème n'a pas de solution. Ce serait le cas si, par exemple, on demandait à la fois d'avoir et . Les contraintes peuvent faire en sorte que la région admissible n'est pas bornée. Si ceci entraine que la fonction objective peut prendre des valeurs aussi larges que l'on veut, alors le maximum n'existe pas. Finalement, dans tous les autres cas, la fonction objective atteint un maximum. Ce dernier se trouve à au moins un des sommets de la région admissible.  On termine avec des commandes Sage en lien avec la sous-section.   Géométrie de la programmation linéaire avec Sage  Sage possède un module pour explorer la programmation linéaire. On y définit les vecteurs , ainsi que la matrice . En principe, il n'est pas obligatoire d'avoir la matrice du problème sous forme canonique, car il est possible de spécifier le type d'inégalité et le type de problème (maximisation ou minimisation). Une fois les vecteurs et la matrice définis, la commande InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") permet de créer la structure du programme linéaire. Les arguments A,b,c sont, dans l'ordre, la matrice des contraintes, le vecteur de ces contraintes et le vecteur des coefficients de la fonction objectif. L'argument [\"x\", \"y\"] donne le nom aux variables. Finalement, l'argument variable_type donne le type d'inégalité, à savoir si les variables doivent être non négatives ou autre chose.  Dans un premier temps, on regarde l'exemple d'introduction qui a servi à motiver la sous-section. En ajoutant la ligne %display typeset à la cellule Sage, il est possible de visualiser l'écriture du problème à même sage.   La commande feasible_set permet de visualiser la région admissible (lorsque le nombre de variable est deux ou trois).   On peut aussi reproduire la région admissible et les contraintes à l'aide de la commande plot_feasible_set . Cette dernière offre plus de flexibilité quant au secteur qui peut être visualisé et à l'opacité de la région admissible.   On peut obtenir directement les coordonnées des sommets de la région admissible à l'aide de la commande vertices .   Ce format n'est pas pratique pour les calculs puisqu'il contient du texte. On peut extraire les vecteurs à l'aide de la fonction suivante.   S contient maintenant la liste des sommets de la région admissible. Comme la fonction objectif est encodée dans le vecteur , on peut l'évaluer en chacun des points de S à l'aide du produit scalaire.   Bien entendu, on peut aussi calculer la solution optimale avec une commande.   Sage peut aussi calculer graphiquement la solution. Il illustre quelques-unes des courbes de niveau et indique le maximum sur le graphique avec un flèche noire. Cette flèche, toujours parallèle à la courbe de niveau, indique la direction qui produit la plus grande variation de la fonction. Dans un cours de calcul de fonctions à plusieurs variables, cette direction est celle qui maximise le gradient de la fonction. Cette direction est aussi très utile dans les problèmes d'apprentissage profond.   On reprend maintenant l'exemple , qui n'était pas sous forme canonique. On montre que Sage peut quand même travailler avec cette forme, si on lui spécifie correctement le type de contraintes et de problème. On peut aussi convertir un problème à sa forme canonique.  Si l'on entre les valeurs telles qu'elles sont données dans le problème, sans égard à la forme canonique, on voit rapidement que le programme créé par Sage ne correspond pas à celui que l'on veut résoudre.   On remédie à cette situation en ajoutant un argument problem_type=\"min\" et un argument constraint_type . Ces arguments permettent à Sage de comprendre que l'on cherche le minimum de la fonction et que les trois premières contraintes sont de type .   À partir de ce programme corrigé, on peut extraire les mêmes informations que pour le problème d'introduction.   Il est possible d'obtenir la matrice, le vecteur et le vecteur d'un problème de programmation linéaire.   Finalement, la commande standard_form permet de convertir un programme existant en forme canonique. On peut en constater l'effet en regardant la matrice et les vecteurs associés au nouveau programme.      L'algorithme du simplexe  La méthode de résolution par la géométrie des problèmes de programmation linéaire est pratique, mais n'est pas envisageable lorsque le problème comporte plusieurs variables. À titre d'exemple, on considère une compagnie qui possède plusieurs points de vente et un certain nombre d'entrepôts. Lorsque les points de vente passent une commande à la maison mère, celle-ci doit regarder l'inventaire disponible dans ses entrepôts et décider de la manière la plus efficace de livrer à ses points de vente les biens demandés.  On peut facilement imaginer une grande compagnie avec des centaines de boutiques, des dizaines d'entrepôts et des milliers de produits. Imaginer la géométrie d'un tel problème est impensable. Si l'on pense au fait que le maximum se trouve sur la frontière, plus particulièrement sur l'un des sommets de la région admissible, on peut alors intuitivement élaborer la méthode suivante pour le trouver. On fixe d'abord un sommet de la région admissible. Souvent, ce sommet sera celui où toutes les variables sont nulles; ce sommet est rarement l'extrémum cherché. Comme la valeur cherchée se trouve à l'un des sommets, on regarde tous les sommets voisins du sommet choisi initialement et l'on compare la variation dans chacune des directions. Celle qui offre la plus grande variation (dans le cas de la recherche d'un maximum, on voudra une variation positive) est choisie et l'on se rend jusqu'au prochain sommet. On répète ensuite jusqu'à ce que toutes les directions voisines à un sommet ne procurent plus de variation permettant d'améliorer la fonction objectif. On a alors atteint l'extremum recherché. La figure permet d'illustrer cela dans le cas où il y a deux variables. En partant du point à l'origine, on peut choisir de se déplacer horizontalement vers le point ou verticalement vers le point . Puisque chaque unité de déplacement en produit une variation de la fonction objectif de et que chaque unité de déplacement en produit une variation de la fonction objectif de , on choisit de se déplacer vers le point . Par la suite, il ne reste qu'une direction à choisir étant donné que chaque sommet n'est relié qu'à deux autres. Le principe est le même pour un plus grand nombre de variables, avec plus de choix possibles pour naviguer entre les sommets.  Pour effectuer la méthode du simplexe, on commence par transformer les contraintes d'inégalité (sauf les contraintes de positivité) en leur ajoutant une variable d'écart positive. Ainsi, la contrainte devient où , puisque et que l'inégalité stipule que est inférieur à .  Variable d'écart  Une variable d'écart est une variable positive qui est ajoutée au plus petit côté d'une inéquation afin de la transformer en égalité.   Ajout des variables d'écart dans les contraintes  On reprend les données de la forme canonique des exemples , et afin de convertir les contraintes d'inégalité sous forme d'égalité.    Dans le cas des contraintes du problème , on a , qui deviennent   Pour les contraintes du problème , on a qui deviennent où .  Finalement, pour les contraintes du problème , sous sa forme canonique, on a , qui deviennent .    Lorsqu'un problème de programmation linéaire à variables possède contraintes d'inégalité, l'ajout de variables d'écart crée un système d'équations linéaires à équations et inconnues. Une solution à ce système d'équations est appelée une solution de base si au plus des variables sont non nulles. La solution est admissible lorsque toutes les variables sont plus grandes ou égales à zéro. Ensemble, ces deux conditions mènent à la définition suivante.   Solution de base admissible   Soit , une matrice et , un vecteur. Une solution à l'équation est une solution de base admissible si toutes les valeurs de la solution sont supérieures ou égales à zéro et qu'au plus de ces valeurs sont non nulles.  Les variables non nulles d'une solution de base sont appelées les variables en base . Les variables nulles sont dites hors base .    On considère le problème d'introduction cherchant à maximiser sous les contraintes . En ajoutant les variables d'écart, on obtient le système d'équations linéaires représenté par la matrice augmentée . Les deux premières colonnes représentent les variables du problème en soi, les trois suivantes contiennent les valeurs des variables d'écart et la dernière est celle de la partie augmentée du système. En plus de la ligne verticale pour la partie augmentée, une autre ligne verticale a été ajoutée afin de séparer les deux catégories de variables.  Sans même échelonner cette matrice, on peut voir que, si et et , on a une solution. Comme il y a variables non nulles, la solution est de base et, puisque toutes les variables sont plus grandes ou égales à , elle est aussi admissible.  Une autre solution de base admissible est possible lorsque . On remarque alors que cette solution est de base, puisqu'il y a variables non nulles, mais qu'elle n'est pas admissible, étant donné la présence du négatif dans la troisième variable d'écart.  Les solutions admissibles se retrouvent dans la région admissible (sans surprise) et les solutions de base, elles, se retrouvent à l'intersection des contraintes d'inégalité. Les solutions de base admissibles sont donc aux sommets de la région admissible. La figure ci-dessous est une modification de la figure dans laquelle on a libéré le point et l'on a ajouté la valeur des variables du problème et des variables d'écart. On peut voir qu'une solution est admissible si elle est dans la région admissible et est de base lorsqu'elle est sur l'un des sommets.   Solution de base admissible.    Dans la matrice de l'équation , on peut voir dans les colonnes et une matrice identité. En fixant aux variables associées à ces colonnes les valeurs dans la dernière colonne, on a obtenu la première solution présentée plus haut. Si l'on effectue l'opération élémentaire suivie de l'opération élémentaire , on obtient la matrice . En regardant maintenant les colonnes et , on trouve à nouveau une matrice identité qui, comme ci-dessus, offre la solution de base obtenues auparavant. Le fait que les solutions de base se trouvent de cette manière donne un sens à l'appellation de base . En effet, dans le cas des systèmes d'équations linéaires, la définition et le reste de cette section montrent que, pour trouver les solutions de base d'un système d'équations linéaires, on peut utiliser la matrice identité qui se trouve à l'intérieur de la forme échelonnée réduite de la matrice du système. Par contre, la solution trouvée ici n'est pas admissible, car elle ne respecte pas la troisième contrainte.  Il est donc possible de trouver les solutions de base (celles qui sont associées au problème d'optimisation) en effectuant des opérations élémentaires sur les lignes afin de changer la position de la matrice identité se trouvant à l'intérieur de la matrice des contraintes. Par exemple, à partir de la matrice de l'équation , on peut remettre la variable en base et obtenir une solution de base en effectuant d'abord l'opération élémentaire , puis l'opération élémentaire . Ces opérations donnent la matrice , offrant cette fois-ci comme solution . La figure permet de constater que cette réponse est la solution optimale trouvée tout au début de la section. L'opération qui consiste à prendre une des variables et de transformer sa colonne à l'identité est appelé le pivotage . Le nom vient du fait que le rôle de la variable ressemble à celui d'un pivot, qui est le seul élément non nul de sa colonne et valant , sans toutefois être le premier élément non nul de la ligne.  Quelle entrée doit-on choisir pour effectuer le pivotage? En excluant la dernière colonne, il y a potentiellement soixante manières de transformer la matrice pour y faire apparaitre une matrice identité dans trois de ses colonnes. Pour un système à plus d'équations et d'inconnues, le nombre est encore plus élevé. Pour s'assurer de ne pas obtenir des solutions non admissibles, on choisit la ligne de l'équation pour effectuer le pivotage en considérant les deux critères suivants:  Si l'on veut pivoter l'entrée en position , il faut que le coefficient soit plus grand que zéro. Ceci assure que le terme dans la partie augmentée sera positif. Comme ce terme correspond à la valeur de la variable de la colonne dans la solution de base, elle doit être positive pour être admissible.  Une fois décidé que la colonne sera celle à pivoter, on détermine la ligne en choisissant, parmi celles où les entrées de la colonne sont positives, la ligne où le ratio est le plus petit. Ceci assure que, dans l'élimination de la colonne , les autres termes de la partie augmentée restent positifs.  Une dernière considération, qui sera discutée plus tard, prend en compte un vecteur augmenté comportant des entrées nulles ou négatives. Cette situation est fréquente lorsque le problème à résoudre est un problème de minimisation.   Choix de la ligne pour le pivotage  On considère le système , qui provient de l'ajout des variables d'écart aux données du problème . La matrice associée est . Toutes les entrées de la matrice des coefficients sont positives, ce qui signifie que l'on peut pivoter selon n'importe quelle variable. Si l'on veut pivoter selon la variable , quelle ligne doit-on choisir?   On choisit la ligne deux, puisque . Afin de voir l'effet des trois choix de ligne et pour confirmer que la ligne deux est bien celle à privilégier, on utilise Sage pour voir l'effet du pivotage pour chaque entrée de la première colonne.      On voit en effet que seule la ligne deux conserve des valeurs positives dans la partie augmentée.    Le choix de la ligne se fait donc à partir de conditions sur les éléments des lignes de la matrice. Qu'en est-il du choix de la colonne? C'est la fonction objectif qui guidera le choix de la variable sur laquelle pivoter. Comme il est décrit dans l'introduction de cette sous-section, on cherche à se déplacer d'une solution de base admissible à une autre en allant dans la direction qui offre la plus grande variation de la fonction objectif. Puisque la fonction est linéaire, les variations dans chacune des directions sont simplement données par la valeur des coefficients qui multiplient les variables. On ajoute une ligne au bas de la matrice contenant les contraintes avec les variables d'écart ainsi qu'une colonne entre la dernière variable d'écart et la colonne représentant la partie augmentée. Dans l'exemple d'introduction, où la fonction à maximiser est , on crée une nouvelle équation en écrivant . La nouvelle variable représente la fonction à optimiser. La matrice devient .  La colonne à choisir pour pivoter est celle qui a la plus petite valeur négative dans la dernière ligne (négative, car les coefficients ont changé de côté dans l'équation). Si toutes les valeurs sont positives, il n'est plus possible d'améliorer la solution. Dans ce cas, la première variable est celle sur laquelle on pivote et l'on choisit la première ligne, puisque . Lorsque l'on effectue les opérations élémentaires, on considère également la dernière ligne. Après pivotage en utilisant les opérations élémentaires et , la matrice devient . La matrice identité se trouve dans les colonnes un, quatre et cinq, offrant comme solution de base et donnant comme valeur pour la fonction . Ceci correspond bien à une solution de base admissible, que l'on peut visualiser sur la figure .  La seule valeur négative de la dernière ligne est dans la deuxième colonne. C'est donc selon que le pivotage se poursuit. La troisième ligne sera choisie étant donné que . Après les opérations élémentaires, on a . La solution de base correspondant à cette solution est , qui donne comme valeur à la fonction . Cette solution est bel et bien la solution optimale au problème, car on voit que toutes les valeurs de la dernière ligne de la matrice sont positives. En réécrivant l'équation correspondant à cette dernière ligne, on voit que et, comme sont positives ou nulles, doit être le maximum.   Matrice initiale du simplexe  On considère un problème de programmation linéaire à variables et contraintes, sous sa forme canonique. On note , la matrice des coefficients des contraintes, on note , la matrice identité , on note , le vecteur des membres de droite et finalement, on note , le vecteur des coefficients de la fonction objectif.  La matrice initiale du simplexe associée au problème de programmation linéaire est la matrice .  La partie de matrice contenant les matrices et est appelé le bloc principal de la matrice . Cette appellation est de l'auteur.    La matrice initiale du simplexe permet d'exécuter efficacement les étapes de l'algorithme du simplexe, présenté ci-dessous, et offre une manière concise de visualiser les informations pertinentes.   La méthode du simplexe   On considère un problème de programmation linéaire sous forme canonique et , sa matrice initiale du simplexe. Pour trouver le maximum de la fonction objectif, on suit la procédure suivante.   L'algorithme du simplexe   Regarder la dernière ligne de la matrice du simplexe. Si toutes les entrées correspondant aux variables des contraintes et aux variables d'écart sont positives, la solution est optimale et l'algorithme est terminé. En cas de présence de valeurs négatives, sélectionner la colonne de la variable dont l'entrée de la dernière ligne est la plus petite (négative) pour effectuer le pivotage.  Pour chaque entrée positive de la colonne choisie, calculer le rapport entre l'entrée de la dernière colonne et celle de la colonne choisie. La ligne où ce rapport est le plus petit est la ligne de pivot.  Effectuer le pivotage en rendant chaque élément de la colonne pivot égal à zéro, hormis ce pivot. La matrice offre maintenant une nouvelle solution de base admissible pour le problème.  Répéter les étapes ci-dessus jusqu'à ce que toutes les entrées de la dernière ligne soient positives.       L'algorithme du simplexe en action  On considère le problème de la culture de maïs et de soja de . La matrice initiale du simplexe est . On veut appliquer l'algorithme du simplexe à cette matrice afin de trouver la solution optimale.  On applique les étapes de l'algorithme du simplexe.  La dernière ligne comporte deux valeurs négatives. La plus petite est dans la deuxième colonne, c'est donc la variable qui sera sélectionnée pour effectuer le pivotage.  Toutes les valeurs de la partie supérieure de la matrice sont positives. On calcule les rapports de l'entrée de la dernière colonne sur l'entrée de la deuxième colonne pour les lignes de la matrice. On obtient, pour la ligne un, le rapport , et pour la deuxième ligne, le rapport . On sélectionne la première ligne pour effectuer le pivotage.  Le pivot est donc l'entrée de la première ligne et de la deuxième colonne. On applique les opérations élémentaires pour modifier la matrice. On a Puisque la dernière ligne comporte toujours une entrée négative, on recommence le processus.    La seule valeur négative de la matrice est dans la première colonne. On pivote selon la variable .  Les deux valeurs du haut de la première colonne sont positives. On compare donc les ratios. Puisque , on pivote par rapport à la deuxième ligne.  On applique les opérations élémentaires pour retrouver des zéros aux lignes non pivots, l'entrée en position étant déjà égale à . On obtient . Comme la dernière ligne ne contient que des entrées positives, l'algorithme est terminé.  On lit la solution dans la matrice. La valeur maximale se trouve dans la dernière ligne et vaut . La solution est atteinte lorsque (obtenue de la deuxième ligne) et (tirée de la première ligne).   On regarde un autre exemple dans lequel on ne décrit pas tous les détails des étapes de l'algorithme. On se contente de faire les opérations nécessaires en justifiant à l'occasion certains choix.   Optimisation de la production de chaises et de tables avec la méthode du simplexe   On considère à nouveau le problème de l'exemple , dont la matrice initiale du simplexe est donnée par .  On trouve la valeur maximale de la fonction objectif à l'aide de la méthode du simplexe.    En suivant les étapes de l'algorithme du simplexe, on choisit comme premier pivot l'entrée de la deuxième colonne et de la première ligne. On obtient . Toutes les entrées de la dernière ligne étant positives, l'algorithme se termine. La solution maximale donne une production de chaises et tables, pour une valeur de dollars. La solution correspond à celle que l'on a trouvée graphiquement à l'exemple .    Avec la méthode du simplexe, comme présentée à l'algorithme , il peut survenir certains problèmes. Par exemple, il n'est pas impossible que, dans les colonnes correspondant aux entrées négatives de la dernière ligne, il n'y ait pas de valeurs positives dans le haut de la matrice. On ne pourra pas effectuer le pivotage de l'étape . Cette situation se produit lorsque la région admissible n'est pas bornée. Dans ce cas, il n'y a pas de maximum possible.  Aussi, autant à l'étape qu'à l'étape , il pourrait y avoir égalité entre les valeurs considérées et un choix à faire. Dans de rares cas, cela peut amener l'algorithme à revenir sur lui-même (il devient cyclique) et rendre la recherche d'optimum impossible. Toutefois, ces cas ne surviennent presque jamais. Dans les autres cas où, en cas d'égalité, un choix est à faire, tous les choix devraient être équivalents, à peu de choses près.  La dernière chose à considérer est le cas des problèmes de minimisation. En théorie, la forme canonique transforme le problème en un problème de maximisation, mais la dernière colonne pourrait alors contenir des nombres négatifs. Cette situation ne survient normalement pas dans le cadre d'un vrai problème de maximisation, en raison du fonctionnement de l'algorithme qui s'assure en choississant le pivot que toutes les entrées de la dernière colonne demeurent positives. Donc si aucune des entrées n'était négative au départ, elles resteront positives tout le long du processus. La prochaine sous-section explique comment traiter,avec l'algorithme du simplexe, les problèmes de minimisation et le cas où un membre de droite négatif est présent dès le départ.    Problèmes de minimisation  Pour que l'algorithme du simplexe fonctionne, toutes les entrées de la dernière colonne doivent être positives afin que les variables d'écart puissent fournir une solution admissible, ces variables devant être positives. En présence de valeurs négatives dans la dernière colonne, on effectue le pivotage sur l'une des entrées négatives d'une ligne dont l'élément de la dernière colonne est aussi négatif. Si une telle entrée n'existe pas et que la seule entrée négative de la ligne se trouve dans la dernière colonne, alors le problème ne possède pas de solution (cela signifierait, par exemple, que la somme de variables positives doit être plus petite qu'un nombre négatif).  À titre d'exemple, on considère le problème de maximisation sous forme canonique suivant. La fonction à maximiser est , qui est sujette aux contraintes . La matrice initiale du simplexe est .  Dans un premier temps, on remarque qu'aucune entrée de la dernière ligne n'est négative. Par contre, la matrice possède un élément négatif dans sa dernière colonne, ce qui fait qu'elle n'est pas, en principe, une matrice initiale du simplexe. La solution initiale de cette matrice, donnée par et , n'est même pas admissible, puisque . Afin de pouvoir utiliser l'algorithme du simplexe, on commence par un pivotage sur la première ligne, qui contient l'entrée négative égale à . Dans ce cas-ci, on peut pivoter par rapport à n'importe quelle variable, puisque et sont tous deux négatifs dans la première ligne. Si l'on choisit de pivoter pour , la matrice devient . Encore une fois, il y a une entrée négative dans la colonne des , ce qui fait que l'on doit pivoter dans la ligne correspondante avant de poursuivre. L'exercice montre que l'on aurait pu éviter une étape en choisissant comme premier pivot. La seule entrée négative du bloc principal de la ligne deux étant dans la colonne , on pivote sur cette valeur. On obtient . Cette fois, les valeurs des sont toutes positives. Mais comme les coefficients sur la dernière ligne sont tous positifs (sauf pour la valeur de ), l'algorithme se termine. Le maximum de la fonction est donc . Dans un scénario concret, ce problème aurait sans doute été un problème de minimisation, le minimum recherché aurait donc été de .   Résolution du problème des nutriments par la méthode du simplexe  On considère à nouveau le problème de la minimisation du cout dans l'optimisation du régime de l'exemple . La forme canonique de ce problème a été donnée à l'exemple . On veut résoudre ce problème à nouveau, mais à l'aide de la méthode du simplexe. La matrice initiale du simplexe est .  La section du vecteur contient trois entrées négatives. La ligne de chacune de ces entrées contient plusieurs valeurs négatives. Bien qu'en théorie on peut effectuer le pivotage sur n'importe laquelle de ces valeurs, on a intérêt à en choisir une qui réduira le nombre de calculs subséquents à effectuer. Pour cela, contrairement à ce qui est normalement fait, on choisit l'entrée dont le ratio est le plus grand . Ceci éliminera en une étape de pivotage les négatifs de la section des . Dans la matrice de cet exemple, c'est l'entrée de la ligne deux et de la colonne un qui produit ce plus grand ratio. Le pivotage donne la nouvelle matrice .  Maintenant que la section du vecteur ne contient que des valeurs positives, l'algorithme du simplexe se poursuit comme dans le contexte régulier. Il reste une entrée négative dans la dernière ligne. On effectue un pivotage selon la deuxième variable. Parmi les entrées positives de la colonne, celle avec le plus petit ratio se trouve dans la troisième ligne. C'est donc par rapport à cette entrée que le pivotage s'effectue. On obtient . Une autre entrée négative est apparue dans la dernière ligne, ce qui nécessite la poursuite de l'algorithme. Le pivot se trouve dans la première ligne, à la quatrième colonne. On obtient . Cette nouvelle matrice ne contient que des entrées positives dans la section du vecteur des coefficients de la fonction objectif. L'algorithme se termine. La solution optimale est , ce qui signifie que le minimum de la fonction objectif associé au problème initial est d'environ dollars. Ce minimum est atteint lorsque la quantité de poudre achetée est environ de grammes et que la quantité de poudre est d'environ grammes. Ceci est conforme à la solution trouvée à l'aide d'arguments géométriques à l'exemple .    Si l'on a un problème de programmation linéaire et que, pour une raison quelconque, l'on considère le problème équivalent d'optimalité opposée (un problème de maximum pour un problème de minimum initial et vice-versa), on parle parfois du problème dual. Le problème initial est, quant à lui, appelé le problème primal. Le problème dual d'un problème de minimisation est toujours un problème de maximisation et le problème dual d'un problème de maximisation est toujours un problème de minimisation. La méthode du simplexe modifiée pour résoudre les problèmes de minimisation est parfois appelée la méthode du simplex dual.   La méthode du simplexe sur Sage  Sage est capable de produire le résultat de la méthode du simplexe. Il peut aussi effectuer l'algoritme, étape par étape. On sait déjà, grâce à l'exemple , que Sage est en mesure de donner la solution à l'aide de la commande optimal_solution . On peut aussi lui demander d'effectuer la méthode du simplexe, il retournera le résultat produit par l'algorithme. Il faut toujours convertir le problème à sa forme canonique, même s'il est déjà sous cette forme.   Le rendu de Sage est différent de celui proposée dans la section. Sage présente un tableau du simplexe dans lequel les variables en base, soit celles qui correspondent aux colonnes de la matrice identité dans la méthode présentée dans la section, sont isolées à gauche du tableau. Les lignes correspondantes à ces entrées sont écrites sous la forme d'une équation. Le membre de droite, composé des entrées du vecteur , se trouve plutôt à gauche et Sage inscrit l'information à l'aide des équations plutôt qu'à l'aide de la matrice. De plus, la dernière ligne, associée à la fonction objectif, a ses coefficients positifs plutôt que négatifs. Sage va toujours nommer les variables d'écart par , où est égal au nombre de variables du problème.  L'écriture comme Sage la propose a pour avantage d'être plus concise, elle permet de voir encore plus rapidement la solution. Par contre, elle a le désavantage qu'il est difficile de passer d'un tableau à l'autre sans faire d'erreurs, puisque la position des variables change souvent. La méthode présentée fait le compromis entre la facilité de lecture et l'organisation mieux structurée. Pour un ordinateur bien programmé, on peut s'épargner beaucoup de calculs en ne considérant que les éléments importants.  Afin de voir la différence entre la méthode présentée dans la section et celle qui est offerte par Sage, on regarde l'application de l'algorithme du simplexe sur le problème de l'exemple pour comparer le rendu des deux démarches.   La première étape que l'on avaite fait à l'exemple était de pivoter selon l'entrée de la première ligne et deuxième colonne. Exprimé dans le langage des variables en base et hors base, cela signifie que l'on fait entrer en base, ce qui fait sortir la première variable d'écart. On peut d'ores et déjà constater que Sage diverge de l'algorithme, car il fait plutôt entrer la variable en base, ce qui fait sortir la deuxième variable d'écart. En d'autres mots, il semble que Sage ne suive pas l'algorithme du simplexe pour sélectionner la bonne colonne. Il y a probablement une raison à cela, mais l'auteur ne la connait pas.  Comme la première étape ne concorde pas, il est difficile de comparer les démarches. Par contre, il est possible de demander à Sage d'effectuer une opération de pivotage choisie. Ainsi, on pourra comparer le cheminement des deux approches. Dans sage, la matrice initiale du simplexe est appelée initial_dictionary . On attribue à D ce tableau initial. L'option %display typeset permet de visualiser le rendu. Le tableau correspond à celui que Sage présente dans l'application de son algorithme, sans les couleurs.   Sage peut vérifier si le tableau en cours est admissible ou optimal.   On peut vérifier quelles sont les variables en base, la solution de base et la valeur de la fonction objectif.   Pour effectuer une étape de pivotage, on doit préciser quelle variable entre en base et quelle variable sort. Ceci revient à préciser la colonne et la ligne. Pour reproduire la démarche de l'exemple , on fait entrer et sortir ce que Sage appelle . On peut faire afficher le tableau afin de voir le choix effectué et de valider s'il correspond à ce que l'on veut. Par la suite, on met le tableau à jour. On affiche à nouveau pour voir l'effet du pivotage.   On peut reconnaitre dans le tableau les éléments correspondants à la matrice du simplexe une fois le premier pivotage effectué. On valide encore les informations avec Sage.   La prochaine étape avait été de pivoter selon l'entrée en position , soit la troisième ligne et la première colonne. Ceci signifie que l'on fait entrer la variable en base et que l'on rend ( pour Sage) hors base.   La solution optimale est atteinte, l'algorithme est terminé.      Un peu plus loin  D'importance historique, l'algorithme du simplexe a maintenant été surpassé par d'autres, plus efficaces, plus rapides ou pouvant résoudre des problèmes plus complexes. Par exemple, dans beaucoup de problèmes, il n'est pas pratique d'avoir une solution optimale où certaines des variables sont des fractions. On ne pourrait pas produire trois quarts de chaise, par exemple, ou cinq tables et demie. La programmation linéaire en nombres entiers et plus généralement la programmation linéaire mixte entière permettent d'ajouter ces contraintes particulières et de résoudre les problèmes associés. La complexité de ces problèmes rend leur résolution difficile. On parle parfois de problème NP-complet . Les algorithmes modernes se contentent souvent de déterminer une solution acceptable plutôt qu'optimale. L'un des problèmes d'optimisation les plus connus et étudiés est le problème du commis voyageur. La page offre une bonne introduction ainsi qu'une liste de références pour en apprendre davantage.  Bien que les applications linéaires soient toujours importantes et étudiées, de nombreux problèmes comportent des fonctions à optimiser et des contraintes qui ne sont pas linéaires. Des méthodes existent pour résoudre ces problèmes, notamment l'optimisation par les multiplicateurs de Lagrange, la descente du gradient et bien d'autres. Il existe même des algorithmes inspirés de la biologie, appelés algorithmes génétiques, qui s'inspirent de la sélection naturelle pour résoudre un problème.      Les points importants de cette section sont:  La notion de région admissible associée à un problème d'optimisation;  L'idée que la solution à un problème d'optimisation linéaire se trouve sur la frontière de la région admissible;  La forme canonique d'un problème d'optimisation linéaire;  La matrice et les vecteurs contenant l'information d'un tel problème;  La notion de variable d'écart , ajoutée à une contrainte d'inégalité afin de la transformer en contrainte d'égalité;  Les concepts de solution de base admissible, de variable en base et de variable hors base, présentés à la définition ;  La matrice initiale du simplexe et sa construction à partir des matrices et , ainsi que des vecteurs et ;  La méthode du simplexe et la méthode du simplexe dual.   De plus avec Sage, on a exploré le module InteractiveLPProblem qui permet de visualiser et résoudre des problèmes de programmation linéaire. On se réfère à l'exemple et à l'exemple pour les commandes précises et leur utilisation.      Exercices    Pour chaque problème de programmation linéaire ci-dessous, illustrer la région admissible.   Maximiser sous les contraintes et .    La région admissible   La région admissible est tracée.   Les trois contraintes d'inégalité forment un triangle, puisque chaque contrainte décrit un demi-plan dans et que les trois droites bordant les demi-plans s'intersectent deux à deux. Les premières s'intersectent lorsque . La première et la troisième s'intersectent lorsque . La deuxième et la troisième s'intersectent lorsque . La région admissible est illustrée à la figure .  Maximiser sous les contraintes et .    La région admissible   La région admissible est tracée.   Les quatre contraintes d'inégalité forment un quadrilatère. Les quatre droites bordant les demi-plans s'intersectent deux à deux. Les premières s'intersectent lorsque . La première et la troisième s'intersectent lorsque . La première et la quatrième s'intersectent lorsque . La deuxième et la troisième s'intersectent lorsque . La deuxième et la quatrième s'intersectent lorsque . La troisième et la quatrième s'intersectent lorsque . En tenant compte du sens des inégalités, on élimine l'intersection des contraintes deux et quatre ainsi que l'intersection des contraintes un et trois. La région admissible est illustrée à la figure .  Maximiser sous les contraintes et .   La région admissible   La région admissible est tracée.   Avec six contraintes qui peuvent toutes avoir une intersection lorsque prises deux à deux, il y a quinze intersections à déterminer. On se contente de donner les paires dont l'intersection fait partie de la région admissible. La première et la deuxième contrainte s'intersectent lorsque et . La première et la cinquième contrainte s'intersectent quand et . La deuxième et la troisième contrainte s'intersectent lorsque . La troisième et la quatrième contrainte s'intersectent quand . La quatrième et la sixième s'intersectent lorsque . Finalement, la cinquième et la sixième s'intersectent quand . La région admissible est illustrée à la figure . Minimiser sous les contraintes et .   La région admissible   La région admissible est tracée.     La première et la deuxième contrainte s'intersectent en , la première et la troisième s'intersectent en et la deuxième et la troisième s'intersectent en . Ces trois intersections forment un triangle qui représente la région admissible. Elle est illustrée à la figure .   Résoudre chacun des problèmes de l'exercice à l'aide de la méthode graphique. La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est .  Écrire chacun des problèmes de l'exercice sous la forme canonique. Ce problème est déjà sous la forme canonique. Ce problème est déjà sous la forme canonique. Maximiser sous les contraintes et . Comme ce problème est déjà sous la forme canonique, il n'y a rien à faire. Comme ce problème est déjà sous la forme canonique, il n'y a rien à faire. Pour qu'un problème soit sous la forme canonique, il faut que ce soit un problème de maximisation et que toutes les contraintes soient des contraintes de la forme . On a donc: maximiser sous les contraintes et . Pour qu'un problème soit sous la forme canonique, il faut que ce soit un problème de maximisation et que toutes les contraintes soient des contraintes de la forme . On a donc: maximiser sous les contraintes et .  Résoudre chacun des problèmes de l'exercice à l'aide de l'algorithme du simplexe.  On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . Puisque la dernière colonne contient une entrée négative, on doit, dans un premier temps, pivoter sur la ligne trois avant de faire l'algorithme. La seule variable négative est , on effectue ainsi le pivotage selon l'entrée en position , ce qui donne . La première entrée de la dernière colonne est, à son tour, négative. On pivote selon l'entrée en position pour la rendre positive. .  À présent, l'algorithme du simplexe, au sens usuel, peut commencer. La plus petite entrée de la dernière ligne se trouve dans la colonne trois. Le pivotage s'effectue donc par rapport à la première variable d'écart. La seule entrée positive dans cette colonne est à la ligne deux. C'est par rapport à cette ligne que s'effectuera le pivotage. On obtient . À ce stade, toutes les entrées de la dernière ligne sont positives. L'algorithme se termine, offrant comme solution optimale la valeur , atteinte lorsque et , ce qui correspond à la solution obtenue à l'exercice .  On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . Cette matrice contient deux entrées négatives dans la dernière colonne. On doit d'abord les éliminer avant de procéder avec l'algorithme du simplexe. Pour optimiser le nombre d'étapes, on choisit de pivoter dans la première ligne, puisque et dans la première colonne, seule valeur négative de la ligne. Cela rendra la valeur dans la deuxième ligne également positive. Ainsi, on a . Une nouvelle entrée négative est apparue à la ligne quatre. L'entrée de la deuxième colonne est négative et est choisie pour faire le pivotage. On a . À présent, l'algorithme du simplexe peut commencer. Il y a deux valeurs négatives dans la dernière ligne et celles-ci ont la même valeur. On choisit la valeur dans la troisième colonne. Il n'y a qu'une entrée positive dans cette colonne, le pivotage s'effectue selon l'entrée en position . On obtient , qui possède encore une entrée négative dans la dernière ligne. Dans la colonne correspondante, il y a trois valeurs positives. Celle ayant le plus petit rapport avec la colonne des , comme prescrit dans l'algorithme , est l'entrée dans la ligne deux. On pivote alors pour obtenir . L'algorithme se termine, offrant comme solution maximale la valeur , atteinte lorsque et , comme trouvé à l'exercice . On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . L'entrée de la deuxième ligne et de la dernière colonne est négative. On pivote sur l'entrée en position afin de la rendre positive. On a , qui contient à nouveau une valeur négative dans la dernière colonne, à la quatrième ligne. Un pivotage selon l'entrée la rendra positive. On obtient . Toutes les entrées de la section du vecteur sont positives. L'algorithme du simplexe peut débuter. L'entrée de la dernière ligne et de la sixième colonne est négative. Dans la colonne six, parmi les entrées positives, celle qui offre le plus petit ratio avec la colonne des se trouve dans la ligne un. Cette ligne est choisie pour pivoter. On a , qui ne contient que des entrées positives dans la dernière ligne. L'algorithme est terminé et offre comme solution la valeur maximale , atteinte lorsque . On commence par écrire la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . On applique l'algorithme du simplexe dual. D'abord, on pivote sur l'entrée en position . . La dernière ligne ne contenant que des entrées positives sous le bloc principal, l'algorithme se termine. Le problème dual de maximisation a pour solution optimale , atteinte lorsque et . La solution au problème primal est ainsi .   La figure représente différentes droites dans le premier quadrant, ainsi que quatre régions identifiées par et .   Quatre régions du premier quadrant   Les droites moins x plus trois y égal huit, x plus y égal seize, moins x plus y égal zéro et moins x plus cinq y égal huit sont illustrées dans le premier quadrant. On y voit également quatre régions appelées A,B,C et D.     On porte le regard sur les quatre régions identifiées dans la figure. On veut écrire des contraintes correspondant à chacune de ces régions. Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple , et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a quatre droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est . La troisième contrainte est , car et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car .  Dans cette partie, on tente de trouver, pour chaque sommet de la région , une fonction objectif qui a pour valeur optimale le sommet en question.  Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. S'inspirer de la droite dans la figure . Une réponse possible est . Une fonction objectif sera optimale au point si, pour une valeur , la courbe de niveau a pour seule intersection avec la région admissible le point . Ce fait ne garantit pas que l'intersection sera un maximum, mais en prenant au besoin, on aura une fonction qui satisfait au problème.  Si le vecteur des coefficients de la fonction objectif était parallèle au vecteur de l'une des contraintes qui sert à déterminer le point , alors la totalité du segment composé de l'intersection de la droite formant la contrainte et de la région admissible offrirait une solution optimale au problème. Pour trouver une fonction où le point est la seule solution optimale, on change les coefficients de la fonction objectif pour que la droite passant par et ayant ces coefficients comme vecteur normal, n'ait comme intersection avec la région admissible que le point . La figure suivante permet de trouver un tel choix. Par exemple, la fonction atteint son maximum au point et celui-ci vaut .   Fonction objectif optimale aux différents points de la région .    Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point . Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point . Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point .   Exercices Sage  Les exercices qui suivent sont conçus pour être résolus avec Sage. Des cellules vides sont disponibles pour écrire les réponses. Évidemment, il y a plusieurs manières d'arriver aux réponses.  Résoudre les problèmes de l'exercice à l'aide de la commande run_simplex_method et vérifier que la réponse obtenue est la même que celle que l'on a obtenue à l'exercice ou .     Code pour le premier problème   A=matrix([[-1,1],[1,5],[1,-7]]) b=vector([0,24,-12]) c=vector([3,2]) P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le deuxième problème   A=matrix([[-2,1],[-1,1],[2,1],[1,-3]]) b=vector([-5,-1,14,0]) c=vector([1,2]) P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le troisième problème   A=matrix([[-1,2],[3,1],[1,2],[1,-2],[1,2],[3,1]]) b=vector([3,26,12,8,21,38]) c=vector([-2,3]) #Noter l'ajout de l'option \"constraint_type\" ci-dessous, étant donnée la présence de contrainte \">=\" dans le problème P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"],constraint_type=[\"<=\",\">=\",\">=\",\"<=\",\"<=\",\"<=\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le dernier problème   A=matrix([[-2,5],[3,2],[5,-3]]) b=vector([1,27,7]) c=vector([1,1]) #Noter l'ajout de l'option \"constraint_type\" ci-dessous étant donnée la présence de contrainte \">=\" dans le problème et l'ajout de \"problem_type=\"min\"\" P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"],constraint_type=[\">=\",\"<=\",\">=\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() P.run_simplex_method()     À la sous-section , on a étudié le problème de maximisation , qui est sujette aux contraintes dont la matrice initiale du simplexe est . Dans le texte, la première étape a été de pivoter selon l'entrée de la première ligne et de la première colonne.  À l'aide de multiplications par des matrices élémentaires, résoudre le problème à nouveau en pivotant, cette fois-ci, selon l'entrée de la première ligne et de la deuxième colonne.        On définit la matrice initiale du simplexe et on multiplie la première ligne par afin de rendre le pivot égal à .   Pour éliminer les entrées de la deuxième colonne, sous le pivot, on multiplie par deux matrices élémentaires.   On remarque que les entrées de la dernière colonne à droite du bloc principal sont maintenant positives et que l'algorithme du simplexe peut commencer. L'unique entrée négative sous le bloc principal est à la première colonne. Selon l'algorithme, la deuxième ligne est choisie pour pivoter. On la divise par pour rendre le pivot égal à et l'on multiplie par les matrices élémentaires permettant d'éliminer les autres entrées de la colonne.   L'algorithe se termine, la solution optimale est , atteinte lorsque et .   Une compagnie forestière effectuant de la coupe responsable possède deux sites de coupe et trois usines de transformation. La figure suivante représente la capacité de production de chaque site et la capacité de transformation de chaque usine, en millions de PMP par année (le PMP est une unité de mesure utilisée dans l'industrie. Un PMP correspond à un pied mesure de planche équivalant à 12 pouces par 12 pouces par un 1 pouce.), ainsi que les couts associés au transport des sites aux usines, en millions de dollars par année. La compagnie souhaite minimiser ses couts reliés au transport des marchandises. Dans cette situation, on veut que tout le bois coupé soit envoyé aux différentes usines. On aura donc deux contraintes d'égalité pour représenter le bois sortant de chacun des sites de coupe.  Traduire ce système sous forme canonique et l'écrire sur Sage.   Le code suivant permet d'écrire le problème sous forme canonique. La variable représente la quantité de bois provenant du site de coupe et allant vers l'usine .  La forme canonique du problème   A = matrix([[1, 1, 1, 0, 0, 0],[-1, -1, -1, 0, 0, 0],[ 0, 0, 0, 1, 1, 1],[ 0, 0, 0, -1, -1, -1],[ 1, 0, 0, 1, 0, 0],[ 0, 1, 0, 0, 1, 0],[ 0, 0, 1, 0, 0, 1]]) b = vector([150,-150, 275,-275, 160, 140, 170,]) c = vector([2,2,3,1,3,1]) P=InteractiveLPProblem(A, b, c, [\"U11\", \"U12\",\"U13\",\"U21\",\"U22\",\"U23\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() %display typeset P    De quelle manière la compagnie devrait-elle effectuer le transport entre les sites de coupe et les usines de transformation? Quel est le cout associé à cette répartition des ressources?   Le code suivant permet de trouver la solution optimale.  La forme canonique du problème   A = matrix([[1, 1, 1, 0, 0, 0],[-1, -1, -1, 0, 0, 0],[ 0, 0, 0, 1, 1, 1],[ 0, 0, 0, -1, -1, -1],[ 1, 0, 0, 1, 0, 0],[ 0, 1, 0, 0, 1, 0],[ 0, 0, 1, 0, 0, 1]]) b = vector([150,-150, 275,-275, 160, 140, 170,]) c = vector([2,2,3,1,3,1]) P=InteractiveLPProblem(A, b, c, [\"U11\", \"U12\",\"U13\",\"U21\",\"U22\",\"U23\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() %display typeset show(P.optimal_solution()) show(c*P.optimal_solution())    On constate que, pour millions de dollars, la compagnie minimise ses couts de transport quand elle envoie du premier site de coupe millions de PMP vers l'usine et millions de PMP vers l'usine ainsi que millions de PMP à l'usine et vers l'usine provenant du deuxième site de coupe.   Une compagnie fabrique trois types de produits, de qualité inférieure, moyenne et supérieure. Un produit de qualité inférieure rapporte dollars à la compagnie, contre dollars pour un produit de qualité moyenne et dollars pour un produit de qualité supérieure. La durée de vie moyenne de ces produits est, respectivement, de et ans. Une nouvelle loi vient de proclamer que l'ensemble des produits de ce type doivent avoir une durée de vie moyenne égale à ans. Pour fabriquer le produit de qualité inférieure, les travailleurs ont besoin de minute, ils ont besoin de minutes pour un produit de qualité moyenne et, finalement, minutes sont nécessaires pour un produit de qualité supérieure. Quel est le profit maximum que la compagnie peut espérer recevoir par journée typique de travail de minutes?   Soit , le nombre de produits de qualité inférieure, moyenne et supérieure, respectivement. La durée de vie moyenne de ces produits est . Si cette moyenne doit être plus grande ou égale à , on peut réécrire la moyenne sous la forme , qui devient . Avec la contrainte de temps, le problème peut être écrit sur Sage de la manière suivante.   La solution optimale est obtenue lorsque le nombre de produits de qualité inférieure est égal à et le nombre de produits de qualité supérieure est . Aucun produit de qualité moyenne n'est produit. Dans ce cas, on obtient un revenu optimal de dollars.   Un promoteur possède un immense terrain de kilomètres carrés sur lequel il veut offrir trois types de service. Un petit commerce rapporte dollars par mois, une grande surface rapporte dollars par mois et un logement rapporte dollars par mois. Il peut y avoir petits commerces par kilomètre carré, grandes surfaces par kilomètre carré ou logements par kilomètre carré. Afin de pouvoir assurer la circulation, le stationnement et les autres infrastructure, la superficie totale des trois types de services offerts ne peut excéder % de la superficie totale du terrain. De plus, le règlement de zonage demande à ce qu'au moins logements soient construits. Finalement, des couts d'entretien sont associés à chaque type de services. Un petit commerce entraine un cout de dollars par mois, une grande surface coute dollars par mois et un logement a des couts mensuels de dollars. Le budget du promoteur est de dollars par mois.  Comment le promoteur devrait-il répartir les types de service de manière à optimiser ses revenus?  Ce problème comporte trois contraintes. On note , le nombre représentant la quantité de chacun des trois types de service, avec pour le nombre de petits commerces, pour le nombre de grandes surfaces et pour le nombre de logements.  La contrainte sur la superficie peut s'écrire sous la forme ,, la contrainte sur le nombre de logements est et la contrainte de budget pour l'entretien est . On inscrit dans Sage ces paramètres, sous la forme de la matrice et des vecteurs nécessaires à la création d'un problème de programmation linéaire.  Comme on ne peut construire une portion de commerce, on choisit de construire petits commerces, grandes surfaces ainsi que les logements demandés par la règlementation. En réalité, il serait possible d'augmenter certains types de commerces tout en satisfaisant l'ensemble des contraintes. C'est un des défauts de l'algorithme du simplexe, lorsque la solution retournée n'est pas applicable.    "
},
{
  "id": "fig-regionadmissible1",
  "level": "2",
  "url": "sec-simplexe.html#fig-regionadmissible1",
  "type": "Figure",
  "number": "7.2.1",
  "title": "",
  "body": " Région admissible de la situation décrite.   La région admissible est montrée en gris.    "
},
{
  "id": "fig-simplexe1",
  "level": "2",
  "url": "sec-simplexe.html#fig-simplexe1",
  "type": "Figure",
  "number": "7.2.2",
  "title": "",
  "body": " Optimisation sous forme dynamique   "
},
{
  "id": "ex-simplexe2",
  "level": "2",
  "url": "sec-simplexe.html#ex-simplexe2",
  "type": "Exemple",
  "number": "7.2.3",
  "title": "Optimisation de l’allocation de ressources.",
  "body": " Optimisation de l'allocation de ressources  On considère un fermier qui dispose d'une certaine superficie de terrain pour cultiver deux types de plantes : le maïs et le soja. Chaque culture nécessite un certain temps de travail et des ressources spécifiques pour atteindre un certain rendement. Le fermier dispose d'un nombre limité d'heures de travail par semaine et d'un nombre limité d'engrais.  Pour une semaine donnée, le fermier est prêt à allouer heures à la production des deux types de plantes et il possède kg d'engrais. Chaque tonne de maïs se vend $ au marché et chaque tonne de soja se vend $. De plus, la production d'une tonne de maïs nécessite kg d'engrais et heures de travail, tandis que la production d'une tonne de soja requiert kg d'engrais et heures de travail.  Quelle devrait être la quantité produite pour chacune de ces plantes afin de maximiser le profit durant cette semaine?    On pose pour représenter les tonnes de maïs et de soja qui seront produites. La fonction à maximiser est , qui est sujette aux contraintes et , qui constituent les contraintes logiques, ainsi que , qui constituent les contraintes de non-négativité. On trace la région admissible à la figure suivante.   Région admissible de la situation décrite.   La région admissible est montrée en gris.     La frontière possède quatre sommets dont l'un sera le maximum. Pour le trouver, on évalue la fonction à chacun des sommets. La plus grande valeur sera le maximum. Les sommets étant et , on trouve . Le maximum se trouve lorsque l'on produit dix tonnes de maïs et dix tonnes de soja.   "
},
{
  "id": "ex-simplexe3",
  "level": "2",
  "url": "sec-simplexe.html#ex-simplexe3",
  "type": "Exemple",
  "number": "7.2.5",
  "title": "Optimisation de la production de chaises et de tables.",
  "body": " Optimisation de la production de chaises et de tables   Une entreprise fabrique des meubles en bois. Elle produit deux types de meubles, des chaises et des tables. La production d'une chaise nécessite planches de bois, boites de vis et heure de travail, tandis que la production d'une table nécessite planches de bois, boites de vis et heures de travail. L'entreprise dispose de planches de bois, boites de vis et heures de travail pour la production. Une chaise est vendue à dollars et une table à dollars. L'entreprise cherche à maximiser son chiffre d'affaires.    On note par le nombre de chaises produites et le nombre de tables produites. La fonction à optimiser est . La figure suivante représente la région admissible provenant des contraintes .   Région admissible de la situation décrite.   La région admissible est montrée en gris.     La région admissible est formée d'un polygone à quatre sommets. En plus des axes, trois droites forment les côtés de ce polygone. On peut trouver les coordonnées des sommets qui ne se retrouvent pas sur les axes en déterminant les intersections de chaque paire de droites. Les équations des droites correspondent aux contraintes, en remplaçant l'inégalité par une égalité. On trouve et . L'image de chacun de ces points par la fonction est . On voit que la valeur maximale des ventes se trouve lorsque le nombre de chaises produites est égal à et le nombre de tables fabriquées est de .   "
},
{
  "id": "ex-simplexe4",
  "level": "2",
  "url": "sec-simplexe.html#ex-simplexe4",
  "type": "Exemple",
  "number": "7.2.7",
  "title": "Minimisation du cout de nutriments.",
  "body": " Minimisation du cout de nutriments  Pour un régime particulier, une personne a besoin d'obtenir une quantité précise de nutriments chaque semaine. Il lui est possible de se procurer la poudre , au cout de $ par grammes, et la poudre , au cout de $ par grammes. La quantité pour chacun des trois nutriments, ainsi que la quantité quotidienne requise, sont données dans la table ci-dessous.   Les nutriments nécessaires au régime.                 A (par 100g)  3  2  1    B (par 100g)  2  4  3    Besoins  28  30  20     La personne peut se permettre un budget maximal de $ par semaine pour ces produits.  On peut traduire ce problème en considérant la fonction qui est assujettie aux contraintes . La figure ci-dessous illustre la région admissible.   Région admissible de la situation décrite.   La région admissible est montrée en gris.     Les sommets de la région admissible se trouve en et . Le cout pour chacune de ces paires est de . Le cout minimal est donc, à deux décimales près, de $. À ce prix, la personne achètera, toujours à deux décimales près, grammes de la poudre et grammes de la poudre .   "
},
{
  "id": "def-proglincan",
  "level": "2",
  "url": "sec-simplexe.html#def-proglincan",
  "type": "Définition",
  "number": "7.2.10",
  "title": "Forme canonique d’un problème de programmation linéaire.",
  "body": " Forme canonique d'un problème de programmation linéaire  On considère une fonction linéaire et un ensemble de contraintes de la forme , appelées les contraintes d'inégalité , ainsi que les contraintes de non-négativité .  Si l'objectif est de maximiser la fonction sous les contraintes, on dit alors que le problème est un problème de programmation linéaire et qu'il est sous forme canonique . La fonction est appelée la fonction objectif . De manière naturelle, il en découle la réécriture suivante: . Dans cette formulation, il est sous-entendu qu'une inégalité entre deux vecteurs s'applique sur chacune des composantes correspondantes.  Un vecteur qui satisfait les deux contraintes est une solution admissible . L'ensemble des solutions admissible forme la région admissible  et le vecteur est la solution optimale .   "
},
{
  "id": "ex-simplexecanonique",
  "level": "2",
  "url": "sec-simplexe.html#ex-simplexecanonique",
  "type": "Exemple",
  "number": "7.2.11",
  "title": "Forme canonique des trois problèmes.",
  "body": " Forme canonique des trois problèmes  On considère à nouveau les problèmes des exemples , et . On veut écrire la forme canonique de chacun de ces problèmes.  On pose , , et . En tenant compte des contraintes de non-négativité, le problème est sous forme canonique. Les contraintes, de même que la fonction objectif, n'ont pas eu à être réécrites puisqu'elles étaient déjà sous la bonne forme.  On pose , , et . En tenant compte des contraintes de non-négativité, le problème est sous forme canonique. Les contraintes, de même que la fonction objectif, n'ont pas eu à être réécrites puisqu'elles étaient déjà sous la bonne forme.  Cette fois-ci, le problème, sous sa forme initiale, comprend des contraintes de la forme et porte sur la minimisation d'une fonction. On remplace la fonction par . On peut alors poser . On remplace les trois contraintes par qui, avec la contrainte sur le cout , donne le vecteur et la matrice . En tenant compte des contraintes de non-négativité, le problème est maintenant sous forme canonique.  "
},
{
  "id": "sageex-simplexegeo",
  "level": "2",
  "url": "sec-simplexe.html#sageex-simplexegeo",
  "type": "Calcul",
  "number": "7.2.12",
  "title": "Géométrie de la programmation linéaire avec Sage.",
  "body": " Géométrie de la programmation linéaire avec Sage  Sage possède un module pour explorer la programmation linéaire. On y définit les vecteurs , ainsi que la matrice . En principe, il n'est pas obligatoire d'avoir la matrice du problème sous forme canonique, car il est possible de spécifier le type d'inégalité et le type de problème (maximisation ou minimisation). Une fois les vecteurs et la matrice définis, la commande InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") permet de créer la structure du programme linéaire. Les arguments A,b,c sont, dans l'ordre, la matrice des contraintes, le vecteur de ces contraintes et le vecteur des coefficients de la fonction objectif. L'argument [\"x\", \"y\"] donne le nom aux variables. Finalement, l'argument variable_type donne le type d'inégalité, à savoir si les variables doivent être non négatives ou autre chose.  Dans un premier temps, on regarde l'exemple d'introduction qui a servi à motiver la sous-section. En ajoutant la ligne %display typeset à la cellule Sage, il est possible de visualiser l'écriture du problème à même sage.   La commande feasible_set permet de visualiser la région admissible (lorsque le nombre de variable est deux ou trois).   On peut aussi reproduire la région admissible et les contraintes à l'aide de la commande plot_feasible_set . Cette dernière offre plus de flexibilité quant au secteur qui peut être visualisé et à l'opacité de la région admissible.   On peut obtenir directement les coordonnées des sommets de la région admissible à l'aide de la commande vertices .   Ce format n'est pas pratique pour les calculs puisqu'il contient du texte. On peut extraire les vecteurs à l'aide de la fonction suivante.   S contient maintenant la liste des sommets de la région admissible. Comme la fonction objectif est encodée dans le vecteur , on peut l'évaluer en chacun des points de S à l'aide du produit scalaire.   Bien entendu, on peut aussi calculer la solution optimale avec une commande.   Sage peut aussi calculer graphiquement la solution. Il illustre quelques-unes des courbes de niveau et indique le maximum sur le graphique avec un flèche noire. Cette flèche, toujours parallèle à la courbe de niveau, indique la direction qui produit la plus grande variation de la fonction. Dans un cours de calcul de fonctions à plusieurs variables, cette direction est celle qui maximise le gradient de la fonction. Cette direction est aussi très utile dans les problèmes d'apprentissage profond.   On reprend maintenant l'exemple , qui n'était pas sous forme canonique. On montre que Sage peut quand même travailler avec cette forme, si on lui spécifie correctement le type de contraintes et de problème. On peut aussi convertir un problème à sa forme canonique.  Si l'on entre les valeurs telles qu'elles sont données dans le problème, sans égard à la forme canonique, on voit rapidement que le programme créé par Sage ne correspond pas à celui que l'on veut résoudre.   On remédie à cette situation en ajoutant un argument problem_type=\"min\" et un argument constraint_type . Ces arguments permettent à Sage de comprendre que l'on cherche le minimum de la fonction et que les trois premières contraintes sont de type .   À partir de ce programme corrigé, on peut extraire les mêmes informations que pour le problème d'introduction.   Il est possible d'obtenir la matrice, le vecteur et le vecteur d'un problème de programmation linéaire.   Finalement, la commande standard_form permet de convertir un programme existant en forme canonique. On peut en constater l'effet en regardant la matrice et les vecteurs associés au nouveau programme.   "
},
{
  "id": "def-variableecart",
  "level": "2",
  "url": "sec-simplexe.html#def-variableecart",
  "type": "Définition",
  "number": "7.2.13",
  "title": "Variable d’écart.",
  "body": "Variable d'écart  Une variable d'écart est une variable positive qui est ajoutée au plus petit côté d'une inéquation afin de la transformer en égalité.  "
},
{
  "id": "example-143",
  "level": "2",
  "url": "sec-simplexe.html#example-143",
  "type": "Exemple",
  "number": "7.2.14",
  "title": "Ajout des variables d’écart dans les contraintes.",
  "body": "Ajout des variables d'écart dans les contraintes  On reprend les données de la forme canonique des exemples , et afin de convertir les contraintes d'inégalité sous forme d'égalité.    Dans le cas des contraintes du problème , on a , qui deviennent   Pour les contraintes du problème , on a qui deviennent où .  Finalement, pour les contraintes du problème , sous sa forme canonique, on a , qui deviennent .   "
},
{
  "id": "def-solbaseadmissible",
  "level": "2",
  "url": "sec-simplexe.html#def-solbaseadmissible",
  "type": "Définition",
  "number": "7.2.15",
  "title": "Solution de base admissible.",
  "body": " Solution de base admissible   Soit , une matrice et , un vecteur. Une solution à l'équation est une solution de base admissible si toutes les valeurs de la solution sont supérieures ou égales à zéro et qu'au plus de ces valeurs sont non nulles.  Les variables non nulles d'une solution de base sont appelées les variables en base . Les variables nulles sont dites hors base .   "
},
{
  "id": "fig-simplexesolbase",
  "level": "2",
  "url": "sec-simplexe.html#fig-simplexesolbase",
  "type": "Figure",
  "number": "7.2.16",
  "title": "",
  "body": " Solution de base admissible.   "
},
{
  "id": "example-144",
  "level": "2",
  "url": "sec-simplexe.html#example-144",
  "type": "Exemple",
  "number": "7.2.17",
  "title": "Choix de la ligne pour le pivotage.",
  "body": " Choix de la ligne pour le pivotage  On considère le système , qui provient de l'ajout des variables d'écart aux données du problème . La matrice associée est . Toutes les entrées de la matrice des coefficients sont positives, ce qui signifie que l'on peut pivoter selon n'importe quelle variable. Si l'on veut pivoter selon la variable , quelle ligne doit-on choisir?   On choisit la ligne deux, puisque . Afin de voir l'effet des trois choix de ligne et pour confirmer que la ligne deux est bien celle à privilégier, on utilise Sage pour voir l'effet du pivotage pour chaque entrée de la première colonne.      On voit en effet que seule la ligne deux conserve des valeurs positives dans la partie augmentée.   "
},
{
  "id": "def-matinitsimplexe",
  "level": "2",
  "url": "sec-simplexe.html#def-matinitsimplexe",
  "type": "Définition",
  "number": "7.2.18",
  "title": "Matrice initiale du simplexe.",
  "body": " Matrice initiale du simplexe  On considère un problème de programmation linéaire à variables et contraintes, sous sa forme canonique. On note , la matrice des coefficients des contraintes, on note , la matrice identité , on note , le vecteur des membres de droite et finalement, on note , le vecteur des coefficients de la fonction objectif.  La matrice initiale du simplexe associée au problème de programmation linéaire est la matrice .  La partie de matrice contenant les matrices et est appelé le bloc principal de la matrice . Cette appellation est de l'auteur.   "
},
{
  "id": "algo-simplexe",
  "level": "2",
  "url": "sec-simplexe.html#algo-simplexe",
  "type": "Algorithme",
  "number": "7.2.19",
  "title": "La méthode du simplexe.",
  "body": " La méthode du simplexe   On considère un problème de programmation linéaire sous forme canonique et , sa matrice initiale du simplexe. Pour trouver le maximum de la fonction objectif, on suit la procédure suivante.   L'algorithme du simplexe   Regarder la dernière ligne de la matrice du simplexe. Si toutes les entrées correspondant aux variables des contraintes et aux variables d'écart sont positives, la solution est optimale et l'algorithme est terminé. En cas de présence de valeurs négatives, sélectionner la colonne de la variable dont l'entrée de la dernière ligne est la plus petite (négative) pour effectuer le pivotage.  Pour chaque entrée positive de la colonne choisie, calculer le rapport entre l'entrée de la dernière colonne et celle de la colonne choisie. La ligne où ce rapport est le plus petit est la ligne de pivot.  Effectuer le pivotage en rendant chaque élément de la colonne pivot égal à zéro, hormis ce pivot. La matrice offre maintenant une nouvelle solution de base admissible pour le problème.  Répéter les étapes ci-dessus jusqu'à ce que toutes les entrées de la dernière ligne soient positives.     "
},
{
  "id": "example-145",
  "level": "2",
  "url": "sec-simplexe.html#example-145",
  "type": "Exemple",
  "number": "7.2.21",
  "title": "L’algorithme du simplexe en action.",
  "body": " L'algorithme du simplexe en action  On considère le problème de la culture de maïs et de soja de . La matrice initiale du simplexe est . On veut appliquer l'algorithme du simplexe à cette matrice afin de trouver la solution optimale.  On applique les étapes de l'algorithme du simplexe.  La dernière ligne comporte deux valeurs négatives. La plus petite est dans la deuxième colonne, c'est donc la variable qui sera sélectionnée pour effectuer le pivotage.  Toutes les valeurs de la partie supérieure de la matrice sont positives. On calcule les rapports de l'entrée de la dernière colonne sur l'entrée de la deuxième colonne pour les lignes de la matrice. On obtient, pour la ligne un, le rapport , et pour la deuxième ligne, le rapport . On sélectionne la première ligne pour effectuer le pivotage.  Le pivot est donc l'entrée de la première ligne et de la deuxième colonne. On applique les opérations élémentaires pour modifier la matrice. On a Puisque la dernière ligne comporte toujours une entrée négative, on recommence le processus.    La seule valeur négative de la matrice est dans la première colonne. On pivote selon la variable .  Les deux valeurs du haut de la première colonne sont positives. On compare donc les ratios. Puisque , on pivote par rapport à la deuxième ligne.  On applique les opérations élémentaires pour retrouver des zéros aux lignes non pivots, l'entrée en position étant déjà égale à . On obtient . Comme la dernière ligne ne contient que des entrées positives, l'algorithme est terminé.  On lit la solution dans la matrice. La valeur maximale se trouve dans la dernière ligne et vaut . La solution est atteinte lorsque (obtenue de la deuxième ligne) et (tirée de la première ligne).  "
},
{
  "id": "ex-simplexe3-2",
  "level": "2",
  "url": "sec-simplexe.html#ex-simplexe3-2",
  "type": "Exemple",
  "number": "7.2.22",
  "title": "Optimisation de la production de chaises et de tables avec la méthode du simplexe.",
  "body": " Optimisation de la production de chaises et de tables avec la méthode du simplexe   On considère à nouveau le problème de l'exemple , dont la matrice initiale du simplexe est donnée par .  On trouve la valeur maximale de la fonction objectif à l'aide de la méthode du simplexe.    En suivant les étapes de l'algorithme du simplexe, on choisit comme premier pivot l'entrée de la deuxième colonne et de la première ligne. On obtient . Toutes les entrées de la dernière ligne étant positives, l'algorithme se termine. La solution maximale donne une production de chaises et tables, pour une valeur de dollars. La solution correspond à celle que l'on a trouvée graphiquement à l'exemple .   "
},
{
  "id": "example-147",
  "level": "2",
  "url": "sec-simplexe.html#example-147",
  "type": "Exemple",
  "number": "7.2.23",
  "title": "Résolution du problème des nutriments par la méthode du simplexe.",
  "body": " Résolution du problème des nutriments par la méthode du simplexe  On considère à nouveau le problème de la minimisation du cout dans l'optimisation du régime de l'exemple . La forme canonique de ce problème a été donnée à l'exemple . On veut résoudre ce problème à nouveau, mais à l'aide de la méthode du simplexe. La matrice initiale du simplexe est .  La section du vecteur contient trois entrées négatives. La ligne de chacune de ces entrées contient plusieurs valeurs négatives. Bien qu'en théorie on peut effectuer le pivotage sur n'importe laquelle de ces valeurs, on a intérêt à en choisir une qui réduira le nombre de calculs subséquents à effectuer. Pour cela, contrairement à ce qui est normalement fait, on choisit l'entrée dont le ratio est le plus grand . Ceci éliminera en une étape de pivotage les négatifs de la section des . Dans la matrice de cet exemple, c'est l'entrée de la ligne deux et de la colonne un qui produit ce plus grand ratio. Le pivotage donne la nouvelle matrice .  Maintenant que la section du vecteur ne contient que des valeurs positives, l'algorithme du simplexe se poursuit comme dans le contexte régulier. Il reste une entrée négative dans la dernière ligne. On effectue un pivotage selon la deuxième variable. Parmi les entrées positives de la colonne, celle avec le plus petit ratio se trouve dans la troisième ligne. C'est donc par rapport à cette entrée que le pivotage s'effectue. On obtient . Une autre entrée négative est apparue dans la dernière ligne, ce qui nécessite la poursuite de l'algorithme. Le pivot se trouve dans la première ligne, à la quatrième colonne. On obtient . Cette nouvelle matrice ne contient que des entrées positives dans la section du vecteur des coefficients de la fonction objectif. L'algorithme se termine. La solution optimale est , ce qui signifie que le minimum de la fonction objectif associé au problème initial est d'environ dollars. Ce minimum est atteint lorsque la quantité de poudre achetée est environ de grammes et que la quantité de poudre est d'environ grammes. Ceci est conforme à la solution trouvée à l'aide d'arguments géométriques à l'exemple .   "
},
{
  "id": "sageex-simplexealg",
  "level": "2",
  "url": "sec-simplexe.html#sageex-simplexealg",
  "type": "Calcul",
  "number": "7.2.24",
  "title": "La méthode du simplexe sur Sage.",
  "body": " La méthode du simplexe sur Sage  Sage est capable de produire le résultat de la méthode du simplexe. Il peut aussi effectuer l'algoritme, étape par étape. On sait déjà, grâce à l'exemple , que Sage est en mesure de donner la solution à l'aide de la commande optimal_solution . On peut aussi lui demander d'effectuer la méthode du simplexe, il retournera le résultat produit par l'algorithme. Il faut toujours convertir le problème à sa forme canonique, même s'il est déjà sous cette forme.   Le rendu de Sage est différent de celui proposée dans la section. Sage présente un tableau du simplexe dans lequel les variables en base, soit celles qui correspondent aux colonnes de la matrice identité dans la méthode présentée dans la section, sont isolées à gauche du tableau. Les lignes correspondantes à ces entrées sont écrites sous la forme d'une équation. Le membre de droite, composé des entrées du vecteur , se trouve plutôt à gauche et Sage inscrit l'information à l'aide des équations plutôt qu'à l'aide de la matrice. De plus, la dernière ligne, associée à la fonction objectif, a ses coefficients positifs plutôt que négatifs. Sage va toujours nommer les variables d'écart par , où est égal au nombre de variables du problème.  L'écriture comme Sage la propose a pour avantage d'être plus concise, elle permet de voir encore plus rapidement la solution. Par contre, elle a le désavantage qu'il est difficile de passer d'un tableau à l'autre sans faire d'erreurs, puisque la position des variables change souvent. La méthode présentée fait le compromis entre la facilité de lecture et l'organisation mieux structurée. Pour un ordinateur bien programmé, on peut s'épargner beaucoup de calculs en ne considérant que les éléments importants.  Afin de voir la différence entre la méthode présentée dans la section et celle qui est offerte par Sage, on regarde l'application de l'algorithme du simplexe sur le problème de l'exemple pour comparer le rendu des deux démarches.   La première étape que l'on avaite fait à l'exemple était de pivoter selon l'entrée de la première ligne et deuxième colonne. Exprimé dans le langage des variables en base et hors base, cela signifie que l'on fait entrer en base, ce qui fait sortir la première variable d'écart. On peut d'ores et déjà constater que Sage diverge de l'algorithme, car il fait plutôt entrer la variable en base, ce qui fait sortir la deuxième variable d'écart. En d'autres mots, il semble que Sage ne suive pas l'algorithme du simplexe pour sélectionner la bonne colonne. Il y a probablement une raison à cela, mais l'auteur ne la connait pas.  Comme la première étape ne concorde pas, il est difficile de comparer les démarches. Par contre, il est possible de demander à Sage d'effectuer une opération de pivotage choisie. Ainsi, on pourra comparer le cheminement des deux approches. Dans sage, la matrice initiale du simplexe est appelée initial_dictionary . On attribue à D ce tableau initial. L'option %display typeset permet de visualiser le rendu. Le tableau correspond à celui que Sage présente dans l'application de son algorithme, sans les couleurs.   Sage peut vérifier si le tableau en cours est admissible ou optimal.   On peut vérifier quelles sont les variables en base, la solution de base et la valeur de la fonction objectif.   Pour effectuer une étape de pivotage, on doit préciser quelle variable entre en base et quelle variable sort. Ceci revient à préciser la colonne et la ligne. Pour reproduire la démarche de l'exemple , on fait entrer et sortir ce que Sage appelle . On peut faire afficher le tableau afin de voir le choix effectué et de valider s'il correspond à ce que l'on veut. Par la suite, on met le tableau à jour. On affiche à nouveau pour voir l'effet du pivotage.   On peut reconnaitre dans le tableau les éléments correspondants à la matrice du simplexe une fois le premier pivotage effectué. On valide encore les informations avec Sage.   La prochaine étape avait été de pivoter selon l'entrée en position , soit la troisième ligne et la première colonne. Ceci signifie que l'on fait entrer la variable en base et que l'on rend ( pour Sage) hors base.   La solution optimale est atteinte, l'algorithme est terminé.   "
},
{
  "id": "exo-proglin1",
  "level": "2",
  "url": "sec-simplexe.html#exo-proglin1",
  "type": "Exercice",
  "number": "7.2.5.1",
  "title": "",
  "body": " Pour chaque problème de programmation linéaire ci-dessous, illustrer la région admissible.   Maximiser sous les contraintes et .    La région admissible   La région admissible est tracée.   Les trois contraintes d'inégalité forment un triangle, puisque chaque contrainte décrit un demi-plan dans et que les trois droites bordant les demi-plans s'intersectent deux à deux. Les premières s'intersectent lorsque . La première et la troisième s'intersectent lorsque . La deuxième et la troisième s'intersectent lorsque . La région admissible est illustrée à la figure .  Maximiser sous les contraintes et .    La région admissible   La région admissible est tracée.   Les quatre contraintes d'inégalité forment un quadrilatère. Les quatre droites bordant les demi-plans s'intersectent deux à deux. Les premières s'intersectent lorsque . La première et la troisième s'intersectent lorsque . La première et la quatrième s'intersectent lorsque . La deuxième et la troisième s'intersectent lorsque . La deuxième et la quatrième s'intersectent lorsque . La troisième et la quatrième s'intersectent lorsque . En tenant compte du sens des inégalités, on élimine l'intersection des contraintes deux et quatre ainsi que l'intersection des contraintes un et trois. La région admissible est illustrée à la figure .  Maximiser sous les contraintes et .   La région admissible   La région admissible est tracée.   Avec six contraintes qui peuvent toutes avoir une intersection lorsque prises deux à deux, il y a quinze intersections à déterminer. On se contente de donner les paires dont l'intersection fait partie de la région admissible. La première et la deuxième contrainte s'intersectent lorsque et . La première et la cinquième contrainte s'intersectent quand et . La deuxième et la troisième contrainte s'intersectent lorsque . La troisième et la quatrième contrainte s'intersectent quand . La quatrième et la sixième s'intersectent lorsque . Finalement, la cinquième et la sixième s'intersectent quand . La région admissible est illustrée à la figure . Minimiser sous les contraintes et .   La région admissible   La région admissible est tracée.     La première et la deuxième contrainte s'intersectent en , la première et la troisième s'intersectent en et la deuxième et la troisième s'intersectent en . Ces trois intersections forment un triangle qui représente la région admissible. Elle est illustrée à la figure .  "
},
{
  "id": "exo-proglin2",
  "level": "2",
  "url": "sec-simplexe.html#exo-proglin2",
  "type": "Exercice",
  "number": "7.2.5.2",
  "title": "",
  "body": "Résoudre chacun des problèmes de l'exercice à l'aide de la méthode graphique. La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut La solution optimale se trouve en et vaut Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . Il faut évaluer la fonction objective pour chacun des sommets de la région admissible. Puisque , la solution optimale est . "
},
{
  "id": "exo-proglin3",
  "level": "2",
  "url": "sec-simplexe.html#exo-proglin3",
  "type": "Exercice",
  "number": "7.2.5.3",
  "title": "",
  "body": "Écrire chacun des problèmes de l'exercice sous la forme canonique. Ce problème est déjà sous la forme canonique. Ce problème est déjà sous la forme canonique. Maximiser sous les contraintes et . Comme ce problème est déjà sous la forme canonique, il n'y a rien à faire. Comme ce problème est déjà sous la forme canonique, il n'y a rien à faire. Pour qu'un problème soit sous la forme canonique, il faut que ce soit un problème de maximisation et que toutes les contraintes soient des contraintes de la forme . On a donc: maximiser sous les contraintes et . Pour qu'un problème soit sous la forme canonique, il faut que ce soit un problème de maximisation et que toutes les contraintes soient des contraintes de la forme . On a donc: maximiser sous les contraintes et . "
},
{
  "id": "exo-proglin4",
  "level": "2",
  "url": "sec-simplexe.html#exo-proglin4",
  "type": "Exercice",
  "number": "7.2.5.4",
  "title": "",
  "body": "Résoudre chacun des problèmes de l'exercice à l'aide de l'algorithme du simplexe.  On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . Puisque la dernière colonne contient une entrée négative, on doit, dans un premier temps, pivoter sur la ligne trois avant de faire l'algorithme. La seule variable négative est , on effectue ainsi le pivotage selon l'entrée en position , ce qui donne . La première entrée de la dernière colonne est, à son tour, négative. On pivote selon l'entrée en position pour la rendre positive. .  À présent, l'algorithme du simplexe, au sens usuel, peut commencer. La plus petite entrée de la dernière ligne se trouve dans la colonne trois. Le pivotage s'effectue donc par rapport à la première variable d'écart. La seule entrée positive dans cette colonne est à la ligne deux. C'est par rapport à cette ligne que s'effectuera le pivotage. On obtient . À ce stade, toutes les entrées de la dernière ligne sont positives. L'algorithme se termine, offrant comme solution optimale la valeur , atteinte lorsque et , ce qui correspond à la solution obtenue à l'exercice .  On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . Cette matrice contient deux entrées négatives dans la dernière colonne. On doit d'abord les éliminer avant de procéder avec l'algorithme du simplexe. Pour optimiser le nombre d'étapes, on choisit de pivoter dans la première ligne, puisque et dans la première colonne, seule valeur négative de la ligne. Cela rendra la valeur dans la deuxième ligne également positive. Ainsi, on a . Une nouvelle entrée négative est apparue à la ligne quatre. L'entrée de la deuxième colonne est négative et est choisie pour faire le pivotage. On a . À présent, l'algorithme du simplexe peut commencer. Il y a deux valeurs négatives dans la dernière ligne et celles-ci ont la même valeur. On choisit la valeur dans la troisième colonne. Il n'y a qu'une entrée positive dans cette colonne, le pivotage s'effectue selon l'entrée en position . On obtient , qui possède encore une entrée négative dans la dernière ligne. Dans la colonne correspondante, il y a trois valeurs positives. Celle ayant le plus petit rapport avec la colonne des , comme prescrit dans l'algorithme , est l'entrée dans la ligne deux. On pivote alors pour obtenir . L'algorithme se termine, offrant comme solution maximale la valeur , atteinte lorsque et , comme trouvé à l'exercice . On commence par créer la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . L'entrée de la deuxième ligne et de la dernière colonne est négative. On pivote sur l'entrée en position afin de la rendre positive. On a , qui contient à nouveau une valeur négative dans la dernière colonne, à la quatrième ligne. Un pivotage selon l'entrée la rendra positive. On obtient . Toutes les entrées de la section du vecteur sont positives. L'algorithme du simplexe peut débuter. L'entrée de la dernière ligne et de la sixième colonne est négative. Dans la colonne six, parmi les entrées positives, celle qui offre le plus petit ratio avec la colonne des se trouve dans la ligne un. Cette ligne est choisie pour pivoter. On a , qui ne contient que des entrées positives dans la dernière ligne. L'algorithme est terminé et offre comme solution la valeur maximale , atteinte lorsque . On commence par écrire la matrice initiale du simplexe à l'aide de la forme canonique de l'exercice . On obtient . On applique l'algorithme du simplexe dual. D'abord, on pivote sur l'entrée en position . . La dernière ligne ne contenant que des entrées positives sous le bloc principal, l'algorithme se termine. Le problème dual de maximisation a pour solution optimale , atteinte lorsque et . La solution au problème primal est ainsi . "
},
{
  "id": "exercise-371",
  "level": "2",
  "url": "sec-simplexe.html#exercise-371",
  "type": "Exercice",
  "number": "7.2.5.5",
  "title": "",
  "body": " La figure représente différentes droites dans le premier quadrant, ainsi que quatre régions identifiées par et .   Quatre régions du premier quadrant   Les droites moins x plus trois y égal huit, x plus y égal seize, moins x plus y égal zéro et moins x plus cinq y égal huit sont illustrées dans le premier quadrant. On y voit également quatre régions appelées A,B,C et D.     On porte le regard sur les quatre régions identifiées dans la figure. On veut écrire des contraintes correspondant à chacune de ces régions. Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple , et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a quatre droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est . La troisième contrainte est , car et la dernière est , car . Écrire les contraintes d'un programme linéaire dont la région admissible correspond à la région de la figure .  avec .  Il y a trois droites délimitant la région , soit et . Pour les convertir en inégalité, on peut prendre un point dans la région, par exemple et déterminer quel sens l'inégalité doit avoir. Puisque , la première contrainte est . La deuxième, puisque , est et la dernière est , car .  Dans cette partie, on tente de trouver, pour chaque sommet de la région , une fonction objectif qui a pour valeur optimale le sommet en question.  Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. S'inspirer de la droite dans la figure . Une réponse possible est . Une fonction objectif sera optimale au point si, pour une valeur , la courbe de niveau a pour seule intersection avec la région admissible le point . Ce fait ne garantit pas que l'intersection sera un maximum, mais en prenant au besoin, on aura une fonction qui satisfait au problème.  Si le vecteur des coefficients de la fonction objectif était parallèle au vecteur de l'une des contraintes qui sert à déterminer le point , alors la totalité du segment composé de l'intersection de la droite formant la contrainte et de la région admissible offrirait une solution optimale au problème. Pour trouver une fonction où le point est la seule solution optimale, on change les coefficients de la fonction objectif pour que la droite passant par et ayant ces coefficients comme vecteur normal, n'ait comme intersection avec la région admissible que le point . La figure suivante permet de trouver un tel choix. Par exemple, la fonction atteint son maximum au point et celui-ci vaut .   Fonction objectif optimale aux différents points de la région .    Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point . Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point . Déterminer une fonction objectif pour laquelle le sommet est la seule solution maximale. En suivant la démarche de la partie précédente et en utilisant la figure , on trouve, par exemple, , qui atteint sa valeur maximale au point . "
},
{
  "id": "exercise-372",
  "level": "2",
  "url": "sec-simplexe.html#exercise-372",
  "type": "Exercice",
  "number": "7.2.5.6",
  "title": "",
  "body": "Résoudre les problèmes de l'exercice à l'aide de la commande run_simplex_method et vérifier que la réponse obtenue est la même que celle que l'on a obtenue à l'exercice ou .     Code pour le premier problème   A=matrix([[-1,1],[1,5],[1,-7]]) b=vector([0,24,-12]) c=vector([3,2]) P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le deuxième problème   A=matrix([[-2,1],[-1,1],[2,1],[1,-3]]) b=vector([-5,-1,14,0]) c=vector([1,2]) P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le troisième problème   A=matrix([[-1,2],[3,1],[1,2],[1,-2],[1,2],[3,1]]) b=vector([3,26,12,8,21,38]) c=vector([-2,3]) #Noter l'ajout de l'option \"constraint_type\" ci-dessous, étant donnée la présence de contrainte \">=\" dans le problème P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"],constraint_type=[\"<=\",\">=\",\">=\",\"<=\",\"<=\",\"<=\"], variable_type=\">=\") P=P.standard_form() P.run_simplex_method()    Code pour le dernier problème   A=matrix([[-2,5],[3,2],[5,-3]]) b=vector([1,27,7]) c=vector([1,1]) #Noter l'ajout de l'option \"constraint_type\" ci-dessous étant donnée la présence de contrainte \">=\" dans le problème et l'ajout de \"problem_type=\"min\"\" P=InteractiveLPProblem(A, b, c, [\"x\", \"y\"],constraint_type=[\">=\",\"<=\",\">=\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() P.run_simplex_method()    "
},
{
  "id": "exosage-minpivoty",
  "level": "2",
  "url": "sec-simplexe.html#exosage-minpivoty",
  "type": "Exercice",
  "number": "7.2.5.7",
  "title": "",
  "body": "À la sous-section , on a étudié le problème de maximisation , qui est sujette aux contraintes dont la matrice initiale du simplexe est . Dans le texte, la première étape a été de pivoter selon l'entrée de la première ligne et de la première colonne.  À l'aide de multiplications par des matrices élémentaires, résoudre le problème à nouveau en pivotant, cette fois-ci, selon l'entrée de la première ligne et de la deuxième colonne.        On définit la matrice initiale du simplexe et on multiplie la première ligne par afin de rendre le pivot égal à .   Pour éliminer les entrées de la deuxième colonne, sous le pivot, on multiplie par deux matrices élémentaires.   On remarque que les entrées de la dernière colonne à droite du bloc principal sont maintenant positives et que l'algorithme du simplexe peut commencer. L'unique entrée négative sous le bloc principal est à la première colonne. Selon l'algorithme, la deuxième ligne est choisie pour pivoter. On la divise par pour rendre le pivot égal à et l'on multiplie par les matrices élémentaires permettant d'éliminer les autres entrées de la colonne.   L'algorithe se termine, la solution optimale est , atteinte lorsque et .  "
},
{
  "id": "exercise-374",
  "level": "2",
  "url": "sec-simplexe.html#exercise-374",
  "type": "Exercice",
  "number": "7.2.5.8",
  "title": "",
  "body": "Une compagnie forestière effectuant de la coupe responsable possède deux sites de coupe et trois usines de transformation. La figure suivante représente la capacité de production de chaque site et la capacité de transformation de chaque usine, en millions de PMP par année (le PMP est une unité de mesure utilisée dans l'industrie. Un PMP correspond à un pied mesure de planche équivalant à 12 pouces par 12 pouces par un 1 pouce.), ainsi que les couts associés au transport des sites aux usines, en millions de dollars par année. La compagnie souhaite minimiser ses couts reliés au transport des marchandises. Dans cette situation, on veut que tout le bois coupé soit envoyé aux différentes usines. On aura donc deux contraintes d'égalité pour représenter le bois sortant de chacun des sites de coupe.  Traduire ce système sous forme canonique et l'écrire sur Sage.   Le code suivant permet d'écrire le problème sous forme canonique. La variable représente la quantité de bois provenant du site de coupe et allant vers l'usine .  La forme canonique du problème   A = matrix([[1, 1, 1, 0, 0, 0],[-1, -1, -1, 0, 0, 0],[ 0, 0, 0, 1, 1, 1],[ 0, 0, 0, -1, -1, -1],[ 1, 0, 0, 1, 0, 0],[ 0, 1, 0, 0, 1, 0],[ 0, 0, 1, 0, 0, 1]]) b = vector([150,-150, 275,-275, 160, 140, 170,]) c = vector([2,2,3,1,3,1]) P=InteractiveLPProblem(A, b, c, [\"U11\", \"U12\",\"U13\",\"U21\",\"U22\",\"U23\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() %display typeset P    De quelle manière la compagnie devrait-elle effectuer le transport entre les sites de coupe et les usines de transformation? Quel est le cout associé à cette répartition des ressources?   Le code suivant permet de trouver la solution optimale.  La forme canonique du problème   A = matrix([[1, 1, 1, 0, 0, 0],[-1, -1, -1, 0, 0, 0],[ 0, 0, 0, 1, 1, 1],[ 0, 0, 0, -1, -1, -1],[ 1, 0, 0, 1, 0, 0],[ 0, 1, 0, 0, 1, 0],[ 0, 0, 1, 0, 0, 1]]) b = vector([150,-150, 275,-275, 160, 140, 170,]) c = vector([2,2,3,1,3,1]) P=InteractiveLPProblem(A, b, c, [\"U11\", \"U12\",\"U13\",\"U21\",\"U22\",\"U23\"], variable_type=\">=\",problem_type=\"min\") P=P.standard_form() %display typeset show(P.optimal_solution()) show(c*P.optimal_solution())    On constate que, pour millions de dollars, la compagnie minimise ses couts de transport quand elle envoie du premier site de coupe millions de PMP vers l'usine et millions de PMP vers l'usine ainsi que millions de PMP à l'usine et vers l'usine provenant du deuxième site de coupe.  "
},
{
  "id": "exercise-375",
  "level": "2",
  "url": "sec-simplexe.html#exercise-375",
  "type": "Exercice",
  "number": "7.2.5.9",
  "title": "",
  "body": "Une compagnie fabrique trois types de produits, de qualité inférieure, moyenne et supérieure. Un produit de qualité inférieure rapporte dollars à la compagnie, contre dollars pour un produit de qualité moyenne et dollars pour un produit de qualité supérieure. La durée de vie moyenne de ces produits est, respectivement, de et ans. Une nouvelle loi vient de proclamer que l'ensemble des produits de ce type doivent avoir une durée de vie moyenne égale à ans. Pour fabriquer le produit de qualité inférieure, les travailleurs ont besoin de minute, ils ont besoin de minutes pour un produit de qualité moyenne et, finalement, minutes sont nécessaires pour un produit de qualité supérieure. Quel est le profit maximum que la compagnie peut espérer recevoir par journée typique de travail de minutes?   Soit , le nombre de produits de qualité inférieure, moyenne et supérieure, respectivement. La durée de vie moyenne de ces produits est . Si cette moyenne doit être plus grande ou égale à , on peut réécrire la moyenne sous la forme , qui devient . Avec la contrainte de temps, le problème peut être écrit sur Sage de la manière suivante.   La solution optimale est obtenue lorsque le nombre de produits de qualité inférieure est égal à et le nombre de produits de qualité supérieure est . Aucun produit de qualité moyenne n'est produit. Dans ce cas, on obtient un revenu optimal de dollars.  "
},
{
  "id": "exercise-376",
  "level": "2",
  "url": "sec-simplexe.html#exercise-376",
  "type": "Exercice",
  "number": "7.2.5.10",
  "title": "",
  "body": "Un promoteur possède un immense terrain de kilomètres carrés sur lequel il veut offrir trois types de service. Un petit commerce rapporte dollars par mois, une grande surface rapporte dollars par mois et un logement rapporte dollars par mois. Il peut y avoir petits commerces par kilomètre carré, grandes surfaces par kilomètre carré ou logements par kilomètre carré. Afin de pouvoir assurer la circulation, le stationnement et les autres infrastructure, la superficie totale des trois types de services offerts ne peut excéder % de la superficie totale du terrain. De plus, le règlement de zonage demande à ce qu'au moins logements soient construits. Finalement, des couts d'entretien sont associés à chaque type de services. Un petit commerce entraine un cout de dollars par mois, une grande surface coute dollars par mois et un logement a des couts mensuels de dollars. Le budget du promoteur est de dollars par mois.  Comment le promoteur devrait-il répartir les types de service de manière à optimiser ses revenus?  Ce problème comporte trois contraintes. On note , le nombre représentant la quantité de chacun des trois types de service, avec pour le nombre de petits commerces, pour le nombre de grandes surfaces et pour le nombre de logements.  La contrainte sur la superficie peut s'écrire sous la forme ,, la contrainte sur le nombre de logements est et la contrainte de budget pour l'entretien est . On inscrit dans Sage ces paramètres, sous la forme de la matrice et des vecteurs nécessaires à la création d'un problème de programmation linéaire.  Comme on ne peut construire une portion de commerce, on choisit de construire petits commerces, grandes surfaces ainsi que les logements demandés par la règlementation. En réalité, il serait possible d'augmenter certains types de commerces tout en satisfaisant l'ensemble des contraintes. C'est un des défauts de l'algorithme du simplexe, lorsque la solution retournée n'est pas applicable. "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
